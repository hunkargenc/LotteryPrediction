{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9783bbda-5280-4e57-aa37-39098b97f6e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lottery Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6c80b-e969-437a-a67f-c8504bfbad48",
   "metadata": {},
   "source": [
    "## Get Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "561d805f-4d01-4014-ba09-faa171dba6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4dd65728-ca18-431c-9f99-54e03f41aa0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Lottery:\n",
    "\n",
    "    PIYANGO = \"millipiyango\"\n",
    "    SAYISAL = \"sayisal-loto\"\n",
    "    SANS_TOPU = \"sanstopu\"\n",
    "    ON_NUMARA = \"onnumara\"\n",
    "    SUPER_LOTO = \"superloto\"\n",
    "\n",
    "    GAME_LIST = [PIYANGO, SAYISAL, SANS_TOPU, ON_NUMARA, SUPER_LOTO]\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n",
    "        \"Referer\": \"https://www.millipiyangoonline.com/cekilis-sonuclari/milli-piyango\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    }\n",
    "\n",
    "    URL = \"https://www.millipiyangoonline.com/sisalsans/result.{}.{}.{}.json\"\n",
    "\n",
    "    @staticmethod\n",
    "    def process_response(resp, error_message: str) -> dict:\n",
    "        if resp.ok and resp.status_code == 200:\n",
    "            try:\n",
    "                data = resp.json()\n",
    "            except json.decoder.JSONDecodeError as jsDecodeError:\n",
    "                # TODO: add proper exception handling\n",
    "                data = resp.content.decode(\"utf-8-sig\").encode(\"utf-8\")\n",
    "                data = json.loads(data)\n",
    "            return data\n",
    "        else:\n",
    "            return {\n",
    "                'error': error_message,\n",
    "                'response': {\n",
    "                    'code': resp.status_code,\n",
    "                    'url': resp.url\n",
    "                }\n",
    "            }\n",
    "\n",
    "    def get_result(self, game: str, month: str, year: str) -> dict:\n",
    "        if game not in self.GAME_LIST:\n",
    "            return {\n",
    "                'error': f\"Oyun adı parametresi {GAME_LIST} içerisinden bir değer olmalıdır.\",\n",
    "                'request': {'oyun_adi': game}\n",
    "            }\n",
    "\n",
    "        url = self.URL.format(game, month, year)\n",
    "        response = requests.get(url=url, headers=self.headers)\n",
    "\n",
    "        return self.process_response(response, \"Bir sorun oluştu.\")\n",
    "\n",
    "    def run_process(self) -> None:\n",
    "        df = pd.DataFrame()\n",
    "        months = [str(i) for i in range(1, 13)]\n",
    "        years = [str(i) for i in range(2020, 2024)]\n",
    "        for year in years:\n",
    "            for month in months:\n",
    "                res = self.get_result(self.PIYANGO, month, year)\n",
    "                if len(res) > 0:\n",
    "                    if len(res[0]['drawNumbers']) > 0:\n",
    "                        #print(res)\n",
    "                        #amorti1 = [i['amortiNumber1'] for i in res]\n",
    "                        res_df = pd.DataFrame({'Date': [i['drawDate'] for i in res], \n",
    "                                               'A': [i['drawNumbers'][0] for i in res], \n",
    "                                               'B': [i['drawNumbers'][1] for i in res], \n",
    "                                               'C': [i['drawNumbers'][2] for i in res], \n",
    "                                               'D': [i['drawNumbers'][3] for i in res], \n",
    "                                               'E': [i['drawNumbers'][4] for i in res], \n",
    "                                               'F': [i['drawNumbers'][5] for i in res], \n",
    "                                               'G': [int(i['drawNumbers'][6]) if 'drawNumbers' in i and len(i['drawNumbers']) > 6 else None for i in res],\n",
    "                                               'A1': [int(i['amortiNumber1']) for i in res], \n",
    "                                               'A2': [int(i['amortiNumber2']) for i in res]})\n",
    "                        df = pd.concat([df, res_df], ignore_index=True)\n",
    "        return df\n",
    "        #print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3f688fc9-8bb9-4afb-9bff-589627f52a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = Lottery().run_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3edfe8-22f6-4478-a5e0-f5f253b0afcb",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9388f836-057d-4f89-a449-22c784e10b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/19/2020</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/30/2020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/19/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  A  B  C  D  E  F     G  A1  A2\n",
       "0  08/09/2020  2  9  0  6  1  1  None   1   6\n",
       "1  08/19/2020  5  6  2  2  1  9  None   4   9\n",
       "2  08/30/2020  4  0  2  5  9  8  None   2   7\n",
       "3  09/09/2020  6  1  7  3  6  6  None   0   5\n",
       "4  09/19/2020  1  6  5  7  5  5  None   2   6"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8a05df2c-25fa-49d0-8f0a-a2da92a38668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>09/29/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>10/09/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10/29/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>11/09/2023</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>12/31/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  A  B  C  D  E  F     G  A1  A2\n",
       "72  09/29/2023  2  9  4  7  8  2  None   4   7\n",
       "73  10/09/2023  3  3  5  3  9  6   NaN   2   9\n",
       "74  10/29/2023  1  0  4  6  1  6   5.0   0   7\n",
       "75  11/09/2023  0  6  5  9  0  4  None   3   7\n",
       "76  12/31/2023  3  5  5  0  0  5     4   2   7"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9873b-2ba1-4cf7-a5ab-f582018ae288",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "39d096ac-40ea-45e0-8729-a0858ae6ac43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Date'][66:76], df['A'][66:76], label='A')\n",
    "plt.plot(df['Date'][66:76], df['B'][66:76], label='B')\n",
    "plt.plot(df['Date'][66:76], df['C'][66:76], label='C')\n",
    "plt.plot(df['Date'][66:76], df['D'][66:76], label='D')\n",
    "plt.plot(df['Date'][66:76], df['E'][66:76], label='E')\n",
    "plt.plot(df['Date'][66:76], df['F'][66:76], label='F')\n",
    "#plt.plot(df['Date'], df['G'], label='G')\n",
    "plt.plot(df['Date'][66:76], df['A1'][66:76], label='A1')\n",
    "plt.plot(df['Date'][66:76], df['A2'][66:76], label='A2')\n",
    "\n",
    "plt.title('Changes')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d7c3a-244a-40d5-a845-f82195bf76c5",
   "metadata": {},
   "source": [
    "**There is a random distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "429bc511-0765-48c7-a7b7-5dfa381970a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "27e1d84a-25b0-450c-b87c-63b71b744a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77 entries, 0 to 76\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    77 non-null     object\n",
      " 1   A       77 non-null     int64 \n",
      " 2   B       77 non-null     int64 \n",
      " 3   C       77 non-null     int64 \n",
      " 4   D       77 non-null     int64 \n",
      " 5   E       77 non-null     int64 \n",
      " 6   F       77 non-null     int64 \n",
      " 7   G       18 non-null     object\n",
      " 8   A1      77 non-null     int64 \n",
      " 9   A2      77 non-null     int64 \n",
      "dtypes: int64(8), object(2)\n",
      "memory usage: 6.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8ec073be-1738-444d-a080-99752d785205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.740260</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>4.051948</td>\n",
       "      <td>4.389610</td>\n",
       "      <td>4.467532</td>\n",
       "      <td>4.922078</td>\n",
       "      <td>1.961039</td>\n",
       "      <td>6.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.607694</td>\n",
       "      <td>3.051786</td>\n",
       "      <td>2.595016</td>\n",
       "      <td>2.570868</td>\n",
       "      <td>2.886376</td>\n",
       "      <td>2.713350</td>\n",
       "      <td>1.454951</td>\n",
       "      <td>1.235856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A          B          C          D          E          F  \\\n",
       "count  77.000000  77.000000  77.000000  77.000000  77.000000  77.000000   \n",
       "mean    2.740260   4.636364   4.051948   4.389610   4.467532   4.922078   \n",
       "std     2.607694   3.051786   2.595016   2.570868   2.886376   2.713350   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     1.000000   2.000000   2.000000   3.000000   2.000000   3.000000   \n",
       "50%     2.000000   5.000000   4.000000   4.000000   4.000000   5.000000   \n",
       "75%     5.000000   7.000000   6.000000   6.000000   7.000000   7.000000   \n",
       "max     9.000000   9.000000   9.000000   9.000000   9.000000   9.000000   \n",
       "\n",
       "              A1         A2  \n",
       "count  77.000000  77.000000  \n",
       "mean    1.961039   6.805195  \n",
       "std     1.454951   1.235856  \n",
       "min     0.000000   5.000000  \n",
       "25%     1.000000   6.000000  \n",
       "50%     2.000000   7.000000  \n",
       "75%     3.000000   8.000000  \n",
       "max     4.000000   9.000000  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "41815026-a135-4a4e-9821-1f7aa94eb9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  F  A1  A2\n",
       "0  2  9  0  6  1  1   1   6\n",
       "1  5  6  2  2  1  9   4   9\n",
       "2  4  0  2  5  9  8   2   7\n",
       "3  6  1  7  3  6  6   0   5\n",
       "4  1  6  5  7  5  5   2   6"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data.drop(['Date', 'G'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9d430d9d-8c45-4195-9b3f-53bd9186a2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(data.values)\n",
    "transformed_dataset = scaler.transform(data.values)\n",
    "transformed_df = pd.DataFrame(data=transformed_dataset, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0cf8a710-6940-4518-9aea-5a5a51b14e18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.285737</td>\n",
       "      <td>1.439239</td>\n",
       "      <td>-1.571674</td>\n",
       "      <td>0.630507</td>\n",
       "      <td>-1.209222</td>\n",
       "      <td>-1.454953</td>\n",
       "      <td>-0.664861</td>\n",
       "      <td>-0.655800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.872249</td>\n",
       "      <td>0.449762</td>\n",
       "      <td>-0.795912</td>\n",
       "      <td>-0.935591</td>\n",
       "      <td>-1.209222</td>\n",
       "      <td>1.512766</td>\n",
       "      <td>1.410584</td>\n",
       "      <td>1.787584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.486254</td>\n",
       "      <td>-1.529192</td>\n",
       "      <td>-0.795912</td>\n",
       "      <td>0.238982</td>\n",
       "      <td>1.580594</td>\n",
       "      <td>1.141801</td>\n",
       "      <td>0.026954</td>\n",
       "      <td>0.158661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.258244</td>\n",
       "      <td>-1.199366</td>\n",
       "      <td>1.143493</td>\n",
       "      <td>-0.544066</td>\n",
       "      <td>0.534413</td>\n",
       "      <td>0.399871</td>\n",
       "      <td>-1.356677</td>\n",
       "      <td>-1.470262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.671732</td>\n",
       "      <td>0.449762</td>\n",
       "      <td>0.367731</td>\n",
       "      <td>1.022031</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>0.028906</td>\n",
       "      <td>0.026954</td>\n",
       "      <td>-0.655800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.285737  1.439239 -1.571674  0.630507 -1.209222 -1.454953 -0.664861   \n",
       "1  0.872249  0.449762 -0.795912 -0.935591 -1.209222  1.512766  1.410584   \n",
       "2  0.486254 -1.529192 -0.795912  0.238982  1.580594  1.141801  0.026954   \n",
       "3  1.258244 -1.199366  1.143493 -0.544066  0.534413  0.399871 -1.356677   \n",
       "4 -0.671732  0.449762  0.367731  1.022031  0.185686  0.028906  0.026954   \n",
       "\n",
       "          7  \n",
       "0 -0.655800  \n",
       "1  1.787584  \n",
       "2  0.158661  \n",
       "3 -1.470262  \n",
       "4 -0.655800  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d839bc06-5862-4fe0-9b8b-2caa3c3d407b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All our games\n",
    "number_of_rows = data.values.shape[0]\n",
    "number_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "70b714ee-1371-4d81-93f8-5403af06c906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balls counts\n",
    "number_of_features = data.values.shape[1]\n",
    "number_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1cc467c5-f587-4103-93ce-26708ded5989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_length = 7\n",
    "window_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "27a43058-1a63-40ee-bdb2-bdfca24aa800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.empty([ number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
    "y = np.empty([ number_of_rows - window_length, number_of_features], dtype=float)\n",
    "for i in range(0, number_of_rows-window_length):\n",
    "    X[i] = transformed_df.iloc[i : i+window_length, 0 : number_of_features]\n",
    "    y[i] = transformed_df.iloc[i+window_length : i+window_length+1, 0 : number_of_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c804654e-4e0a-4ff1-9727-f427ef691bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 7, 8)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cd533c63-184e-49fe-9810-4a4e35a77722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 8)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c775013c-0ddc-49a6-ad4a-356c7fc3032d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28573672,  1.43923946, -1.57167374,  0.63050666, -1.20922226,\n",
       "        -1.4549529 , -0.6648614 , -0.65580015],\n",
       "       [ 0.87224894,  0.44976233, -0.7959117 , -0.93559053, -1.20922226,\n",
       "         1.5127656 ,  1.41058433,  1.78758429],\n",
       "       [ 0.48625372, -1.52919193, -0.7959117 ,  0.23898236,  1.5805939 ,\n",
       "         1.14180079,  0.02695384,  0.15866133],\n",
       "       [ 1.25824416, -1.19936622,  1.14349339, -0.54406623,  0.53441284,\n",
       "         0.39987116, -1.35667665, -1.47026164],\n",
       "       [-0.67173194,  0.44976233,  0.36773136,  1.02203096,  0.18568582,\n",
       "         0.02890635,  0.02695384, -0.65580015],\n",
       "       [ 1.25824416, -1.52919193, -1.57167374, -0.93559053, -0.86049524,\n",
       "         1.14180079,  0.02695384, -0.65580015],\n",
       "       [-1.05772716,  0.44976233,  0.36773136,  0.63050666, -1.55794928,\n",
       "         1.14180079, -0.6648614 , -0.65580015]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "310bfaf2-1183-412a-802f-5d9e3242079c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67173194,  1.10941375,  0.75561237,  0.23898236, -0.51176822,\n",
       "        1.5127656 , -0.6648614 , -1.47026164])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "15d614a8-d4a9-4b3f-a2c5-c716408705fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87224894,  0.44976233, -0.7959117 , -0.93559053, -1.20922226,\n",
       "         1.5127656 ,  1.41058433,  1.78758429],\n",
       "       [ 0.48625372, -1.52919193, -0.7959117 ,  0.23898236,  1.5805939 ,\n",
       "         1.14180079,  0.02695384,  0.15866133],\n",
       "       [ 1.25824416, -1.19936622,  1.14349339, -0.54406623,  0.53441284,\n",
       "         0.39987116, -1.35667665, -1.47026164],\n",
       "       [-0.67173194,  0.44976233,  0.36773136,  1.02203096,  0.18568582,\n",
       "         0.02890635,  0.02695384, -0.65580015],\n",
       "       [ 1.25824416, -1.52919193, -1.57167374, -0.93559053, -0.86049524,\n",
       "         1.14180079,  0.02695384, -0.65580015],\n",
       "       [-1.05772716,  0.44976233,  0.36773136,  0.63050666, -1.55794928,\n",
       "         1.14180079, -0.6648614 , -0.65580015],\n",
       "       [-0.67173194,  1.10941375,  0.75561237,  0.23898236, -0.51176822,\n",
       "         1.5127656 , -0.6648614 , -1.47026164]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4c16b024-a694-4f6c-b19c-4e4ba5e56abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67173194,  0.44976233,  1.14349339,  1.41355526,  1.5805939 ,\n",
       "        0.02890635, -1.35667665, -0.65580015])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4daf74-ee3b-43d2-9a53-b70dca6c7bc9",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d831a5a9-af32-473c-9a5c-66afd7a6d533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (56, 7, 8)\n",
      "y_train shape: (56, 8)\n",
      "X_val shape: (14, 7, 8)\n",
      "y_val shape: (14, 8)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X and y are your features and labels, respectively\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# If you have already created X and y, you can use the train_test_split function to split them\n",
    "# The test_size parameter controls the ratio of the validation set (0.2 means 20% validation, 80% training)\n",
    "\n",
    "# Print the shapes to verify the split\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86d9cf-6585-4126-9561-db6b7ddbbd8c",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "eb1514ad-0064-4c8e-b9bd-4504627dbc28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_and_train_model(learning_rate, dropout_rate, lstm_unit, window_length, epoch, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(lstm_unit, input_shape=(window_length, number_of_features), return_sequences=True)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Bidirectional(LSTM(lstm_unit, input_shape=(window_length, number_of_features), return_sequences=True)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Bidirectional(LSTM(lstm_unit, input_shape=(window_length, number_of_features), return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(lstm_unit, input_shape=(window_length, number_of_features), return_sequences=False)))\n",
    "    model.add(Dense(59))\n",
    "    model.add(Dense(number_of_features))\n",
    "    \n",
    "    # Compile the model (replace optimizer and loss with your specific settings)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss ='mse', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model (replace X_train, y_train, validation_data with your specific data)\n",
    "    model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Evaluate the model on the validation set (replace X_val, y_val with your specific data)\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    \n",
    "    return score  # Return the metric you want to optimize (e.g., validation loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "73576a0e-1de2-49ff-93ec-c4d3217cfc2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9863 - accuracy: 0.0714 - val_loss: 1.0655 - val_accuracy: 0.2143\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9830 - accuracy: 0.0893 - val_loss: 1.0655 - val_accuracy: 0.0714\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.9811 - accuracy: 0.0536 - val_loss: 1.0655 - val_accuracy: 0.0714\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.9791 - accuracy: 0.1786 - val_loss: 1.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9767 - accuracy: 0.1964 - val_loss: 1.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9728 - accuracy: 0.2321 - val_loss: 1.0657 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9718 - accuracy: 0.2679 - val_loss: 1.0658 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.9710 - accuracy: 0.2679 - val_loss: 1.0660 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9676 - accuracy: 0.2679 - val_loss: 1.0661 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9654 - accuracy: 0.2857 - val_loss: 1.0662 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9627 - accuracy: 0.3214 - val_loss: 1.0664 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9604 - accuracy: 0.3214 - val_loss: 1.0665 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9588 - accuracy: 0.3036 - val_loss: 1.0666 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9560 - accuracy: 0.3393 - val_loss: 1.0668 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9539 - accuracy: 0.3393 - val_loss: 1.0669 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9509 - accuracy: 0.3929 - val_loss: 1.0671 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9496 - accuracy: 0.3571 - val_loss: 1.0672 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9454 - accuracy: 0.3036 - val_loss: 1.0674 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9421 - accuracy: 0.3571 - val_loss: 1.0675 - val_accuracy: 0.2143\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9398 - accuracy: 0.3393 - val_loss: 1.0676 - val_accuracy: 0.2143\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9371 - accuracy: 0.3750 - val_loss: 1.0678 - val_accuracy: 0.2143\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9355 - accuracy: 0.3750 - val_loss: 1.0679 - val_accuracy: 0.2143\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9307 - accuracy: 0.3929 - val_loss: 1.0681 - val_accuracy: 0.2143\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9281 - accuracy: 0.4107 - val_loss: 1.0682 - val_accuracy: 0.2143\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9247 - accuracy: 0.3393 - val_loss: 1.0684 - val_accuracy: 0.2143\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9210 - accuracy: 0.3750 - val_loss: 1.0685 - val_accuracy: 0.2143\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9177 - accuracy: 0.3750 - val_loss: 1.0687 - val_accuracy: 0.2857\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9142 - accuracy: 0.3571 - val_loss: 1.0690 - val_accuracy: 0.2857\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9101 - accuracy: 0.3750 - val_loss: 1.0692 - val_accuracy: 0.2857\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9054 - accuracy: 0.3750 - val_loss: 1.0695 - val_accuracy: 0.2857\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9036 - accuracy: 0.3750 - val_loss: 1.0698 - val_accuracy: 0.2857\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8988 - accuracy: 0.4107 - val_loss: 1.0703 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0703 - accuracy: 0.2143\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=32, batch_size=100, Scores: [1.0702568292617798, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.0702568292617798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9868 - accuracy: 0.1071 - val_loss: 1.0668 - val_accuracy: 0.2857\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9853 - accuracy: 0.1429 - val_loss: 1.0671 - val_accuracy: 0.2857\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9824 - accuracy: 0.1964 - val_loss: 1.0673 - val_accuracy: 0.3571\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9797 - accuracy: 0.2321 - val_loss: 1.0675 - val_accuracy: 0.2857\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9785 - accuracy: 0.2679 - val_loss: 1.0677 - val_accuracy: 0.2143\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9748 - accuracy: 0.3571 - val_loss: 1.0680 - val_accuracy: 0.2143\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9724 - accuracy: 0.3750 - val_loss: 1.0683 - val_accuracy: 0.2143\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9717 - accuracy: 0.3393 - val_loss: 1.0685 - val_accuracy: 0.2143\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9676 - accuracy: 0.3750 - val_loss: 1.0688 - val_accuracy: 0.2143\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9661 - accuracy: 0.3393 - val_loss: 1.0691 - val_accuracy: 0.2143\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9642 - accuracy: 0.3393 - val_loss: 1.0693 - val_accuracy: 0.2143\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9618 - accuracy: 0.3929 - val_loss: 1.0696 - val_accuracy: 0.2143\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9601 - accuracy: 0.3929 - val_loss: 1.0699 - val_accuracy: 0.2143\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9577 - accuracy: 0.3750 - val_loss: 1.0701 - val_accuracy: 0.2143\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9546 - accuracy: 0.3393 - val_loss: 1.0704 - val_accuracy: 0.2143\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9528 - accuracy: 0.3214 - val_loss: 1.0707 - val_accuracy: 0.2143\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9511 - accuracy: 0.3214 - val_loss: 1.0709 - val_accuracy: 0.2143\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9470 - accuracy: 0.3393 - val_loss: 1.0712 - val_accuracy: 0.2143\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9456 - accuracy: 0.3214 - val_loss: 1.0714 - val_accuracy: 0.2143\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9431 - accuracy: 0.3036 - val_loss: 1.0717 - val_accuracy: 0.2143\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9398 - accuracy: 0.3214 - val_loss: 1.0719 - val_accuracy: 0.2143\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9362 - accuracy: 0.3214 - val_loss: 1.0721 - val_accuracy: 0.2143\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9346 - accuracy: 0.3214 - val_loss: 1.0724 - val_accuracy: 0.2143\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9318 - accuracy: 0.3214 - val_loss: 1.0726 - val_accuracy: 0.2143\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9279 - accuracy: 0.3214 - val_loss: 1.0729 - val_accuracy: 0.2143\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9249 - accuracy: 0.3214 - val_loss: 1.0731 - val_accuracy: 0.2143\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9220 - accuracy: 0.3036 - val_loss: 1.0734 - val_accuracy: 0.2143\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9181 - accuracy: 0.3036 - val_loss: 1.0738 - val_accuracy: 0.2143\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9147 - accuracy: 0.3214 - val_loss: 1.0741 - val_accuracy: 0.2143\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9122 - accuracy: 0.2857 - val_loss: 1.0745 - val_accuracy: 0.2143\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9095 - accuracy: 0.3214 - val_loss: 1.0750 - val_accuracy: 0.2143\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9063 - accuracy: 0.2857 - val_loss: 1.0755 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0755 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=32, batch_size=300, Scores: [1.0755412578582764, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.0755412578582764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9816 - accuracy: 0.1964 - val_loss: 1.0726 - val_accuracy: 0.2143\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9802 - accuracy: 0.2321 - val_loss: 1.0734 - val_accuracy: 0.2143\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9784 - accuracy: 0.1964 - val_loss: 1.0743 - val_accuracy: 0.2143\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9755 - accuracy: 0.2857 - val_loss: 1.0751 - val_accuracy: 0.2143\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9743 - accuracy: 0.2321 - val_loss: 1.0761 - val_accuracy: 0.2143\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9723 - accuracy: 0.3036 - val_loss: 1.0770 - val_accuracy: 0.2143\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9704 - accuracy: 0.2679 - val_loss: 1.0779 - val_accuracy: 0.2857\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9676 - accuracy: 0.3036 - val_loss: 1.0789 - val_accuracy: 0.2857\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9661 - accuracy: 0.3036 - val_loss: 1.0799 - val_accuracy: 0.2857\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9634 - accuracy: 0.3393 - val_loss: 1.0809 - val_accuracy: 0.2857\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9621 - accuracy: 0.2857 - val_loss: 1.0819 - val_accuracy: 0.2857\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9597 - accuracy: 0.3214 - val_loss: 1.0830 - val_accuracy: 0.2857\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9559 - accuracy: 0.3036 - val_loss: 1.0841 - val_accuracy: 0.2857\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9545 - accuracy: 0.2857 - val_loss: 1.0852 - val_accuracy: 0.2857\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9513 - accuracy: 0.3214 - val_loss: 1.0864 - val_accuracy: 0.2857\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9499 - accuracy: 0.3036 - val_loss: 1.0877 - val_accuracy: 0.2857\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9485 - accuracy: 0.2857 - val_loss: 1.0890 - val_accuracy: 0.2857\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9454 - accuracy: 0.2857 - val_loss: 1.0903 - val_accuracy: 0.2857\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9437 - accuracy: 0.2857 - val_loss: 1.0916 - val_accuracy: 0.2857\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9413 - accuracy: 0.3036 - val_loss: 1.0930 - val_accuracy: 0.2857\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9383 - accuracy: 0.3036 - val_loss: 1.0945 - val_accuracy: 0.2857\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9350 - accuracy: 0.3214 - val_loss: 1.0960 - val_accuracy: 0.2857\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9320 - accuracy: 0.2857 - val_loss: 1.0975 - val_accuracy: 0.2857\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9300 - accuracy: 0.3393 - val_loss: 1.0991 - val_accuracy: 0.2857\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9264 - accuracy: 0.3214 - val_loss: 1.1008 - val_accuracy: 0.2857\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9248 - accuracy: 0.3036 - val_loss: 1.1025 - val_accuracy: 0.2857\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9203 - accuracy: 0.3214 - val_loss: 1.1042 - val_accuracy: 0.2857\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9171 - accuracy: 0.3036 - val_loss: 1.1060 - val_accuracy: 0.2857\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9147 - accuracy: 0.3214 - val_loss: 1.1078 - val_accuracy: 0.2857\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9114 - accuracy: 0.3214 - val_loss: 1.1097 - val_accuracy: 0.2857\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9094 - accuracy: 0.3393 - val_loss: 1.1116 - val_accuracy: 0.2857\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9054 - accuracy: 0.3393 - val_loss: 1.1136 - val_accuracy: 0.2857\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1136 - accuracy: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=32, batch_size=400, Scores: [1.113624930381775, 0.2857142984867096]\n",
      "Accuracy on validation set: 0.2857142984867096\n",
      "Loss on validation set: 1.113624930381775\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9858 - accuracy: 0.0714 - val_loss: 1.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9821 - accuracy: 0.1250 - val_loss: 1.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9818 - accuracy: 0.1071 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9780 - accuracy: 0.0893 - val_loss: 1.0767 - val_accuracy: 0.1429\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9769 - accuracy: 0.1786 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9738 - accuracy: 0.1786 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9721 - accuracy: 0.1964 - val_loss: 1.0785 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9685 - accuracy: 0.2143 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9671 - accuracy: 0.2857 - val_loss: 1.0798 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9650 - accuracy: 0.2857 - val_loss: 1.0805 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9629 - accuracy: 0.2679 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9614 - accuracy: 0.1786 - val_loss: 1.0819 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9588 - accuracy: 0.2143 - val_loss: 1.0826 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.9561 - accuracy: 0.2857 - val_loss: 1.0833 - val_accuracy: 0.0714\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9542 - accuracy: 0.3214 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9523 - accuracy: 0.3036 - val_loss: 1.0848 - val_accuracy: 0.0714\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9492 - accuracy: 0.2857 - val_loss: 1.0856 - val_accuracy: 0.0714\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9464 - accuracy: 0.3214 - val_loss: 1.0864 - val_accuracy: 0.0714\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9433 - accuracy: 0.3214 - val_loss: 1.0872 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9423 - accuracy: 0.3036 - val_loss: 1.0881 - val_accuracy: 0.0714\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9384 - accuracy: 0.2857 - val_loss: 1.0890 - val_accuracy: 0.0714\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9354 - accuracy: 0.3214 - val_loss: 1.0899 - val_accuracy: 0.0714\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9326 - accuracy: 0.3214 - val_loss: 1.0909 - val_accuracy: 0.0714\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9294 - accuracy: 0.3214 - val_loss: 1.0919 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9268 - accuracy: 0.3393 - val_loss: 1.0929 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9229 - accuracy: 0.3393 - val_loss: 1.0940 - val_accuracy: 0.0714\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9208 - accuracy: 0.3393 - val_loss: 1.0951 - val_accuracy: 0.0714\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9158 - accuracy: 0.3571 - val_loss: 1.0963 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9120 - accuracy: 0.3214 - val_loss: 1.0976 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9093 - accuracy: 0.3214 - val_loss: 1.0990 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9057 - accuracy: 0.3393 - val_loss: 1.1004 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8990 - accuracy: 0.3571 - val_loss: 1.1020 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1020 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=32, batch_size=500, Scores: [1.1019634008407593, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.1019634008407593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9850 - accuracy: 0.0893 - val_loss: 1.0702 - val_accuracy: 0.2143\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9824 - accuracy: 0.1250 - val_loss: 1.0707 - val_accuracy: 0.2143\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9809 - accuracy: 0.1786 - val_loss: 1.0712 - val_accuracy: 0.2143\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9789 - accuracy: 0.1429 - val_loss: 1.0717 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9764 - accuracy: 0.1786 - val_loss: 1.0722 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9751 - accuracy: 0.1786 - val_loss: 1.0727 - val_accuracy: 0.2143\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9723 - accuracy: 0.2679 - val_loss: 1.0732 - val_accuracy: 0.2143\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9699 - accuracy: 0.2679 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9683 - accuracy: 0.2500 - val_loss: 1.0743 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9657 - accuracy: 0.3036 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9637 - accuracy: 0.2679 - val_loss: 1.0755 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9618 - accuracy: 0.3214 - val_loss: 1.0761 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9587 - accuracy: 0.2857 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9576 - accuracy: 0.2679 - val_loss: 1.0774 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9545 - accuracy: 0.3036 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9527 - accuracy: 0.2857 - val_loss: 1.0788 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9499 - accuracy: 0.3214 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9485 - accuracy: 0.2857 - val_loss: 1.0802 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9454 - accuracy: 0.2857 - val_loss: 1.0809 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9431 - accuracy: 0.2857 - val_loss: 1.0817 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9395 - accuracy: 0.3393 - val_loss: 1.0824 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9377 - accuracy: 0.3393 - val_loss: 1.0832 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9350 - accuracy: 0.2857 - val_loss: 1.0840 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9316 - accuracy: 0.3036 - val_loss: 1.0848 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9299 - accuracy: 0.3214 - val_loss: 1.0856 - val_accuracy: 0.2143\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9261 - accuracy: 0.3214 - val_loss: 1.0864 - val_accuracy: 0.2143\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9229 - accuracy: 0.3214 - val_loss: 1.0872 - val_accuracy: 0.2143\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9197 - accuracy: 0.3393 - val_loss: 1.0881 - val_accuracy: 0.2143\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9167 - accuracy: 0.3571 - val_loss: 1.0890 - val_accuracy: 0.2143\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9125 - accuracy: 0.2857 - val_loss: 1.0899 - val_accuracy: 0.2143\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9095 - accuracy: 0.3393 - val_loss: 1.0908 - val_accuracy: 0.2143\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9057 - accuracy: 0.3571 - val_loss: 1.0917 - val_accuracy: 0.2143\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9036 - accuracy: 0.3571 - val_loss: 1.0927 - val_accuracy: 0.2143\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8976 - accuracy: 0.3571 - val_loss: 1.0937 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8947 - accuracy: 0.3036 - val_loss: 1.0948 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8921 - accuracy: 0.3571 - val_loss: 1.0959 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8863 - accuracy: 0.3393 - val_loss: 1.0971 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8823 - accuracy: 0.3393 - val_loss: 1.0983 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8780 - accuracy: 0.3214 - val_loss: 1.0996 - val_accuracy: 0.2143\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8752 - accuracy: 0.3750 - val_loss: 1.1010 - val_accuracy: 0.2143\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8687 - accuracy: 0.3393 - val_loss: 1.1026 - val_accuracy: 0.2143\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8653 - accuracy: 0.3036 - val_loss: 1.1043 - val_accuracy: 0.2143\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8614 - accuracy: 0.3214 - val_loss: 1.1061 - val_accuracy: 0.2143\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8563 - accuracy: 0.3214 - val_loss: 1.1082 - val_accuracy: 0.2143\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8516 - accuracy: 0.3571 - val_loss: 1.1104 - val_accuracy: 0.2143\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8478 - accuracy: 0.3214 - val_loss: 1.1129 - val_accuracy: 0.2143\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8430 - accuracy: 0.3214 - val_loss: 1.1156 - val_accuracy: 0.2143\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8367 - accuracy: 0.3036 - val_loss: 1.1186 - val_accuracy: 0.2143\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8341 - accuracy: 0.3393 - val_loss: 1.1218 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8286 - accuracy: 0.2679 - val_loss: 1.1253 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8243 - accuracy: 0.3393 - val_loss: 1.1291 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8218 - accuracy: 0.2857 - val_loss: 1.1332 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8185 - accuracy: 0.2857 - val_loss: 1.1375 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8097 - accuracy: 0.2857 - val_loss: 1.1421 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8065 - accuracy: 0.3036 - val_loss: 1.1470 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8057 - accuracy: 0.3036 - val_loss: 1.1521 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7978 - accuracy: 0.3036 - val_loss: 1.1575 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7967 - accuracy: 0.3036 - val_loss: 1.1629 - val_accuracy: 0.2143\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7931 - accuracy: 0.3036 - val_loss: 1.1686 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7867 - accuracy: 0.3036 - val_loss: 1.1745 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7822 - accuracy: 0.3214 - val_loss: 1.1804 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7803 - accuracy: 0.3036 - val_loss: 1.1863 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7772 - accuracy: 0.3036 - val_loss: 1.1923 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7723 - accuracy: 0.3393 - val_loss: 1.1981 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1981 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=64, batch_size=100, Scores: [1.1981345415115356, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1981345415115356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9837 - accuracy: 0.1250 - val_loss: 1.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9811 - accuracy: 0.1786 - val_loss: 1.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9794 - accuracy: 0.2143 - val_loss: 1.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9770 - accuracy: 0.2500 - val_loss: 1.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9750 - accuracy: 0.3393 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9720 - accuracy: 0.3036 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9701 - accuracy: 0.3214 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9671 - accuracy: 0.3214 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9664 - accuracy: 0.3036 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9638 - accuracy: 0.2321 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9611 - accuracy: 0.3036 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.9603 - accuracy: 0.2857 - val_loss: 1.0764 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9580 - accuracy: 0.2500 - val_loss: 1.0771 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9540 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9526 - accuracy: 0.3214 - val_loss: 1.0786 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9503 - accuracy: 0.3036 - val_loss: 1.0793 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9478 - accuracy: 0.2857 - val_loss: 1.0800 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9444 - accuracy: 0.2857 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9421 - accuracy: 0.3214 - val_loss: 1.0814 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9395 - accuracy: 0.3214 - val_loss: 1.0821 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9371 - accuracy: 0.3571 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9346 - accuracy: 0.3036 - val_loss: 1.0835 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9299 - accuracy: 0.3393 - val_loss: 1.0842 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9285 - accuracy: 0.3393 - val_loss: 1.0849 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9234 - accuracy: 0.3036 - val_loss: 1.0856 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9200 - accuracy: 0.3393 - val_loss: 1.0863 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9175 - accuracy: 0.3214 - val_loss: 1.0871 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9139 - accuracy: 0.3214 - val_loss: 1.0878 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9101 - accuracy: 0.3393 - val_loss: 1.0886 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9064 - accuracy: 0.3571 - val_loss: 1.0894 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9024 - accuracy: 0.3393 - val_loss: 1.0903 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8981 - accuracy: 0.3750 - val_loss: 1.0912 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8931 - accuracy: 0.3393 - val_loss: 1.0922 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8913 - accuracy: 0.3214 - val_loss: 1.0932 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8865 - accuracy: 0.3214 - val_loss: 1.0943 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8809 - accuracy: 0.3036 - val_loss: 1.0955 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8753 - accuracy: 0.3214 - val_loss: 1.0968 - val_accuracy: 0.1429\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8718 - accuracy: 0.3214 - val_loss: 1.0982 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8690 - accuracy: 0.3214 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8622 - accuracy: 0.3036 - val_loss: 1.1015 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8582 - accuracy: 0.3214 - val_loss: 1.1033 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8516 - accuracy: 0.3214 - val_loss: 1.1053 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8487 - accuracy: 0.3036 - val_loss: 1.1074 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8435 - accuracy: 0.3571 - val_loss: 1.1097 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8412 - accuracy: 0.3214 - val_loss: 1.1122 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8384 - accuracy: 0.3393 - val_loss: 1.1148 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8287 - accuracy: 0.3036 - val_loss: 1.1176 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8259 - accuracy: 0.3214 - val_loss: 1.1205 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8206 - accuracy: 0.3393 - val_loss: 1.1235 - val_accuracy: 0.1429\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8173 - accuracy: 0.3036 - val_loss: 1.1267 - val_accuracy: 0.1429\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8141 - accuracy: 0.3393 - val_loss: 1.1299 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8121 - accuracy: 0.3036 - val_loss: 1.1332 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8100 - accuracy: 0.3393 - val_loss: 1.1367 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8059 - accuracy: 0.3393 - val_loss: 1.1403 - val_accuracy: 0.1429\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7962 - accuracy: 0.3393 - val_loss: 1.1441 - val_accuracy: 0.1429\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7964 - accuracy: 0.3214 - val_loss: 1.1479 - val_accuracy: 0.1429\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7907 - accuracy: 0.3393 - val_loss: 1.1518 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7860 - accuracy: 0.3571 - val_loss: 1.1559 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7835 - accuracy: 0.3393 - val_loss: 1.1599 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7848 - accuracy: 0.3571 - val_loss: 1.1640 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7782 - accuracy: 0.3750 - val_loss: 1.1681 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7758 - accuracy: 0.3393 - val_loss: 1.1721 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7735 - accuracy: 0.3750 - val_loss: 1.1760 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7691 - accuracy: 0.3393 - val_loss: 1.1798 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1798 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=64, batch_size=300, Scores: [1.1797876358032227, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1797876358032227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9853 - accuracy: 0.0714 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9828 - accuracy: 0.1071 - val_loss: 1.0749 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9814 - accuracy: 0.1607 - val_loss: 1.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9789 - accuracy: 0.1786 - val_loss: 1.0757 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9759 - accuracy: 0.1607 - val_loss: 1.0760 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9742 - accuracy: 0.1964 - val_loss: 1.0765 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9720 - accuracy: 0.2143 - val_loss: 1.0769 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9697 - accuracy: 0.2679 - val_loss: 1.0773 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9679 - accuracy: 0.2321 - val_loss: 1.0778 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9657 - accuracy: 0.1964 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9629 - accuracy: 0.2679 - val_loss: 1.0787 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9618 - accuracy: 0.2679 - val_loss: 1.0792 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9588 - accuracy: 0.2679 - val_loss: 1.0797 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9561 - accuracy: 0.2321 - val_loss: 1.0801 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9543 - accuracy: 0.3036 - val_loss: 1.0806 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9515 - accuracy: 0.2679 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9489 - accuracy: 0.3393 - val_loss: 1.0816 - val_accuracy: 0.0714\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9460 - accuracy: 0.3393 - val_loss: 1.0821 - val_accuracy: 0.0714\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.9440 - accuracy: 0.3036 - val_loss: 1.0826 - val_accuracy: 0.0714\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9406 - accuracy: 0.3214 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9388 - accuracy: 0.3393 - val_loss: 1.0837 - val_accuracy: 0.0714\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9372 - accuracy: 0.3393 - val_loss: 1.0842 - val_accuracy: 0.0714\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9323 - accuracy: 0.3214 - val_loss: 1.0847 - val_accuracy: 0.0714\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9297 - accuracy: 0.3393 - val_loss: 1.0852 - val_accuracy: 0.0714\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9259 - accuracy: 0.3036 - val_loss: 1.0858 - val_accuracy: 0.0714\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.9219 - accuracy: 0.3036 - val_loss: 1.0863 - val_accuracy: 0.0714\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9190 - accuracy: 0.3393 - val_loss: 1.0869 - val_accuracy: 0.0714\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9162 - accuracy: 0.2857 - val_loss: 1.0875 - val_accuracy: 0.0714\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9141 - accuracy: 0.3393 - val_loss: 1.0881 - val_accuracy: 0.0714\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9083 - accuracy: 0.3036 - val_loss: 1.0888 - val_accuracy: 0.0714\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9070 - accuracy: 0.3036 - val_loss: 1.0896 - val_accuracy: 0.0714\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9021 - accuracy: 0.3214 - val_loss: 1.0904 - val_accuracy: 0.0714\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8970 - accuracy: 0.3036 - val_loss: 1.0913 - val_accuracy: 0.0714\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8944 - accuracy: 0.2857 - val_loss: 1.0923 - val_accuracy: 0.0714\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8915 - accuracy: 0.3036 - val_loss: 1.0934 - val_accuracy: 0.0714\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8883 - accuracy: 0.3036 - val_loss: 1.0945 - val_accuracy: 0.0714\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8827 - accuracy: 0.2857 - val_loss: 1.0958 - val_accuracy: 0.0714\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8805 - accuracy: 0.3393 - val_loss: 1.0971 - val_accuracy: 0.0714\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8748 - accuracy: 0.3214 - val_loss: 1.0985 - val_accuracy: 0.0714\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8719 - accuracy: 0.3214 - val_loss: 1.1001 - val_accuracy: 0.0714\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8694 - accuracy: 0.3214 - val_loss: 1.1018 - val_accuracy: 0.0714\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8648 - accuracy: 0.2679 - val_loss: 1.1035 - val_accuracy: 0.0714\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8641 - accuracy: 0.3214 - val_loss: 1.1053 - val_accuracy: 0.0714\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8556 - accuracy: 0.3036 - val_loss: 1.1073 - val_accuracy: 0.0714\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8563 - accuracy: 0.2857 - val_loss: 1.1094 - val_accuracy: 0.0714\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8504 - accuracy: 0.3036 - val_loss: 1.1116 - val_accuracy: 0.0714\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8473 - accuracy: 0.3214 - val_loss: 1.1140 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8463 - accuracy: 0.3214 - val_loss: 1.1166 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8420 - accuracy: 0.3393 - val_loss: 1.1194 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8358 - accuracy: 0.2857 - val_loss: 1.1224 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8366 - accuracy: 0.2857 - val_loss: 1.1256 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8297 - accuracy: 0.3393 - val_loss: 1.1292 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8264 - accuracy: 0.3571 - val_loss: 1.1329 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8225 - accuracy: 0.3214 - val_loss: 1.1368 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8185 - accuracy: 0.3393 - val_loss: 1.1410 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8148 - accuracy: 0.3571 - val_loss: 1.1453 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8128 - accuracy: 0.3750 - val_loss: 1.1498 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8105 - accuracy: 0.3571 - val_loss: 1.1545 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8031 - accuracy: 0.3393 - val_loss: 1.1594 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8018 - accuracy: 0.3571 - val_loss: 1.1646 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7972 - accuracy: 0.3393 - val_loss: 1.1699 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7927 - accuracy: 0.3750 - val_loss: 1.1754 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7918 - accuracy: 0.3393 - val_loss: 1.1809 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7890 - accuracy: 0.3571 - val_loss: 1.1867 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1867 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=64, batch_size=400, Scores: [1.1866751909255981, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.1866751909255981\n",
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9814 - accuracy: 0.1429 - val_loss: 1.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9804 - accuracy: 0.1250 - val_loss: 1.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9779 - accuracy: 0.2143 - val_loss: 1.0704 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9749 - accuracy: 0.2143 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9734 - accuracy: 0.2143 - val_loss: 1.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9706 - accuracy: 0.2500 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9696 - accuracy: 0.2143 - val_loss: 1.0718 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9659 - accuracy: 0.2321 - val_loss: 1.0721 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9641 - accuracy: 0.2321 - val_loss: 1.0724 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9617 - accuracy: 0.1964 - val_loss: 1.0727 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9593 - accuracy: 0.2679 - val_loss: 1.0730 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9562 - accuracy: 0.3036 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9551 - accuracy: 0.2500 - val_loss: 1.0735 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9529 - accuracy: 0.3036 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9504 - accuracy: 0.2500 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9472 - accuracy: 0.2857 - val_loss: 1.0741 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9438 - accuracy: 0.2679 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9424 - accuracy: 0.2679 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9395 - accuracy: 0.2500 - val_loss: 1.0745 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9368 - accuracy: 0.2679 - val_loss: 1.0746 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9337 - accuracy: 0.2857 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9316 - accuracy: 0.3036 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9276 - accuracy: 0.3036 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9244 - accuracy: 0.3214 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9198 - accuracy: 0.2857 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9168 - accuracy: 0.3214 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9137 - accuracy: 0.2857 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9100 - accuracy: 0.2857 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9061 - accuracy: 0.3036 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9023 - accuracy: 0.3036 - val_loss: 1.0750 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8980 - accuracy: 0.3036 - val_loss: 1.0752 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8947 - accuracy: 0.3036 - val_loss: 1.0755 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8909 - accuracy: 0.3036 - val_loss: 1.0759 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8853 - accuracy: 0.3036 - val_loss: 1.0764 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8828 - accuracy: 0.2857 - val_loss: 1.0771 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8771 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8745 - accuracy: 0.2857 - val_loss: 1.0791 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8705 - accuracy: 0.2857 - val_loss: 1.0804 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8662 - accuracy: 0.3571 - val_loss: 1.0821 - val_accuracy: 0.2143\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 0.8617 - accuracy: 0.3393 - val_loss: 1.0841 - val_accuracy: 0.2143\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8609 - accuracy: 0.3036 - val_loss: 1.0864 - val_accuracy: 0.2143\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8534 - accuracy: 0.3214 - val_loss: 1.0891 - val_accuracy: 0.2143\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8550 - accuracy: 0.3036 - val_loss: 1.0922 - val_accuracy: 0.2143\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8486 - accuracy: 0.3214 - val_loss: 1.0957 - val_accuracy: 0.2143\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8434 - accuracy: 0.2679 - val_loss: 1.0996 - val_accuracy: 0.2143\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8425 - accuracy: 0.3214 - val_loss: 1.1037 - val_accuracy: 0.2143\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8372 - accuracy: 0.3036 - val_loss: 1.1082 - val_accuracy: 0.2143\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8345 - accuracy: 0.3393 - val_loss: 1.1131 - val_accuracy: 0.2143\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8315 - accuracy: 0.2857 - val_loss: 1.1182 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8254 - accuracy: 0.3214 - val_loss: 1.1235 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8194 - accuracy: 0.3393 - val_loss: 1.1290 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8190 - accuracy: 0.3393 - val_loss: 1.1348 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8120 - accuracy: 0.3214 - val_loss: 1.1407 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8130 - accuracy: 0.3571 - val_loss: 1.1469 - val_accuracy: 0.1429\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8054 - accuracy: 0.3036 - val_loss: 1.1532 - val_accuracy: 0.1429\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8032 - accuracy: 0.3214 - val_loss: 1.1596 - val_accuracy: 0.1429\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7984 - accuracy: 0.3036 - val_loss: 1.1661 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7967 - accuracy: 0.3036 - val_loss: 1.1726 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7910 - accuracy: 0.3393 - val_loss: 1.1791 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7878 - accuracy: 0.3036 - val_loss: 1.1854 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7883 - accuracy: 0.2857 - val_loss: 1.1916 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7872 - accuracy: 0.3036 - val_loss: 1.1976 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7803 - accuracy: 0.3214 - val_loss: 1.2032 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7737 - accuracy: 0.3214 - val_loss: 1.2087 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2087 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=64, batch_size=500, Scores: [1.2087420225143433, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2087420225143433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9858 - accuracy: 0.0893 - val_loss: 1.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9831 - accuracy: 0.1250 - val_loss: 1.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9803 - accuracy: 0.1786 - val_loss: 1.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9801 - accuracy: 0.1964 - val_loss: 1.0749 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9781 - accuracy: 0.1964 - val_loss: 1.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9758 - accuracy: 0.1964 - val_loss: 1.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9726 - accuracy: 0.1607 - val_loss: 1.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9716 - accuracy: 0.2143 - val_loss: 1.0780 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9695 - accuracy: 0.2500 - val_loss: 1.0788 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9677 - accuracy: 0.2321 - val_loss: 1.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9640 - accuracy: 0.2143 - val_loss: 1.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9626 - accuracy: 0.2679 - val_loss: 1.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9614 - accuracy: 0.2679 - val_loss: 1.0823 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9586 - accuracy: 0.2500 - val_loss: 1.0832 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9556 - accuracy: 0.2321 - val_loss: 1.0841 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9544 - accuracy: 0.2857 - val_loss: 1.0851 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9513 - accuracy: 0.2857 - val_loss: 1.0862 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9487 - accuracy: 0.2679 - val_loss: 1.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9470 - accuracy: 0.2679 - val_loss: 1.0883 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9444 - accuracy: 0.2679 - val_loss: 1.0894 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9420 - accuracy: 0.2857 - val_loss: 1.0905 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9398 - accuracy: 0.2679 - val_loss: 1.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9366 - accuracy: 0.3036 - val_loss: 1.0930 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9346 - accuracy: 0.2679 - val_loss: 1.0942 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9311 - accuracy: 0.3036 - val_loss: 1.0955 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9266 - accuracy: 0.3214 - val_loss: 1.0968 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9246 - accuracy: 0.3036 - val_loss: 1.0982 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9231 - accuracy: 0.3036 - val_loss: 1.0996 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9179 - accuracy: 0.3036 - val_loss: 1.1010 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9151 - accuracy: 0.2857 - val_loss: 1.1025 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9131 - accuracy: 0.2857 - val_loss: 1.1040 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9088 - accuracy: 0.2857 - val_loss: 1.1056 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9060 - accuracy: 0.2679 - val_loss: 1.1072 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9027 - accuracy: 0.3036 - val_loss: 1.1089 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8973 - accuracy: 0.3036 - val_loss: 1.1106 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8931 - accuracy: 0.3036 - val_loss: 1.1124 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8910 - accuracy: 0.3036 - val_loss: 1.1142 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8868 - accuracy: 0.3036 - val_loss: 1.1160 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8830 - accuracy: 0.3571 - val_loss: 1.1179 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8777 - accuracy: 0.3393 - val_loss: 1.1198 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8758 - accuracy: 0.3571 - val_loss: 1.1216 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8689 - accuracy: 0.3036 - val_loss: 1.1235 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8666 - accuracy: 0.3393 - val_loss: 1.1253 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8613 - accuracy: 0.3571 - val_loss: 1.1272 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8566 - accuracy: 0.3750 - val_loss: 1.1290 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8525 - accuracy: 0.3393 - val_loss: 1.1309 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8492 - accuracy: 0.3750 - val_loss: 1.1327 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8429 - accuracy: 0.3393 - val_loss: 1.1346 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8395 - accuracy: 0.3571 - val_loss: 1.1364 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8350 - accuracy: 0.3571 - val_loss: 1.1383 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8310 - accuracy: 0.3571 - val_loss: 1.1403 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.8249 - accuracy: 0.3393 - val_loss: 1.1424 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8224 - accuracy: 0.3571 - val_loss: 1.1446 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8172 - accuracy: 0.3393 - val_loss: 1.1471 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.8132 - accuracy: 0.3393 - val_loss: 1.1499 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8095 - accuracy: 0.3214 - val_loss: 1.1529 - val_accuracy: 0.2143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8081 - accuracy: 0.3036 - val_loss: 1.1562 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7993 - accuracy: 0.3393 - val_loss: 1.1597 - val_accuracy: 0.1429\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7967 - accuracy: 0.3393 - val_loss: 1.1636 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7903 - accuracy: 0.3214 - val_loss: 1.1678 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7874 - accuracy: 0.3214 - val_loss: 1.1723 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7877 - accuracy: 0.3393 - val_loss: 1.1771 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7809 - accuracy: 0.3393 - val_loss: 1.1821 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7799 - accuracy: 0.3036 - val_loss: 1.1872 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7768 - accuracy: 0.3393 - val_loss: 1.1924 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7707 - accuracy: 0.3036 - val_loss: 1.1975 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7709 - accuracy: 0.3036 - val_loss: 1.2026 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7635 - accuracy: 0.3036 - val_loss: 1.2077 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7594 - accuracy: 0.3214 - val_loss: 1.2127 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7573 - accuracy: 0.3036 - val_loss: 1.2176 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7510 - accuracy: 0.3036 - val_loss: 1.2227 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7535 - accuracy: 0.3214 - val_loss: 1.2275 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7466 - accuracy: 0.3571 - val_loss: 1.2321 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7523 - accuracy: 0.3036 - val_loss: 1.2366 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7437 - accuracy: 0.3214 - val_loss: 1.2409 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7367 - accuracy: 0.3571 - val_loss: 1.2451 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7339 - accuracy: 0.3393 - val_loss: 1.2489 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7331 - accuracy: 0.3393 - val_loss: 1.2526 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7276 - accuracy: 0.3929 - val_loss: 1.2564 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7289 - accuracy: 0.3750 - val_loss: 1.2600 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7160 - accuracy: 0.3929 - val_loss: 1.2637 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7189 - accuracy: 0.3571 - val_loss: 1.2675 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7158 - accuracy: 0.3750 - val_loss: 1.2714 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7117 - accuracy: 0.3571 - val_loss: 1.2756 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7064 - accuracy: 0.3750 - val_loss: 1.2798 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7068 - accuracy: 0.3393 - val_loss: 1.2839 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6998 - accuracy: 0.3750 - val_loss: 1.2878 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6992 - accuracy: 0.3929 - val_loss: 1.2917 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6969 - accuracy: 0.3750 - val_loss: 1.2955 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6918 - accuracy: 0.3929 - val_loss: 1.2994 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6885 - accuracy: 0.3929 - val_loss: 1.3029 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6846 - accuracy: 0.3929 - val_loss: 1.3067 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6816 - accuracy: 0.3750 - val_loss: 1.3104 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6815 - accuracy: 0.3929 - val_loss: 1.3142 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6734 - accuracy: 0.3750 - val_loss: 1.3182 - val_accuracy: 0.0714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6661 - accuracy: 0.3571 - val_loss: 1.3227 - val_accuracy: 0.0714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6605 - accuracy: 0.3750 - val_loss: 1.3276 - val_accuracy: 0.0714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6577 - accuracy: 0.4107 - val_loss: 1.3325 - val_accuracy: 0.0714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6600 - accuracy: 0.3571 - val_loss: 1.3372 - val_accuracy: 0.0714\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6563 - accuracy: 0.4107 - val_loss: 1.3423 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3423 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=100, batch_size=100, Scores: [1.342293381690979, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.342293381690979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9846 - accuracy: 0.1250 - val_loss: 1.0739 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9831 - accuracy: 0.1429 - val_loss: 1.0747 - val_accuracy: 0.2857\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9800 - accuracy: 0.1071 - val_loss: 1.0757 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9766 - accuracy: 0.1429 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9744 - accuracy: 0.1607 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9730 - accuracy: 0.2143 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9691 - accuracy: 0.2321 - val_loss: 1.0796 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9679 - accuracy: 0.2143 - val_loss: 1.0807 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9651 - accuracy: 0.2143 - val_loss: 1.0818 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9641 - accuracy: 0.1964 - val_loss: 1.0829 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9613 - accuracy: 0.2143 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9583 - accuracy: 0.2500 - val_loss: 1.0852 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9556 - accuracy: 0.2321 - val_loss: 1.0864 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9540 - accuracy: 0.2321 - val_loss: 1.0876 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9510 - accuracy: 0.2321 - val_loss: 1.0889 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9480 - accuracy: 0.2679 - val_loss: 1.0901 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9458 - accuracy: 0.2500 - val_loss: 1.0914 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9435 - accuracy: 0.2321 - val_loss: 1.0927 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9412 - accuracy: 0.2321 - val_loss: 1.0940 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9374 - accuracy: 0.2857 - val_loss: 1.0953 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9346 - accuracy: 0.2857 - val_loss: 1.0966 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9318 - accuracy: 0.2679 - val_loss: 1.0980 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9304 - accuracy: 0.2857 - val_loss: 1.0993 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9264 - accuracy: 0.2679 - val_loss: 1.1007 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9230 - accuracy: 0.2500 - val_loss: 1.1021 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9202 - accuracy: 0.3214 - val_loss: 1.1035 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9163 - accuracy: 0.2679 - val_loss: 1.1050 - val_accuracy: 0.0714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9127 - accuracy: 0.2857 - val_loss: 1.1064 - val_accuracy: 0.0714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9097 - accuracy: 0.2857 - val_loss: 1.1079 - val_accuracy: 0.0714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9060 - accuracy: 0.3214 - val_loss: 1.1095 - val_accuracy: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9029 - accuracy: 0.3214 - val_loss: 1.1111 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8995 - accuracy: 0.3214 - val_loss: 1.1127 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8946 - accuracy: 0.3393 - val_loss: 1.1143 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8908 - accuracy: 0.2857 - val_loss: 1.1160 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 0.8854 - accuracy: 0.3929 - val_loss: 1.1176 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8829 - accuracy: 0.3571 - val_loss: 1.1193 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8799 - accuracy: 0.3750 - val_loss: 1.1210 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8738 - accuracy: 0.3750 - val_loss: 1.1227 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8715 - accuracy: 0.4286 - val_loss: 1.1244 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8679 - accuracy: 0.4107 - val_loss: 1.1261 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8624 - accuracy: 0.4107 - val_loss: 1.1278 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8581 - accuracy: 0.3929 - val_loss: 1.1295 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8550 - accuracy: 0.3929 - val_loss: 1.1311 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8497 - accuracy: 0.3750 - val_loss: 1.1327 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8461 - accuracy: 0.3929 - val_loss: 1.1343 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8417 - accuracy: 0.3750 - val_loss: 1.1361 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8370 - accuracy: 0.3750 - val_loss: 1.1379 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8326 - accuracy: 0.3393 - val_loss: 1.1398 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8299 - accuracy: 0.3393 - val_loss: 1.1419 - val_accuracy: 0.2143\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8277 - accuracy: 0.3750 - val_loss: 1.1441 - val_accuracy: 0.2143\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8249 - accuracy: 0.3214 - val_loss: 1.1465 - val_accuracy: 0.2143\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8189 - accuracy: 0.3750 - val_loss: 1.1491 - val_accuracy: 0.2143\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8146 - accuracy: 0.3393 - val_loss: 1.1521 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8071 - accuracy: 0.3750 - val_loss: 1.1554 - val_accuracy: 0.2143\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8037 - accuracy: 0.3750 - val_loss: 1.1592 - val_accuracy: 0.2143\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8019 - accuracy: 0.3750 - val_loss: 1.1635 - val_accuracy: 0.2143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.8002 - accuracy: 0.4107 - val_loss: 1.1682 - val_accuracy: 0.2143\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7920 - accuracy: 0.3571 - val_loss: 1.1731 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7927 - accuracy: 0.3929 - val_loss: 1.1784 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7847 - accuracy: 0.3929 - val_loss: 1.1841 - val_accuracy: 0.2143\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7833 - accuracy: 0.3929 - val_loss: 1.1902 - val_accuracy: 0.2143\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7780 - accuracy: 0.3929 - val_loss: 1.1967 - val_accuracy: 0.2143\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7742 - accuracy: 0.3929 - val_loss: 1.2033 - val_accuracy: 0.2143\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7682 - accuracy: 0.3929 - val_loss: 1.2099 - val_accuracy: 0.2143\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7684 - accuracy: 0.3929 - val_loss: 1.2166 - val_accuracy: 0.2143\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7647 - accuracy: 0.3929 - val_loss: 1.2234 - val_accuracy: 0.2143\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7586 - accuracy: 0.3750 - val_loss: 1.2296 - val_accuracy: 0.2143\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7577 - accuracy: 0.3750 - val_loss: 1.2353 - val_accuracy: 0.2143\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7546 - accuracy: 0.3750 - val_loss: 1.2408 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7495 - accuracy: 0.3750 - val_loss: 1.2456 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7452 - accuracy: 0.3929 - val_loss: 1.2496 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7419 - accuracy: 0.3929 - val_loss: 1.2535 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7359 - accuracy: 0.3750 - val_loss: 1.2572 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7351 - accuracy: 0.3929 - val_loss: 1.2611 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7299 - accuracy: 0.3571 - val_loss: 1.2651 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7300 - accuracy: 0.3750 - val_loss: 1.2686 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7247 - accuracy: 0.3750 - val_loss: 1.2723 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7268 - accuracy: 0.3750 - val_loss: 1.2757 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7223 - accuracy: 0.3571 - val_loss: 1.2791 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7207 - accuracy: 0.3750 - val_loss: 1.2833 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7150 - accuracy: 0.3750 - val_loss: 1.2876 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7157 - accuracy: 0.3929 - val_loss: 1.2912 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7066 - accuracy: 0.3750 - val_loss: 1.2945 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7086 - accuracy: 0.3750 - val_loss: 1.2973 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7029 - accuracy: 0.3750 - val_loss: 1.3002 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.6995 - accuracy: 0.3571 - val_loss: 1.3027 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6968 - accuracy: 0.3929 - val_loss: 1.3056 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6912 - accuracy: 0.3750 - val_loss: 1.3085 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6888 - accuracy: 0.3750 - val_loss: 1.3110 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6803 - accuracy: 0.3571 - val_loss: 1.3131 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6827 - accuracy: 0.3750 - val_loss: 1.3155 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6776 - accuracy: 0.3750 - val_loss: 1.3178 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6731 - accuracy: 0.3929 - val_loss: 1.3206 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6730 - accuracy: 0.3929 - val_loss: 1.3234 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.6681 - accuracy: 0.3750 - val_loss: 1.3263 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6610 - accuracy: 0.3929 - val_loss: 1.3299 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6573 - accuracy: 0.3571 - val_loss: 1.3338 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6597 - accuracy: 0.3929 - val_loss: 1.3373 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6480 - accuracy: 0.3393 - val_loss: 1.3404 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6504 - accuracy: 0.3750 - val_loss: 1.3430 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3430 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=100, batch_size=300, Scores: [1.3429707288742065, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.3429707288742065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9839 - accuracy: 0.1429 - val_loss: 1.0669 - val_accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9801 - accuracy: 0.1786 - val_loss: 1.0673 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9778 - accuracy: 0.1964 - val_loss: 1.0677 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9767 - accuracy: 0.2143 - val_loss: 1.0682 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9733 - accuracy: 0.3036 - val_loss: 1.0686 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9715 - accuracy: 0.2321 - val_loss: 1.0691 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9703 - accuracy: 0.2857 - val_loss: 1.0695 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9672 - accuracy: 0.2500 - val_loss: 1.0700 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9653 - accuracy: 0.1964 - val_loss: 1.0705 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9623 - accuracy: 0.2321 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9598 - accuracy: 0.2857 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9579 - accuracy: 0.3036 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9559 - accuracy: 0.2679 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.9528 - accuracy: 0.3036 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9505 - accuracy: 0.2857 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9478 - accuracy: 0.3036 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9448 - accuracy: 0.3036 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9435 - accuracy: 0.2857 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9405 - accuracy: 0.3036 - val_loss: 1.0756 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9378 - accuracy: 0.3036 - val_loss: 1.0761 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9356 - accuracy: 0.2857 - val_loss: 1.0766 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9315 - accuracy: 0.3214 - val_loss: 1.0771 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9289 - accuracy: 0.2857 - val_loss: 1.0776 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9262 - accuracy: 0.2857 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9239 - accuracy: 0.3036 - val_loss: 1.0785 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9199 - accuracy: 0.3214 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9147 - accuracy: 0.3036 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9129 - accuracy: 0.2857 - val_loss: 1.0799 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9086 - accuracy: 0.3036 - val_loss: 1.0803 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9044 - accuracy: 0.2857 - val_loss: 1.0808 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9005 - accuracy: 0.3036 - val_loss: 1.0812 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8974 - accuracy: 0.3214 - val_loss: 1.0817 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8935 - accuracy: 0.3571 - val_loss: 1.0821 - val_accuracy: 0.2143\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8900 - accuracy: 0.3393 - val_loss: 1.0826 - val_accuracy: 0.2143\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8875 - accuracy: 0.3393 - val_loss: 1.0831 - val_accuracy: 0.2143\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8772 - accuracy: 0.3750 - val_loss: 1.0837 - val_accuracy: 0.2143\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8789 - accuracy: 0.3214 - val_loss: 1.0843 - val_accuracy: 0.2143\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8725 - accuracy: 0.3393 - val_loss: 1.0850 - val_accuracy: 0.2143\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8686 - accuracy: 0.3571 - val_loss: 1.0859 - val_accuracy: 0.2143\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8633 - accuracy: 0.3393 - val_loss: 1.0868 - val_accuracy: 0.2143\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8605 - accuracy: 0.3036 - val_loss: 1.0879 - val_accuracy: 0.2143\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8564 - accuracy: 0.2857 - val_loss: 1.0892 - val_accuracy: 0.2143\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8504 - accuracy: 0.3393 - val_loss: 1.0908 - val_accuracy: 0.2143\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8457 - accuracy: 0.3214 - val_loss: 1.0925 - val_accuracy: 0.2143\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8415 - accuracy: 0.3036 - val_loss: 1.0945 - val_accuracy: 0.2143\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8385 - accuracy: 0.3036 - val_loss: 1.0967 - val_accuracy: 0.2143\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8344 - accuracy: 0.3036 - val_loss: 1.0992 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8325 - accuracy: 0.2857 - val_loss: 1.1021 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8263 - accuracy: 0.2857 - val_loss: 1.1052 - val_accuracy: 0.2143\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8220 - accuracy: 0.3214 - val_loss: 1.1086 - val_accuracy: 0.2143\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8201 - accuracy: 0.3214 - val_loss: 1.1122 - val_accuracy: 0.2143\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8188 - accuracy: 0.3393 - val_loss: 1.1161 - val_accuracy: 0.2143\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8133 - accuracy: 0.3214 - val_loss: 1.1202 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8089 - accuracy: 0.3393 - val_loss: 1.1246 - val_accuracy: 0.2143\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8047 - accuracy: 0.3393 - val_loss: 1.1291 - val_accuracy: 0.2143\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8017 - accuracy: 0.3214 - val_loss: 1.1338 - val_accuracy: 0.2143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7972 - accuracy: 0.3393 - val_loss: 1.1386 - val_accuracy: 0.2143\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7951 - accuracy: 0.3036 - val_loss: 1.1435 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7869 - accuracy: 0.3393 - val_loss: 1.1484 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7800 - accuracy: 0.3393 - val_loss: 1.1534 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7855 - accuracy: 0.3393 - val_loss: 1.1583 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7785 - accuracy: 0.3571 - val_loss: 1.1633 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7727 - accuracy: 0.3750 - val_loss: 1.1683 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7748 - accuracy: 0.3393 - val_loss: 1.1731 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7666 - accuracy: 0.3571 - val_loss: 1.1779 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7645 - accuracy: 0.3750 - val_loss: 1.1826 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7643 - accuracy: 0.3571 - val_loss: 1.1872 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7597 - accuracy: 0.3750 - val_loss: 1.1918 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7526 - accuracy: 0.3750 - val_loss: 1.1963 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7465 - accuracy: 0.3571 - val_loss: 1.2007 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7483 - accuracy: 0.3393 - val_loss: 1.2049 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7501 - accuracy: 0.3393 - val_loss: 1.2087 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7443 - accuracy: 0.3571 - val_loss: 1.2126 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7409 - accuracy: 0.3393 - val_loss: 1.2162 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7379 - accuracy: 0.3750 - val_loss: 1.2196 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7337 - accuracy: 0.3571 - val_loss: 1.2229 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7346 - accuracy: 0.3571 - val_loss: 1.2257 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7331 - accuracy: 0.3571 - val_loss: 1.2284 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7288 - accuracy: 0.3750 - val_loss: 1.2311 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7249 - accuracy: 0.3214 - val_loss: 1.2339 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7161 - accuracy: 0.3571 - val_loss: 1.2366 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7176 - accuracy: 0.3214 - val_loss: 1.2392 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7158 - accuracy: 0.3571 - val_loss: 1.2418 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7128 - accuracy: 0.3571 - val_loss: 1.2443 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7052 - accuracy: 0.3929 - val_loss: 1.2468 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7029 - accuracy: 0.3750 - val_loss: 1.2491 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6993 - accuracy: 0.3929 - val_loss: 1.2514 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6987 - accuracy: 0.3929 - val_loss: 1.2538 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6899 - accuracy: 0.3750 - val_loss: 1.2560 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6919 - accuracy: 0.4107 - val_loss: 1.2588 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6849 - accuracy: 0.3750 - val_loss: 1.2617 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6826 - accuracy: 0.4286 - val_loss: 1.2645 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6823 - accuracy: 0.4107 - val_loss: 1.2677 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6795 - accuracy: 0.4107 - val_loss: 1.2710 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6741 - accuracy: 0.4107 - val_loss: 1.2743 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6722 - accuracy: 0.3750 - val_loss: 1.2775 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6676 - accuracy: 0.3571 - val_loss: 1.2806 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6613 - accuracy: 0.4286 - val_loss: 1.2837 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6648 - accuracy: 0.4286 - val_loss: 1.2870 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6501 - accuracy: 0.4286 - val_loss: 1.2907 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2907 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=100, batch_size=400, Scores: [1.290684700012207, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.290684700012207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9843 - accuracy: 0.0714 - val_loss: 1.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.9813 - accuracy: 0.1071 - val_loss: 1.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9800 - accuracy: 0.1071 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9773 - accuracy: 0.1250 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9754 - accuracy: 0.1964 - val_loss: 1.0731 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9724 - accuracy: 0.2143 - val_loss: 1.0738 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9695 - accuracy: 0.2143 - val_loss: 1.0744 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9680 - accuracy: 0.2143 - val_loss: 1.0750 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9665 - accuracy: 0.2500 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9640 - accuracy: 0.1964 - val_loss: 1.0763 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9610 - accuracy: 0.1607 - val_loss: 1.0770 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9582 - accuracy: 0.2321 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9553 - accuracy: 0.2500 - val_loss: 1.0783 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9532 - accuracy: 0.2143 - val_loss: 1.0789 - val_accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9517 - accuracy: 0.1964 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9496 - accuracy: 0.1964 - val_loss: 1.0801 - val_accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.9453 - accuracy: 0.1964 - val_loss: 1.0808 - val_accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9426 - accuracy: 0.1964 - val_loss: 1.0814 - val_accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9415 - accuracy: 0.2321 - val_loss: 1.0819 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9379 - accuracy: 0.2143 - val_loss: 1.0825 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9362 - accuracy: 0.2143 - val_loss: 1.0831 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9327 - accuracy: 0.2143 - val_loss: 1.0837 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9289 - accuracy: 0.2321 - val_loss: 1.0842 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9287 - accuracy: 0.2143 - val_loss: 1.0848 - val_accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9247 - accuracy: 0.2321 - val_loss: 1.0853 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9218 - accuracy: 0.2321 - val_loss: 1.0859 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9183 - accuracy: 0.2321 - val_loss: 1.0864 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9141 - accuracy: 0.2321 - val_loss: 1.0869 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9098 - accuracy: 0.2321 - val_loss: 1.0874 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9065 - accuracy: 0.2321 - val_loss: 1.0879 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9027 - accuracy: 0.2321 - val_loss: 1.0884 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8994 - accuracy: 0.2321 - val_loss: 1.0889 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8990 - accuracy: 0.2321 - val_loss: 1.0894 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8936 - accuracy: 0.2321 - val_loss: 1.0900 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8898 - accuracy: 0.2500 - val_loss: 1.0906 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8857 - accuracy: 0.2321 - val_loss: 1.0913 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8811 - accuracy: 0.2321 - val_loss: 1.0919 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8794 - accuracy: 0.2500 - val_loss: 1.0927 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8758 - accuracy: 0.2500 - val_loss: 1.0936 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8701 - accuracy: 0.2679 - val_loss: 1.0946 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8651 - accuracy: 0.2500 - val_loss: 1.0957 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8650 - accuracy: 0.2679 - val_loss: 1.0970 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8603 - accuracy: 0.2679 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8558 - accuracy: 0.2857 - val_loss: 1.1002 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8545 - accuracy: 0.2500 - val_loss: 1.1020 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8518 - accuracy: 0.3036 - val_loss: 1.1039 - val_accuracy: 0.0714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8449 - accuracy: 0.3036 - val_loss: 1.1061 - val_accuracy: 0.0714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8399 - accuracy: 0.2500 - val_loss: 1.1085 - val_accuracy: 0.0714\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8389 - accuracy: 0.3036 - val_loss: 1.1110 - val_accuracy: 0.0714\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8379 - accuracy: 0.3036 - val_loss: 1.1138 - val_accuracy: 0.0714\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8334 - accuracy: 0.3036 - val_loss: 1.1167 - val_accuracy: 0.0714\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8278 - accuracy: 0.3036 - val_loss: 1.1198 - val_accuracy: 0.0714\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8266 - accuracy: 0.3036 - val_loss: 1.1232 - val_accuracy: 0.0714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8185 - accuracy: 0.3036 - val_loss: 1.1267 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8177 - accuracy: 0.3393 - val_loss: 1.1304 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8120 - accuracy: 0.3036 - val_loss: 1.1343 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8126 - accuracy: 0.3214 - val_loss: 1.1383 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8101 - accuracy: 0.3393 - val_loss: 1.1423 - val_accuracy: 0.1429\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8054 - accuracy: 0.3393 - val_loss: 1.1465 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8016 - accuracy: 0.3393 - val_loss: 1.1507 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7977 - accuracy: 0.3393 - val_loss: 1.1550 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7928 - accuracy: 0.3214 - val_loss: 1.1593 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7899 - accuracy: 0.3393 - val_loss: 1.1635 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7859 - accuracy: 0.3214 - val_loss: 1.1678 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7855 - accuracy: 0.3214 - val_loss: 1.1720 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7803 - accuracy: 0.3214 - val_loss: 1.1759 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7762 - accuracy: 0.3393 - val_loss: 1.1799 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7737 - accuracy: 0.3214 - val_loss: 1.1838 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7727 - accuracy: 0.3393 - val_loss: 1.1876 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7670 - accuracy: 0.3393 - val_loss: 1.1913 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7667 - accuracy: 0.3393 - val_loss: 1.1946 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7606 - accuracy: 0.3393 - val_loss: 1.1978 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7563 - accuracy: 0.3214 - val_loss: 1.2009 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7541 - accuracy: 0.3036 - val_loss: 1.2038 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7528 - accuracy: 0.3571 - val_loss: 1.2067 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7455 - accuracy: 0.3036 - val_loss: 1.2093 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7444 - accuracy: 0.3214 - val_loss: 1.2116 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7413 - accuracy: 0.3393 - val_loss: 1.2136 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7365 - accuracy: 0.3214 - val_loss: 1.2155 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7313 - accuracy: 0.3214 - val_loss: 1.2174 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7244 - accuracy: 0.3393 - val_loss: 1.2195 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7281 - accuracy: 0.3214 - val_loss: 1.2218 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.7223 - accuracy: 0.3571 - val_loss: 1.2240 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7234 - accuracy: 0.3036 - val_loss: 1.2262 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7189 - accuracy: 0.3571 - val_loss: 1.2285 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7162 - accuracy: 0.3571 - val_loss: 1.2307 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7137 - accuracy: 0.3571 - val_loss: 1.2329 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7075 - accuracy: 0.3571 - val_loss: 1.2350 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7048 - accuracy: 0.3571 - val_loss: 1.2367 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7037 - accuracy: 0.3214 - val_loss: 1.2387 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6997 - accuracy: 0.3393 - val_loss: 1.2405 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7023 - accuracy: 0.3571 - val_loss: 1.2419 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6925 - accuracy: 0.3214 - val_loss: 1.2432 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6839 - accuracy: 0.3571 - val_loss: 1.2447 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6815 - accuracy: 0.3750 - val_loss: 1.2461 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6818 - accuracy: 0.3393 - val_loss: 1.2479 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6794 - accuracy: 0.3571 - val_loss: 1.2503 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6760 - accuracy: 0.3571 - val_loss: 1.2527 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6731 - accuracy: 0.3929 - val_loss: 1.2555 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6750 - accuracy: 0.3571 - val_loss: 1.2591 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2591 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=100, batch_size=500, Scores: [1.2591485977172852, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2591485977172852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9793 - accuracy: 0.1429 - val_loss: 1.0702 - val_accuracy: 0.2143\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9777 - accuracy: 0.1964 - val_loss: 1.0709 - val_accuracy: 0.2143\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9750 - accuracy: 0.2679 - val_loss: 1.0717 - val_accuracy: 0.2143\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9740 - accuracy: 0.2679 - val_loss: 1.0724 - val_accuracy: 0.2143\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9710 - accuracy: 0.2500 - val_loss: 1.0732 - val_accuracy: 0.2143\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9695 - accuracy: 0.2321 - val_loss: 1.0740 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9672 - accuracy: 0.1964 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9642 - accuracy: 0.2321 - val_loss: 1.0756 - val_accuracy: 0.1429\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9618 - accuracy: 0.2500 - val_loss: 1.0764 - val_accuracy: 0.1429\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9598 - accuracy: 0.2679 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.9577 - accuracy: 0.3036 - val_loss: 1.0782 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9556 - accuracy: 0.3036 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9526 - accuracy: 0.2857 - val_loss: 1.0800 - val_accuracy: 0.1429\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9512 - accuracy: 0.2857 - val_loss: 1.0809 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9484 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9455 - accuracy: 0.3214 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9430 - accuracy: 0.2679 - val_loss: 1.0838 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9410 - accuracy: 0.2679 - val_loss: 1.0848 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9366 - accuracy: 0.2857 - val_loss: 1.0859 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9349 - accuracy: 0.2679 - val_loss: 1.0869 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9318 - accuracy: 0.3214 - val_loss: 1.0880 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9297 - accuracy: 0.2857 - val_loss: 1.0891 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9261 - accuracy: 0.2857 - val_loss: 1.0902 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9223 - accuracy: 0.3036 - val_loss: 1.0914 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9200 - accuracy: 0.3214 - val_loss: 1.0926 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9151 - accuracy: 0.2679 - val_loss: 1.0938 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9139 - accuracy: 0.2857 - val_loss: 1.0951 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9101 - accuracy: 0.2679 - val_loss: 1.0963 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9069 - accuracy: 0.2679 - val_loss: 1.0977 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9040 - accuracy: 0.2679 - val_loss: 1.0991 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8991 - accuracy: 0.2679 - val_loss: 1.1005 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8969 - accuracy: 0.2857 - val_loss: 1.1019 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8905 - accuracy: 0.3036 - val_loss: 1.1034 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8866 - accuracy: 0.2679 - val_loss: 1.1050 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8807 - accuracy: 0.2500 - val_loss: 1.1066 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8797 - accuracy: 0.2679 - val_loss: 1.1082 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8760 - accuracy: 0.3036 - val_loss: 1.1100 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8691 - accuracy: 0.2857 - val_loss: 1.1118 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8670 - accuracy: 0.2857 - val_loss: 1.1137 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8610 - accuracy: 0.2857 - val_loss: 1.1157 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8587 - accuracy: 0.2679 - val_loss: 1.1178 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8518 - accuracy: 0.2857 - val_loss: 1.1200 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8478 - accuracy: 0.2857 - val_loss: 1.1224 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8438 - accuracy: 0.3036 - val_loss: 1.1250 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8376 - accuracy: 0.3393 - val_loss: 1.1277 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8350 - accuracy: 0.3036 - val_loss: 1.1306 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8271 - accuracy: 0.3036 - val_loss: 1.1336 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8235 - accuracy: 0.3214 - val_loss: 1.1368 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8188 - accuracy: 0.3214 - val_loss: 1.1402 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8174 - accuracy: 0.3571 - val_loss: 1.1438 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8129 - accuracy: 0.3214 - val_loss: 1.1476 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8086 - accuracy: 0.3393 - val_loss: 1.1514 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8063 - accuracy: 0.3214 - val_loss: 1.1554 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8014 - accuracy: 0.2857 - val_loss: 1.1593 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7951 - accuracy: 0.3036 - val_loss: 1.1634 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7900 - accuracy: 0.3393 - val_loss: 1.1674 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7844 - accuracy: 0.3214 - val_loss: 1.1714 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7840 - accuracy: 0.3571 - val_loss: 1.1753 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7782 - accuracy: 0.3214 - val_loss: 1.1792 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7765 - accuracy: 0.3750 - val_loss: 1.1831 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7686 - accuracy: 0.3393 - val_loss: 1.1871 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7702 - accuracy: 0.3571 - val_loss: 1.1910 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7663 - accuracy: 0.3571 - val_loss: 1.1948 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7653 - accuracy: 0.3393 - val_loss: 1.1984 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7603 - accuracy: 0.3393 - val_loss: 1.2020 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7567 - accuracy: 0.3571 - val_loss: 1.2056 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7543 - accuracy: 0.3214 - val_loss: 1.2089 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7514 - accuracy: 0.3571 - val_loss: 1.2121 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7459 - accuracy: 0.3750 - val_loss: 1.2152 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7436 - accuracy: 0.3214 - val_loss: 1.2181 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7413 - accuracy: 0.3036 - val_loss: 1.2207 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7384 - accuracy: 0.3036 - val_loss: 1.2231 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7371 - accuracy: 0.3214 - val_loss: 1.2255 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7314 - accuracy: 0.3393 - val_loss: 1.2279 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7290 - accuracy: 0.3393 - val_loss: 1.2302 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7242 - accuracy: 0.3214 - val_loss: 1.2323 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7257 - accuracy: 0.3036 - val_loss: 1.2345 - val_accuracy: 0.0714\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7195 - accuracy: 0.3393 - val_loss: 1.2364 - val_accuracy: 0.0714\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7126 - accuracy: 0.3393 - val_loss: 1.2385 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7163 - accuracy: 0.3393 - val_loss: 1.2407 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7098 - accuracy: 0.3393 - val_loss: 1.2431 - val_accuracy: 0.0714\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7095 - accuracy: 0.3393 - val_loss: 1.2458 - val_accuracy: 0.0714\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7070 - accuracy: 0.3393 - val_loss: 1.2486 - val_accuracy: 0.0714\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7051 - accuracy: 0.3036 - val_loss: 1.2517 - val_accuracy: 0.0714\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7005 - accuracy: 0.3214 - val_loss: 1.2547 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6954 - accuracy: 0.3393 - val_loss: 1.2580 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6919 - accuracy: 0.3393 - val_loss: 1.2614 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6905 - accuracy: 0.3393 - val_loss: 1.2652 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6902 - accuracy: 0.3214 - val_loss: 1.2689 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6833 - accuracy: 0.3571 - val_loss: 1.2729 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6754 - accuracy: 0.3214 - val_loss: 1.2773 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6779 - accuracy: 0.3214 - val_loss: 1.2814 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6697 - accuracy: 0.3393 - val_loss: 1.2856 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6711 - accuracy: 0.3214 - val_loss: 1.2903 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6651 - accuracy: 0.3393 - val_loss: 1.2950 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6616 - accuracy: 0.3036 - val_loss: 1.2997 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6571 - accuracy: 0.3750 - val_loss: 1.3045 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6535 - accuracy: 0.3750 - val_loss: 1.3091 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6547 - accuracy: 0.3214 - val_loss: 1.3139 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6420 - accuracy: 0.3750 - val_loss: 1.3186 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6420 - accuracy: 0.3750 - val_loss: 1.3230 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6436 - accuracy: 0.3571 - val_loss: 1.3278 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6383 - accuracy: 0.3750 - val_loss: 1.3330 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6364 - accuracy: 0.3571 - val_loss: 1.3384 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6245 - accuracy: 0.3750 - val_loss: 1.3439 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6284 - accuracy: 0.3571 - val_loss: 1.3489 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6189 - accuracy: 0.3929 - val_loss: 1.3535 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6232 - accuracy: 0.3929 - val_loss: 1.3579 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6120 - accuracy: 0.3571 - val_loss: 1.3623 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6149 - accuracy: 0.3929 - val_loss: 1.3671 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6081 - accuracy: 0.3750 - val_loss: 1.3717 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6043 - accuracy: 0.3571 - val_loss: 1.3765 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5977 - accuracy: 0.3929 - val_loss: 1.3809 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5898 - accuracy: 0.4286 - val_loss: 1.3854 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5936 - accuracy: 0.4286 - val_loss: 1.3905 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5892 - accuracy: 0.4107 - val_loss: 1.3960 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5891 - accuracy: 0.3929 - val_loss: 1.4015 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5772 - accuracy: 0.3929 - val_loss: 1.4076 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5810 - accuracy: 0.3929 - val_loss: 1.4137 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5699 - accuracy: 0.4286 - val_loss: 1.4192 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5713 - accuracy: 0.4107 - val_loss: 1.4241 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5667 - accuracy: 0.4107 - val_loss: 1.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5538 - accuracy: 0.4107 - val_loss: 1.4325 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5576 - accuracy: 0.3929 - val_loss: 1.4365 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5570 - accuracy: 0.3750 - val_loss: 1.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5457 - accuracy: 0.4107 - val_loss: 1.4452 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5436 - accuracy: 0.3750 - val_loss: 1.4506 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5399 - accuracy: 0.4107 - val_loss: 1.4560 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4560 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=128, batch_size=100, Scores: [1.4560188055038452, 0.0]\n",
      "Accuracy on validation set: 0.0\n",
      "Loss on validation set: 1.4560188055038452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9838 - accuracy: 0.0893 - val_loss: 1.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.9814 - accuracy: 0.1250 - val_loss: 1.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9794 - accuracy: 0.1250 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9765 - accuracy: 0.1786 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9749 - accuracy: 0.1607 - val_loss: 1.0740 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9734 - accuracy: 0.1964 - val_loss: 1.0743 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9704 - accuracy: 0.2143 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9673 - accuracy: 0.2679 - val_loss: 1.0750 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9659 - accuracy: 0.2679 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9644 - accuracy: 0.2143 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9606 - accuracy: 0.2321 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9585 - accuracy: 0.2321 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9568 - accuracy: 0.3036 - val_loss: 1.0770 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9531 - accuracy: 0.3036 - val_loss: 1.0774 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9515 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9476 - accuracy: 0.3214 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9455 - accuracy: 0.3393 - val_loss: 1.0789 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9441 - accuracy: 0.3036 - val_loss: 1.0794 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9407 - accuracy: 0.3214 - val_loss: 1.0799 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9384 - accuracy: 0.2857 - val_loss: 1.0805 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.9352 - accuracy: 0.3214 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9310 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9291 - accuracy: 0.3214 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9268 - accuracy: 0.3036 - val_loss: 1.0832 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9236 - accuracy: 0.3393 - val_loss: 1.0839 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9189 - accuracy: 0.3036 - val_loss: 1.0848 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9161 - accuracy: 0.3214 - val_loss: 1.0857 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9126 - accuracy: 0.2857 - val_loss: 1.0866 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9093 - accuracy: 0.3036 - val_loss: 1.0877 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9063 - accuracy: 0.3214 - val_loss: 1.0888 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9006 - accuracy: 0.3036 - val_loss: 1.0900 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8994 - accuracy: 0.3036 - val_loss: 1.0914 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8937 - accuracy: 0.3214 - val_loss: 1.0928 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8893 - accuracy: 0.3036 - val_loss: 1.0944 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8836 - accuracy: 0.2857 - val_loss: 1.0960 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8825 - accuracy: 0.3214 - val_loss: 1.0979 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8788 - accuracy: 0.3214 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8739 - accuracy: 0.3214 - val_loss: 1.1019 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8697 - accuracy: 0.3214 - val_loss: 1.1042 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8684 - accuracy: 0.3214 - val_loss: 1.1066 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8625 - accuracy: 0.3214 - val_loss: 1.1091 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8588 - accuracy: 0.3214 - val_loss: 1.1117 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8547 - accuracy: 0.3036 - val_loss: 1.1144 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8504 - accuracy: 0.3036 - val_loss: 1.1172 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8471 - accuracy: 0.2857 - val_loss: 1.1201 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8422 - accuracy: 0.2857 - val_loss: 1.1231 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8379 - accuracy: 0.2857 - val_loss: 1.1261 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8345 - accuracy: 0.2857 - val_loss: 1.1291 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8285 - accuracy: 0.2857 - val_loss: 1.1322 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8295 - accuracy: 0.3036 - val_loss: 1.1354 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8212 - accuracy: 0.3393 - val_loss: 1.1387 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8185 - accuracy: 0.3036 - val_loss: 1.1422 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8136 - accuracy: 0.3571 - val_loss: 1.1457 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8115 - accuracy: 0.3571 - val_loss: 1.1495 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8058 - accuracy: 0.3571 - val_loss: 1.1533 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8006 - accuracy: 0.3214 - val_loss: 1.1574 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8029 - accuracy: 0.3214 - val_loss: 1.1614 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7929 - accuracy: 0.3571 - val_loss: 1.1657 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7943 - accuracy: 0.3214 - val_loss: 1.1699 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7870 - accuracy: 0.3214 - val_loss: 1.1741 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7849 - accuracy: 0.3393 - val_loss: 1.1784 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7776 - accuracy: 0.3036 - val_loss: 1.1826 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7788 - accuracy: 0.3214 - val_loss: 1.1869 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7778 - accuracy: 0.3214 - val_loss: 1.1911 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7692 - accuracy: 0.3393 - val_loss: 1.1952 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7674 - accuracy: 0.3214 - val_loss: 1.1992 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7665 - accuracy: 0.3571 - val_loss: 1.2030 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7628 - accuracy: 0.3571 - val_loss: 1.2066 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7595 - accuracy: 0.3393 - val_loss: 1.2100 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.7523 - accuracy: 0.3393 - val_loss: 1.2132 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7474 - accuracy: 0.3214 - val_loss: 1.2162 - val_accuracy: 0.0714\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7530 - accuracy: 0.3571 - val_loss: 1.2189 - val_accuracy: 0.0714\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7476 - accuracy: 0.3214 - val_loss: 1.2214 - val_accuracy: 0.0714\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7431 - accuracy: 0.3393 - val_loss: 1.2237 - val_accuracy: 0.0714\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7419 - accuracy: 0.3929 - val_loss: 1.2259 - val_accuracy: 0.0714\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7406 - accuracy: 0.3393 - val_loss: 1.2278 - val_accuracy: 0.0714\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7346 - accuracy: 0.3750 - val_loss: 1.2294 - val_accuracy: 0.0714\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7346 - accuracy: 0.3571 - val_loss: 1.2310 - val_accuracy: 0.0714\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7301 - accuracy: 0.3571 - val_loss: 1.2324 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7277 - accuracy: 0.3750 - val_loss: 1.2338 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7257 - accuracy: 0.3571 - val_loss: 1.2354 - val_accuracy: 0.0714\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7271 - accuracy: 0.3571 - val_loss: 1.2367 - val_accuracy: 0.0714\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7205 - accuracy: 0.3750 - val_loss: 1.2383 - val_accuracy: 0.0714\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7153 - accuracy: 0.3571 - val_loss: 1.2402 - val_accuracy: 0.0714\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7165 - accuracy: 0.3571 - val_loss: 1.2425 - val_accuracy: 0.0714\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7151 - accuracy: 0.3750 - val_loss: 1.2451 - val_accuracy: 0.0714\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7092 - accuracy: 0.3750 - val_loss: 1.2477 - val_accuracy: 0.0714\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7056 - accuracy: 0.3571 - val_loss: 1.2503 - val_accuracy: 0.0714\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7000 - accuracy: 0.3571 - val_loss: 1.2528 - val_accuracy: 0.0714\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7012 - accuracy: 0.3571 - val_loss: 1.2549 - val_accuracy: 0.0714\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7011 - accuracy: 0.3393 - val_loss: 1.2573 - val_accuracy: 0.0714\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6928 - accuracy: 0.3571 - val_loss: 1.2595 - val_accuracy: 0.0714\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6906 - accuracy: 0.3214 - val_loss: 1.2615 - val_accuracy: 0.0714\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6897 - accuracy: 0.3393 - val_loss: 1.2633 - val_accuracy: 0.0714\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6851 - accuracy: 0.3929 - val_loss: 1.2653 - val_accuracy: 0.0714\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6823 - accuracy: 0.3750 - val_loss: 1.2672 - val_accuracy: 0.0714\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6789 - accuracy: 0.3571 - val_loss: 1.2695 - val_accuracy: 0.0714\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6777 - accuracy: 0.3571 - val_loss: 1.2721 - val_accuracy: 0.0714\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6732 - accuracy: 0.3750 - val_loss: 1.2750 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6686 - accuracy: 0.3750 - val_loss: 1.2780 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6648 - accuracy: 0.3750 - val_loss: 1.2818 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6624 - accuracy: 0.3571 - val_loss: 1.2858 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6598 - accuracy: 0.4107 - val_loss: 1.2900 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6497 - accuracy: 0.3750 - val_loss: 1.2944 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6493 - accuracy: 0.3750 - val_loss: 1.2990 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6522 - accuracy: 0.4286 - val_loss: 1.3034 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6550 - accuracy: 0.3750 - val_loss: 1.3079 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6437 - accuracy: 0.3750 - val_loss: 1.3122 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6356 - accuracy: 0.3929 - val_loss: 1.3168 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6291 - accuracy: 0.4464 - val_loss: 1.3211 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6282 - accuracy: 0.4286 - val_loss: 1.3252 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6233 - accuracy: 0.4286 - val_loss: 1.3292 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6250 - accuracy: 0.4286 - val_loss: 1.3333 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6186 - accuracy: 0.3929 - val_loss: 1.3379 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6112 - accuracy: 0.4464 - val_loss: 1.3426 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6110 - accuracy: 0.4464 - val_loss: 1.3478 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6031 - accuracy: 0.4286 - val_loss: 1.3525 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6003 - accuracy: 0.4464 - val_loss: 1.3572 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.5974 - accuracy: 0.4643 - val_loss: 1.3618 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5958 - accuracy: 0.4286 - val_loss: 1.3669 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5930 - accuracy: 0.4464 - val_loss: 1.3729 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5860 - accuracy: 0.4286 - val_loss: 1.3796 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5806 - accuracy: 0.4464 - val_loss: 1.3864 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5935 - accuracy: 0.3929 - val_loss: 1.3932 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5732 - accuracy: 0.4464 - val_loss: 1.3993 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5708 - accuracy: 0.4107 - val_loss: 1.4055 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5790 - accuracy: 0.4107 - val_loss: 1.4112 - val_accuracy: 0.2143\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5616 - accuracy: 0.3929 - val_loss: 1.4171 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4171 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=128, batch_size=300, Scores: [1.4170774221420288, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.4170774221420288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9822 - accuracy: 0.1071 - val_loss: 1.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9810 - accuracy: 0.1786 - val_loss: 1.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9781 - accuracy: 0.1964 - val_loss: 1.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9751 - accuracy: 0.2321 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9737 - accuracy: 0.2143 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9717 - accuracy: 0.2679 - val_loss: 1.0746 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.9694 - accuracy: 0.2857 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9678 - accuracy: 0.2857 - val_loss: 1.0753 - val_accuracy: 0.1429\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9642 - accuracy: 0.2857 - val_loss: 1.0757 - val_accuracy: 0.1429\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9629 - accuracy: 0.3214 - val_loss: 1.0761 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9592 - accuracy: 0.2500 - val_loss: 1.0764 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.9578 - accuracy: 0.3214 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9548 - accuracy: 0.3393 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9532 - accuracy: 0.2857 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9507 - accuracy: 0.3393 - val_loss: 1.0780 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9475 - accuracy: 0.3393 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9448 - accuracy: 0.3571 - val_loss: 1.0788 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9426 - accuracy: 0.3036 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9399 - accuracy: 0.3214 - val_loss: 1.0796 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9354 - accuracy: 0.3393 - val_loss: 1.0800 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9344 - accuracy: 0.2857 - val_loss: 1.0805 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.9299 - accuracy: 0.3214 - val_loss: 1.0809 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9279 - accuracy: 0.2857 - val_loss: 1.0813 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9254 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9198 - accuracy: 0.3214 - val_loss: 1.0823 - val_accuracy: 0.0714\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9182 - accuracy: 0.3036 - val_loss: 1.0827 - val_accuracy: 0.0714\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9146 - accuracy: 0.3036 - val_loss: 1.0832 - val_accuracy: 0.0714\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9108 - accuracy: 0.3036 - val_loss: 1.0838 - val_accuracy: 0.0714\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9080 - accuracy: 0.3214 - val_loss: 1.0843 - val_accuracy: 0.0714\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9044 - accuracy: 0.2857 - val_loss: 1.0849 - val_accuracy: 0.0714\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8996 - accuracy: 0.3393 - val_loss: 1.0856 - val_accuracy: 0.0714\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8953 - accuracy: 0.3214 - val_loss: 1.0864 - val_accuracy: 0.0714\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8920 - accuracy: 0.3393 - val_loss: 1.0871 - val_accuracy: 0.0714\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8868 - accuracy: 0.3393 - val_loss: 1.0880 - val_accuracy: 0.0714\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8844 - accuracy: 0.3571 - val_loss: 1.0889 - val_accuracy: 0.0714\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8825 - accuracy: 0.3036 - val_loss: 1.0899 - val_accuracy: 0.0714\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8764 - accuracy: 0.3036 - val_loss: 1.0910 - val_accuracy: 0.0714\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8732 - accuracy: 0.3036 - val_loss: 1.0923 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8703 - accuracy: 0.3393 - val_loss: 1.0936 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8636 - accuracy: 0.3214 - val_loss: 1.0950 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8570 - accuracy: 0.3036 - val_loss: 1.0966 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8544 - accuracy: 0.3393 - val_loss: 1.0983 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8516 - accuracy: 0.3036 - val_loss: 1.1002 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8471 - accuracy: 0.3036 - val_loss: 1.1022 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8420 - accuracy: 0.3036 - val_loss: 1.1044 - val_accuracy: 0.0714\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8369 - accuracy: 0.3036 - val_loss: 1.1067 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8336 - accuracy: 0.3036 - val_loss: 1.1092 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8293 - accuracy: 0.2857 - val_loss: 1.1118 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8267 - accuracy: 0.3036 - val_loss: 1.1145 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8224 - accuracy: 0.3214 - val_loss: 1.1172 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8160 - accuracy: 0.3214 - val_loss: 1.1200 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8136 - accuracy: 0.3393 - val_loss: 1.1229 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8086 - accuracy: 0.3214 - val_loss: 1.1259 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8066 - accuracy: 0.3393 - val_loss: 1.1291 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8007 - accuracy: 0.3393 - val_loss: 1.1325 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7984 - accuracy: 0.3393 - val_loss: 1.1361 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7903 - accuracy: 0.3393 - val_loss: 1.1399 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7894 - accuracy: 0.3393 - val_loss: 1.1438 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7904 - accuracy: 0.3571 - val_loss: 1.1479 - val_accuracy: 0.0714\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7858 - accuracy: 0.3393 - val_loss: 1.1522 - val_accuracy: 0.0714\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7815 - accuracy: 0.3393 - val_loss: 1.1566 - val_accuracy: 0.0714\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7808 - accuracy: 0.3214 - val_loss: 1.1610 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7747 - accuracy: 0.3571 - val_loss: 1.1654 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7691 - accuracy: 0.3393 - val_loss: 1.1700 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7669 - accuracy: 0.3393 - val_loss: 1.1746 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7685 - accuracy: 0.3571 - val_loss: 1.1791 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7602 - accuracy: 0.3571 - val_loss: 1.1836 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7570 - accuracy: 0.3214 - val_loss: 1.1880 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7560 - accuracy: 0.3214 - val_loss: 1.1923 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7539 - accuracy: 0.3393 - val_loss: 1.1962 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7492 - accuracy: 0.3393 - val_loss: 1.2000 - val_accuracy: 0.0714\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7528 - accuracy: 0.3571 - val_loss: 1.2036 - val_accuracy: 0.0714\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7469 - accuracy: 0.3214 - val_loss: 1.2070 - val_accuracy: 0.0714\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7445 - accuracy: 0.3393 - val_loss: 1.2103 - val_accuracy: 0.0714\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7430 - accuracy: 0.3393 - val_loss: 1.2134 - val_accuracy: 0.0714\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7405 - accuracy: 0.3393 - val_loss: 1.2163 - val_accuracy: 0.0714\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7307 - accuracy: 0.3214 - val_loss: 1.2190 - val_accuracy: 0.0714\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7381 - accuracy: 0.3393 - val_loss: 1.2215 - val_accuracy: 0.0714\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7372 - accuracy: 0.3214 - val_loss: 1.2238 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7311 - accuracy: 0.3214 - val_loss: 1.2260 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7263 - accuracy: 0.3750 - val_loss: 1.2284 - val_accuracy: 0.0714\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7269 - accuracy: 0.3571 - val_loss: 1.2307 - val_accuracy: 0.0714\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7237 - accuracy: 0.3214 - val_loss: 1.2331 - val_accuracy: 0.0714\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7226 - accuracy: 0.3571 - val_loss: 1.2357 - val_accuracy: 0.0714\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7157 - accuracy: 0.3571 - val_loss: 1.2382 - val_accuracy: 0.0714\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7156 - accuracy: 0.3393 - val_loss: 1.2407 - val_accuracy: 0.0714\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7122 - accuracy: 0.3750 - val_loss: 1.2430 - val_accuracy: 0.0714\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7060 - accuracy: 0.3393 - val_loss: 1.2456 - val_accuracy: 0.0714\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7055 - accuracy: 0.3214 - val_loss: 1.2483 - val_accuracy: 0.0714\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7017 - accuracy: 0.3929 - val_loss: 1.2508 - val_accuracy: 0.0714\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6999 - accuracy: 0.3571 - val_loss: 1.2535 - val_accuracy: 0.0714\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6981 - accuracy: 0.3571 - val_loss: 1.2565 - val_accuracy: 0.0714\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6996 - accuracy: 0.3929 - val_loss: 1.2595 - val_accuracy: 0.0714\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6886 - accuracy: 0.3929 - val_loss: 1.2624 - val_accuracy: 0.0714\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6878 - accuracy: 0.3393 - val_loss: 1.2655 - val_accuracy: 0.0714\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6818 - accuracy: 0.3750 - val_loss: 1.2683 - val_accuracy: 0.0714\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6788 - accuracy: 0.3214 - val_loss: 1.2713 - val_accuracy: 0.0714\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6796 - accuracy: 0.3929 - val_loss: 1.2745 - val_accuracy: 0.0714\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6797 - accuracy: 0.3929 - val_loss: 1.2780 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6764 - accuracy: 0.3571 - val_loss: 1.2821 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6764 - accuracy: 0.3750 - val_loss: 1.2863 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6660 - accuracy: 0.3393 - val_loss: 1.2908 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6632 - accuracy: 0.4107 - val_loss: 1.2951 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6630 - accuracy: 0.3929 - val_loss: 1.2995 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6579 - accuracy: 0.4107 - val_loss: 1.3033 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6524 - accuracy: 0.3929 - val_loss: 1.3071 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6479 - accuracy: 0.3929 - val_loss: 1.3115 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6496 - accuracy: 0.4107 - val_loss: 1.3162 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6487 - accuracy: 0.3929 - val_loss: 1.3213 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6454 - accuracy: 0.3750 - val_loss: 1.3256 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6372 - accuracy: 0.3929 - val_loss: 1.3296 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6316 - accuracy: 0.4107 - val_loss: 1.3338 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6261 - accuracy: 0.4464 - val_loss: 1.3375 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6264 - accuracy: 0.4643 - val_loss: 1.3414 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6200 - accuracy: 0.4464 - val_loss: 1.3456 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6207 - accuracy: 0.4821 - val_loss: 1.3499 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6119 - accuracy: 0.4643 - val_loss: 1.3544 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6110 - accuracy: 0.4643 - val_loss: 1.3588 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6134 - accuracy: 0.4464 - val_loss: 1.3628 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6063 - accuracy: 0.4286 - val_loss: 1.3676 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.5915 - accuracy: 0.4643 - val_loss: 1.3723 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5906 - accuracy: 0.5000 - val_loss: 1.3768 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5942 - accuracy: 0.4464 - val_loss: 1.3805 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.5861 - accuracy: 0.4464 - val_loss: 1.3843 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5844 - accuracy: 0.4107 - val_loss: 1.3878 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5779 - accuracy: 0.4821 - val_loss: 1.3912 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5708 - accuracy: 0.4643 - val_loss: 1.3949 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5687 - accuracy: 0.4464 - val_loss: 1.3987 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3987 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=128, batch_size=400, Scores: [1.3986760377883911, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.3986760377883911\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9866 - accuracy: 0.0893 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9842 - accuracy: 0.0357 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9816 - accuracy: 0.1429 - val_loss: 1.0724 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9802 - accuracy: 0.1429 - val_loss: 1.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9778 - accuracy: 0.1786 - val_loss: 1.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9744 - accuracy: 0.2143 - val_loss: 1.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9724 - accuracy: 0.2679 - val_loss: 1.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9704 - accuracy: 0.1964 - val_loss: 1.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9689 - accuracy: 0.1964 - val_loss: 1.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9666 - accuracy: 0.2500 - val_loss: 1.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9646 - accuracy: 0.2500 - val_loss: 1.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9609 - accuracy: 0.2857 - val_loss: 1.0763 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9592 - accuracy: 0.3214 - val_loss: 1.0768 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9567 - accuracy: 0.2857 - val_loss: 1.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9551 - accuracy: 0.2679 - val_loss: 1.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9523 - accuracy: 0.3750 - val_loss: 1.0783 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9497 - accuracy: 0.2679 - val_loss: 1.0789 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9477 - accuracy: 0.2857 - val_loss: 1.0794 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9460 - accuracy: 0.3571 - val_loss: 1.0800 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9432 - accuracy: 0.3393 - val_loss: 1.0806 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9411 - accuracy: 0.3214 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9382 - accuracy: 0.3036 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9354 - accuracy: 0.3214 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9311 - accuracy: 0.3214 - val_loss: 1.0830 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9282 - accuracy: 0.3214 - val_loss: 1.0837 - val_accuracy: 0.0714\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9268 - accuracy: 0.3214 - val_loss: 1.0845 - val_accuracy: 0.0714\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9239 - accuracy: 0.3393 - val_loss: 1.0852 - val_accuracy: 0.0714\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9204 - accuracy: 0.3214 - val_loss: 1.0861 - val_accuracy: 0.0714\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9155 - accuracy: 0.3214 - val_loss: 1.0870 - val_accuracy: 0.0714\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9132 - accuracy: 0.3393 - val_loss: 1.0880 - val_accuracy: 0.0714\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9091 - accuracy: 0.3036 - val_loss: 1.0891 - val_accuracy: 0.0714\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9056 - accuracy: 0.3214 - val_loss: 1.0903 - val_accuracy: 0.0714\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9024 - accuracy: 0.3393 - val_loss: 1.0916 - val_accuracy: 0.0714\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8992 - accuracy: 0.3393 - val_loss: 1.0930 - val_accuracy: 0.0714\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8974 - accuracy: 0.3036 - val_loss: 1.0946 - val_accuracy: 0.0714\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8914 - accuracy: 0.3393 - val_loss: 1.0964 - val_accuracy: 0.0714\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8856 - accuracy: 0.3571 - val_loss: 1.0983 - val_accuracy: 0.0714\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8835 - accuracy: 0.3214 - val_loss: 1.1004 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8804 - accuracy: 0.3214 - val_loss: 1.1027 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8738 - accuracy: 0.3393 - val_loss: 1.1051 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8708 - accuracy: 0.3214 - val_loss: 1.1077 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8681 - accuracy: 0.3214 - val_loss: 1.1104 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.8656 - accuracy: 0.3571 - val_loss: 1.1133 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8592 - accuracy: 0.3393 - val_loss: 1.1162 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8565 - accuracy: 0.3393 - val_loss: 1.1193 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8518 - accuracy: 0.3214 - val_loss: 1.1225 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8472 - accuracy: 0.3214 - val_loss: 1.1257 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8423 - accuracy: 0.3393 - val_loss: 1.1291 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8394 - accuracy: 0.3393 - val_loss: 1.1325 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8353 - accuracy: 0.3571 - val_loss: 1.1360 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8327 - accuracy: 0.3214 - val_loss: 1.1397 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8253 - accuracy: 0.3214 - val_loss: 1.1434 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8203 - accuracy: 0.3571 - val_loss: 1.1473 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8187 - accuracy: 0.3214 - val_loss: 1.1512 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8173 - accuracy: 0.3214 - val_loss: 1.1552 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8132 - accuracy: 0.3393 - val_loss: 1.1591 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8074 - accuracy: 0.3214 - val_loss: 1.1631 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8016 - accuracy: 0.3036 - val_loss: 1.1671 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7975 - accuracy: 0.3393 - val_loss: 1.1710 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7960 - accuracy: 0.3214 - val_loss: 1.1748 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7917 - accuracy: 0.3393 - val_loss: 1.1784 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7873 - accuracy: 0.2857 - val_loss: 1.1820 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7857 - accuracy: 0.3214 - val_loss: 1.1856 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7800 - accuracy: 0.3036 - val_loss: 1.1889 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7825 - accuracy: 0.3036 - val_loss: 1.1921 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7737 - accuracy: 0.2857 - val_loss: 1.1949 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7705 - accuracy: 0.2857 - val_loss: 1.1975 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7663 - accuracy: 0.2857 - val_loss: 1.2000 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7662 - accuracy: 0.2857 - val_loss: 1.2022 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7603 - accuracy: 0.2857 - val_loss: 1.2042 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7570 - accuracy: 0.2857 - val_loss: 1.2059 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7565 - accuracy: 0.2857 - val_loss: 1.2076 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7505 - accuracy: 0.3036 - val_loss: 1.2093 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7453 - accuracy: 0.3036 - val_loss: 1.2108 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7403 - accuracy: 0.2857 - val_loss: 1.2124 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7387 - accuracy: 0.2857 - val_loss: 1.2136 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7331 - accuracy: 0.2857 - val_loss: 1.2149 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7337 - accuracy: 0.3393 - val_loss: 1.2162 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7249 - accuracy: 0.3214 - val_loss: 1.2174 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7188 - accuracy: 0.2857 - val_loss: 1.2187 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7175 - accuracy: 0.3214 - val_loss: 1.2200 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7150 - accuracy: 0.3036 - val_loss: 1.2209 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7127 - accuracy: 0.3036 - val_loss: 1.2218 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7048 - accuracy: 0.3750 - val_loss: 1.2229 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7048 - accuracy: 0.3036 - val_loss: 1.2244 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.6999 - accuracy: 0.3393 - val_loss: 1.2260 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7035 - accuracy: 0.3750 - val_loss: 1.2279 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6927 - accuracy: 0.3393 - val_loss: 1.2302 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6934 - accuracy: 0.3571 - val_loss: 1.2327 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6908 - accuracy: 0.3393 - val_loss: 1.2353 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6822 - accuracy: 0.3393 - val_loss: 1.2382 - val_accuracy: 0.2143\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6765 - accuracy: 0.3750 - val_loss: 1.2414 - val_accuracy: 0.2143\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6786 - accuracy: 0.3571 - val_loss: 1.2456 - val_accuracy: 0.2143\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6713 - accuracy: 0.3393 - val_loss: 1.2500 - val_accuracy: 0.2143\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6647 - accuracy: 0.3571 - val_loss: 1.2544 - val_accuracy: 0.2143\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6616 - accuracy: 0.3571 - val_loss: 1.2588 - val_accuracy: 0.2143\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6563 - accuracy: 0.3571 - val_loss: 1.2629 - val_accuracy: 0.2143\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6600 - accuracy: 0.3571 - val_loss: 1.2673 - val_accuracy: 0.2143\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6516 - accuracy: 0.3214 - val_loss: 1.2715 - val_accuracy: 0.2143\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6485 - accuracy: 0.4107 - val_loss: 1.2760 - val_accuracy: 0.2143\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6420 - accuracy: 0.3929 - val_loss: 1.2805 - val_accuracy: 0.2143\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6409 - accuracy: 0.3750 - val_loss: 1.2855 - val_accuracy: 0.2143\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6368 - accuracy: 0.4107 - val_loss: 1.2908 - val_accuracy: 0.2143\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6358 - accuracy: 0.3571 - val_loss: 1.2962 - val_accuracy: 0.2143\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6270 - accuracy: 0.3750 - val_loss: 1.3019 - val_accuracy: 0.2143\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.6243 - accuracy: 0.3750 - val_loss: 1.3074 - val_accuracy: 0.2143\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6203 - accuracy: 0.3571 - val_loss: 1.3123 - val_accuracy: 0.2143\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6148 - accuracy: 0.3571 - val_loss: 1.3172 - val_accuracy: 0.2143\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6150 - accuracy: 0.3750 - val_loss: 1.3230 - val_accuracy: 0.2143\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6094 - accuracy: 0.3571 - val_loss: 1.3294 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6046 - accuracy: 0.3750 - val_loss: 1.3361 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6018 - accuracy: 0.4107 - val_loss: 1.3419 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5990 - accuracy: 0.4107 - val_loss: 1.3484 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5913 - accuracy: 0.3750 - val_loss: 1.3551 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5880 - accuracy: 0.3929 - val_loss: 1.3613 - val_accuracy: 0.1429\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5854 - accuracy: 0.3750 - val_loss: 1.3667 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5843 - accuracy: 0.4107 - val_loss: 1.3724 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.5795 - accuracy: 0.3929 - val_loss: 1.3794 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5737 - accuracy: 0.4286 - val_loss: 1.3872 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5678 - accuracy: 0.3750 - val_loss: 1.3949 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5646 - accuracy: 0.3929 - val_loss: 1.4030 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5588 - accuracy: 0.4464 - val_loss: 1.4093 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.5536 - accuracy: 0.3929 - val_loss: 1.4150 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5573 - accuracy: 0.3929 - val_loss: 1.4207 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5599 - accuracy: 0.3929 - val_loss: 1.4255 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5500 - accuracy: 0.4286 - val_loss: 1.4293 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5491 - accuracy: 0.4107 - val_loss: 1.4331 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5369 - accuracy: 0.3750 - val_loss: 1.4361 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4361 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=128, batch_size=500, Scores: [1.4360688924789429, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.4360688924789429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9847 - accuracy: 0.1071 - val_loss: 1.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9819 - accuracy: 0.1429 - val_loss: 1.0711 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9808 - accuracy: 0.1607 - val_loss: 1.0717 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9773 - accuracy: 0.2321 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9754 - accuracy: 0.1786 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9735 - accuracy: 0.2143 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9707 - accuracy: 0.2321 - val_loss: 1.0743 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9694 - accuracy: 0.2143 - val_loss: 1.0750 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9665 - accuracy: 0.3393 - val_loss: 1.0757 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9643 - accuracy: 0.2500 - val_loss: 1.0765 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9618 - accuracy: 0.2500 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9599 - accuracy: 0.2857 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9578 - accuracy: 0.2679 - val_loss: 1.0789 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9548 - accuracy: 0.2500 - val_loss: 1.0798 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9530 - accuracy: 0.2500 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9504 - accuracy: 0.2321 - val_loss: 1.0816 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9477 - accuracy: 0.2679 - val_loss: 1.0825 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9452 - accuracy: 0.2679 - val_loss: 1.0835 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9422 - accuracy: 0.2679 - val_loss: 1.0845 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9406 - accuracy: 0.2679 - val_loss: 1.0855 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9369 - accuracy: 0.2500 - val_loss: 1.0866 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9364 - accuracy: 0.2500 - val_loss: 1.0878 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9322 - accuracy: 0.2679 - val_loss: 1.0889 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9281 - accuracy: 0.2679 - val_loss: 1.0902 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9257 - accuracy: 0.2857 - val_loss: 1.0914 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9230 - accuracy: 0.2679 - val_loss: 1.0927 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9202 - accuracy: 0.2500 - val_loss: 1.0941 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9171 - accuracy: 0.2500 - val_loss: 1.0955 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9131 - accuracy: 0.2857 - val_loss: 1.0969 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9104 - accuracy: 0.3036 - val_loss: 1.0984 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9061 - accuracy: 0.3214 - val_loss: 1.0999 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9027 - accuracy: 0.2679 - val_loss: 1.1015 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8990 - accuracy: 0.2500 - val_loss: 1.1032 - val_accuracy: 0.0714\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8951 - accuracy: 0.2500 - val_loss: 1.1049 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8913 - accuracy: 0.2321 - val_loss: 1.1067 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8867 - accuracy: 0.2500 - val_loss: 1.1085 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8839 - accuracy: 0.3036 - val_loss: 1.1104 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8790 - accuracy: 0.3214 - val_loss: 1.1124 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8749 - accuracy: 0.2857 - val_loss: 1.1145 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8719 - accuracy: 0.2679 - val_loss: 1.1166 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8675 - accuracy: 0.3036 - val_loss: 1.1188 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8613 - accuracy: 0.2857 - val_loss: 1.1211 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8572 - accuracy: 0.3036 - val_loss: 1.1235 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8523 - accuracy: 0.3214 - val_loss: 1.1259 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8477 - accuracy: 0.2857 - val_loss: 1.1284 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8438 - accuracy: 0.3393 - val_loss: 1.1309 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8374 - accuracy: 0.3393 - val_loss: 1.1335 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8338 - accuracy: 0.3393 - val_loss: 1.1362 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8265 - accuracy: 0.3750 - val_loss: 1.1389 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8237 - accuracy: 0.3571 - val_loss: 1.1416 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8193 - accuracy: 0.3036 - val_loss: 1.1444 - val_accuracy: 0.2143\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8151 - accuracy: 0.3571 - val_loss: 1.1472 - val_accuracy: 0.2143\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8107 - accuracy: 0.3393 - val_loss: 1.1500 - val_accuracy: 0.2143\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8040 - accuracy: 0.3214 - val_loss: 1.1529 - val_accuracy: 0.2143\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8001 - accuracy: 0.3214 - val_loss: 1.1557 - val_accuracy: 0.2143\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.7969 - accuracy: 0.3571 - val_loss: 1.1585 - val_accuracy: 0.2143\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7937 - accuracy: 0.3214 - val_loss: 1.1615 - val_accuracy: 0.2143\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7868 - accuracy: 0.3571 - val_loss: 1.1645 - val_accuracy: 0.2143\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7812 - accuracy: 0.3571 - val_loss: 1.1676 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7810 - accuracy: 0.3571 - val_loss: 1.1706 - val_accuracy: 0.2143\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7734 - accuracy: 0.3750 - val_loss: 1.1738 - val_accuracy: 0.2143\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7723 - accuracy: 0.3571 - val_loss: 1.1772 - val_accuracy: 0.2143\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7702 - accuracy: 0.3929 - val_loss: 1.1808 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7627 - accuracy: 0.3750 - val_loss: 1.1846 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7615 - accuracy: 0.3750 - val_loss: 1.1885 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7621 - accuracy: 0.3929 - val_loss: 1.1923 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7590 - accuracy: 0.3750 - val_loss: 1.1961 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7525 - accuracy: 0.3929 - val_loss: 1.1996 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7485 - accuracy: 0.3929 - val_loss: 1.2030 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7446 - accuracy: 0.3571 - val_loss: 1.2063 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7444 - accuracy: 0.3750 - val_loss: 1.2091 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7397 - accuracy: 0.3750 - val_loss: 1.2118 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7434 - accuracy: 0.3393 - val_loss: 1.2143 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7418 - accuracy: 0.3929 - val_loss: 1.2164 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7316 - accuracy: 0.3750 - val_loss: 1.2185 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7327 - accuracy: 0.3750 - val_loss: 1.2207 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7260 - accuracy: 0.3750 - val_loss: 1.2227 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7269 - accuracy: 0.3571 - val_loss: 1.2246 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7233 - accuracy: 0.3571 - val_loss: 1.2262 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7247 - accuracy: 0.3750 - val_loss: 1.2279 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7195 - accuracy: 0.3750 - val_loss: 1.2299 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7137 - accuracy: 0.3750 - val_loss: 1.2325 - val_accuracy: 0.1429\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7140 - accuracy: 0.3571 - val_loss: 1.2351 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7085 - accuracy: 0.3929 - val_loss: 1.2377 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7045 - accuracy: 0.3750 - val_loss: 1.2403 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7015 - accuracy: 0.3750 - val_loss: 1.2428 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6959 - accuracy: 0.3929 - val_loss: 1.2454 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6990 - accuracy: 0.4107 - val_loss: 1.2483 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6923 - accuracy: 0.3750 - val_loss: 1.2511 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.6907 - accuracy: 0.4107 - val_loss: 1.2539 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6910 - accuracy: 0.3929 - val_loss: 1.2568 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6837 - accuracy: 0.3929 - val_loss: 1.2596 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6800 - accuracy: 0.4286 - val_loss: 1.2627 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6815 - accuracy: 0.4107 - val_loss: 1.2659 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.6775 - accuracy: 0.3929 - val_loss: 1.2691 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6767 - accuracy: 0.4286 - val_loss: 1.2722 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6716 - accuracy: 0.4286 - val_loss: 1.2755 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6693 - accuracy: 0.4107 - val_loss: 1.2791 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6643 - accuracy: 0.4107 - val_loss: 1.2826 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6642 - accuracy: 0.3929 - val_loss: 1.2858 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6575 - accuracy: 0.4107 - val_loss: 1.2889 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6520 - accuracy: 0.4286 - val_loss: 1.2920 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6482 - accuracy: 0.4286 - val_loss: 1.2959 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6440 - accuracy: 0.4286 - val_loss: 1.2997 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6448 - accuracy: 0.4286 - val_loss: 1.3034 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6384 - accuracy: 0.4464 - val_loss: 1.3067 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.6365 - accuracy: 0.4643 - val_loss: 1.3094 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6380 - accuracy: 0.4286 - val_loss: 1.3122 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6345 - accuracy: 0.4464 - val_loss: 1.3147 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6295 - accuracy: 0.4464 - val_loss: 1.3170 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6205 - accuracy: 0.4464 - val_loss: 1.3198 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6122 - accuracy: 0.4643 - val_loss: 1.3237 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6135 - accuracy: 0.4464 - val_loss: 1.3280 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6167 - accuracy: 0.4464 - val_loss: 1.3327 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6078 - accuracy: 0.4286 - val_loss: 1.3377 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6064 - accuracy: 0.4643 - val_loss: 1.3437 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5997 - accuracy: 0.4464 - val_loss: 1.3497 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5965 - accuracy: 0.4464 - val_loss: 1.3557 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5855 - accuracy: 0.4643 - val_loss: 1.3603 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.5852 - accuracy: 0.4464 - val_loss: 1.3645 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5827 - accuracy: 0.4464 - val_loss: 1.3682 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5759 - accuracy: 0.4643 - val_loss: 1.3714 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5755 - accuracy: 0.4643 - val_loss: 1.3747 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5781 - accuracy: 0.4464 - val_loss: 1.3777 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5684 - accuracy: 0.4464 - val_loss: 1.3815 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.5701 - accuracy: 0.5000 - val_loss: 1.3861 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.5610 - accuracy: 0.4821 - val_loss: 1.3910 - val_accuracy: 0.2143\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5535 - accuracy: 0.4821 - val_loss: 1.3971 - val_accuracy: 0.2143\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5513 - accuracy: 0.4643 - val_loss: 1.4039 - val_accuracy: 0.2143\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5447 - accuracy: 0.4821 - val_loss: 1.4104 - val_accuracy: 0.2143\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5498 - accuracy: 0.4643 - val_loss: 1.4167 - val_accuracy: 0.2143\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5391 - accuracy: 0.4464 - val_loss: 1.4214 - val_accuracy: 0.2143\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5370 - accuracy: 0.4464 - val_loss: 1.4265 - val_accuracy: 0.2143\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.5302 - accuracy: 0.4464 - val_loss: 1.4313 - val_accuracy: 0.2143\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5314 - accuracy: 0.4643 - val_loss: 1.4355 - val_accuracy: 0.2143\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.5233 - accuracy: 0.4821 - val_loss: 1.4387 - val_accuracy: 0.2143\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5190 - accuracy: 0.4464 - val_loss: 1.4419 - val_accuracy: 0.2143\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5124 - accuracy: 0.4286 - val_loss: 1.4447 - val_accuracy: 0.2143\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5186 - accuracy: 0.4464 - val_loss: 1.4470 - val_accuracy: 0.2143\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5105 - accuracy: 0.4107 - val_loss: 1.4487 - val_accuracy: 0.2143\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.5015 - accuracy: 0.4821 - val_loss: 1.4505 - val_accuracy: 0.2143\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4999 - accuracy: 0.4821 - val_loss: 1.4531 - val_accuracy: 0.2143\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4946 - accuracy: 0.4464 - val_loss: 1.4556 - val_accuracy: 0.2143\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4920 - accuracy: 0.4464 - val_loss: 1.4601 - val_accuracy: 0.2143\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4881 - accuracy: 0.4643 - val_loss: 1.4658 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4825 - accuracy: 0.4286 - val_loss: 1.4713 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4840 - accuracy: 0.4464 - val_loss: 1.4752 - val_accuracy: 0.1429\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4767 - accuracy: 0.4643 - val_loss: 1.4773 - val_accuracy: 0.1429\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4594 - accuracy: 0.4464 - val_loss: 1.4805 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.4522 - accuracy: 0.4821 - val_loss: 1.4843 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4580 - accuracy: 0.4464 - val_loss: 1.4888 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4561 - accuracy: 0.4821 - val_loss: 1.4941 - val_accuracy: 0.1429\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4552 - accuracy: 0.4643 - val_loss: 1.4974 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4529 - accuracy: 0.4643 - val_loss: 1.4983 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4460 - accuracy: 0.4464 - val_loss: 1.4988 - val_accuracy: 0.1429\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4398 - accuracy: 0.5000 - val_loss: 1.4994 - val_accuracy: 0.1429\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4422 - accuracy: 0.4643 - val_loss: 1.5023 - val_accuracy: 0.1429\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.4293 - accuracy: 0.5000 - val_loss: 1.5045 - val_accuracy: 0.1429\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4295 - accuracy: 0.4464 - val_loss: 1.5075 - val_accuracy: 0.1429\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4290 - accuracy: 0.4643 - val_loss: 1.5082 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4126 - accuracy: 0.4643 - val_loss: 1.5057 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4215 - accuracy: 0.4821 - val_loss: 1.5030 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4073 - accuracy: 0.5000 - val_loss: 1.5010 - val_accuracy: 0.1429\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.4157 - accuracy: 0.4821 - val_loss: 1.5004 - val_accuracy: 0.1429\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4048 - accuracy: 0.5179 - val_loss: 1.5008 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3995 - accuracy: 0.5357 - val_loss: 1.5039 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3846 - accuracy: 0.5000 - val_loss: 1.5097 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3903 - accuracy: 0.4821 - val_loss: 1.5148 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3901 - accuracy: 0.4821 - val_loss: 1.5202 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3732 - accuracy: 0.5357 - val_loss: 1.5247 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3844 - accuracy: 0.4286 - val_loss: 1.5274 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3659 - accuracy: 0.5536 - val_loss: 1.5276 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3775 - accuracy: 0.5000 - val_loss: 1.5257 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3626 - accuracy: 0.5536 - val_loss: 1.5239 - val_accuracy: 0.1429\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3600 - accuracy: 0.5179 - val_loss: 1.5237 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3519 - accuracy: 0.5357 - val_loss: 1.5232 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3485 - accuracy: 0.5179 - val_loss: 1.5252 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3456 - accuracy: 0.5536 - val_loss: 1.5313 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3469 - accuracy: 0.5714 - val_loss: 1.5360 - val_accuracy: 0.1429\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3378 - accuracy: 0.5357 - val_loss: 1.5387 - val_accuracy: 0.1429\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3316 - accuracy: 0.6250 - val_loss: 1.5357 - val_accuracy: 0.1429\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.3392 - accuracy: 0.5000 - val_loss: 1.5299 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3317 - accuracy: 0.6429 - val_loss: 1.5224 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3272 - accuracy: 0.5714 - val_loss: 1.5168 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3287 - accuracy: 0.5357 - val_loss: 1.5149 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3334 - accuracy: 0.6250 - val_loss: 1.5195 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3374 - accuracy: 0.5714 - val_loss: 1.5307 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3167 - accuracy: 0.5536 - val_loss: 1.5439 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3030 - accuracy: 0.6071 - val_loss: 1.5596 - val_accuracy: 0.1429\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3080 - accuracy: 0.6250 - val_loss: 1.5691 - val_accuracy: 0.1429\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3126 - accuracy: 0.5893 - val_loss: 1.5738 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3073 - accuracy: 0.5536 - val_loss: 1.5719 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3086 - accuracy: 0.5714 - val_loss: 1.5681 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3028 - accuracy: 0.5893 - val_loss: 1.5633 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2994 - accuracy: 0.5357 - val_loss: 1.5654 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3005 - accuracy: 0.6071 - val_loss: 1.5772 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2912 - accuracy: 0.6071 - val_loss: 1.5928 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2847 - accuracy: 0.5893 - val_loss: 1.6057 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2912 - accuracy: 0.5893 - val_loss: 1.6123 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2885 - accuracy: 0.5536 - val_loss: 1.6155 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2797 - accuracy: 0.6071 - val_loss: 1.6111 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2762 - accuracy: 0.5714 - val_loss: 1.6065 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2705 - accuracy: 0.5714 - val_loss: 1.6041 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2826 - accuracy: 0.5893 - val_loss: 1.6009 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2638 - accuracy: 0.6250 - val_loss: 1.6021 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2827 - accuracy: 0.6607 - val_loss: 1.5993 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2702 - accuracy: 0.6250 - val_loss: 1.5973 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2561 - accuracy: 0.6429 - val_loss: 1.5984 - val_accuracy: 0.1429\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2530 - accuracy: 0.5714 - val_loss: 1.5997 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2694 - accuracy: 0.6071 - val_loss: 1.5989 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2459 - accuracy: 0.6429 - val_loss: 1.5986 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2594 - accuracy: 0.6607 - val_loss: 1.6014 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2461 - accuracy: 0.6429 - val_loss: 1.6028 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2519 - accuracy: 0.6429 - val_loss: 1.6062 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2329 - accuracy: 0.5893 - val_loss: 1.6050 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2410 - accuracy: 0.6607 - val_loss: 1.6046 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2483 - accuracy: 0.6071 - val_loss: 1.6060 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2376 - accuracy: 0.6607 - val_loss: 1.6119 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2352 - accuracy: 0.6071 - val_loss: 1.6156 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2354 - accuracy: 0.6607 - val_loss: 1.6199 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2346 - accuracy: 0.6429 - val_loss: 1.6258 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.2325 - accuracy: 0.6250 - val_loss: 1.6268 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2253 - accuracy: 0.6607 - val_loss: 1.6229 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2277 - accuracy: 0.6786 - val_loss: 1.6156 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2219 - accuracy: 0.6964 - val_loss: 1.6050 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2136 - accuracy: 0.6607 - val_loss: 1.5976 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2024 - accuracy: 0.6250 - val_loss: 1.5928 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2174 - accuracy: 0.6786 - val_loss: 1.5945 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2065 - accuracy: 0.6071 - val_loss: 1.5933 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2063 - accuracy: 0.7321 - val_loss: 1.5991 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.2084 - accuracy: 0.6071 - val_loss: 1.6068 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1973 - accuracy: 0.6607 - val_loss: 1.6173 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2051 - accuracy: 0.7143 - val_loss: 1.6263 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1996 - accuracy: 0.7321 - val_loss: 1.6236 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2046 - accuracy: 0.6250 - val_loss: 1.6190 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2001 - accuracy: 0.6071 - val_loss: 1.6062 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1959 - accuracy: 0.7143 - val_loss: 1.5899 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1952 - accuracy: 0.6607 - val_loss: 1.5820 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1914 - accuracy: 0.6607 - val_loss: 1.5771 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1888 - accuracy: 0.6250 - val_loss: 1.5761 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5761 - accuracy: 0.0000e+00\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=240, batch_size=100, Scores: [1.5760843753814697, 0.0]\n",
      "Accuracy on validation set: 0.0\n",
      "Loss on validation set: 1.5760843753814697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9829 - accuracy: 0.1071 - val_loss: 1.0700 - val_accuracy: 0.2857\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9809 - accuracy: 0.1429 - val_loss: 1.0705 - val_accuracy: 0.2857\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9780 - accuracy: 0.1429 - val_loss: 1.0711 - val_accuracy: 0.2143\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9766 - accuracy: 0.1071 - val_loss: 1.0717 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9732 - accuracy: 0.1964 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9724 - accuracy: 0.1964 - val_loss: 1.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9698 - accuracy: 0.1786 - val_loss: 1.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9670 - accuracy: 0.2143 - val_loss: 1.0743 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9652 - accuracy: 0.2857 - val_loss: 1.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9626 - accuracy: 0.2500 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9613 - accuracy: 0.2857 - val_loss: 1.0765 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9585 - accuracy: 0.3036 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9567 - accuracy: 0.3036 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9530 - accuracy: 0.3036 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9523 - accuracy: 0.2500 - val_loss: 1.0799 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9495 - accuracy: 0.2679 - val_loss: 1.0808 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9469 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9448 - accuracy: 0.2857 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9418 - accuracy: 0.2500 - val_loss: 1.0838 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9394 - accuracy: 0.2857 - val_loss: 1.0848 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9370 - accuracy: 0.3036 - val_loss: 1.0859 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9343 - accuracy: 0.2857 - val_loss: 1.0870 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9309 - accuracy: 0.3036 - val_loss: 1.0882 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9291 - accuracy: 0.3214 - val_loss: 1.0893 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9252 - accuracy: 0.3036 - val_loss: 1.0906 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9224 - accuracy: 0.3214 - val_loss: 1.0919 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9194 - accuracy: 0.3214 - val_loss: 1.0932 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9166 - accuracy: 0.3036 - val_loss: 1.0945 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9135 - accuracy: 0.3214 - val_loss: 1.0959 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9101 - accuracy: 0.3036 - val_loss: 1.0974 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9069 - accuracy: 0.2679 - val_loss: 1.0989 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9021 - accuracy: 0.3036 - val_loss: 1.1005 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9002 - accuracy: 0.2857 - val_loss: 1.1022 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8955 - accuracy: 0.3214 - val_loss: 1.1039 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8919 - accuracy: 0.2679 - val_loss: 1.1057 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8879 - accuracy: 0.2857 - val_loss: 1.1076 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8847 - accuracy: 0.2857 - val_loss: 1.1096 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8788 - accuracy: 0.3036 - val_loss: 1.1116 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8768 - accuracy: 0.2857 - val_loss: 1.1137 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8737 - accuracy: 0.3214 - val_loss: 1.1159 - val_accuracy: 0.2143\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8683 - accuracy: 0.3036 - val_loss: 1.1181 - val_accuracy: 0.2143\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8635 - accuracy: 0.3214 - val_loss: 1.1205 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8595 - accuracy: 0.2857 - val_loss: 1.1228 - val_accuracy: 0.2143\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8542 - accuracy: 0.3214 - val_loss: 1.1252 - val_accuracy: 0.2143\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8514 - accuracy: 0.3393 - val_loss: 1.1277 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8460 - accuracy: 0.3393 - val_loss: 1.1302 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8429 - accuracy: 0.3750 - val_loss: 1.1328 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.8380 - accuracy: 0.2857 - val_loss: 1.1354 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.8341 - accuracy: 0.3214 - val_loss: 1.1380 - val_accuracy: 0.2143\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8312 - accuracy: 0.3393 - val_loss: 1.1406 - val_accuracy: 0.2143\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8265 - accuracy: 0.3571 - val_loss: 1.1432 - val_accuracy: 0.2143\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8230 - accuracy: 0.3571 - val_loss: 1.1456 - val_accuracy: 0.2143\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8185 - accuracy: 0.3571 - val_loss: 1.1481 - val_accuracy: 0.2143\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8123 - accuracy: 0.3571 - val_loss: 1.1505 - val_accuracy: 0.2143\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8052 - accuracy: 0.3571 - val_loss: 1.1529 - val_accuracy: 0.2143\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8058 - accuracy: 0.3571 - val_loss: 1.1554 - val_accuracy: 0.2143\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7985 - accuracy: 0.3571 - val_loss: 1.1579 - val_accuracy: 0.2143\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7955 - accuracy: 0.3571 - val_loss: 1.1603 - val_accuracy: 0.2143\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7943 - accuracy: 0.3571 - val_loss: 1.1629 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7859 - accuracy: 0.3214 - val_loss: 1.1657 - val_accuracy: 0.2143\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7842 - accuracy: 0.3571 - val_loss: 1.1687 - val_accuracy: 0.2143\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7782 - accuracy: 0.3571 - val_loss: 1.1719 - val_accuracy: 0.2143\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7723 - accuracy: 0.3571 - val_loss: 1.1753 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7697 - accuracy: 0.3571 - val_loss: 1.1790 - val_accuracy: 0.2143\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7662 - accuracy: 0.3571 - val_loss: 1.1828 - val_accuracy: 0.2143\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7682 - accuracy: 0.3214 - val_loss: 1.1868 - val_accuracy: 0.2143\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7613 - accuracy: 0.3036 - val_loss: 1.1913 - val_accuracy: 0.2143\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7569 - accuracy: 0.3214 - val_loss: 1.1963 - val_accuracy: 0.2143\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.7521 - accuracy: 0.3750 - val_loss: 1.2016 - val_accuracy: 0.2143\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7505 - accuracy: 0.3036 - val_loss: 1.2068 - val_accuracy: 0.2143\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7440 - accuracy: 0.3393 - val_loss: 1.2121 - val_accuracy: 0.2143\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7420 - accuracy: 0.3393 - val_loss: 1.2177 - val_accuracy: 0.2143\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7380 - accuracy: 0.3571 - val_loss: 1.2235 - val_accuracy: 0.2143\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7378 - accuracy: 0.3214 - val_loss: 1.2292 - val_accuracy: 0.2143\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7301 - accuracy: 0.3750 - val_loss: 1.2346 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.7263 - accuracy: 0.3571 - val_loss: 1.2397 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7273 - accuracy: 0.3393 - val_loss: 1.2443 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7239 - accuracy: 0.3393 - val_loss: 1.2484 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7193 - accuracy: 0.3393 - val_loss: 1.2523 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7198 - accuracy: 0.3571 - val_loss: 1.2558 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7103 - accuracy: 0.3393 - val_loss: 1.2594 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7067 - accuracy: 0.3571 - val_loss: 1.2627 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7029 - accuracy: 0.3571 - val_loss: 1.2662 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7025 - accuracy: 0.3393 - val_loss: 1.2698 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7014 - accuracy: 0.3750 - val_loss: 1.2735 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7012 - accuracy: 0.3393 - val_loss: 1.2769 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6918 - accuracy: 0.3571 - val_loss: 1.2803 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6872 - accuracy: 0.3214 - val_loss: 1.2838 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6858 - accuracy: 0.3393 - val_loss: 1.2869 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.6761 - accuracy: 0.3571 - val_loss: 1.2903 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6761 - accuracy: 0.3393 - val_loss: 1.2935 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6791 - accuracy: 0.3393 - val_loss: 1.2971 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6784 - accuracy: 0.3214 - val_loss: 1.3013 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6716 - accuracy: 0.3214 - val_loss: 1.3055 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6656 - accuracy: 0.3571 - val_loss: 1.3095 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6642 - accuracy: 0.3393 - val_loss: 1.3137 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6604 - accuracy: 0.3214 - val_loss: 1.3182 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6598 - accuracy: 0.3571 - val_loss: 1.3228 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6538 - accuracy: 0.3750 - val_loss: 1.3274 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6479 - accuracy: 0.3571 - val_loss: 1.3316 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6412 - accuracy: 0.3571 - val_loss: 1.3361 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6406 - accuracy: 0.3750 - val_loss: 1.3407 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6341 - accuracy: 0.3750 - val_loss: 1.3452 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6337 - accuracy: 0.3929 - val_loss: 1.3498 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6253 - accuracy: 0.3393 - val_loss: 1.3545 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6219 - accuracy: 0.3750 - val_loss: 1.3602 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6196 - accuracy: 0.3750 - val_loss: 1.3655 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6095 - accuracy: 0.3929 - val_loss: 1.3721 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6111 - accuracy: 0.4286 - val_loss: 1.3800 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6012 - accuracy: 0.3929 - val_loss: 1.3877 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6080 - accuracy: 0.3929 - val_loss: 1.3965 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5997 - accuracy: 0.3929 - val_loss: 1.4051 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5975 - accuracy: 0.4107 - val_loss: 1.4143 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5907 - accuracy: 0.4107 - val_loss: 1.4231 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5876 - accuracy: 0.4464 - val_loss: 1.4316 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5898 - accuracy: 0.4107 - val_loss: 1.4407 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5735 - accuracy: 0.3750 - val_loss: 1.4507 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5799 - accuracy: 0.3929 - val_loss: 1.4610 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.5692 - accuracy: 0.4464 - val_loss: 1.4716 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5654 - accuracy: 0.4464 - val_loss: 1.4813 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5593 - accuracy: 0.4464 - val_loss: 1.4916 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5563 - accuracy: 0.4286 - val_loss: 1.5006 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5566 - accuracy: 0.4107 - val_loss: 1.5097 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.5508 - accuracy: 0.4107 - val_loss: 1.5177 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5438 - accuracy: 0.4107 - val_loss: 1.5242 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.5433 - accuracy: 0.3750 - val_loss: 1.5314 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5242 - accuracy: 0.4286 - val_loss: 1.5388 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5297 - accuracy: 0.4286 - val_loss: 1.5438 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5278 - accuracy: 0.4286 - val_loss: 1.5477 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5251 - accuracy: 0.4286 - val_loss: 1.5508 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5200 - accuracy: 0.4286 - val_loss: 1.5541 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.5194 - accuracy: 0.4107 - val_loss: 1.5574 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5137 - accuracy: 0.3929 - val_loss: 1.5625 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4993 - accuracy: 0.4286 - val_loss: 1.5701 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5063 - accuracy: 0.4107 - val_loss: 1.5763 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5038 - accuracy: 0.3929 - val_loss: 1.5820 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4991 - accuracy: 0.4107 - val_loss: 1.5842 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4849 - accuracy: 0.4286 - val_loss: 1.5862 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4910 - accuracy: 0.4286 - val_loss: 1.5907 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4756 - accuracy: 0.4643 - val_loss: 1.5961 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4768 - accuracy: 0.4286 - val_loss: 1.6016 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4775 - accuracy: 0.4464 - val_loss: 1.6046 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4702 - accuracy: 0.4286 - val_loss: 1.6101 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4624 - accuracy: 0.4464 - val_loss: 1.6132 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4557 - accuracy: 0.4643 - val_loss: 1.6110 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4479 - accuracy: 0.4286 - val_loss: 1.6125 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4613 - accuracy: 0.4286 - val_loss: 1.6139 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4427 - accuracy: 0.4464 - val_loss: 1.6163 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4375 - accuracy: 0.4643 - val_loss: 1.6225 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4449 - accuracy: 0.4821 - val_loss: 1.6296 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4267 - accuracy: 0.4821 - val_loss: 1.6350 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4255 - accuracy: 0.4643 - val_loss: 1.6395 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.4352 - accuracy: 0.4464 - val_loss: 1.6396 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4151 - accuracy: 0.4643 - val_loss: 1.6374 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4183 - accuracy: 0.4643 - val_loss: 1.6355 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4140 - accuracy: 0.4464 - val_loss: 1.6363 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4063 - accuracy: 0.4643 - val_loss: 1.6383 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4077 - accuracy: 0.4464 - val_loss: 1.6408 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3924 - accuracy: 0.4643 - val_loss: 1.6459 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4044 - accuracy: 0.4286 - val_loss: 1.6458 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4028 - accuracy: 0.4464 - val_loss: 1.6450 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3858 - accuracy: 0.4643 - val_loss: 1.6468 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3869 - accuracy: 0.5357 - val_loss: 1.6504 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3702 - accuracy: 0.5179 - val_loss: 1.6510 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3711 - accuracy: 0.4821 - val_loss: 1.6538 - val_accuracy: 0.0714\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3704 - accuracy: 0.5179 - val_loss: 1.6536 - val_accuracy: 0.0714\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3709 - accuracy: 0.5179 - val_loss: 1.6499 - val_accuracy: 0.0714\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3623 - accuracy: 0.5357 - val_loss: 1.6425 - val_accuracy: 0.0714\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3621 - accuracy: 0.4464 - val_loss: 1.6335 - val_accuracy: 0.0714\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.3477 - accuracy: 0.5536 - val_loss: 1.6231 - val_accuracy: 0.0714\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3581 - accuracy: 0.5357 - val_loss: 1.6182 - val_accuracy: 0.0714\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3497 - accuracy: 0.5179 - val_loss: 1.6204 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3507 - accuracy: 0.5179 - val_loss: 1.6302 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3480 - accuracy: 0.5179 - val_loss: 1.6441 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3432 - accuracy: 0.5893 - val_loss: 1.6545 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3372 - accuracy: 0.5536 - val_loss: 1.6551 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3384 - accuracy: 0.5714 - val_loss: 1.6528 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3319 - accuracy: 0.5893 - val_loss: 1.6458 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3229 - accuracy: 0.5357 - val_loss: 1.6340 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3171 - accuracy: 0.6429 - val_loss: 1.6223 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3145 - accuracy: 0.5179 - val_loss: 1.6149 - val_accuracy: 0.0714\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.3219 - accuracy: 0.5536 - val_loss: 1.6146 - val_accuracy: 0.0714\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3201 - accuracy: 0.5357 - val_loss: 1.6157 - val_accuracy: 0.0714\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3049 - accuracy: 0.5357 - val_loss: 1.6178 - val_accuracy: 0.0714\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3180 - accuracy: 0.5357 - val_loss: 1.6246 - val_accuracy: 0.0714\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3047 - accuracy: 0.5893 - val_loss: 1.6260 - val_accuracy: 0.0714\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3012 - accuracy: 0.6250 - val_loss: 1.6254 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2913 - accuracy: 0.5893 - val_loss: 1.6218 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2966 - accuracy: 0.6071 - val_loss: 1.6179 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2840 - accuracy: 0.5357 - val_loss: 1.6126 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2879 - accuracy: 0.5714 - val_loss: 1.6092 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2825 - accuracy: 0.5536 - val_loss: 1.6078 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2708 - accuracy: 0.5357 - val_loss: 1.6040 - val_accuracy: 0.0714\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2911 - accuracy: 0.5714 - val_loss: 1.6035 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2615 - accuracy: 0.5893 - val_loss: 1.6057 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2710 - accuracy: 0.5893 - val_loss: 1.6083 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2574 - accuracy: 0.5893 - val_loss: 1.6133 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2661 - accuracy: 0.6429 - val_loss: 1.6173 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2549 - accuracy: 0.5893 - val_loss: 1.6219 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2609 - accuracy: 0.6607 - val_loss: 1.6268 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2484 - accuracy: 0.6250 - val_loss: 1.6252 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2413 - accuracy: 0.6250 - val_loss: 1.6231 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2403 - accuracy: 0.5893 - val_loss: 1.6171 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2505 - accuracy: 0.6250 - val_loss: 1.6113 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.2376 - accuracy: 0.5357 - val_loss: 1.6074 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2455 - accuracy: 0.5536 - val_loss: 1.6050 - val_accuracy: 0.0714\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2347 - accuracy: 0.6250 - val_loss: 1.6028 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2345 - accuracy: 0.5357 - val_loss: 1.6035 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2237 - accuracy: 0.6071 - val_loss: 1.6033 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2288 - accuracy: 0.5536 - val_loss: 1.6019 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2182 - accuracy: 0.6071 - val_loss: 1.5994 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2205 - accuracy: 0.6071 - val_loss: 1.5957 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2193 - accuracy: 0.5893 - val_loss: 1.5966 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 0.2138 - accuracy: 0.5893 - val_loss: 1.6028 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2171 - accuracy: 0.6071 - val_loss: 1.6073 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2056 - accuracy: 0.6429 - val_loss: 1.6139 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2104 - accuracy: 0.6607 - val_loss: 1.6190 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2123 - accuracy: 0.5893 - val_loss: 1.6210 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1970 - accuracy: 0.6250 - val_loss: 1.6180 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1945 - accuracy: 0.6250 - val_loss: 1.6157 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1928 - accuracy: 0.6071 - val_loss: 1.6087 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1903 - accuracy: 0.6786 - val_loss: 1.6021 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1999 - accuracy: 0.6071 - val_loss: 1.5976 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1885 - accuracy: 0.6607 - val_loss: 1.5922 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1875 - accuracy: 0.6071 - val_loss: 1.5912 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1990 - accuracy: 0.5893 - val_loss: 1.5950 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1827 - accuracy: 0.5893 - val_loss: 1.6005 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1833 - accuracy: 0.6786 - val_loss: 1.6057 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1793 - accuracy: 0.6250 - val_loss: 1.6088 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1758 - accuracy: 0.6071 - val_loss: 1.6086 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1714 - accuracy: 0.6786 - val_loss: 1.6087 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1905 - accuracy: 0.6607 - val_loss: 1.6059 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1790 - accuracy: 0.6429 - val_loss: 1.6036 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1836 - accuracy: 0.6429 - val_loss: 1.6028 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1680 - accuracy: 0.6786 - val_loss: 1.6040 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1626 - accuracy: 0.6250 - val_loss: 1.6021 - val_accuracy: 0.1429\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1685 - accuracy: 0.6250 - val_loss: 1.5971 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1588 - accuracy: 0.6607 - val_loss: 1.5918 - val_accuracy: 0.1429\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1530 - accuracy: 0.5893 - val_loss: 1.5866 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1602 - accuracy: 0.6250 - val_loss: 1.5814 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5814 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=240, batch_size=300, Scores: [1.581350564956665, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.581350564956665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9855 - accuracy: 0.0893 - val_loss: 1.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9829 - accuracy: 0.1250 - val_loss: 1.0744 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9805 - accuracy: 0.1429 - val_loss: 1.0747 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9795 - accuracy: 0.1429 - val_loss: 1.0750 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9756 - accuracy: 0.1964 - val_loss: 1.0753 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9731 - accuracy: 0.1964 - val_loss: 1.0757 - val_accuracy: 0.1429\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.9714 - accuracy: 0.1964 - val_loss: 1.0761 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9693 - accuracy: 0.2143 - val_loss: 1.0766 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9659 - accuracy: 0.2857 - val_loss: 1.0770 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9641 - accuracy: 0.2143 - val_loss: 1.0774 - val_accuracy: 0.2143\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9629 - accuracy: 0.2500 - val_loss: 1.0779 - val_accuracy: 0.2143\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9598 - accuracy: 0.2500 - val_loss: 1.0784 - val_accuracy: 0.2143\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9571 - accuracy: 0.3036 - val_loss: 1.0789 - val_accuracy: 0.2143\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9545 - accuracy: 0.2321 - val_loss: 1.0794 - val_accuracy: 0.2143\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9513 - accuracy: 0.2321 - val_loss: 1.0800 - val_accuracy: 0.2143\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9499 - accuracy: 0.2500 - val_loss: 1.0806 - val_accuracy: 0.2143\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9473 - accuracy: 0.2857 - val_loss: 1.0812 - val_accuracy: 0.2143\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9444 - accuracy: 0.2500 - val_loss: 1.0818 - val_accuracy: 0.2143\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9403 - accuracy: 0.2500 - val_loss: 1.0825 - val_accuracy: 0.2143\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9395 - accuracy: 0.2500 - val_loss: 1.0831 - val_accuracy: 0.2143\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9353 - accuracy: 0.2679 - val_loss: 1.0839 - val_accuracy: 0.2143\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9332 - accuracy: 0.2500 - val_loss: 1.0846 - val_accuracy: 0.2143\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9307 - accuracy: 0.3036 - val_loss: 1.0854 - val_accuracy: 0.2857\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9269 - accuracy: 0.2857 - val_loss: 1.0863 - val_accuracy: 0.2857\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9253 - accuracy: 0.3036 - val_loss: 1.0871 - val_accuracy: 0.2857\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9209 - accuracy: 0.3036 - val_loss: 1.0881 - val_accuracy: 0.2143\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9171 - accuracy: 0.3214 - val_loss: 1.0891 - val_accuracy: 0.2143\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9156 - accuracy: 0.3036 - val_loss: 1.0902 - val_accuracy: 0.2143\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9118 - accuracy: 0.3214 - val_loss: 1.0913 - val_accuracy: 0.2143\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9080 - accuracy: 0.2857 - val_loss: 1.0925 - val_accuracy: 0.2143\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9042 - accuracy: 0.3214 - val_loss: 1.0938 - val_accuracy: 0.2143\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8983 - accuracy: 0.3214 - val_loss: 1.0952 - val_accuracy: 0.2143\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8968 - accuracy: 0.3036 - val_loss: 1.0967 - val_accuracy: 0.2143\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8936 - accuracy: 0.3393 - val_loss: 1.0982 - val_accuracy: 0.2143\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8905 - accuracy: 0.3571 - val_loss: 1.0999 - val_accuracy: 0.2143\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8844 - accuracy: 0.3036 - val_loss: 1.1017 - val_accuracy: 0.2143\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8808 - accuracy: 0.3571 - val_loss: 1.1036 - val_accuracy: 0.2143\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8780 - accuracy: 0.3214 - val_loss: 1.1056 - val_accuracy: 0.2143\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8743 - accuracy: 0.3571 - val_loss: 1.1077 - val_accuracy: 0.2143\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.8682 - accuracy: 0.3571 - val_loss: 1.1099 - val_accuracy: 0.2143\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8664 - accuracy: 0.3393 - val_loss: 1.1123 - val_accuracy: 0.2143\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8574 - accuracy: 0.3036 - val_loss: 1.1148 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8556 - accuracy: 0.3750 - val_loss: 1.1175 - val_accuracy: 0.2143\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8514 - accuracy: 0.3571 - val_loss: 1.1203 - val_accuracy: 0.2143\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8497 - accuracy: 0.3393 - val_loss: 1.1232 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8458 - accuracy: 0.3393 - val_loss: 1.1263 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8406 - accuracy: 0.3393 - val_loss: 1.1295 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8335 - accuracy: 0.3214 - val_loss: 1.1328 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8334 - accuracy: 0.3393 - val_loss: 1.1363 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8284 - accuracy: 0.3393 - val_loss: 1.1399 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8287 - accuracy: 0.3214 - val_loss: 1.1436 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8236 - accuracy: 0.3393 - val_loss: 1.1474 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8192 - accuracy: 0.3036 - val_loss: 1.1513 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8154 - accuracy: 0.3393 - val_loss: 1.1553 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8108 - accuracy: 0.3214 - val_loss: 1.1593 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8088 - accuracy: 0.3393 - val_loss: 1.1635 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8059 - accuracy: 0.3214 - val_loss: 1.1677 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8045 - accuracy: 0.3393 - val_loss: 1.1719 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7986 - accuracy: 0.3214 - val_loss: 1.1761 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8008 - accuracy: 0.3214 - val_loss: 1.1803 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7918 - accuracy: 0.3393 - val_loss: 1.1844 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7923 - accuracy: 0.3214 - val_loss: 1.1884 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7896 - accuracy: 0.3393 - val_loss: 1.1922 - val_accuracy: 0.1429\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7842 - accuracy: 0.3036 - val_loss: 1.1958 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7825 - accuracy: 0.3393 - val_loss: 1.1993 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7797 - accuracy: 0.3036 - val_loss: 1.2025 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7723 - accuracy: 0.3393 - val_loss: 1.2056 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7734 - accuracy: 0.3214 - val_loss: 1.2085 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7722 - accuracy: 0.3393 - val_loss: 1.2112 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7679 - accuracy: 0.3036 - val_loss: 1.2137 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7657 - accuracy: 0.3036 - val_loss: 1.2159 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7620 - accuracy: 0.3393 - val_loss: 1.2180 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7586 - accuracy: 0.3393 - val_loss: 1.2199 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7554 - accuracy: 0.3571 - val_loss: 1.2215 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7513 - accuracy: 0.3214 - val_loss: 1.2230 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7495 - accuracy: 0.3929 - val_loss: 1.2244 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7501 - accuracy: 0.3393 - val_loss: 1.2257 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7418 - accuracy: 0.3571 - val_loss: 1.2271 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7448 - accuracy: 0.3750 - val_loss: 1.2287 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7408 - accuracy: 0.3393 - val_loss: 1.2304 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7336 - accuracy: 0.4107 - val_loss: 1.2321 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7291 - accuracy: 0.3929 - val_loss: 1.2339 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7289 - accuracy: 0.3929 - val_loss: 1.2358 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7217 - accuracy: 0.3929 - val_loss: 1.2380 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7247 - accuracy: 0.4107 - val_loss: 1.2400 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7168 - accuracy: 0.4286 - val_loss: 1.2423 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7084 - accuracy: 0.4286 - val_loss: 1.2449 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7099 - accuracy: 0.4464 - val_loss: 1.2479 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7044 - accuracy: 0.4286 - val_loss: 1.2511 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7037 - accuracy: 0.4107 - val_loss: 1.2541 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7024 - accuracy: 0.4464 - val_loss: 1.2573 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6975 - accuracy: 0.4643 - val_loss: 1.2611 - val_accuracy: 0.0714\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6902 - accuracy: 0.4643 - val_loss: 1.2649 - val_accuracy: 0.0714\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6856 - accuracy: 0.4464 - val_loss: 1.2693 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6839 - accuracy: 0.4643 - val_loss: 1.2730 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6825 - accuracy: 0.4464 - val_loss: 1.2769 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6763 - accuracy: 0.4464 - val_loss: 1.2812 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6744 - accuracy: 0.4643 - val_loss: 1.2856 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6674 - accuracy: 0.4286 - val_loss: 1.2907 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6689 - accuracy: 0.4464 - val_loss: 1.2957 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6612 - accuracy: 0.4286 - val_loss: 1.3007 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6589 - accuracy: 0.4286 - val_loss: 1.3049 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6594 - accuracy: 0.4286 - val_loss: 1.3084 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6538 - accuracy: 0.4464 - val_loss: 1.3125 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6525 - accuracy: 0.4464 - val_loss: 1.3166 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6449 - accuracy: 0.3929 - val_loss: 1.3202 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6475 - accuracy: 0.4464 - val_loss: 1.3237 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.6367 - accuracy: 0.4464 - val_loss: 1.3274 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6380 - accuracy: 0.4286 - val_loss: 1.3311 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6277 - accuracy: 0.4464 - val_loss: 1.3359 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6236 - accuracy: 0.4107 - val_loss: 1.3400 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6272 - accuracy: 0.4286 - val_loss: 1.3441 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6231 - accuracy: 0.4286 - val_loss: 1.3482 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6229 - accuracy: 0.3750 - val_loss: 1.3516 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6112 - accuracy: 0.4464 - val_loss: 1.3545 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6019 - accuracy: 0.4107 - val_loss: 1.3579 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6043 - accuracy: 0.4286 - val_loss: 1.3613 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5980 - accuracy: 0.4286 - val_loss: 1.3669 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5974 - accuracy: 0.4107 - val_loss: 1.3723 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5972 - accuracy: 0.4286 - val_loss: 1.3782 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.5854 - accuracy: 0.4286 - val_loss: 1.3854 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.5904 - accuracy: 0.3929 - val_loss: 1.3914 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5862 - accuracy: 0.3929 - val_loss: 1.3966 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5814 - accuracy: 0.3929 - val_loss: 1.4021 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5790 - accuracy: 0.4107 - val_loss: 1.4073 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5743 - accuracy: 0.3929 - val_loss: 1.4105 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5663 - accuracy: 0.4107 - val_loss: 1.4119 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5661 - accuracy: 0.4286 - val_loss: 1.4121 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5609 - accuracy: 0.4107 - val_loss: 1.4130 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5500 - accuracy: 0.4107 - val_loss: 1.4128 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5502 - accuracy: 0.4107 - val_loss: 1.4134 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.5576 - accuracy: 0.4107 - val_loss: 1.4160 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5457 - accuracy: 0.3571 - val_loss: 1.4204 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5419 - accuracy: 0.3929 - val_loss: 1.4251 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5354 - accuracy: 0.3929 - val_loss: 1.4273 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.5289 - accuracy: 0.3929 - val_loss: 1.4289 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5203 - accuracy: 0.3929 - val_loss: 1.4311 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5207 - accuracy: 0.3929 - val_loss: 1.4345 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5186 - accuracy: 0.3571 - val_loss: 1.4394 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5093 - accuracy: 0.4107 - val_loss: 1.4458 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.5096 - accuracy: 0.3750 - val_loss: 1.4525 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5026 - accuracy: 0.4107 - val_loss: 1.4579 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4998 - accuracy: 0.4107 - val_loss: 1.4617 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4941 - accuracy: 0.4464 - val_loss: 1.4647 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4910 - accuracy: 0.4286 - val_loss: 1.4687 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.4890 - accuracy: 0.4107 - val_loss: 1.4720 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4812 - accuracy: 0.4286 - val_loss: 1.4709 - val_accuracy: 0.1429\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4764 - accuracy: 0.4286 - val_loss: 1.4689 - val_accuracy: 0.1429\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4813 - accuracy: 0.4643 - val_loss: 1.4700 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4766 - accuracy: 0.4643 - val_loss: 1.4737 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4637 - accuracy: 0.4286 - val_loss: 1.4821 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4604 - accuracy: 0.4464 - val_loss: 1.4889 - val_accuracy: 0.1429\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4601 - accuracy: 0.4643 - val_loss: 1.4919 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4519 - accuracy: 0.4464 - val_loss: 1.4909 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.4500 - accuracy: 0.4643 - val_loss: 1.4899 - val_accuracy: 0.2143\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4436 - accuracy: 0.4286 - val_loss: 1.4903 - val_accuracy: 0.2143\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4379 - accuracy: 0.4464 - val_loss: 1.4906 - val_accuracy: 0.2143\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4395 - accuracy: 0.4286 - val_loss: 1.4937 - val_accuracy: 0.2143\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4237 - accuracy: 0.4464 - val_loss: 1.5008 - val_accuracy: 0.2143\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4307 - accuracy: 0.5000 - val_loss: 1.5106 - val_accuracy: 0.2143\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4290 - accuracy: 0.4821 - val_loss: 1.5222 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.4282 - accuracy: 0.5000 - val_loss: 1.5310 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4282 - accuracy: 0.5000 - val_loss: 1.5325 - val_accuracy: 0.2143\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4152 - accuracy: 0.5000 - val_loss: 1.5323 - val_accuracy: 0.2143\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4162 - accuracy: 0.4464 - val_loss: 1.5348 - val_accuracy: 0.2143\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.4069 - accuracy: 0.4821 - val_loss: 1.5376 - val_accuracy: 0.2143\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4101 - accuracy: 0.4643 - val_loss: 1.5417 - val_accuracy: 0.2143\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3913 - accuracy: 0.5000 - val_loss: 1.5451 - val_accuracy: 0.2143\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3948 - accuracy: 0.5179 - val_loss: 1.5407 - val_accuracy: 0.2143\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4016 - accuracy: 0.5357 - val_loss: 1.5360 - val_accuracy: 0.2143\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3951 - accuracy: 0.5357 - val_loss: 1.5286 - val_accuracy: 0.2143\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.3904 - accuracy: 0.5000 - val_loss: 1.5233 - val_accuracy: 0.2143\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3923 - accuracy: 0.5000 - val_loss: 1.5210 - val_accuracy: 0.2143\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3767 - accuracy: 0.5536 - val_loss: 1.5205 - val_accuracy: 0.2143\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3752 - accuracy: 0.5893 - val_loss: 1.5211 - val_accuracy: 0.2143\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3756 - accuracy: 0.5000 - val_loss: 1.5285 - val_accuracy: 0.2143\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3777 - accuracy: 0.5357 - val_loss: 1.5388 - val_accuracy: 0.2143\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3617 - accuracy: 0.5000 - val_loss: 1.5467 - val_accuracy: 0.2143\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3692 - accuracy: 0.5179 - val_loss: 1.5492 - val_accuracy: 0.2143\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3670 - accuracy: 0.5536 - val_loss: 1.5454 - val_accuracy: 0.2143\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3530 - accuracy: 0.5357 - val_loss: 1.5392 - val_accuracy: 0.2143\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3586 - accuracy: 0.5357 - val_loss: 1.5321 - val_accuracy: 0.2143\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3586 - accuracy: 0.5179 - val_loss: 1.5256 - val_accuracy: 0.2143\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3554 - accuracy: 0.6429 - val_loss: 1.5215 - val_accuracy: 0.2143\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3472 - accuracy: 0.5893 - val_loss: 1.5200 - val_accuracy: 0.2143\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3418 - accuracy: 0.5893 - val_loss: 1.5177 - val_accuracy: 0.2143\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3487 - accuracy: 0.5714 - val_loss: 1.5159 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3399 - accuracy: 0.5536 - val_loss: 1.5114 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3372 - accuracy: 0.6071 - val_loss: 1.5059 - val_accuracy: 0.1429\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3347 - accuracy: 0.5536 - val_loss: 1.4998 - val_accuracy: 0.1429\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3228 - accuracy: 0.5357 - val_loss: 1.4961 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3196 - accuracy: 0.5536 - val_loss: 1.4942 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3161 - accuracy: 0.5536 - val_loss: 1.4938 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3181 - accuracy: 0.5357 - val_loss: 1.4950 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3147 - accuracy: 0.6250 - val_loss: 1.4973 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3173 - accuracy: 0.5714 - val_loss: 1.4989 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3143 - accuracy: 0.6071 - val_loss: 1.5007 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3071 - accuracy: 0.5893 - val_loss: 1.4995 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3035 - accuracy: 0.5893 - val_loss: 1.4972 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2912 - accuracy: 0.5893 - val_loss: 1.4932 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2970 - accuracy: 0.4821 - val_loss: 1.4875 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2935 - accuracy: 0.5179 - val_loss: 1.4826 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2908 - accuracy: 0.6429 - val_loss: 1.4796 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2813 - accuracy: 0.6071 - val_loss: 1.4773 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2809 - accuracy: 0.5893 - val_loss: 1.4741 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2847 - accuracy: 0.5714 - val_loss: 1.4741 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.2753 - accuracy: 0.6071 - val_loss: 1.4766 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2701 - accuracy: 0.5536 - val_loss: 1.4791 - val_accuracy: 0.1429\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.2670 - accuracy: 0.5893 - val_loss: 1.4772 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2686 - accuracy: 0.6250 - val_loss: 1.4711 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2679 - accuracy: 0.5536 - val_loss: 1.4683 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2597 - accuracy: 0.5714 - val_loss: 1.4653 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2518 - accuracy: 0.5714 - val_loss: 1.4625 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2645 - accuracy: 0.6071 - val_loss: 1.4621 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2542 - accuracy: 0.6429 - val_loss: 1.4636 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2514 - accuracy: 0.5893 - val_loss: 1.4634 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2372 - accuracy: 0.6250 - val_loss: 1.4658 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2464 - accuracy: 0.6071 - val_loss: 1.4636 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2457 - accuracy: 0.6786 - val_loss: 1.4625 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2396 - accuracy: 0.6250 - val_loss: 1.4623 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2423 - accuracy: 0.6607 - val_loss: 1.4648 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2377 - accuracy: 0.6429 - val_loss: 1.4658 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2411 - accuracy: 0.6607 - val_loss: 1.4690 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2289 - accuracy: 0.5893 - val_loss: 1.4705 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2233 - accuracy: 0.6607 - val_loss: 1.4693 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2295 - accuracy: 0.5893 - val_loss: 1.4690 - val_accuracy: 0.2143\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2285 - accuracy: 0.6607 - val_loss: 1.4691 - val_accuracy: 0.2143\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2303 - accuracy: 0.6250 - val_loss: 1.4670 - val_accuracy: 0.2143\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2289 - accuracy: 0.6964 - val_loss: 1.4625 - val_accuracy: 0.2143\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2188 - accuracy: 0.7143 - val_loss: 1.4598 - val_accuracy: 0.2143\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2195 - accuracy: 0.6964 - val_loss: 1.4570 - val_accuracy: 0.2143\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2177 - accuracy: 0.6786 - val_loss: 1.4573 - val_accuracy: 0.2143\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2156 - accuracy: 0.6786 - val_loss: 1.4552 - val_accuracy: 0.2143\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2191 - accuracy: 0.6607 - val_loss: 1.4513 - val_accuracy: 0.2143\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2063 - accuracy: 0.5893 - val_loss: 1.4472 - val_accuracy: 0.2143\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1955 - accuracy: 0.6607 - val_loss: 1.4439 - val_accuracy: 0.2143\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2163 - accuracy: 0.6607 - val_loss: 1.4435 - val_accuracy: 0.2143\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2015 - accuracy: 0.6607 - val_loss: 1.4460 - val_accuracy: 0.2143\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1983 - accuracy: 0.6786 - val_loss: 1.4503 - val_accuracy: 0.2143\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1993 - accuracy: 0.7143 - val_loss: 1.4553 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4553 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=240, batch_size=400, Scores: [1.4553143978118896, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.4553143978118896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9807 - accuracy: 0.1429 - val_loss: 1.0649 - val_accuracy: 0.2143\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9778 - accuracy: 0.1250 - val_loss: 1.0654 - val_accuracy: 0.1429\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9769 - accuracy: 0.2143 - val_loss: 1.0658 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9744 - accuracy: 0.1607 - val_loss: 1.0663 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9710 - accuracy: 0.1786 - val_loss: 1.0668 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9696 - accuracy: 0.2500 - val_loss: 1.0673 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9675 - accuracy: 0.2500 - val_loss: 1.0679 - val_accuracy: 0.0714\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9654 - accuracy: 0.2500 - val_loss: 1.0684 - val_accuracy: 0.0714\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9625 - accuracy: 0.2321 - val_loss: 1.0689 - val_accuracy: 0.0714\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9602 - accuracy: 0.2857 - val_loss: 1.0695 - val_accuracy: 0.0714\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9577 - accuracy: 0.3036 - val_loss: 1.0700 - val_accuracy: 0.0714\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9549 - accuracy: 0.2500 - val_loss: 1.0706 - val_accuracy: 0.0714\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9530 - accuracy: 0.2500 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9500 - accuracy: 0.2500 - val_loss: 1.0717 - val_accuracy: 0.0714\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9472 - accuracy: 0.3036 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9448 - accuracy: 0.2679 - val_loss: 1.0729 - val_accuracy: 0.0714\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9413 - accuracy: 0.2857 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9398 - accuracy: 0.2679 - val_loss: 1.0742 - val_accuracy: 0.0714\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9360 - accuracy: 0.3036 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9337 - accuracy: 0.2500 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9303 - accuracy: 0.2679 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9278 - accuracy: 0.2857 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9236 - accuracy: 0.3214 - val_loss: 1.0774 - val_accuracy: 0.0714\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9219 - accuracy: 0.2857 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9184 - accuracy: 0.2679 - val_loss: 1.0788 - val_accuracy: 0.0714\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9149 - accuracy: 0.3036 - val_loss: 1.0796 - val_accuracy: 0.0714\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9088 - accuracy: 0.2679 - val_loss: 1.0804 - val_accuracy: 0.0714\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9079 - accuracy: 0.2857 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.9023 - accuracy: 0.2679 - val_loss: 1.0821 - val_accuracy: 0.0714\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.8989 - accuracy: 0.2857 - val_loss: 1.0830 - val_accuracy: 0.0714\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8959 - accuracy: 0.2679 - val_loss: 1.0840 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.8911 - accuracy: 0.2500 - val_loss: 1.0850 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8869 - accuracy: 0.2679 - val_loss: 1.0862 - val_accuracy: 0.0714\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8829 - accuracy: 0.2857 - val_loss: 1.0874 - val_accuracy: 0.0714\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8773 - accuracy: 0.2857 - val_loss: 1.0887 - val_accuracy: 0.0714\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8748 - accuracy: 0.2679 - val_loss: 1.0901 - val_accuracy: 0.0714\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8709 - accuracy: 0.2857 - val_loss: 1.0917 - val_accuracy: 0.0714\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8659 - accuracy: 0.2857 - val_loss: 1.0934 - val_accuracy: 0.0714\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8597 - accuracy: 0.2679 - val_loss: 1.0953 - val_accuracy: 0.0714\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8551 - accuracy: 0.2500 - val_loss: 1.0974 - val_accuracy: 0.0714\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8521 - accuracy: 0.2857 - val_loss: 1.0997 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8471 - accuracy: 0.2857 - val_loss: 1.1022 - val_accuracy: 0.0714\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8413 - accuracy: 0.2857 - val_loss: 1.1049 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8398 - accuracy: 0.2679 - val_loss: 1.1078 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8346 - accuracy: 0.3036 - val_loss: 1.1110 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8323 - accuracy: 0.2857 - val_loss: 1.1143 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8272 - accuracy: 0.3036 - val_loss: 1.1178 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8225 - accuracy: 0.2679 - val_loss: 1.1215 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8233 - accuracy: 0.2500 - val_loss: 1.1253 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8173 - accuracy: 0.2500 - val_loss: 1.1293 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8131 - accuracy: 0.2857 - val_loss: 1.1333 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8127 - accuracy: 0.2143 - val_loss: 1.1375 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8050 - accuracy: 0.2321 - val_loss: 1.1418 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8027 - accuracy: 0.2857 - val_loss: 1.1463 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7979 - accuracy: 0.2679 - val_loss: 1.1509 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7926 - accuracy: 0.2857 - val_loss: 1.1556 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7882 - accuracy: 0.2857 - val_loss: 1.1605 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7882 - accuracy: 0.3214 - val_loss: 1.1655 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7867 - accuracy: 0.3393 - val_loss: 1.1705 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7810 - accuracy: 0.2857 - val_loss: 1.1756 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7778 - accuracy: 0.2857 - val_loss: 1.1808 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7731 - accuracy: 0.2857 - val_loss: 1.1859 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7699 - accuracy: 0.2857 - val_loss: 1.1911 - val_accuracy: 0.1429\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7632 - accuracy: 0.3214 - val_loss: 1.1963 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7601 - accuracy: 0.3036 - val_loss: 1.2013 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7641 - accuracy: 0.3214 - val_loss: 1.2061 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7568 - accuracy: 0.3393 - val_loss: 1.2106 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7543 - accuracy: 0.2679 - val_loss: 1.2148 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7516 - accuracy: 0.3036 - val_loss: 1.2188 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7492 - accuracy: 0.3214 - val_loss: 1.2225 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7505 - accuracy: 0.3036 - val_loss: 1.2258 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7402 - accuracy: 0.3036 - val_loss: 1.2290 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7384 - accuracy: 0.3571 - val_loss: 1.2321 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7354 - accuracy: 0.3036 - val_loss: 1.2348 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7374 - accuracy: 0.3393 - val_loss: 1.2374 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7319 - accuracy: 0.3214 - val_loss: 1.2399 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7266 - accuracy: 0.3393 - val_loss: 1.2421 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7236 - accuracy: 0.3571 - val_loss: 1.2442 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7197 - accuracy: 0.3214 - val_loss: 1.2459 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7147 - accuracy: 0.3750 - val_loss: 1.2474 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7159 - accuracy: 0.3571 - val_loss: 1.2490 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7087 - accuracy: 0.3571 - val_loss: 1.2503 - val_accuracy: 0.2143\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7099 - accuracy: 0.3929 - val_loss: 1.2515 - val_accuracy: 0.2143\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7056 - accuracy: 0.3214 - val_loss: 1.2527 - val_accuracy: 0.2143\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7040 - accuracy: 0.3393 - val_loss: 1.2542 - val_accuracy: 0.2143\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6995 - accuracy: 0.3571 - val_loss: 1.2555 - val_accuracy: 0.2143\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.6971 - accuracy: 0.3393 - val_loss: 1.2570 - val_accuracy: 0.2143\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6964 - accuracy: 0.3750 - val_loss: 1.2582 - val_accuracy: 0.2143\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6903 - accuracy: 0.3750 - val_loss: 1.2597 - val_accuracy: 0.2143\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6917 - accuracy: 0.3750 - val_loss: 1.2613 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6848 - accuracy: 0.3571 - val_loss: 1.2630 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6830 - accuracy: 0.3750 - val_loss: 1.2649 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6793 - accuracy: 0.3750 - val_loss: 1.2671 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6775 - accuracy: 0.3571 - val_loss: 1.2694 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6690 - accuracy: 0.3750 - val_loss: 1.2717 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6690 - accuracy: 0.3571 - val_loss: 1.2741 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6654 - accuracy: 0.3750 - val_loss: 1.2767 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6633 - accuracy: 0.4107 - val_loss: 1.2795 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6589 - accuracy: 0.3929 - val_loss: 1.2824 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6594 - accuracy: 0.4107 - val_loss: 1.2853 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6518 - accuracy: 0.4107 - val_loss: 1.2884 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6518 - accuracy: 0.4286 - val_loss: 1.2916 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6439 - accuracy: 0.4286 - val_loss: 1.2948 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6386 - accuracy: 0.3750 - val_loss: 1.2981 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6430 - accuracy: 0.4464 - val_loss: 1.3015 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6379 - accuracy: 0.4107 - val_loss: 1.3051 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6280 - accuracy: 0.4107 - val_loss: 1.3087 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6242 - accuracy: 0.4107 - val_loss: 1.3125 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6297 - accuracy: 0.4107 - val_loss: 1.3168 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6235 - accuracy: 0.4464 - val_loss: 1.3210 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6186 - accuracy: 0.4107 - val_loss: 1.3254 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6105 - accuracy: 0.4286 - val_loss: 1.3301 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6048 - accuracy: 0.4286 - val_loss: 1.3353 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6110 - accuracy: 0.4107 - val_loss: 1.3412 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6013 - accuracy: 0.3929 - val_loss: 1.3468 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5967 - accuracy: 0.4107 - val_loss: 1.3527 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5917 - accuracy: 0.4286 - val_loss: 1.3585 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5825 - accuracy: 0.4286 - val_loss: 1.3639 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5859 - accuracy: 0.4286 - val_loss: 1.3684 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.5843 - accuracy: 0.3929 - val_loss: 1.3721 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5755 - accuracy: 0.4107 - val_loss: 1.3752 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5701 - accuracy: 0.3929 - val_loss: 1.3780 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5692 - accuracy: 0.4107 - val_loss: 1.3803 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5683 - accuracy: 0.4107 - val_loss: 1.3825 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5632 - accuracy: 0.4286 - val_loss: 1.3851 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5540 - accuracy: 0.4107 - val_loss: 1.3884 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5523 - accuracy: 0.4286 - val_loss: 1.3926 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5504 - accuracy: 0.4107 - val_loss: 1.3978 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5481 - accuracy: 0.4286 - val_loss: 1.4039 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.5336 - accuracy: 0.4643 - val_loss: 1.4103 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5422 - accuracy: 0.4107 - val_loss: 1.4144 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5281 - accuracy: 0.4107 - val_loss: 1.4166 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5307 - accuracy: 0.4464 - val_loss: 1.4177 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.5253 - accuracy: 0.4286 - val_loss: 1.4180 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5204 - accuracy: 0.4464 - val_loss: 1.4180 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5194 - accuracy: 0.4107 - val_loss: 1.4180 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.5123 - accuracy: 0.4286 - val_loss: 1.4186 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5040 - accuracy: 0.4107 - val_loss: 1.4206 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4922 - accuracy: 0.4643 - val_loss: 1.4230 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4984 - accuracy: 0.4464 - val_loss: 1.4242 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4853 - accuracy: 0.4464 - val_loss: 1.4259 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4911 - accuracy: 0.4286 - val_loss: 1.4277 - val_accuracy: 0.1429\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4790 - accuracy: 0.4643 - val_loss: 1.4300 - val_accuracy: 0.1429\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4786 - accuracy: 0.4286 - val_loss: 1.4321 - val_accuracy: 0.1429\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4791 - accuracy: 0.4286 - val_loss: 1.4343 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4721 - accuracy: 0.4643 - val_loss: 1.4351 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4702 - accuracy: 0.4821 - val_loss: 1.4354 - val_accuracy: 0.1429\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4629 - accuracy: 0.4464 - val_loss: 1.4362 - val_accuracy: 0.1429\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4600 - accuracy: 0.4643 - val_loss: 1.4360 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4468 - accuracy: 0.4286 - val_loss: 1.4348 - val_accuracy: 0.2143\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4477 - accuracy: 0.4464 - val_loss: 1.4336 - val_accuracy: 0.2143\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4395 - accuracy: 0.4643 - val_loss: 1.4327 - val_accuracy: 0.2143\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4484 - accuracy: 0.4643 - val_loss: 1.4314 - val_accuracy: 0.2143\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4306 - accuracy: 0.4286 - val_loss: 1.4322 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4334 - accuracy: 0.4464 - val_loss: 1.4337 - val_accuracy: 0.1429\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4148 - accuracy: 0.4464 - val_loss: 1.4372 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4297 - accuracy: 0.4286 - val_loss: 1.4416 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4235 - accuracy: 0.4643 - val_loss: 1.4446 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4097 - accuracy: 0.4643 - val_loss: 1.4490 - val_accuracy: 0.1429\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4098 - accuracy: 0.4643 - val_loss: 1.4511 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3999 - accuracy: 0.4464 - val_loss: 1.4508 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4000 - accuracy: 0.4643 - val_loss: 1.4501 - val_accuracy: 0.2143\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3970 - accuracy: 0.4286 - val_loss: 1.4498 - val_accuracy: 0.2143\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4013 - accuracy: 0.5000 - val_loss: 1.4505 - val_accuracy: 0.2143\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3899 - accuracy: 0.4464 - val_loss: 1.4516 - val_accuracy: 0.2143\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3888 - accuracy: 0.4821 - val_loss: 1.4529 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3667 - accuracy: 0.4107 - val_loss: 1.4552 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3677 - accuracy: 0.5000 - val_loss: 1.4562 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3663 - accuracy: 0.4643 - val_loss: 1.4562 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3758 - accuracy: 0.4821 - val_loss: 1.4518 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3556 - accuracy: 0.5179 - val_loss: 1.4466 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3665 - accuracy: 0.5000 - val_loss: 1.4416 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3450 - accuracy: 0.4643 - val_loss: 1.4380 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3579 - accuracy: 0.4643 - val_loss: 1.4358 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3457 - accuracy: 0.4821 - val_loss: 1.4325 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3432 - accuracy: 0.5000 - val_loss: 1.4319 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3388 - accuracy: 0.4643 - val_loss: 1.4356 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3328 - accuracy: 0.5893 - val_loss: 1.4436 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3419 - accuracy: 0.5357 - val_loss: 1.4489 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3378 - accuracy: 0.5179 - val_loss: 1.4572 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3282 - accuracy: 0.5357 - val_loss: 1.4641 - val_accuracy: 0.0714\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3240 - accuracy: 0.5536 - val_loss: 1.4664 - val_accuracy: 0.0714\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3203 - accuracy: 0.5714 - val_loss: 1.4646 - val_accuracy: 0.0714\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3217 - accuracy: 0.5714 - val_loss: 1.4610 - val_accuracy: 0.0714\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3288 - accuracy: 0.5357 - val_loss: 1.4515 - val_accuracy: 0.0714\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3249 - accuracy: 0.5536 - val_loss: 1.4465 - val_accuracy: 0.0714\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3062 - accuracy: 0.5714 - val_loss: 1.4425 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3118 - accuracy: 0.5357 - val_loss: 1.4395 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3168 - accuracy: 0.6250 - val_loss: 1.4411 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3026 - accuracy: 0.6250 - val_loss: 1.4449 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3037 - accuracy: 0.5357 - val_loss: 1.4492 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.3028 - accuracy: 0.5536 - val_loss: 1.4547 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2866 - accuracy: 0.5536 - val_loss: 1.4632 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2835 - accuracy: 0.5536 - val_loss: 1.4720 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2868 - accuracy: 0.5893 - val_loss: 1.4820 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2872 - accuracy: 0.5893 - val_loss: 1.4883 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2820 - accuracy: 0.6250 - val_loss: 1.4873 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2780 - accuracy: 0.5714 - val_loss: 1.4800 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2804 - accuracy: 0.5893 - val_loss: 1.4671 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2677 - accuracy: 0.6250 - val_loss: 1.4579 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2790 - accuracy: 0.6429 - val_loss: 1.4525 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2796 - accuracy: 0.6071 - val_loss: 1.4483 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2653 - accuracy: 0.6429 - val_loss: 1.4471 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2608 - accuracy: 0.6607 - val_loss: 1.4509 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2611 - accuracy: 0.5893 - val_loss: 1.4557 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2636 - accuracy: 0.6429 - val_loss: 1.4610 - val_accuracy: 0.0714\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2487 - accuracy: 0.6964 - val_loss: 1.4644 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2570 - accuracy: 0.6429 - val_loss: 1.4675 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2534 - accuracy: 0.6786 - val_loss: 1.4706 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2434 - accuracy: 0.6607 - val_loss: 1.4705 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2449 - accuracy: 0.6071 - val_loss: 1.4675 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2393 - accuracy: 0.6429 - val_loss: 1.4637 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2452 - accuracy: 0.6607 - val_loss: 1.4595 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2379 - accuracy: 0.6607 - val_loss: 1.4583 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2341 - accuracy: 0.7321 - val_loss: 1.4598 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2371 - accuracy: 0.7143 - val_loss: 1.4641 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2309 - accuracy: 0.6607 - val_loss: 1.4688 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2314 - accuracy: 0.7143 - val_loss: 1.4764 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2401 - accuracy: 0.7321 - val_loss: 1.4829 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2277 - accuracy: 0.6786 - val_loss: 1.4870 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2216 - accuracy: 0.6786 - val_loss: 1.4902 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.2389 - accuracy: 0.6607 - val_loss: 1.4941 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2228 - accuracy: 0.6964 - val_loss: 1.4957 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2175 - accuracy: 0.6786 - val_loss: 1.4944 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.2176 - accuracy: 0.7143 - val_loss: 1.4955 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2174 - accuracy: 0.6607 - val_loss: 1.4953 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2039 - accuracy: 0.6250 - val_loss: 1.4969 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2030 - accuracy: 0.6964 - val_loss: 1.4984 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2071 - accuracy: 0.6786 - val_loss: 1.5019 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2084 - accuracy: 0.6429 - val_loss: 1.5017 - val_accuracy: 0.0714\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2049 - accuracy: 0.6964 - val_loss: 1.4973 - val_accuracy: 0.0714\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2015 - accuracy: 0.7143 - val_loss: 1.4927 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1970 - accuracy: 0.6964 - val_loss: 1.4927 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2027 - accuracy: 0.6607 - val_loss: 1.4933 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1947 - accuracy: 0.6786 - val_loss: 1.4969 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1836 - accuracy: 0.6964 - val_loss: 1.4995 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1909 - accuracy: 0.6607 - val_loss: 1.5032 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1941 - accuracy: 0.7143 - val_loss: 1.5050 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1871 - accuracy: 0.7143 - val_loss: 1.5077 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1824 - accuracy: 0.6786 - val_loss: 1.5070 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.5070 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=120, wl= 7, epoch=240, batch_size=500, Scores: [1.5070180892944336, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.5070180892944336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9856 - accuracy: 0.1429 - val_loss: 1.0687 - val_accuracy: 0.0714\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9804 - accuracy: 0.2143 - val_loss: 1.0688 - val_accuracy: 0.1429\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9759 - accuracy: 0.3036 - val_loss: 1.0691 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9715 - accuracy: 0.3036 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9679 - accuracy: 0.3750 - val_loss: 1.0698 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9619 - accuracy: 0.3571 - val_loss: 1.0702 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9581 - accuracy: 0.3214 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9545 - accuracy: 0.3036 - val_loss: 1.0712 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9495 - accuracy: 0.3571 - val_loss: 1.0718 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9446 - accuracy: 0.3571 - val_loss: 1.0724 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.9396 - accuracy: 0.3393 - val_loss: 1.0731 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9345 - accuracy: 0.3036 - val_loss: 1.0738 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9295 - accuracy: 0.3214 - val_loss: 1.0746 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9230 - accuracy: 0.3214 - val_loss: 1.0755 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9191 - accuracy: 0.3214 - val_loss: 1.0764 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9115 - accuracy: 0.3393 - val_loss: 1.0776 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9053 - accuracy: 0.3214 - val_loss: 1.0789 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9004 - accuracy: 0.3214 - val_loss: 1.0805 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8940 - accuracy: 0.3036 - val_loss: 1.0822 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8859 - accuracy: 0.2857 - val_loss: 1.0843 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8795 - accuracy: 0.3036 - val_loss: 1.0867 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8719 - accuracy: 0.3036 - val_loss: 1.0895 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8667 - accuracy: 0.3214 - val_loss: 1.0926 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8582 - accuracy: 0.3036 - val_loss: 1.0960 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8544 - accuracy: 0.3036 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 0.8470 - accuracy: 0.3571 - val_loss: 1.1039 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8400 - accuracy: 0.2679 - val_loss: 1.1082 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8334 - accuracy: 0.3214 - val_loss: 1.1131 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8302 - accuracy: 0.3214 - val_loss: 1.1183 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8193 - accuracy: 0.3393 - val_loss: 1.1242 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8133 - accuracy: 0.3393 - val_loss: 1.1306 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8053 - accuracy: 0.3393 - val_loss: 1.1377 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1377 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=32, batch_size=100, Scores: [1.1377084255218506, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1377084255218506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9832 - accuracy: 0.1786 - val_loss: 1.0700 - val_accuracy: 0.0714\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9794 - accuracy: 0.2679 - val_loss: 1.0701 - val_accuracy: 0.1429\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9756 - accuracy: 0.3393 - val_loss: 1.0703 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9719 - accuracy: 0.3750 - val_loss: 1.0705 - val_accuracy: 0.1429\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.9671 - accuracy: 0.4286 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9641 - accuracy: 0.3571 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9597 - accuracy: 0.3750 - val_loss: 1.0714 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9555 - accuracy: 0.3929 - val_loss: 1.0718 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9523 - accuracy: 0.3393 - val_loss: 1.0722 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9480 - accuracy: 0.3571 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9446 - accuracy: 0.3571 - val_loss: 1.0733 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9392 - accuracy: 0.3393 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9340 - accuracy: 0.3571 - val_loss: 1.0746 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9304 - accuracy: 0.3393 - val_loss: 1.0753 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9253 - accuracy: 0.3214 - val_loss: 1.0762 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9216 - accuracy: 0.3214 - val_loss: 1.0772 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9150 - accuracy: 0.3393 - val_loss: 1.0784 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9094 - accuracy: 0.3393 - val_loss: 1.0797 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9046 - accuracy: 0.3393 - val_loss: 1.0812 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8981 - accuracy: 0.3393 - val_loss: 1.0829 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8928 - accuracy: 0.3750 - val_loss: 1.0848 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8864 - accuracy: 0.3571 - val_loss: 1.0871 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8805 - accuracy: 0.3214 - val_loss: 1.0897 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8723 - accuracy: 0.3571 - val_loss: 1.0927 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8676 - accuracy: 0.3750 - val_loss: 1.0961 - val_accuracy: 0.1429\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8602 - accuracy: 0.3571 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.8536 - accuracy: 0.3750 - val_loss: 1.1039 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8466 - accuracy: 0.3750 - val_loss: 1.1085 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8421 - accuracy: 0.3571 - val_loss: 1.1136 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8311 - accuracy: 0.3571 - val_loss: 1.1193 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8225 - accuracy: 0.3571 - val_loss: 1.1254 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8189 - accuracy: 0.3750 - val_loss: 1.1320 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1320 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=32, batch_size=300, Scores: [1.132043719291687, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.132043719291687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9831 - accuracy: 0.1964 - val_loss: 1.0673 - val_accuracy: 0.0714\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9789 - accuracy: 0.1964 - val_loss: 1.0673 - val_accuracy: 0.0714\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9735 - accuracy: 0.2143 - val_loss: 1.0673 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9702 - accuracy: 0.1964 - val_loss: 1.0675 - val_accuracy: 0.1429\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9652 - accuracy: 0.2857 - val_loss: 1.0677 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9607 - accuracy: 0.2857 - val_loss: 1.0679 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9553 - accuracy: 0.2321 - val_loss: 1.0682 - val_accuracy: 0.2143\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9516 - accuracy: 0.2857 - val_loss: 1.0686 - val_accuracy: 0.2143\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9475 - accuracy: 0.2679 - val_loss: 1.0691 - val_accuracy: 0.2143\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9423 - accuracy: 0.2857 - val_loss: 1.0696 - val_accuracy: 0.2143\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9378 - accuracy: 0.2679 - val_loss: 1.0703 - val_accuracy: 0.2143\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9332 - accuracy: 0.2857 - val_loss: 1.0710 - val_accuracy: 0.2143\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9287 - accuracy: 0.2857 - val_loss: 1.0719 - val_accuracy: 0.2143\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9226 - accuracy: 0.3036 - val_loss: 1.0729 - val_accuracy: 0.2143\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9175 - accuracy: 0.2679 - val_loss: 1.0740 - val_accuracy: 0.2143\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9120 - accuracy: 0.2679 - val_loss: 1.0754 - val_accuracy: 0.2143\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9063 - accuracy: 0.3036 - val_loss: 1.0769 - val_accuracy: 0.2143\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9000 - accuracy: 0.2679 - val_loss: 1.0787 - val_accuracy: 0.2143\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8953 - accuracy: 0.2857 - val_loss: 1.0806 - val_accuracy: 0.2143\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8884 - accuracy: 0.2857 - val_loss: 1.0828 - val_accuracy: 0.2143\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8810 - accuracy: 0.2857 - val_loss: 1.0853 - val_accuracy: 0.2143\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8745 - accuracy: 0.2857 - val_loss: 1.0880 - val_accuracy: 0.2143\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8678 - accuracy: 0.3036 - val_loss: 1.0911 - val_accuracy: 0.2143\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8627 - accuracy: 0.3036 - val_loss: 1.0946 - val_accuracy: 0.2143\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8565 - accuracy: 0.2857 - val_loss: 1.0983 - val_accuracy: 0.2143\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8506 - accuracy: 0.3036 - val_loss: 1.1025 - val_accuracy: 0.2143\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8429 - accuracy: 0.3214 - val_loss: 1.1071 - val_accuracy: 0.2143\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8367 - accuracy: 0.3036 - val_loss: 1.1123 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8299 - accuracy: 0.3036 - val_loss: 1.1180 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8212 - accuracy: 0.3036 - val_loss: 1.1245 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8174 - accuracy: 0.3036 - val_loss: 1.1315 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8113 - accuracy: 0.3036 - val_loss: 1.1391 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1391 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=32, batch_size=400, Scores: [1.1391103267669678, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1391103267669678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9819 - accuracy: 0.2143 - val_loss: 1.0733 - val_accuracy: 0.0714\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9774 - accuracy: 0.2143 - val_loss: 1.0740 - val_accuracy: 0.0714\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9724 - accuracy: 0.2500 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9682 - accuracy: 0.1786 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9636 - accuracy: 0.1964 - val_loss: 1.0767 - val_accuracy: 0.0714\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9589 - accuracy: 0.2679 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.9541 - accuracy: 0.3214 - val_loss: 1.0789 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.9488 - accuracy: 0.2857 - val_loss: 1.0802 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9443 - accuracy: 0.3393 - val_loss: 1.0816 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9396 - accuracy: 0.3036 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9338 - accuracy: 0.3393 - val_loss: 1.0849 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9267 - accuracy: 0.3214 - val_loss: 1.0869 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9226 - accuracy: 0.3393 - val_loss: 1.0891 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9163 - accuracy: 0.3393 - val_loss: 1.0917 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9101 - accuracy: 0.3393 - val_loss: 1.0946 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9036 - accuracy: 0.3214 - val_loss: 1.0979 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8983 - accuracy: 0.3393 - val_loss: 1.1015 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8938 - accuracy: 0.3393 - val_loss: 1.1055 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8874 - accuracy: 0.3571 - val_loss: 1.1099 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8800 - accuracy: 0.3393 - val_loss: 1.1145 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8745 - accuracy: 0.3393 - val_loss: 1.1194 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8708 - accuracy: 0.3393 - val_loss: 1.1243 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8635 - accuracy: 0.3393 - val_loss: 1.1293 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8591 - accuracy: 0.3393 - val_loss: 1.1341 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8533 - accuracy: 0.3393 - val_loss: 1.1388 - val_accuracy: 0.1429\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.8465 - accuracy: 0.3393 - val_loss: 1.1435 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8393 - accuracy: 0.3393 - val_loss: 1.1479 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8303 - accuracy: 0.3571 - val_loss: 1.1524 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8261 - accuracy: 0.3214 - val_loss: 1.1569 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8190 - accuracy: 0.3393 - val_loss: 1.1614 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8157 - accuracy: 0.3214 - val_loss: 1.1660 - val_accuracy: 0.2143\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8078 - accuracy: 0.3214 - val_loss: 1.1706 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1706 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=32, batch_size=500, Scores: [1.170591950416565, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.170591950416565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9844 - accuracy: 0.0893 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9796 - accuracy: 0.2500 - val_loss: 1.0712 - val_accuracy: 0.1429\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9751 - accuracy: 0.2321 - val_loss: 1.0718 - val_accuracy: 0.2143\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9708 - accuracy: 0.2143 - val_loss: 1.0725 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9659 - accuracy: 0.2857 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9615 - accuracy: 0.3036 - val_loss: 1.0740 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9573 - accuracy: 0.2500 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9522 - accuracy: 0.3036 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9467 - accuracy: 0.2500 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9424 - accuracy: 0.2679 - val_loss: 1.0780 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9373 - accuracy: 0.2679 - val_loss: 1.0792 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9329 - accuracy: 0.3214 - val_loss: 1.0806 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9266 - accuracy: 0.2857 - val_loss: 1.0820 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.9208 - accuracy: 0.3036 - val_loss: 1.0837 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.9156 - accuracy: 0.2857 - val_loss: 1.0855 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9097 - accuracy: 0.3214 - val_loss: 1.0875 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9046 - accuracy: 0.3036 - val_loss: 1.0898 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8957 - accuracy: 0.3036 - val_loss: 1.0924 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8918 - accuracy: 0.3393 - val_loss: 1.0953 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8828 - accuracy: 0.3571 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8772 - accuracy: 0.3393 - val_loss: 1.1021 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8698 - accuracy: 0.3571 - val_loss: 1.1060 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8642 - accuracy: 0.3393 - val_loss: 1.1101 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8560 - accuracy: 0.3214 - val_loss: 1.1146 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8501 - accuracy: 0.3750 - val_loss: 1.1194 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8436 - accuracy: 0.3571 - val_loss: 1.1244 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8389 - accuracy: 0.3571 - val_loss: 1.1297 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8311 - accuracy: 0.3571 - val_loss: 1.1349 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8266 - accuracy: 0.3214 - val_loss: 1.1403 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8209 - accuracy: 0.2857 - val_loss: 1.1455 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8144 - accuracy: 0.2857 - val_loss: 1.1507 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8082 - accuracy: 0.2857 - val_loss: 1.1560 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8049 - accuracy: 0.2857 - val_loss: 1.1613 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7995 - accuracy: 0.2857 - val_loss: 1.1668 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7912 - accuracy: 0.2857 - val_loss: 1.1725 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7875 - accuracy: 0.2857 - val_loss: 1.1784 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7787 - accuracy: 0.3036 - val_loss: 1.1847 - val_accuracy: 0.1429\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7723 - accuracy: 0.3036 - val_loss: 1.1912 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7701 - accuracy: 0.3036 - val_loss: 1.1980 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7659 - accuracy: 0.3036 - val_loss: 1.2049 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7597 - accuracy: 0.3036 - val_loss: 1.2120 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7532 - accuracy: 0.3036 - val_loss: 1.2192 - val_accuracy: 0.2143\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7514 - accuracy: 0.3036 - val_loss: 1.2265 - val_accuracy: 0.2143\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7426 - accuracy: 0.3036 - val_loss: 1.2340 - val_accuracy: 0.2143\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7407 - accuracy: 0.3393 - val_loss: 1.2414 - val_accuracy: 0.2143\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7375 - accuracy: 0.3214 - val_loss: 1.2486 - val_accuracy: 0.2143\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7347 - accuracy: 0.3214 - val_loss: 1.2558 - val_accuracy: 0.2143\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7232 - accuracy: 0.3571 - val_loss: 1.2624 - val_accuracy: 0.2143\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7251 - accuracy: 0.3571 - val_loss: 1.2682 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7174 - accuracy: 0.4107 - val_loss: 1.2733 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7106 - accuracy: 0.3571 - val_loss: 1.2781 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7087 - accuracy: 0.3214 - val_loss: 1.2821 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7041 - accuracy: 0.3571 - val_loss: 1.2853 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7005 - accuracy: 0.3393 - val_loss: 1.2883 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.6940 - accuracy: 0.3393 - val_loss: 1.2912 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6873 - accuracy: 0.3393 - val_loss: 1.2945 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6810 - accuracy: 0.3571 - val_loss: 1.2986 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6763 - accuracy: 0.3393 - val_loss: 1.3034 - val_accuracy: 0.2143\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6696 - accuracy: 0.3750 - val_loss: 1.3087 - val_accuracy: 0.2143\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6635 - accuracy: 0.3571 - val_loss: 1.3151 - val_accuracy: 0.2143\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6645 - accuracy: 0.3571 - val_loss: 1.3222 - val_accuracy: 0.2143\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6590 - accuracy: 0.3036 - val_loss: 1.3304 - val_accuracy: 0.2143\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6518 - accuracy: 0.3393 - val_loss: 1.3392 - val_accuracy: 0.2143\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.6452 - accuracy: 0.3393 - val_loss: 1.3481 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3481 - accuracy: 0.2143\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=64, batch_size=100, Scores: [1.3481051921844482, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.3481051921844482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9846 - accuracy: 0.0893 - val_loss: 1.0686 - val_accuracy: 0.3571\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9795 - accuracy: 0.2321 - val_loss: 1.0689 - val_accuracy: 0.2143\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9751 - accuracy: 0.2500 - val_loss: 1.0692 - val_accuracy: 0.1429\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9709 - accuracy: 0.2679 - val_loss: 1.0697 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9664 - accuracy: 0.2321 - val_loss: 1.0701 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9629 - accuracy: 0.2500 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9577 - accuracy: 0.2500 - val_loss: 1.0713 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9529 - accuracy: 0.2679 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9488 - accuracy: 0.2500 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9426 - accuracy: 0.2679 - val_loss: 1.0735 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9390 - accuracy: 0.2679 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9327 - accuracy: 0.2679 - val_loss: 1.0753 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9273 - accuracy: 0.2857 - val_loss: 1.0765 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9223 - accuracy: 0.2857 - val_loss: 1.0777 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9163 - accuracy: 0.2857 - val_loss: 1.0791 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9105 - accuracy: 0.3036 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9043 - accuracy: 0.3036 - val_loss: 1.0826 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8983 - accuracy: 0.2679 - val_loss: 1.0847 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8919 - accuracy: 0.2679 - val_loss: 1.0871 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8855 - accuracy: 0.2857 - val_loss: 1.0898 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8787 - accuracy: 0.2857 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8717 - accuracy: 0.3036 - val_loss: 1.0965 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8667 - accuracy: 0.3036 - val_loss: 1.1006 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8616 - accuracy: 0.2857 - val_loss: 1.1050 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8539 - accuracy: 0.3036 - val_loss: 1.1099 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8481 - accuracy: 0.3036 - val_loss: 1.1153 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8436 - accuracy: 0.2857 - val_loss: 1.1211 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8393 - accuracy: 0.2857 - val_loss: 1.1273 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8320 - accuracy: 0.2857 - val_loss: 1.1341 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8259 - accuracy: 0.2679 - val_loss: 1.1414 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8221 - accuracy: 0.3036 - val_loss: 1.1492 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8166 - accuracy: 0.3036 - val_loss: 1.1573 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8121 - accuracy: 0.3036 - val_loss: 1.1658 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8069 - accuracy: 0.3036 - val_loss: 1.1744 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8037 - accuracy: 0.3036 - val_loss: 1.1829 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7985 - accuracy: 0.3036 - val_loss: 1.1913 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7914 - accuracy: 0.3036 - val_loss: 1.1993 - val_accuracy: 0.1429\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7896 - accuracy: 0.3036 - val_loss: 1.2068 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7855 - accuracy: 0.3214 - val_loss: 1.2140 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7797 - accuracy: 0.3214 - val_loss: 1.2207 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7723 - accuracy: 0.3214 - val_loss: 1.2271 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7709 - accuracy: 0.3214 - val_loss: 1.2330 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7675 - accuracy: 0.3214 - val_loss: 1.2384 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7607 - accuracy: 0.3214 - val_loss: 1.2429 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7566 - accuracy: 0.3571 - val_loss: 1.2465 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7513 - accuracy: 0.3571 - val_loss: 1.2491 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7440 - accuracy: 0.3393 - val_loss: 1.2508 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7417 - accuracy: 0.3214 - val_loss: 1.2519 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7371 - accuracy: 0.3393 - val_loss: 1.2527 - val_accuracy: 0.1429\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7300 - accuracy: 0.3214 - val_loss: 1.2539 - val_accuracy: 0.1429\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7267 - accuracy: 0.3393 - val_loss: 1.2556 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7182 - accuracy: 0.3393 - val_loss: 1.2579 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7168 - accuracy: 0.3393 - val_loss: 1.2607 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7111 - accuracy: 0.3393 - val_loss: 1.2643 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7066 - accuracy: 0.3571 - val_loss: 1.2688 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7017 - accuracy: 0.3393 - val_loss: 1.2742 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6961 - accuracy: 0.3750 - val_loss: 1.2802 - val_accuracy: 0.0714\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6857 - accuracy: 0.3571 - val_loss: 1.2871 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6882 - accuracy: 0.3571 - val_loss: 1.2945 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6796 - accuracy: 0.3750 - val_loss: 1.3017 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6771 - accuracy: 0.3929 - val_loss: 1.3092 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6682 - accuracy: 0.4107 - val_loss: 1.3166 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6685 - accuracy: 0.3929 - val_loss: 1.3236 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6626 - accuracy: 0.3750 - val_loss: 1.3296 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3296 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=64, batch_size=300, Scores: [1.329642653465271, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.329642653465271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9834 - accuracy: 0.0714 - val_loss: 1.0707 - val_accuracy: 0.2143\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.9807 - accuracy: 0.1607 - val_loss: 1.0719 - val_accuracy: 0.2857\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9762 - accuracy: 0.1964 - val_loss: 1.0731 - val_accuracy: 0.2857\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9714 - accuracy: 0.3214 - val_loss: 1.0744 - val_accuracy: 0.2857\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9679 - accuracy: 0.3571 - val_loss: 1.0757 - val_accuracy: 0.2857\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9635 - accuracy: 0.3214 - val_loss: 1.0771 - val_accuracy: 0.2857\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9587 - accuracy: 0.3393 - val_loss: 1.0785 - val_accuracy: 0.2857\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9545 - accuracy: 0.3393 - val_loss: 1.0801 - val_accuracy: 0.2857\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9498 - accuracy: 0.3036 - val_loss: 1.0817 - val_accuracy: 0.2857\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9459 - accuracy: 0.3393 - val_loss: 1.0834 - val_accuracy: 0.2857\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9409 - accuracy: 0.3571 - val_loss: 1.0852 - val_accuracy: 0.2857\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9357 - accuracy: 0.3571 - val_loss: 1.0871 - val_accuracy: 0.2857\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9306 - accuracy: 0.3393 - val_loss: 1.0892 - val_accuracy: 0.2857\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9249 - accuracy: 0.3571 - val_loss: 1.0915 - val_accuracy: 0.2143\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9202 - accuracy: 0.3571 - val_loss: 1.0939 - val_accuracy: 0.2143\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9144 - accuracy: 0.3571 - val_loss: 1.0966 - val_accuracy: 0.2143\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9086 - accuracy: 0.3571 - val_loss: 1.0995 - val_accuracy: 0.2143\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9025 - accuracy: 0.3750 - val_loss: 1.1028 - val_accuracy: 0.2143\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8959 - accuracy: 0.3571 - val_loss: 1.1064 - val_accuracy: 0.2143\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8891 - accuracy: 0.3571 - val_loss: 1.1104 - val_accuracy: 0.2143\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8827 - accuracy: 0.3571 - val_loss: 1.1148 - val_accuracy: 0.2143\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8775 - accuracy: 0.3571 - val_loss: 1.1198 - val_accuracy: 0.2143\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8687 - accuracy: 0.3571 - val_loss: 1.1253 - val_accuracy: 0.2143\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8623 - accuracy: 0.3393 - val_loss: 1.1312 - val_accuracy: 0.2143\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8558 - accuracy: 0.3036 - val_loss: 1.1377 - val_accuracy: 0.2143\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8477 - accuracy: 0.3214 - val_loss: 1.1445 - val_accuracy: 0.2143\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8422 - accuracy: 0.3214 - val_loss: 1.1516 - val_accuracy: 0.2143\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8345 - accuracy: 0.3214 - val_loss: 1.1589 - val_accuracy: 0.2143\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8282 - accuracy: 0.3036 - val_loss: 1.1661 - val_accuracy: 0.2143\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8224 - accuracy: 0.3571 - val_loss: 1.1733 - val_accuracy: 0.2143\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8151 - accuracy: 0.3393 - val_loss: 1.1802 - val_accuracy: 0.2143\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8083 - accuracy: 0.3750 - val_loss: 1.1870 - val_accuracy: 0.2143\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8024 - accuracy: 0.3750 - val_loss: 1.1932 - val_accuracy: 0.2143\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7971 - accuracy: 0.3393 - val_loss: 1.1987 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7900 - accuracy: 0.3393 - val_loss: 1.2036 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7841 - accuracy: 0.3214 - val_loss: 1.2079 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7785 - accuracy: 0.3214 - val_loss: 1.2120 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7712 - accuracy: 0.3571 - val_loss: 1.2158 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7672 - accuracy: 0.3214 - val_loss: 1.2194 - val_accuracy: 0.2143\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7573 - accuracy: 0.3214 - val_loss: 1.2229 - val_accuracy: 0.2143\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7580 - accuracy: 0.3036 - val_loss: 1.2262 - val_accuracy: 0.2143\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7479 - accuracy: 0.3036 - val_loss: 1.2294 - val_accuracy: 0.2143\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7422 - accuracy: 0.3393 - val_loss: 1.2327 - val_accuracy: 0.2143\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7447 - accuracy: 0.3393 - val_loss: 1.2359 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7356 - accuracy: 0.3571 - val_loss: 1.2392 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7329 - accuracy: 0.3571 - val_loss: 1.2422 - val_accuracy: 0.0714\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7258 - accuracy: 0.3214 - val_loss: 1.2453 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7213 - accuracy: 0.3393 - val_loss: 1.2486 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7200 - accuracy: 0.3393 - val_loss: 1.2519 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7136 - accuracy: 0.3571 - val_loss: 1.2553 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7047 - accuracy: 0.3393 - val_loss: 1.2589 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7038 - accuracy: 0.3571 - val_loss: 1.2620 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6927 - accuracy: 0.3393 - val_loss: 1.2649 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6943 - accuracy: 0.3393 - val_loss: 1.2674 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6847 - accuracy: 0.3214 - val_loss: 1.2694 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6787 - accuracy: 0.3214 - val_loss: 1.2713 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6761 - accuracy: 0.3571 - val_loss: 1.2733 - val_accuracy: 0.0714\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6736 - accuracy: 0.3571 - val_loss: 1.2761 - val_accuracy: 0.0714\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6681 - accuracy: 0.3750 - val_loss: 1.2791 - val_accuracy: 0.0714\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6605 - accuracy: 0.3571 - val_loss: 1.2834 - val_accuracy: 0.0714\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6603 - accuracy: 0.3929 - val_loss: 1.2882 - val_accuracy: 0.0714\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6489 - accuracy: 0.4107 - val_loss: 1.2947 - val_accuracy: 0.0714\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6460 - accuracy: 0.3929 - val_loss: 1.3024 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6362 - accuracy: 0.3929 - val_loss: 1.3106 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3106 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=64, batch_size=400, Scores: [1.3105831146240234, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.3105831146240234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9843 - accuracy: 0.1429 - val_loss: 1.0690 - val_accuracy: 0.1429\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9796 - accuracy: 0.3214 - val_loss: 1.0695 - val_accuracy: 0.2143\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9758 - accuracy: 0.3214 - val_loss: 1.0701 - val_accuracy: 0.2143\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9713 - accuracy: 0.3214 - val_loss: 1.0707 - val_accuracy: 0.2143\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9678 - accuracy: 0.3214 - val_loss: 1.0713 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9627 - accuracy: 0.3214 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9594 - accuracy: 0.3571 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9552 - accuracy: 0.3393 - val_loss: 1.0735 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9500 - accuracy: 0.3214 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9444 - accuracy: 0.3393 - val_loss: 1.0750 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9402 - accuracy: 0.3036 - val_loss: 1.0759 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9354 - accuracy: 0.3214 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9300 - accuracy: 0.3393 - val_loss: 1.0778 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9262 - accuracy: 0.3036 - val_loss: 1.0789 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9199 - accuracy: 0.3214 - val_loss: 1.0801 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9134 - accuracy: 0.3393 - val_loss: 1.0815 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9082 - accuracy: 0.3214 - val_loss: 1.0829 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9009 - accuracy: 0.3036 - val_loss: 1.0846 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8946 - accuracy: 0.3214 - val_loss: 1.0864 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8873 - accuracy: 0.3214 - val_loss: 1.0884 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8793 - accuracy: 0.3036 - val_loss: 1.0907 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8717 - accuracy: 0.3036 - val_loss: 1.0933 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8637 - accuracy: 0.3214 - val_loss: 1.0964 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8587 - accuracy: 0.3036 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8502 - accuracy: 0.3036 - val_loss: 1.1037 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8420 - accuracy: 0.2857 - val_loss: 1.1081 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8365 - accuracy: 0.2857 - val_loss: 1.1131 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8301 - accuracy: 0.3036 - val_loss: 1.1187 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8222 - accuracy: 0.3214 - val_loss: 1.1248 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8169 - accuracy: 0.3036 - val_loss: 1.1314 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.8108 - accuracy: 0.3036 - val_loss: 1.1385 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8060 - accuracy: 0.3214 - val_loss: 1.1458 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7997 - accuracy: 0.3214 - val_loss: 1.1535 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7943 - accuracy: 0.3036 - val_loss: 1.1610 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7899 - accuracy: 0.3036 - val_loss: 1.1686 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7862 - accuracy: 0.3036 - val_loss: 1.1760 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7780 - accuracy: 0.3214 - val_loss: 1.1833 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7705 - accuracy: 0.3036 - val_loss: 1.1902 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7656 - accuracy: 0.2857 - val_loss: 1.1967 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7621 - accuracy: 0.3393 - val_loss: 1.2024 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7558 - accuracy: 0.3214 - val_loss: 1.2077 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7491 - accuracy: 0.3750 - val_loss: 1.2123 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7439 - accuracy: 0.3571 - val_loss: 1.2165 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7422 - accuracy: 0.3750 - val_loss: 1.2201 - val_accuracy: 0.0714\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7364 - accuracy: 0.3571 - val_loss: 1.2234 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7365 - accuracy: 0.3571 - val_loss: 1.2262 - val_accuracy: 0.0714\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7236 - accuracy: 0.3571 - val_loss: 1.2291 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7216 - accuracy: 0.3750 - val_loss: 1.2321 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7180 - accuracy: 0.3750 - val_loss: 1.2349 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7160 - accuracy: 0.3750 - val_loss: 1.2374 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7104 - accuracy: 0.3750 - val_loss: 1.2400 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7101 - accuracy: 0.3750 - val_loss: 1.2432 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7025 - accuracy: 0.3929 - val_loss: 1.2466 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6953 - accuracy: 0.3571 - val_loss: 1.2505 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6935 - accuracy: 0.3750 - val_loss: 1.2547 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6864 - accuracy: 0.3393 - val_loss: 1.2590 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6834 - accuracy: 0.3750 - val_loss: 1.2634 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6769 - accuracy: 0.3571 - val_loss: 1.2679 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6721 - accuracy: 0.3571 - val_loss: 1.2724 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6688 - accuracy: 0.3393 - val_loss: 1.2770 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6630 - accuracy: 0.4107 - val_loss: 1.2827 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6552 - accuracy: 0.3929 - val_loss: 1.2885 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6531 - accuracy: 0.3929 - val_loss: 1.2947 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6474 - accuracy: 0.4286 - val_loss: 1.3013 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3013 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=64, batch_size=500, Scores: [1.3013023138046265, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.3013023138046265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9839 - accuracy: 0.1250 - val_loss: 1.0686 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9789 - accuracy: 0.1786 - val_loss: 1.0688 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9761 - accuracy: 0.2679 - val_loss: 1.0691 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9716 - accuracy: 0.2679 - val_loss: 1.0695 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9675 - accuracy: 0.2500 - val_loss: 1.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9632 - accuracy: 0.3214 - val_loss: 1.0703 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9594 - accuracy: 0.3036 - val_loss: 1.0707 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9555 - accuracy: 0.3214 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9507 - accuracy: 0.3214 - val_loss: 1.0718 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9467 - accuracy: 0.3571 - val_loss: 1.0723 - val_accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9411 - accuracy: 0.3393 - val_loss: 1.0730 - val_accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.9374 - accuracy: 0.3393 - val_loss: 1.0737 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9317 - accuracy: 0.3750 - val_loss: 1.0744 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9271 - accuracy: 0.3214 - val_loss: 1.0752 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9208 - accuracy: 0.3214 - val_loss: 1.0760 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9157 - accuracy: 0.3571 - val_loss: 1.0770 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9108 - accuracy: 0.3393 - val_loss: 1.0780 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9040 - accuracy: 0.3393 - val_loss: 1.0792 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8981 - accuracy: 0.3036 - val_loss: 1.0805 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8923 - accuracy: 0.3393 - val_loss: 1.0820 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8862 - accuracy: 0.3214 - val_loss: 1.0837 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8777 - accuracy: 0.3214 - val_loss: 1.0857 - val_accuracy: 0.2143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8714 - accuracy: 0.3214 - val_loss: 1.0879 - val_accuracy: 0.2143\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8636 - accuracy: 0.3214 - val_loss: 1.0904 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8557 - accuracy: 0.3214 - val_loss: 1.0932 - val_accuracy: 0.2143\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8492 - accuracy: 0.3393 - val_loss: 1.0965 - val_accuracy: 0.2143\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8423 - accuracy: 0.3214 - val_loss: 1.1001 - val_accuracy: 0.2143\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8319 - accuracy: 0.3214 - val_loss: 1.1042 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8284 - accuracy: 0.3571 - val_loss: 1.1090 - val_accuracy: 0.2143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8186 - accuracy: 0.3393 - val_loss: 1.1143 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8124 - accuracy: 0.3393 - val_loss: 1.1204 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.8049 - accuracy: 0.3571 - val_loss: 1.1272 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7994 - accuracy: 0.3393 - val_loss: 1.1349 - val_accuracy: 0.2143\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7897 - accuracy: 0.3393 - val_loss: 1.1435 - val_accuracy: 0.2143\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7852 - accuracy: 0.3214 - val_loss: 1.1528 - val_accuracy: 0.2143\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7785 - accuracy: 0.3214 - val_loss: 1.1627 - val_accuracy: 0.2143\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7734 - accuracy: 0.3214 - val_loss: 1.1730 - val_accuracy: 0.2143\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7653 - accuracy: 0.3214 - val_loss: 1.1837 - val_accuracy: 0.2143\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7637 - accuracy: 0.3036 - val_loss: 1.1943 - val_accuracy: 0.2143\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7580 - accuracy: 0.3214 - val_loss: 1.2045 - val_accuracy: 0.2143\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7541 - accuracy: 0.3393 - val_loss: 1.2141 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7490 - accuracy: 0.3393 - val_loss: 1.2230 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7454 - accuracy: 0.3393 - val_loss: 1.2308 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7394 - accuracy: 0.3393 - val_loss: 1.2373 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7362 - accuracy: 0.3393 - val_loss: 1.2428 - val_accuracy: 0.0714\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7304 - accuracy: 0.3571 - val_loss: 1.2468 - val_accuracy: 0.0714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7253 - accuracy: 0.3571 - val_loss: 1.2497 - val_accuracy: 0.0714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7207 - accuracy: 0.3393 - val_loss: 1.2517 - val_accuracy: 0.0714\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7181 - accuracy: 0.3571 - val_loss: 1.2528 - val_accuracy: 0.0714\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7106 - accuracy: 0.3571 - val_loss: 1.2537 - val_accuracy: 0.0714\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7122 - accuracy: 0.3571 - val_loss: 1.2545 - val_accuracy: 0.0714\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7037 - accuracy: 0.3571 - val_loss: 1.2555 - val_accuracy: 0.0714\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6973 - accuracy: 0.3393 - val_loss: 1.2564 - val_accuracy: 0.0714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6976 - accuracy: 0.3393 - val_loss: 1.2577 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6944 - accuracy: 0.3393 - val_loss: 1.2593 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6856 - accuracy: 0.3571 - val_loss: 1.2614 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6806 - accuracy: 0.3214 - val_loss: 1.2640 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6788 - accuracy: 0.3214 - val_loss: 1.2670 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6744 - accuracy: 0.3571 - val_loss: 1.2703 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6688 - accuracy: 0.3393 - val_loss: 1.2742 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6598 - accuracy: 0.3393 - val_loss: 1.2786 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6562 - accuracy: 0.3750 - val_loss: 1.2837 - val_accuracy: 0.0714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6510 - accuracy: 0.3393 - val_loss: 1.2892 - val_accuracy: 0.0714\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6443 - accuracy: 0.3929 - val_loss: 1.2955 - val_accuracy: 0.0714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6407 - accuracy: 0.3571 - val_loss: 1.3029 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6361 - accuracy: 0.3929 - val_loss: 1.3112 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6344 - accuracy: 0.3750 - val_loss: 1.3198 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6213 - accuracy: 0.3929 - val_loss: 1.3290 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6204 - accuracy: 0.3571 - val_loss: 1.3384 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6147 - accuracy: 0.3571 - val_loss: 1.3477 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6080 - accuracy: 0.3750 - val_loss: 1.3567 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6021 - accuracy: 0.3750 - val_loss: 1.3666 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6006 - accuracy: 0.3750 - val_loss: 1.3772 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5956 - accuracy: 0.4286 - val_loss: 1.3874 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5878 - accuracy: 0.4464 - val_loss: 1.3967 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5802 - accuracy: 0.4286 - val_loss: 1.4064 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5792 - accuracy: 0.4286 - val_loss: 1.4162 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5733 - accuracy: 0.4286 - val_loss: 1.4251 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5677 - accuracy: 0.4286 - val_loss: 1.4325 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5588 - accuracy: 0.3929 - val_loss: 1.4385 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5599 - accuracy: 0.4286 - val_loss: 1.4443 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5478 - accuracy: 0.4107 - val_loss: 1.4486 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5476 - accuracy: 0.4643 - val_loss: 1.4513 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5392 - accuracy: 0.4286 - val_loss: 1.4514 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.5328 - accuracy: 0.4107 - val_loss: 1.4520 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5293 - accuracy: 0.4107 - val_loss: 1.4529 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5172 - accuracy: 0.4643 - val_loss: 1.4539 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5194 - accuracy: 0.4286 - val_loss: 1.4560 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5133 - accuracy: 0.4643 - val_loss: 1.4588 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5058 - accuracy: 0.4464 - val_loss: 1.4609 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5001 - accuracy: 0.4821 - val_loss: 1.4648 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4918 - accuracy: 0.4643 - val_loss: 1.4704 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4873 - accuracy: 0.4821 - val_loss: 1.4755 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4744 - accuracy: 0.4464 - val_loss: 1.4803 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4714 - accuracy: 0.5000 - val_loss: 1.4839 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4675 - accuracy: 0.4643 - val_loss: 1.4855 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.4639 - accuracy: 0.4464 - val_loss: 1.4871 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.4533 - accuracy: 0.4464 - val_loss: 1.4902 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4496 - accuracy: 0.4464 - val_loss: 1.4950 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4450 - accuracy: 0.4821 - val_loss: 1.4995 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4995 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=100, batch_size=100, Scores: [1.499472737312317, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.499472737312317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9845 - accuracy: 0.0536 - val_loss: 1.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9807 - accuracy: 0.1964 - val_loss: 1.0711 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9764 - accuracy: 0.2143 - val_loss: 1.0712 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9718 - accuracy: 0.2500 - val_loss: 1.0714 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9664 - accuracy: 0.2857 - val_loss: 1.0716 - val_accuracy: 0.2143\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9628 - accuracy: 0.2857 - val_loss: 1.0719 - val_accuracy: 0.2143\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9575 - accuracy: 0.3214 - val_loss: 1.0722 - val_accuracy: 0.2857\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9525 - accuracy: 0.3214 - val_loss: 1.0727 - val_accuracy: 0.2857\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9480 - accuracy: 0.2857 - val_loss: 1.0731 - val_accuracy: 0.2857\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9438 - accuracy: 0.2857 - val_loss: 1.0736 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9385 - accuracy: 0.3214 - val_loss: 1.0743 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9339 - accuracy: 0.3214 - val_loss: 1.0750 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9268 - accuracy: 0.3036 - val_loss: 1.0758 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9239 - accuracy: 0.3214 - val_loss: 1.0767 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9190 - accuracy: 0.3036 - val_loss: 1.0778 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9116 - accuracy: 0.3214 - val_loss: 1.0791 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9047 - accuracy: 0.3036 - val_loss: 1.0805 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8991 - accuracy: 0.3393 - val_loss: 1.0822 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8933 - accuracy: 0.3036 - val_loss: 1.0840 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8886 - accuracy: 0.3214 - val_loss: 1.0861 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8823 - accuracy: 0.3214 - val_loss: 1.0883 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8768 - accuracy: 0.3214 - val_loss: 1.0907 - val_accuracy: 0.2143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8678 - accuracy: 0.3214 - val_loss: 1.0934 - val_accuracy: 0.2143\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8619 - accuracy: 0.3214 - val_loss: 1.0961 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8551 - accuracy: 0.2857 - val_loss: 1.0991 - val_accuracy: 0.2143\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8483 - accuracy: 0.3214 - val_loss: 1.1023 - val_accuracy: 0.2143\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8452 - accuracy: 0.3214 - val_loss: 1.1058 - val_accuracy: 0.2143\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8356 - accuracy: 0.3214 - val_loss: 1.1097 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8329 - accuracy: 0.3214 - val_loss: 1.1141 - val_accuracy: 0.2143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8282 - accuracy: 0.3214 - val_loss: 1.1190 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8205 - accuracy: 0.3036 - val_loss: 1.1246 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8157 - accuracy: 0.2857 - val_loss: 1.1309 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.8068 - accuracy: 0.2500 - val_loss: 1.1378 - val_accuracy: 0.2143\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8040 - accuracy: 0.2679 - val_loss: 1.1453 - val_accuracy: 0.2143\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7988 - accuracy: 0.2679 - val_loss: 1.1531 - val_accuracy: 0.2143\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7937 - accuracy: 0.2857 - val_loss: 1.1610 - val_accuracy: 0.2143\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7873 - accuracy: 0.2679 - val_loss: 1.1691 - val_accuracy: 0.2143\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7853 - accuracy: 0.2857 - val_loss: 1.1771 - val_accuracy: 0.2143\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7760 - accuracy: 0.3036 - val_loss: 1.1850 - val_accuracy: 0.2143\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7733 - accuracy: 0.2500 - val_loss: 1.1925 - val_accuracy: 0.2143\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7667 - accuracy: 0.2500 - val_loss: 1.1998 - val_accuracy: 0.2143\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7612 - accuracy: 0.3036 - val_loss: 1.2068 - val_accuracy: 0.2143\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7589 - accuracy: 0.2857 - val_loss: 1.2135 - val_accuracy: 0.2143\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7487 - accuracy: 0.3214 - val_loss: 1.2197 - val_accuracy: 0.2143\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7466 - accuracy: 0.3214 - val_loss: 1.2255 - val_accuracy: 0.2143\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7451 - accuracy: 0.3036 - val_loss: 1.2305 - val_accuracy: 0.2143\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7374 - accuracy: 0.3214 - val_loss: 1.2348 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7364 - accuracy: 0.3571 - val_loss: 1.2382 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7307 - accuracy: 0.3393 - val_loss: 1.2412 - val_accuracy: 0.2143\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7267 - accuracy: 0.3571 - val_loss: 1.2439 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7250 - accuracy: 0.3571 - val_loss: 1.2463 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7187 - accuracy: 0.3214 - val_loss: 1.2488 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7122 - accuracy: 0.3571 - val_loss: 1.2512 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7072 - accuracy: 0.3393 - val_loss: 1.2543 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7039 - accuracy: 0.3214 - val_loss: 1.2583 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.6923 - accuracy: 0.3571 - val_loss: 1.2624 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6943 - accuracy: 0.3571 - val_loss: 1.2672 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6865 - accuracy: 0.3214 - val_loss: 1.2722 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6827 - accuracy: 0.3393 - val_loss: 1.2776 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6739 - accuracy: 0.3750 - val_loss: 1.2833 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6690 - accuracy: 0.3750 - val_loss: 1.2887 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6617 - accuracy: 0.3750 - val_loss: 1.2935 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.6585 - accuracy: 0.3750 - val_loss: 1.2975 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6542 - accuracy: 0.3571 - val_loss: 1.3012 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6502 - accuracy: 0.3750 - val_loss: 1.3043 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6418 - accuracy: 0.3929 - val_loss: 1.3091 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6374 - accuracy: 0.3750 - val_loss: 1.3150 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6313 - accuracy: 0.3750 - val_loss: 1.3226 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6263 - accuracy: 0.3750 - val_loss: 1.3309 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6241 - accuracy: 0.3929 - val_loss: 1.3400 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6116 - accuracy: 0.3929 - val_loss: 1.3486 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6126 - accuracy: 0.3571 - val_loss: 1.3566 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6080 - accuracy: 0.4107 - val_loss: 1.3644 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5990 - accuracy: 0.4107 - val_loss: 1.3721 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5953 - accuracy: 0.3929 - val_loss: 1.3794 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5845 - accuracy: 0.4107 - val_loss: 1.3869 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5873 - accuracy: 0.3929 - val_loss: 1.3929 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5798 - accuracy: 0.4107 - val_loss: 1.3985 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5752 - accuracy: 0.4286 - val_loss: 1.4047 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5691 - accuracy: 0.3929 - val_loss: 1.4154 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5589 - accuracy: 0.4286 - val_loss: 1.4238 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5551 - accuracy: 0.4107 - val_loss: 1.4299 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5578 - accuracy: 0.3929 - val_loss: 1.4304 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5455 - accuracy: 0.3929 - val_loss: 1.4305 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5404 - accuracy: 0.3929 - val_loss: 1.4308 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5367 - accuracy: 0.4107 - val_loss: 1.4321 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5326 - accuracy: 0.4107 - val_loss: 1.4331 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5206 - accuracy: 0.4286 - val_loss: 1.4325 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5163 - accuracy: 0.3929 - val_loss: 1.4350 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5174 - accuracy: 0.4464 - val_loss: 1.4404 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5013 - accuracy: 0.4286 - val_loss: 1.4448 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4958 - accuracy: 0.4107 - val_loss: 1.4492 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4849 - accuracy: 0.4107 - val_loss: 1.4540 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4821 - accuracy: 0.4107 - val_loss: 1.4556 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4765 - accuracy: 0.3929 - val_loss: 1.4583 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4689 - accuracy: 0.3929 - val_loss: 1.4656 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4625 - accuracy: 0.4643 - val_loss: 1.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4578 - accuracy: 0.4464 - val_loss: 1.4841 - val_accuracy: 0.0714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4562 - accuracy: 0.4821 - val_loss: 1.4893 - val_accuracy: 0.0714\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.4401 - accuracy: 0.4643 - val_loss: 1.4901 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4901 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=100, batch_size=300, Scores: [1.4901397228240967, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.4901397228240967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9843 - accuracy: 0.1071 - val_loss: 1.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9796 - accuracy: 0.1786 - val_loss: 1.0702 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9744 - accuracy: 0.2321 - val_loss: 1.0703 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9703 - accuracy: 0.3036 - val_loss: 1.0704 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9668 - accuracy: 0.2857 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9622 - accuracy: 0.2500 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.9574 - accuracy: 0.3036 - val_loss: 1.0714 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.9528 - accuracy: 0.3393 - val_loss: 1.0718 - val_accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9482 - accuracy: 0.3036 - val_loss: 1.0724 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9429 - accuracy: 0.3036 - val_loss: 1.0730 - val_accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9389 - accuracy: 0.3393 - val_loss: 1.0738 - val_accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9331 - accuracy: 0.3750 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9285 - accuracy: 0.3571 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9224 - accuracy: 0.3393 - val_loss: 1.0771 - val_accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9182 - accuracy: 0.3929 - val_loss: 1.0786 - val_accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9111 - accuracy: 0.3571 - val_loss: 1.0803 - val_accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9067 - accuracy: 0.3214 - val_loss: 1.0824 - val_accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8986 - accuracy: 0.3393 - val_loss: 1.0847 - val_accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8934 - accuracy: 0.3571 - val_loss: 1.0873 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8874 - accuracy: 0.3393 - val_loss: 1.0903 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8793 - accuracy: 0.3393 - val_loss: 1.0937 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8743 - accuracy: 0.3214 - val_loss: 1.0973 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8680 - accuracy: 0.3571 - val_loss: 1.1011 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8611 - accuracy: 0.3393 - val_loss: 1.1052 - val_accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8555 - accuracy: 0.3393 - val_loss: 1.1093 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8505 - accuracy: 0.3393 - val_loss: 1.1134 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8417 - accuracy: 0.3036 - val_loss: 1.1173 - val_accuracy: 0.2143\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8339 - accuracy: 0.3214 - val_loss: 1.1209 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8290 - accuracy: 0.3571 - val_loss: 1.1242 - val_accuracy: 0.2143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8238 - accuracy: 0.3393 - val_loss: 1.1273 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8185 - accuracy: 0.3214 - val_loss: 1.1301 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8140 - accuracy: 0.3393 - val_loss: 1.1328 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8042 - accuracy: 0.3036 - val_loss: 1.1358 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7992 - accuracy: 0.3393 - val_loss: 1.1390 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7937 - accuracy: 0.3393 - val_loss: 1.1430 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7853 - accuracy: 0.3393 - val_loss: 1.1478 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7808 - accuracy: 0.3393 - val_loss: 1.1535 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7760 - accuracy: 0.3571 - val_loss: 1.1599 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7723 - accuracy: 0.3571 - val_loss: 1.1669 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7666 - accuracy: 0.3750 - val_loss: 1.1742 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7617 - accuracy: 0.3929 - val_loss: 1.1815 - val_accuracy: 0.0714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7580 - accuracy: 0.3929 - val_loss: 1.1886 - val_accuracy: 0.0714\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 0.7513 - accuracy: 0.4107 - val_loss: 1.1955 - val_accuracy: 0.0714\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7473 - accuracy: 0.3750 - val_loss: 1.2018 - val_accuracy: 0.0714\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7428 - accuracy: 0.3571 - val_loss: 1.2078 - val_accuracy: 0.0714\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7415 - accuracy: 0.3393 - val_loss: 1.2135 - val_accuracy: 0.0714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7372 - accuracy: 0.3393 - val_loss: 1.2188 - val_accuracy: 0.0714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7302 - accuracy: 0.3393 - val_loss: 1.2237 - val_accuracy: 0.0714\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7210 - accuracy: 0.3214 - val_loss: 1.2282 - val_accuracy: 0.0714\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7189 - accuracy: 0.3036 - val_loss: 1.2326 - val_accuracy: 0.0714\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7107 - accuracy: 0.3036 - val_loss: 1.2371 - val_accuracy: 0.0714\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7125 - accuracy: 0.3036 - val_loss: 1.2411 - val_accuracy: 0.0714\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7043 - accuracy: 0.3036 - val_loss: 1.2447 - val_accuracy: 0.0714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7032 - accuracy: 0.3036 - val_loss: 1.2481 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6956 - accuracy: 0.3036 - val_loss: 1.2516 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6928 - accuracy: 0.3036 - val_loss: 1.2551 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6850 - accuracy: 0.3036 - val_loss: 1.2587 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6810 - accuracy: 0.3214 - val_loss: 1.2622 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6772 - accuracy: 0.3214 - val_loss: 1.2658 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6715 - accuracy: 0.3750 - val_loss: 1.2693 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6665 - accuracy: 0.3571 - val_loss: 1.2729 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6605 - accuracy: 0.3393 - val_loss: 1.2775 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6562 - accuracy: 0.3750 - val_loss: 1.2834 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6469 - accuracy: 0.3929 - val_loss: 1.2905 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6381 - accuracy: 0.3929 - val_loss: 1.2980 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.6333 - accuracy: 0.4107 - val_loss: 1.3066 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6304 - accuracy: 0.4107 - val_loss: 1.3163 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6286 - accuracy: 0.3929 - val_loss: 1.3273 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6158 - accuracy: 0.3929 - val_loss: 1.3389 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6066 - accuracy: 0.3571 - val_loss: 1.3510 - val_accuracy: 0.2143\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6070 - accuracy: 0.3571 - val_loss: 1.3612 - val_accuracy: 0.2143\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6026 - accuracy: 0.3750 - val_loss: 1.3699 - val_accuracy: 0.2143\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5942 - accuracy: 0.3750 - val_loss: 1.3779 - val_accuracy: 0.2143\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5950 - accuracy: 0.3750 - val_loss: 1.3844 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5851 - accuracy: 0.3750 - val_loss: 1.3924 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5821 - accuracy: 0.3750 - val_loss: 1.3985 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5783 - accuracy: 0.3750 - val_loss: 1.4068 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5653 - accuracy: 0.3750 - val_loss: 1.4135 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5623 - accuracy: 0.3929 - val_loss: 1.4179 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5524 - accuracy: 0.3750 - val_loss: 1.4238 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5445 - accuracy: 0.3929 - val_loss: 1.4307 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5450 - accuracy: 0.3750 - val_loss: 1.4337 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5455 - accuracy: 0.3750 - val_loss: 1.4353 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5383 - accuracy: 0.4107 - val_loss: 1.4333 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5266 - accuracy: 0.3929 - val_loss: 1.4319 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5151 - accuracy: 0.3929 - val_loss: 1.4334 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5163 - accuracy: 0.4107 - val_loss: 1.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5019 - accuracy: 0.3929 - val_loss: 1.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5020 - accuracy: 0.3929 - val_loss: 1.4510 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5001 - accuracy: 0.3929 - val_loss: 1.4624 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4890 - accuracy: 0.3750 - val_loss: 1.4629 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4840 - accuracy: 0.4107 - val_loss: 1.4611 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4826 - accuracy: 0.4107 - val_loss: 1.4616 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4701 - accuracy: 0.4464 - val_loss: 1.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.4614 - accuracy: 0.3929 - val_loss: 1.4719 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4628 - accuracy: 0.3929 - val_loss: 1.4719 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4494 - accuracy: 0.4464 - val_loss: 1.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4430 - accuracy: 0.3929 - val_loss: 1.4722 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4359 - accuracy: 0.4107 - val_loss: 1.4768 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4275 - accuracy: 0.3929 - val_loss: 1.4841 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4841 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=100, batch_size=400, Scores: [1.4840668439865112, 0.0]\n",
      "Accuracy on validation set: 0.0\n",
      "Loss on validation set: 1.4840668439865112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9818 - accuracy: 0.2321 - val_loss: 1.0687 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9776 - accuracy: 0.2321 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9732 - accuracy: 0.3393 - val_loss: 1.0702 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9693 - accuracy: 0.2857 - val_loss: 1.0710 - val_accuracy: 0.2143\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9644 - accuracy: 0.3036 - val_loss: 1.0719 - val_accuracy: 0.2143\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9595 - accuracy: 0.3929 - val_loss: 1.0729 - val_accuracy: 0.2143\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9556 - accuracy: 0.3750 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9510 - accuracy: 0.3393 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9469 - accuracy: 0.3571 - val_loss: 1.0761 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9404 - accuracy: 0.3571 - val_loss: 1.0773 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9361 - accuracy: 0.3750 - val_loss: 1.0786 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9302 - accuracy: 0.3393 - val_loss: 1.0800 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9245 - accuracy: 0.3750 - val_loss: 1.0815 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9205 - accuracy: 0.3750 - val_loss: 1.0832 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9126 - accuracy: 0.3393 - val_loss: 1.0850 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9071 - accuracy: 0.3929 - val_loss: 1.0870 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9016 - accuracy: 0.3571 - val_loss: 1.0891 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8922 - accuracy: 0.3929 - val_loss: 1.0914 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8863 - accuracy: 0.3571 - val_loss: 1.0939 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8797 - accuracy: 0.3214 - val_loss: 1.0967 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8746 - accuracy: 0.3750 - val_loss: 1.0996 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8673 - accuracy: 0.3393 - val_loss: 1.1026 - val_accuracy: 0.2143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.8613 - accuracy: 0.3214 - val_loss: 1.1056 - val_accuracy: 0.2143\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8514 - accuracy: 0.3393 - val_loss: 1.1087 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8438 - accuracy: 0.3393 - val_loss: 1.1120 - val_accuracy: 0.2143\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.8375 - accuracy: 0.3393 - val_loss: 1.1157 - val_accuracy: 0.2143\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8311 - accuracy: 0.3571 - val_loss: 1.1197 - val_accuracy: 0.2143\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.8252 - accuracy: 0.3214 - val_loss: 1.1242 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8163 - accuracy: 0.3214 - val_loss: 1.1295 - val_accuracy: 0.2143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8097 - accuracy: 0.3214 - val_loss: 1.1356 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8024 - accuracy: 0.3393 - val_loss: 1.1429 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7971 - accuracy: 0.3214 - val_loss: 1.1512 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7912 - accuracy: 0.3393 - val_loss: 1.1606 - val_accuracy: 0.2143\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7862 - accuracy: 0.3571 - val_loss: 1.1710 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7819 - accuracy: 0.3214 - val_loss: 1.1821 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7792 - accuracy: 0.3214 - val_loss: 1.1934 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7720 - accuracy: 0.3571 - val_loss: 1.2047 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7676 - accuracy: 0.4107 - val_loss: 1.2154 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7625 - accuracy: 0.3750 - val_loss: 1.2258 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7598 - accuracy: 0.3571 - val_loss: 1.2353 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7533 - accuracy: 0.3571 - val_loss: 1.2430 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7537 - accuracy: 0.3571 - val_loss: 1.2492 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7481 - accuracy: 0.3571 - val_loss: 1.2538 - val_accuracy: 0.0714\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7445 - accuracy: 0.3571 - val_loss: 1.2570 - val_accuracy: 0.0714\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7402 - accuracy: 0.3571 - val_loss: 1.2590 - val_accuracy: 0.0714\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7372 - accuracy: 0.3393 - val_loss: 1.2602 - val_accuracy: 0.0714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7307 - accuracy: 0.3214 - val_loss: 1.2609 - val_accuracy: 0.0714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7232 - accuracy: 0.3571 - val_loss: 1.2618 - val_accuracy: 0.0714\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7198 - accuracy: 0.3571 - val_loss: 1.2629 - val_accuracy: 0.0714\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7150 - accuracy: 0.3571 - val_loss: 1.2647 - val_accuracy: 0.0714\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7137 - accuracy: 0.3571 - val_loss: 1.2668 - val_accuracy: 0.0714\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7115 - accuracy: 0.3393 - val_loss: 1.2693 - val_accuracy: 0.0714\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7019 - accuracy: 0.3571 - val_loss: 1.2727 - val_accuracy: 0.0714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6984 - accuracy: 0.3571 - val_loss: 1.2771 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6929 - accuracy: 0.3929 - val_loss: 1.2822 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6910 - accuracy: 0.3571 - val_loss: 1.2886 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6857 - accuracy: 0.3750 - val_loss: 1.2955 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.6789 - accuracy: 0.3929 - val_loss: 1.3033 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6773 - accuracy: 0.3750 - val_loss: 1.3113 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6687 - accuracy: 0.3750 - val_loss: 1.3195 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6636 - accuracy: 0.3750 - val_loss: 1.3274 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6615 - accuracy: 0.3929 - val_loss: 1.3352 - val_accuracy: 0.0714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6584 - accuracy: 0.3393 - val_loss: 1.3416 - val_accuracy: 0.0714\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6461 - accuracy: 0.3929 - val_loss: 1.3465 - val_accuracy: 0.0714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6506 - accuracy: 0.3929 - val_loss: 1.3507 - val_accuracy: 0.0714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6421 - accuracy: 0.3571 - val_loss: 1.3548 - val_accuracy: 0.0714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6406 - accuracy: 0.3929 - val_loss: 1.3599 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6373 - accuracy: 0.3750 - val_loss: 1.3656 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6260 - accuracy: 0.3750 - val_loss: 1.3739 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6194 - accuracy: 0.3571 - val_loss: 1.3829 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6134 - accuracy: 0.4107 - val_loss: 1.3930 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6091 - accuracy: 0.3929 - val_loss: 1.4033 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6075 - accuracy: 0.4107 - val_loss: 1.4113 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.5967 - accuracy: 0.4286 - val_loss: 1.4168 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5949 - accuracy: 0.3929 - val_loss: 1.4210 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5919 - accuracy: 0.3571 - val_loss: 1.4278 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.5774 - accuracy: 0.3571 - val_loss: 1.4317 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5796 - accuracy: 0.3750 - val_loss: 1.4341 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5715 - accuracy: 0.3929 - val_loss: 1.4385 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5683 - accuracy: 0.3750 - val_loss: 1.4420 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5635 - accuracy: 0.3750 - val_loss: 1.4468 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5553 - accuracy: 0.3750 - val_loss: 1.4541 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5454 - accuracy: 0.3929 - val_loss: 1.4623 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5442 - accuracy: 0.3750 - val_loss: 1.4707 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5431 - accuracy: 0.4107 - val_loss: 1.4774 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5334 - accuracy: 0.4107 - val_loss: 1.4831 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5279 - accuracy: 0.3929 - val_loss: 1.4886 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5214 - accuracy: 0.4107 - val_loss: 1.4926 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5184 - accuracy: 0.4464 - val_loss: 1.4966 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5098 - accuracy: 0.4286 - val_loss: 1.5038 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5049 - accuracy: 0.4107 - val_loss: 1.5096 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5027 - accuracy: 0.4821 - val_loss: 1.5084 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4978 - accuracy: 0.4643 - val_loss: 1.5088 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4865 - accuracy: 0.4286 - val_loss: 1.5078 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4849 - accuracy: 0.4286 - val_loss: 1.5077 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4787 - accuracy: 0.4643 - val_loss: 1.5077 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4715 - accuracy: 0.4286 - val_loss: 1.5105 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4626 - accuracy: 0.4821 - val_loss: 1.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4580 - accuracy: 0.4821 - val_loss: 1.5115 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.4536 - accuracy: 0.4464 - val_loss: 1.5146 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5146 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=100, batch_size=500, Scores: [1.5146400928497314, 0.0]\n",
      "Accuracy on validation set: 0.0\n",
      "Loss on validation set: 1.5146400928497314\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9815 - accuracy: 0.2500 - val_loss: 1.0693 - val_accuracy: 0.1429\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9770 - accuracy: 0.2500 - val_loss: 1.0703 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.9732 - accuracy: 0.2500 - val_loss: 1.0714 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9685 - accuracy: 0.2321 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9646 - accuracy: 0.2857 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.9598 - accuracy: 0.2857 - val_loss: 1.0750 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9564 - accuracy: 0.2500 - val_loss: 1.0764 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9517 - accuracy: 0.2679 - val_loss: 1.0778 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9467 - accuracy: 0.2857 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9430 - accuracy: 0.3036 - val_loss: 1.0808 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9362 - accuracy: 0.3036 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9314 - accuracy: 0.3036 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9260 - accuracy: 0.3036 - val_loss: 1.0859 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9205 - accuracy: 0.3036 - val_loss: 1.0878 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9138 - accuracy: 0.3214 - val_loss: 1.0900 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9093 - accuracy: 0.3393 - val_loss: 1.0923 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9027 - accuracy: 0.3036 - val_loss: 1.0949 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8948 - accuracy: 0.3393 - val_loss: 1.0977 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8898 - accuracy: 0.3393 - val_loss: 1.1009 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8828 - accuracy: 0.3393 - val_loss: 1.1043 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8759 - accuracy: 0.3393 - val_loss: 1.1082 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8691 - accuracy: 0.3393 - val_loss: 1.1126 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8628 - accuracy: 0.3214 - val_loss: 1.1174 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8555 - accuracy: 0.3214 - val_loss: 1.1227 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8468 - accuracy: 0.2857 - val_loss: 1.1285 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8435 - accuracy: 0.3036 - val_loss: 1.1347 - val_accuracy: 0.2143\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8370 - accuracy: 0.2857 - val_loss: 1.1413 - val_accuracy: 0.2143\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8296 - accuracy: 0.2857 - val_loss: 1.1483 - val_accuracy: 0.2143\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8226 - accuracy: 0.2857 - val_loss: 1.1555 - val_accuracy: 0.2143\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8176 - accuracy: 0.2857 - val_loss: 1.1629 - val_accuracy: 0.2143\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8112 - accuracy: 0.2857 - val_loss: 1.1706 - val_accuracy: 0.2143\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8043 - accuracy: 0.2857 - val_loss: 1.1784 - val_accuracy: 0.2143\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7983 - accuracy: 0.2857 - val_loss: 1.1865 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7915 - accuracy: 0.2857 - val_loss: 1.1948 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7879 - accuracy: 0.3036 - val_loss: 1.2033 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7828 - accuracy: 0.3036 - val_loss: 1.2118 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7744 - accuracy: 0.3036 - val_loss: 1.2201 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7737 - accuracy: 0.3036 - val_loss: 1.2281 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7660 - accuracy: 0.3214 - val_loss: 1.2357 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7576 - accuracy: 0.3036 - val_loss: 1.2431 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7566 - accuracy: 0.3214 - val_loss: 1.2501 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7499 - accuracy: 0.3214 - val_loss: 1.2565 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7452 - accuracy: 0.3214 - val_loss: 1.2626 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7416 - accuracy: 0.3571 - val_loss: 1.2680 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7397 - accuracy: 0.3571 - val_loss: 1.2728 - val_accuracy: 0.0714\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7324 - accuracy: 0.3393 - val_loss: 1.2767 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7246 - accuracy: 0.3750 - val_loss: 1.2798 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7230 - accuracy: 0.3571 - val_loss: 1.2824 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.7100 - accuracy: 0.3750 - val_loss: 1.2853 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7108 - accuracy: 0.3929 - val_loss: 1.2878 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7036 - accuracy: 0.4286 - val_loss: 1.2905 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7008 - accuracy: 0.4107 - val_loss: 1.2934 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6956 - accuracy: 0.4286 - val_loss: 1.2959 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6920 - accuracy: 0.4286 - val_loss: 1.2985 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6828 - accuracy: 0.4464 - val_loss: 1.3021 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6813 - accuracy: 0.4464 - val_loss: 1.3063 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6761 - accuracy: 0.4464 - val_loss: 1.3110 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6735 - accuracy: 0.4464 - val_loss: 1.3160 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6705 - accuracy: 0.4643 - val_loss: 1.3222 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6635 - accuracy: 0.4464 - val_loss: 1.3283 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6634 - accuracy: 0.4464 - val_loss: 1.3334 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6494 - accuracy: 0.4286 - val_loss: 1.3371 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6447 - accuracy: 0.4464 - val_loss: 1.3392 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6486 - accuracy: 0.4464 - val_loss: 1.3407 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6372 - accuracy: 0.3929 - val_loss: 1.3412 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6349 - accuracy: 0.4464 - val_loss: 1.3405 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6260 - accuracy: 0.4107 - val_loss: 1.3418 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6233 - accuracy: 0.4286 - val_loss: 1.3438 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6193 - accuracy: 0.4286 - val_loss: 1.3461 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6081 - accuracy: 0.4286 - val_loss: 1.3485 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6005 - accuracy: 0.3929 - val_loss: 1.3520 - val_accuracy: 0.0714\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5997 - accuracy: 0.4107 - val_loss: 1.3565 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5984 - accuracy: 0.3929 - val_loss: 1.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5913 - accuracy: 0.4107 - val_loss: 1.3697 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5839 - accuracy: 0.4286 - val_loss: 1.3772 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5714 - accuracy: 0.4107 - val_loss: 1.3854 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5766 - accuracy: 0.4107 - val_loss: 1.3926 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5671 - accuracy: 0.3929 - val_loss: 1.3971 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5643 - accuracy: 0.4107 - val_loss: 1.4007 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5489 - accuracy: 0.3929 - val_loss: 1.4068 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5447 - accuracy: 0.4107 - val_loss: 1.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5381 - accuracy: 0.4286 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5314 - accuracy: 0.3929 - val_loss: 1.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5322 - accuracy: 0.4286 - val_loss: 1.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5243 - accuracy: 0.4286 - val_loss: 1.4517 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5154 - accuracy: 0.3750 - val_loss: 1.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5036 - accuracy: 0.4286 - val_loss: 1.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5022 - accuracy: 0.4464 - val_loss: 1.4510 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4863 - accuracy: 0.4286 - val_loss: 1.4534 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4883 - accuracy: 0.4286 - val_loss: 1.4579 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4782 - accuracy: 0.4643 - val_loss: 1.4651 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4766 - accuracy: 0.4286 - val_loss: 1.4717 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4637 - accuracy: 0.4286 - val_loss: 1.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4711 - accuracy: 0.4286 - val_loss: 1.4756 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4468 - accuracy: 0.4821 - val_loss: 1.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4448 - accuracy: 0.4821 - val_loss: 1.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4544 - accuracy: 0.4643 - val_loss: 1.4791 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4370 - accuracy: 0.4643 - val_loss: 1.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4370 - accuracy: 0.5000 - val_loss: 1.4856 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4288 - accuracy: 0.4464 - val_loss: 1.4709 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4120 - accuracy: 0.5000 - val_loss: 1.4633 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4191 - accuracy: 0.4821 - val_loss: 1.4652 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4048 - accuracy: 0.4643 - val_loss: 1.4722 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4001 - accuracy: 0.4643 - val_loss: 1.4782 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3893 - accuracy: 0.4821 - val_loss: 1.4784 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3962 - accuracy: 0.4464 - val_loss: 1.4611 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3819 - accuracy: 0.5357 - val_loss: 1.4439 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3751 - accuracy: 0.5000 - val_loss: 1.4380 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3800 - accuracy: 0.4821 - val_loss: 1.4439 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3774 - accuracy: 0.4643 - val_loss: 1.4638 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3568 - accuracy: 0.4821 - val_loss: 1.4869 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3571 - accuracy: 0.5179 - val_loss: 1.5002 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3555 - accuracy: 0.5536 - val_loss: 1.4961 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3426 - accuracy: 0.4821 - val_loss: 1.4894 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3522 - accuracy: 0.5000 - val_loss: 1.4885 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3460 - accuracy: 0.5714 - val_loss: 1.4916 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3330 - accuracy: 0.5536 - val_loss: 1.4932 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3292 - accuracy: 0.4643 - val_loss: 1.4958 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3237 - accuracy: 0.5536 - val_loss: 1.4933 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3176 - accuracy: 0.5536 - val_loss: 1.4893 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3172 - accuracy: 0.5536 - val_loss: 1.4826 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3139 - accuracy: 0.5893 - val_loss: 1.4851 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3186 - accuracy: 0.5357 - val_loss: 1.4941 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3091 - accuracy: 0.5179 - val_loss: 1.5056 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3142 - accuracy: 0.5357 - val_loss: 1.5089 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3090 - accuracy: 0.5179 - val_loss: 1.5034 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2974 - accuracy: 0.5714 - val_loss: 1.4975 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2918 - accuracy: 0.6071 - val_loss: 1.4919 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4919 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=128, batch_size=100, Scores: [1.491934895515442, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.491934895515442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9836 - accuracy: 0.0893 - val_loss: 1.0666 - val_accuracy: 0.1429\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9804 - accuracy: 0.1964 - val_loss: 1.0669 - val_accuracy: 0.1429\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.9745 - accuracy: 0.2500 - val_loss: 1.0673 - val_accuracy: 0.1429\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9704 - accuracy: 0.2500 - val_loss: 1.0677 - val_accuracy: 0.1429\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9658 - accuracy: 0.2321 - val_loss: 1.0682 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9624 - accuracy: 0.2143 - val_loss: 1.0686 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9575 - accuracy: 0.2679 - val_loss: 1.0692 - val_accuracy: 0.1429\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9526 - accuracy: 0.3036 - val_loss: 1.0697 - val_accuracy: 0.2143\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9465 - accuracy: 0.3214 - val_loss: 1.0702 - val_accuracy: 0.2143\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9421 - accuracy: 0.2857 - val_loss: 1.0708 - val_accuracy: 0.2143\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9366 - accuracy: 0.3214 - val_loss: 1.0713 - val_accuracy: 0.2143\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9326 - accuracy: 0.3214 - val_loss: 1.0719 - val_accuracy: 0.2143\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9253 - accuracy: 0.2857 - val_loss: 1.0726 - val_accuracy: 0.2143\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9207 - accuracy: 0.3214 - val_loss: 1.0733 - val_accuracy: 0.2143\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9157 - accuracy: 0.3036 - val_loss: 1.0741 - val_accuracy: 0.2143\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9074 - accuracy: 0.2857 - val_loss: 1.0750 - val_accuracy: 0.2143\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9026 - accuracy: 0.3393 - val_loss: 1.0760 - val_accuracy: 0.2143\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8953 - accuracy: 0.3036 - val_loss: 1.0772 - val_accuracy: 0.2143\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8891 - accuracy: 0.3036 - val_loss: 1.0787 - val_accuracy: 0.2143\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8800 - accuracy: 0.3214 - val_loss: 1.0804 - val_accuracy: 0.2143\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8742 - accuracy: 0.2857 - val_loss: 1.0825 - val_accuracy: 0.2143\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8664 - accuracy: 0.2857 - val_loss: 1.0849 - val_accuracy: 0.2143\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8584 - accuracy: 0.3036 - val_loss: 1.0878 - val_accuracy: 0.2143\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8516 - accuracy: 0.3036 - val_loss: 1.0910 - val_accuracy: 0.2143\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8477 - accuracy: 0.3036 - val_loss: 1.0948 - val_accuracy: 0.2143\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8385 - accuracy: 0.2679 - val_loss: 1.0990 - val_accuracy: 0.2143\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8321 - accuracy: 0.2679 - val_loss: 1.1037 - val_accuracy: 0.2143\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8254 - accuracy: 0.2679 - val_loss: 1.1088 - val_accuracy: 0.2143\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8194 - accuracy: 0.2857 - val_loss: 1.1146 - val_accuracy: 0.2143\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8136 - accuracy: 0.2857 - val_loss: 1.1208 - val_accuracy: 0.2143\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8070 - accuracy: 0.3036 - val_loss: 1.1277 - val_accuracy: 0.2143\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8011 - accuracy: 0.3214 - val_loss: 1.1353 - val_accuracy: 0.2143\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7946 - accuracy: 0.3036 - val_loss: 1.1435 - val_accuracy: 0.2143\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7901 - accuracy: 0.3393 - val_loss: 1.1522 - val_accuracy: 0.2143\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7837 - accuracy: 0.3214 - val_loss: 1.1611 - val_accuracy: 0.2143\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7803 - accuracy: 0.2857 - val_loss: 1.1700 - val_accuracy: 0.2143\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7760 - accuracy: 0.3036 - val_loss: 1.1787 - val_accuracy: 0.2143\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7721 - accuracy: 0.3036 - val_loss: 1.1872 - val_accuracy: 0.2143\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7657 - accuracy: 0.3036 - val_loss: 1.1953 - val_accuracy: 0.2143\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7626 - accuracy: 0.3393 - val_loss: 1.2032 - val_accuracy: 0.2143\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7574 - accuracy: 0.3393 - val_loss: 1.2108 - val_accuracy: 0.2143\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7524 - accuracy: 0.3393 - val_loss: 1.2179 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.7493 - accuracy: 0.3571 - val_loss: 1.2245 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7463 - accuracy: 0.3571 - val_loss: 1.2303 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7449 - accuracy: 0.3571 - val_loss: 1.2352 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7386 - accuracy: 0.3571 - val_loss: 1.2390 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7337 - accuracy: 0.3750 - val_loss: 1.2424 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7293 - accuracy: 0.3571 - val_loss: 1.2452 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7236 - accuracy: 0.3571 - val_loss: 1.2477 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7223 - accuracy: 0.3750 - val_loss: 1.2501 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7163 - accuracy: 0.3571 - val_loss: 1.2521 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7139 - accuracy: 0.3393 - val_loss: 1.2540 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7076 - accuracy: 0.3393 - val_loss: 1.2559 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7059 - accuracy: 0.3393 - val_loss: 1.2581 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7003 - accuracy: 0.3393 - val_loss: 1.2605 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6963 - accuracy: 0.3393 - val_loss: 1.2628 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6939 - accuracy: 0.3750 - val_loss: 1.2652 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6899 - accuracy: 0.3571 - val_loss: 1.2674 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6843 - accuracy: 0.3929 - val_loss: 1.2693 - val_accuracy: 0.0714\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6803 - accuracy: 0.3571 - val_loss: 1.2709 - val_accuracy: 0.0714\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6799 - accuracy: 0.3571 - val_loss: 1.2729 - val_accuracy: 0.0714\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6695 - accuracy: 0.3750 - val_loss: 1.2747 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6633 - accuracy: 0.3929 - val_loss: 1.2777 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6640 - accuracy: 0.3750 - val_loss: 1.2811 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6545 - accuracy: 0.4107 - val_loss: 1.2851 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6508 - accuracy: 0.3750 - val_loss: 1.2891 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6481 - accuracy: 0.3929 - val_loss: 1.2941 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6433 - accuracy: 0.4464 - val_loss: 1.3000 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6318 - accuracy: 0.4464 - val_loss: 1.3061 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6293 - accuracy: 0.4286 - val_loss: 1.3137 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6239 - accuracy: 0.4286 - val_loss: 1.3229 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6220 - accuracy: 0.4107 - val_loss: 1.3319 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6093 - accuracy: 0.3929 - val_loss: 1.3396 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6058 - accuracy: 0.4107 - val_loss: 1.3473 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6054 - accuracy: 0.3750 - val_loss: 1.3556 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6005 - accuracy: 0.3750 - val_loss: 1.3631 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5957 - accuracy: 0.4107 - val_loss: 1.3704 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5906 - accuracy: 0.4107 - val_loss: 1.3757 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5902 - accuracy: 0.4107 - val_loss: 1.3819 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5779 - accuracy: 0.4107 - val_loss: 1.3893 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5754 - accuracy: 0.4107 - val_loss: 1.3954 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.5611 - accuracy: 0.4107 - val_loss: 1.3994 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5619 - accuracy: 0.4107 - val_loss: 1.4016 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5566 - accuracy: 0.3929 - val_loss: 1.4008 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5552 - accuracy: 0.3929 - val_loss: 1.4005 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5441 - accuracy: 0.4286 - val_loss: 1.3994 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5439 - accuracy: 0.3929 - val_loss: 1.3996 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5391 - accuracy: 0.4107 - val_loss: 1.3990 - val_accuracy: 0.2143\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5227 - accuracy: 0.4107 - val_loss: 1.4023 - val_accuracy: 0.2143\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5238 - accuracy: 0.4286 - val_loss: 1.4043 - val_accuracy: 0.2143\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5189 - accuracy: 0.4107 - val_loss: 1.4040 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5101 - accuracy: 0.4286 - val_loss: 1.4050 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5004 - accuracy: 0.4464 - val_loss: 1.4065 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4958 - accuracy: 0.4286 - val_loss: 1.4085 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4886 - accuracy: 0.4286 - val_loss: 1.4112 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4879 - accuracy: 0.3929 - val_loss: 1.4157 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4750 - accuracy: 0.3929 - val_loss: 1.4218 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4772 - accuracy: 0.3929 - val_loss: 1.4269 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4644 - accuracy: 0.4464 - val_loss: 1.4276 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4616 - accuracy: 0.4286 - val_loss: 1.4263 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4534 - accuracy: 0.4286 - val_loss: 1.4287 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4473 - accuracy: 0.4107 - val_loss: 1.4296 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4366 - accuracy: 0.4643 - val_loss: 1.4379 - val_accuracy: 0.2143\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4253 - accuracy: 0.4286 - val_loss: 1.4407 - val_accuracy: 0.2857\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4258 - accuracy: 0.4643 - val_loss: 1.4454 - val_accuracy: 0.2143\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4115 - accuracy: 0.4643 - val_loss: 1.4456 - val_accuracy: 0.2143\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4011 - accuracy: 0.4643 - val_loss: 1.4476 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3918 - accuracy: 0.4821 - val_loss: 1.4536 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3887 - accuracy: 0.5000 - val_loss: 1.4609 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3849 - accuracy: 0.5179 - val_loss: 1.4745 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3765 - accuracy: 0.5179 - val_loss: 1.4756 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3730 - accuracy: 0.4643 - val_loss: 1.4636 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3635 - accuracy: 0.5714 - val_loss: 1.4473 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 0.3650 - accuracy: 0.6071 - val_loss: 1.4483 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3502 - accuracy: 0.5714 - val_loss: 1.4584 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3425 - accuracy: 0.5536 - val_loss: 1.4763 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3429 - accuracy: 0.5536 - val_loss: 1.4731 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3269 - accuracy: 0.5536 - val_loss: 1.4555 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3230 - accuracy: 0.6250 - val_loss: 1.4479 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3290 - accuracy: 0.5357 - val_loss: 1.4531 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3203 - accuracy: 0.5536 - val_loss: 1.4651 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3003 - accuracy: 0.5893 - val_loss: 1.4775 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3040 - accuracy: 0.6071 - val_loss: 1.4874 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3032 - accuracy: 0.5893 - val_loss: 1.4726 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2899 - accuracy: 0.6429 - val_loss: 1.4589 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2926 - accuracy: 0.5714 - val_loss: 1.4578 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2834 - accuracy: 0.6250 - val_loss: 1.4667 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2796 - accuracy: 0.5893 - val_loss: 1.4887 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4887 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=128, batch_size=300, Scores: [1.488716959953308, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.488716959953308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9841 - accuracy: 0.1429 - val_loss: 1.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9794 - accuracy: 0.1607 - val_loss: 1.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9751 - accuracy: 0.2143 - val_loss: 1.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9698 - accuracy: 0.2857 - val_loss: 1.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9658 - accuracy: 0.3214 - val_loss: 1.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9605 - accuracy: 0.3036 - val_loss: 1.0756 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9550 - accuracy: 0.3571 - val_loss: 1.0765 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9504 - accuracy: 0.3750 - val_loss: 1.0774 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9462 - accuracy: 0.3571 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9410 - accuracy: 0.3929 - val_loss: 1.0795 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9368 - accuracy: 0.3571 - val_loss: 1.0807 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9301 - accuracy: 0.3929 - val_loss: 1.0819 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.9244 - accuracy: 0.3214 - val_loss: 1.0832 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9190 - accuracy: 0.3750 - val_loss: 1.0847 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.9130 - accuracy: 0.3571 - val_loss: 1.0863 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9071 - accuracy: 0.3750 - val_loss: 1.0880 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9010 - accuracy: 0.3929 - val_loss: 1.0899 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8933 - accuracy: 0.3571 - val_loss: 1.0921 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8896 - accuracy: 0.3393 - val_loss: 1.0945 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8807 - accuracy: 0.3571 - val_loss: 1.0972 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8742 - accuracy: 0.3214 - val_loss: 1.1002 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8689 - accuracy: 0.3393 - val_loss: 1.1036 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8616 - accuracy: 0.3571 - val_loss: 1.1074 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8566 - accuracy: 0.3393 - val_loss: 1.1116 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8494 - accuracy: 0.3393 - val_loss: 1.1163 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8450 - accuracy: 0.3393 - val_loss: 1.1213 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8397 - accuracy: 0.3214 - val_loss: 1.1268 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8341 - accuracy: 0.3393 - val_loss: 1.1327 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8265 - accuracy: 0.3036 - val_loss: 1.1391 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8236 - accuracy: 0.3036 - val_loss: 1.1458 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8172 - accuracy: 0.3036 - val_loss: 1.1528 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8128 - accuracy: 0.2857 - val_loss: 1.1601 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8085 - accuracy: 0.3036 - val_loss: 1.1676 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8023 - accuracy: 0.3393 - val_loss: 1.1751 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7984 - accuracy: 0.2857 - val_loss: 1.1826 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.7914 - accuracy: 0.3571 - val_loss: 1.1899 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7861 - accuracy: 0.3214 - val_loss: 1.1970 - val_accuracy: 0.0714\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.7815 - accuracy: 0.3036 - val_loss: 1.2038 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.7775 - accuracy: 0.3036 - val_loss: 1.2105 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7739 - accuracy: 0.3036 - val_loss: 1.2168 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7680 - accuracy: 0.3214 - val_loss: 1.2228 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7645 - accuracy: 0.3214 - val_loss: 1.2284 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7569 - accuracy: 0.3214 - val_loss: 1.2337 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7557 - accuracy: 0.3393 - val_loss: 1.2386 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7485 - accuracy: 0.3393 - val_loss: 1.2427 - val_accuracy: 0.0714\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7498 - accuracy: 0.3393 - val_loss: 1.2461 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7393 - accuracy: 0.3750 - val_loss: 1.2489 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7353 - accuracy: 0.3750 - val_loss: 1.2511 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7302 - accuracy: 0.3929 - val_loss: 1.2525 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7257 - accuracy: 0.3929 - val_loss: 1.2535 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7209 - accuracy: 0.3750 - val_loss: 1.2544 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7159 - accuracy: 0.4107 - val_loss: 1.2549 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.7179 - accuracy: 0.3750 - val_loss: 1.2552 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7079 - accuracy: 0.3929 - val_loss: 1.2555 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7068 - accuracy: 0.3750 - val_loss: 1.2559 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7022 - accuracy: 0.3929 - val_loss: 1.2564 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6943 - accuracy: 0.4286 - val_loss: 1.2570 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6875 - accuracy: 0.3929 - val_loss: 1.2583 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6826 - accuracy: 0.3750 - val_loss: 1.2603 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6793 - accuracy: 0.3929 - val_loss: 1.2632 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6768 - accuracy: 0.3929 - val_loss: 1.2667 - val_accuracy: 0.0714\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6711 - accuracy: 0.3750 - val_loss: 1.2714 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6635 - accuracy: 0.3929 - val_loss: 1.2766 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6591 - accuracy: 0.3929 - val_loss: 1.2821 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6555 - accuracy: 0.3750 - val_loss: 1.2883 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6475 - accuracy: 0.3571 - val_loss: 1.2950 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6420 - accuracy: 0.4107 - val_loss: 1.3016 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6335 - accuracy: 0.3750 - val_loss: 1.3081 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6315 - accuracy: 0.3750 - val_loss: 1.3149 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6255 - accuracy: 0.4107 - val_loss: 1.3216 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6152 - accuracy: 0.3750 - val_loss: 1.3284 - val_accuracy: 0.0714\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6130 - accuracy: 0.4107 - val_loss: 1.3350 - val_accuracy: 0.0714\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6062 - accuracy: 0.3929 - val_loss: 1.3415 - val_accuracy: 0.0714\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5979 - accuracy: 0.3929 - val_loss: 1.3481 - val_accuracy: 0.0714\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5859 - accuracy: 0.4107 - val_loss: 1.3570 - val_accuracy: 0.0714\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5827 - accuracy: 0.4107 - val_loss: 1.3668 - val_accuracy: 0.0714\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5780 - accuracy: 0.4286 - val_loss: 1.3770 - val_accuracy: 0.0714\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5688 - accuracy: 0.4286 - val_loss: 1.3860 - val_accuracy: 0.0714\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5598 - accuracy: 0.4107 - val_loss: 1.3952 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5531 - accuracy: 0.4464 - val_loss: 1.4040 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5493 - accuracy: 0.4286 - val_loss: 1.4131 - val_accuracy: 0.0714\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5411 - accuracy: 0.4107 - val_loss: 1.4215 - val_accuracy: 0.0714\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5350 - accuracy: 0.4286 - val_loss: 1.4322 - val_accuracy: 0.0714\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5278 - accuracy: 0.4107 - val_loss: 1.4416 - val_accuracy: 0.0714\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5261 - accuracy: 0.4464 - val_loss: 1.4484 - val_accuracy: 0.0714\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5157 - accuracy: 0.4286 - val_loss: 1.4531 - val_accuracy: 0.0714\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5094 - accuracy: 0.4286 - val_loss: 1.4599 - val_accuracy: 0.0714\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5089 - accuracy: 0.4464 - val_loss: 1.4659 - val_accuracy: 0.0714\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4964 - accuracy: 0.4643 - val_loss: 1.4720 - val_accuracy: 0.0714\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4858 - accuracy: 0.4643 - val_loss: 1.4787 - val_accuracy: 0.0714\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4822 - accuracy: 0.4643 - val_loss: 1.4875 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4814 - accuracy: 0.4286 - val_loss: 1.4936 - val_accuracy: 0.0714\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4684 - accuracy: 0.4464 - val_loss: 1.4983 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4665 - accuracy: 0.4643 - val_loss: 1.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4551 - accuracy: 0.4643 - val_loss: 1.5040 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4503 - accuracy: 0.4464 - val_loss: 1.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4440 - accuracy: 0.4821 - val_loss: 1.5084 - val_accuracy: 0.0714\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4387 - accuracy: 0.4464 - val_loss: 1.5072 - val_accuracy: 0.0714\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.4248 - accuracy: 0.4821 - val_loss: 1.5033 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4309 - accuracy: 0.4643 - val_loss: 1.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4196 - accuracy: 0.4821 - val_loss: 1.5061 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4194 - accuracy: 0.4643 - val_loss: 1.5136 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3967 - accuracy: 0.5357 - val_loss: 1.5224 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3986 - accuracy: 0.4643 - val_loss: 1.5284 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3891 - accuracy: 0.4821 - val_loss: 1.5314 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3987 - accuracy: 0.5000 - val_loss: 1.5326 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3737 - accuracy: 0.4821 - val_loss: 1.5323 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3879 - accuracy: 0.4821 - val_loss: 1.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3746 - accuracy: 0.4821 - val_loss: 1.5291 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.3671 - accuracy: 0.5000 - val_loss: 1.5319 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3707 - accuracy: 0.5000 - val_loss: 1.5284 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3703 - accuracy: 0.5000 - val_loss: 1.5262 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3530 - accuracy: 0.5179 - val_loss: 1.5264 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3457 - accuracy: 0.5179 - val_loss: 1.5248 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3441 - accuracy: 0.5000 - val_loss: 1.5226 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3439 - accuracy: 0.5357 - val_loss: 1.5214 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3358 - accuracy: 0.5179 - val_loss: 1.5212 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3323 - accuracy: 0.5536 - val_loss: 1.5064 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3223 - accuracy: 0.5179 - val_loss: 1.4877 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3218 - accuracy: 0.4821 - val_loss: 1.4777 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3203 - accuracy: 0.4821 - val_loss: 1.4746 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3162 - accuracy: 0.5000 - val_loss: 1.4846 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3091 - accuracy: 0.5000 - val_loss: 1.4896 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3065 - accuracy: 0.5357 - val_loss: 1.4854 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3004 - accuracy: 0.5179 - val_loss: 1.4803 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2936 - accuracy: 0.5714 - val_loss: 1.4757 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2844 - accuracy: 0.5714 - val_loss: 1.4657 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2880 - accuracy: 0.5536 - val_loss: 1.4594 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4594 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=128, batch_size=400, Scores: [1.4593721628189087, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.4593721628189087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9842 - accuracy: 0.1607 - val_loss: 1.0733 - val_accuracy: 0.0714\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9792 - accuracy: 0.2857 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9751 - accuracy: 0.3393 - val_loss: 1.0745 - val_accuracy: 0.1429\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.9705 - accuracy: 0.4107 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9661 - accuracy: 0.4107 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9619 - accuracy: 0.4107 - val_loss: 1.0765 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9575 - accuracy: 0.3929 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9528 - accuracy: 0.3929 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9478 - accuracy: 0.3929 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9442 - accuracy: 0.3929 - val_loss: 1.0799 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9386 - accuracy: 0.3571 - val_loss: 1.0809 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9338 - accuracy: 0.3571 - val_loss: 1.0819 - val_accuracy: 0.1429\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9272 - accuracy: 0.3929 - val_loss: 1.0831 - val_accuracy: 0.1429\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9220 - accuracy: 0.3750 - val_loss: 1.0844 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9167 - accuracy: 0.3571 - val_loss: 1.0858 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9098 - accuracy: 0.3750 - val_loss: 1.0874 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9042 - accuracy: 0.3750 - val_loss: 1.0892 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8976 - accuracy: 0.3750 - val_loss: 1.0912 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8897 - accuracy: 0.3571 - val_loss: 1.0936 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8829 - accuracy: 0.3929 - val_loss: 1.0963 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8760 - accuracy: 0.3571 - val_loss: 1.0994 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.8700 - accuracy: 0.3750 - val_loss: 1.1029 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8618 - accuracy: 0.3750 - val_loss: 1.1071 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8552 - accuracy: 0.3571 - val_loss: 1.1118 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8457 - accuracy: 0.3750 - val_loss: 1.1172 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8413 - accuracy: 0.3929 - val_loss: 1.1233 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8342 - accuracy: 0.3750 - val_loss: 1.1301 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.8285 - accuracy: 0.3571 - val_loss: 1.1375 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.8201 - accuracy: 0.3571 - val_loss: 1.1453 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8145 - accuracy: 0.3750 - val_loss: 1.1536 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8090 - accuracy: 0.3571 - val_loss: 1.1623 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8029 - accuracy: 0.3750 - val_loss: 1.1712 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7971 - accuracy: 0.3750 - val_loss: 1.1805 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7932 - accuracy: 0.3750 - val_loss: 1.1902 - val_accuracy: 0.0714\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7875 - accuracy: 0.3750 - val_loss: 1.2000 - val_accuracy: 0.0714\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7806 - accuracy: 0.3750 - val_loss: 1.2100 - val_accuracy: 0.0714\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7770 - accuracy: 0.3750 - val_loss: 1.2199 - val_accuracy: 0.0714\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7721 - accuracy: 0.3750 - val_loss: 1.2295 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7695 - accuracy: 0.3929 - val_loss: 1.2385 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7623 - accuracy: 0.3571 - val_loss: 1.2468 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7609 - accuracy: 0.3750 - val_loss: 1.2541 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7563 - accuracy: 0.3750 - val_loss: 1.2603 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7524 - accuracy: 0.3929 - val_loss: 1.2654 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7473 - accuracy: 0.3750 - val_loss: 1.2696 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7442 - accuracy: 0.3571 - val_loss: 1.2726 - val_accuracy: 0.0714\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7382 - accuracy: 0.3571 - val_loss: 1.2745 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7341 - accuracy: 0.3571 - val_loss: 1.2760 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7299 - accuracy: 0.3750 - val_loss: 1.2767 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7268 - accuracy: 0.3750 - val_loss: 1.2770 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7201 - accuracy: 0.3571 - val_loss: 1.2772 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7170 - accuracy: 0.3929 - val_loss: 1.2774 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7134 - accuracy: 0.3750 - val_loss: 1.2775 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7051 - accuracy: 0.3750 - val_loss: 1.2780 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7037 - accuracy: 0.3750 - val_loss: 1.2788 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7010 - accuracy: 0.3929 - val_loss: 1.2807 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6946 - accuracy: 0.4107 - val_loss: 1.2837 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6905 - accuracy: 0.3750 - val_loss: 1.2877 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6818 - accuracy: 0.3750 - val_loss: 1.2924 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6792 - accuracy: 0.4107 - val_loss: 1.2979 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6710 - accuracy: 0.3929 - val_loss: 1.3047 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6657 - accuracy: 0.4286 - val_loss: 1.3126 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6641 - accuracy: 0.4464 - val_loss: 1.3217 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6552 - accuracy: 0.4107 - val_loss: 1.3312 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6497 - accuracy: 0.4107 - val_loss: 1.3406 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6476 - accuracy: 0.4107 - val_loss: 1.3495 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6381 - accuracy: 0.4107 - val_loss: 1.3590 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6304 - accuracy: 0.4286 - val_loss: 1.3692 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6295 - accuracy: 0.4286 - val_loss: 1.3795 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6203 - accuracy: 0.4286 - val_loss: 1.3890 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6101 - accuracy: 0.4107 - val_loss: 1.3986 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6148 - accuracy: 0.4286 - val_loss: 1.4087 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6049 - accuracy: 0.4107 - val_loss: 1.4188 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5991 - accuracy: 0.4286 - val_loss: 1.4293 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5920 - accuracy: 0.3929 - val_loss: 1.4384 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5871 - accuracy: 0.3929 - val_loss: 1.4475 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5835 - accuracy: 0.4107 - val_loss: 1.4544 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5767 - accuracy: 0.4286 - val_loss: 1.4602 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5659 - accuracy: 0.4107 - val_loss: 1.4678 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5646 - accuracy: 0.4286 - val_loss: 1.4750 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5574 - accuracy: 0.4286 - val_loss: 1.4802 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5507 - accuracy: 0.4286 - val_loss: 1.4852 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5437 - accuracy: 0.4286 - val_loss: 1.4889 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5439 - accuracy: 0.4286 - val_loss: 1.4925 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5385 - accuracy: 0.4464 - val_loss: 1.4946 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5311 - accuracy: 0.4821 - val_loss: 1.4979 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5241 - accuracy: 0.4464 - val_loss: 1.5001 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.5169 - accuracy: 0.4464 - val_loss: 1.5037 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5130 - accuracy: 0.4643 - val_loss: 1.5091 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5069 - accuracy: 0.4464 - val_loss: 1.5185 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5021 - accuracy: 0.4821 - val_loss: 1.5292 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5001 - accuracy: 0.4464 - val_loss: 1.5336 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4839 - accuracy: 0.4821 - val_loss: 1.5332 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4918 - accuracy: 0.4464 - val_loss: 1.5303 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4795 - accuracy: 0.4464 - val_loss: 1.5239 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4735 - accuracy: 0.4643 - val_loss: 1.5180 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4606 - accuracy: 0.4286 - val_loss: 1.5180 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4626 - accuracy: 0.4643 - val_loss: 1.5207 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4578 - accuracy: 0.4286 - val_loss: 1.5256 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4418 - accuracy: 0.4821 - val_loss: 1.5273 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4434 - accuracy: 0.4643 - val_loss: 1.5247 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4366 - accuracy: 0.4464 - val_loss: 1.5220 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.4315 - accuracy: 0.4821 - val_loss: 1.5188 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4179 - accuracy: 0.5179 - val_loss: 1.5156 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4185 - accuracy: 0.4821 - val_loss: 1.5138 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4080 - accuracy: 0.5000 - val_loss: 1.5101 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4012 - accuracy: 0.5179 - val_loss: 1.5065 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3953 - accuracy: 0.5893 - val_loss: 1.5059 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3924 - accuracy: 0.5357 - val_loss: 1.5061 - val_accuracy: 0.1429\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3809 - accuracy: 0.5179 - val_loss: 1.5045 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3795 - accuracy: 0.5357 - val_loss: 1.4982 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3758 - accuracy: 0.5357 - val_loss: 1.4917 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3625 - accuracy: 0.5179 - val_loss: 1.4932 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3574 - accuracy: 0.5000 - val_loss: 1.5028 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3480 - accuracy: 0.5714 - val_loss: 1.5066 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.3394 - accuracy: 0.5714 - val_loss: 1.5037 - val_accuracy: 0.1429\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3357 - accuracy: 0.5536 - val_loss: 1.4951 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3381 - accuracy: 0.5714 - val_loss: 1.4934 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3224 - accuracy: 0.5893 - val_loss: 1.5002 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3160 - accuracy: 0.5714 - val_loss: 1.5016 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3129 - accuracy: 0.5357 - val_loss: 1.5043 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3117 - accuracy: 0.5714 - val_loss: 1.5153 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2976 - accuracy: 0.6071 - val_loss: 1.5243 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2936 - accuracy: 0.6250 - val_loss: 1.5260 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2838 - accuracy: 0.5536 - val_loss: 1.5216 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2864 - accuracy: 0.6071 - val_loss: 1.5111 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2831 - accuracy: 0.5893 - val_loss: 1.5099 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2773 - accuracy: 0.5893 - val_loss: 1.5183 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2744 - accuracy: 0.6250 - val_loss: 1.5384 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5384 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=128, batch_size=500, Scores: [1.5384485721588135, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.5384485721588135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9841 - accuracy: 0.0357 - val_loss: 1.0681 - val_accuracy: 0.1429\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9790 - accuracy: 0.1786 - val_loss: 1.0686 - val_accuracy: 0.2143\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9736 - accuracy: 0.2500 - val_loss: 1.0692 - val_accuracy: 0.1429\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9697 - accuracy: 0.1607 - val_loss: 1.0698 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9643 - accuracy: 0.2321 - val_loss: 1.0705 - val_accuracy: 0.1429\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.9604 - accuracy: 0.2143 - val_loss: 1.0712 - val_accuracy: 0.2143\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9552 - accuracy: 0.2143 - val_loss: 1.0720 - val_accuracy: 0.2143\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9502 - accuracy: 0.2143 - val_loss: 1.0729 - val_accuracy: 0.2143\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9454 - accuracy: 0.2321 - val_loss: 1.0738 - val_accuracy: 0.2143\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9396 - accuracy: 0.2143 - val_loss: 1.0749 - val_accuracy: 0.2143\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9344 - accuracy: 0.2321 - val_loss: 1.0761 - val_accuracy: 0.2143\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9289 - accuracy: 0.2321 - val_loss: 1.0774 - val_accuracy: 0.2143\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9244 - accuracy: 0.2500 - val_loss: 1.0788 - val_accuracy: 0.2143\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9177 - accuracy: 0.2679 - val_loss: 1.0804 - val_accuracy: 0.2143\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9112 - accuracy: 0.2500 - val_loss: 1.0822 - val_accuracy: 0.2143\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.9056 - accuracy: 0.2321 - val_loss: 1.0842 - val_accuracy: 0.2857\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8989 - accuracy: 0.2500 - val_loss: 1.0864 - val_accuracy: 0.2857\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8942 - accuracy: 0.2679 - val_loss: 1.0888 - val_accuracy: 0.2857\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8899 - accuracy: 0.2679 - val_loss: 1.0913 - val_accuracy: 0.2857\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8814 - accuracy: 0.2500 - val_loss: 1.0940 - val_accuracy: 0.2143\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8751 - accuracy: 0.2857 - val_loss: 1.0967 - val_accuracy: 0.2143\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.8705 - accuracy: 0.2679 - val_loss: 1.0994 - val_accuracy: 0.2143\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8621 - accuracy: 0.2679 - val_loss: 1.1021 - val_accuracy: 0.2143\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8574 - accuracy: 0.2321 - val_loss: 1.1048 - val_accuracy: 0.2143\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8500 - accuracy: 0.3036 - val_loss: 1.1075 - val_accuracy: 0.2143\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8434 - accuracy: 0.3214 - val_loss: 1.1103 - val_accuracy: 0.2143\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8416 - accuracy: 0.2857 - val_loss: 1.1133 - val_accuracy: 0.2143\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8320 - accuracy: 0.2679 - val_loss: 1.1168 - val_accuracy: 0.2143\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8266 - accuracy: 0.3214 - val_loss: 1.1205 - val_accuracy: 0.2143\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8210 - accuracy: 0.3571 - val_loss: 1.1248 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8147 - accuracy: 0.3393 - val_loss: 1.1297 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8112 - accuracy: 0.3214 - val_loss: 1.1353 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8060 - accuracy: 0.3036 - val_loss: 1.1413 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7994 - accuracy: 0.3214 - val_loss: 1.1476 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7976 - accuracy: 0.3036 - val_loss: 1.1539 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7887 - accuracy: 0.3036 - val_loss: 1.1603 - val_accuracy: 0.0714\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7820 - accuracy: 0.3393 - val_loss: 1.1664 - val_accuracy: 0.0714\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7823 - accuracy: 0.3036 - val_loss: 1.1724 - val_accuracy: 0.0714\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7725 - accuracy: 0.2857 - val_loss: 1.1778 - val_accuracy: 0.0714\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7684 - accuracy: 0.3214 - val_loss: 1.1827 - val_accuracy: 0.0714\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7663 - accuracy: 0.2857 - val_loss: 1.1871 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7570 - accuracy: 0.3036 - val_loss: 1.1905 - val_accuracy: 0.0714\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7557 - accuracy: 0.3036 - val_loss: 1.1930 - val_accuracy: 0.0714\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7476 - accuracy: 0.3214 - val_loss: 1.1954 - val_accuracy: 0.0714\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7436 - accuracy: 0.3036 - val_loss: 1.1980 - val_accuracy: 0.0714\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7415 - accuracy: 0.3393 - val_loss: 1.2008 - val_accuracy: 0.0714\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7346 - accuracy: 0.3393 - val_loss: 1.2040 - val_accuracy: 0.0714\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7305 - accuracy: 0.3214 - val_loss: 1.2069 - val_accuracy: 0.0714\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7282 - accuracy: 0.3214 - val_loss: 1.2103 - val_accuracy: 0.0714\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7208 - accuracy: 0.3214 - val_loss: 1.2139 - val_accuracy: 0.0714\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7170 - accuracy: 0.3214 - val_loss: 1.2178 - val_accuracy: 0.0714\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7137 - accuracy: 0.3393 - val_loss: 1.2219 - val_accuracy: 0.0714\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7077 - accuracy: 0.3214 - val_loss: 1.2264 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7064 - accuracy: 0.3214 - val_loss: 1.2305 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7011 - accuracy: 0.3393 - val_loss: 1.2350 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6938 - accuracy: 0.3393 - val_loss: 1.2393 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6930 - accuracy: 0.3571 - val_loss: 1.2433 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6862 - accuracy: 0.3571 - val_loss: 1.2471 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6853 - accuracy: 0.3571 - val_loss: 1.2515 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6776 - accuracy: 0.3393 - val_loss: 1.2564 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6765 - accuracy: 0.3214 - val_loss: 1.2618 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6669 - accuracy: 0.3393 - val_loss: 1.2685 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6673 - accuracy: 0.3393 - val_loss: 1.2763 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6619 - accuracy: 0.3393 - val_loss: 1.2837 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6543 - accuracy: 0.3571 - val_loss: 1.2902 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6445 - accuracy: 0.3571 - val_loss: 1.2963 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6488 - accuracy: 0.3571 - val_loss: 1.3013 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6377 - accuracy: 0.3393 - val_loss: 1.3056 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6337 - accuracy: 0.3571 - val_loss: 1.3092 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6313 - accuracy: 0.3393 - val_loss: 1.3127 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6230 - accuracy: 0.3393 - val_loss: 1.3179 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6125 - accuracy: 0.3750 - val_loss: 1.3239 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6134 - accuracy: 0.3929 - val_loss: 1.3305 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6058 - accuracy: 0.3750 - val_loss: 1.3394 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6007 - accuracy: 0.3750 - val_loss: 1.3493 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5947 - accuracy: 0.3750 - val_loss: 1.3603 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5877 - accuracy: 0.3750 - val_loss: 1.3713 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5826 - accuracy: 0.4107 - val_loss: 1.3829 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5741 - accuracy: 0.3929 - val_loss: 1.3943 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5715 - accuracy: 0.3750 - val_loss: 1.4061 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5650 - accuracy: 0.4107 - val_loss: 1.4187 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5638 - accuracy: 0.3929 - val_loss: 1.4315 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5562 - accuracy: 0.3929 - val_loss: 1.4429 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5476 - accuracy: 0.3929 - val_loss: 1.4535 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5381 - accuracy: 0.3929 - val_loss: 1.4623 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.5333 - accuracy: 0.4107 - val_loss: 1.4700 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5332 - accuracy: 0.4107 - val_loss: 1.4773 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5283 - accuracy: 0.4286 - val_loss: 1.4827 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5111 - accuracy: 0.4107 - val_loss: 1.4866 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5097 - accuracy: 0.4107 - val_loss: 1.4899 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5068 - accuracy: 0.4464 - val_loss: 1.4953 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4873 - accuracy: 0.4286 - val_loss: 1.5004 - val_accuracy: 0.0714\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4910 - accuracy: 0.4464 - val_loss: 1.5056 - val_accuracy: 0.0714\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4840 - accuracy: 0.4286 - val_loss: 1.5123 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4781 - accuracy: 0.4286 - val_loss: 1.5169 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.4685 - accuracy: 0.4821 - val_loss: 1.5209 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4556 - accuracy: 0.4821 - val_loss: 1.5227 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4552 - accuracy: 0.4821 - val_loss: 1.5269 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4470 - accuracy: 0.4464 - val_loss: 1.5324 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4453 - accuracy: 0.4464 - val_loss: 1.5387 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4347 - accuracy: 0.4464 - val_loss: 1.5430 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4322 - accuracy: 0.4821 - val_loss: 1.5476 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4179 - accuracy: 0.5179 - val_loss: 1.5459 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4145 - accuracy: 0.4643 - val_loss: 1.5422 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4073 - accuracy: 0.5000 - val_loss: 1.5410 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4043 - accuracy: 0.5179 - val_loss: 1.5406 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3919 - accuracy: 0.5179 - val_loss: 1.5422 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3953 - accuracy: 0.5179 - val_loss: 1.5472 - val_accuracy: 0.0714\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3788 - accuracy: 0.5179 - val_loss: 1.5541 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3811 - accuracy: 0.4821 - val_loss: 1.5627 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3656 - accuracy: 0.5000 - val_loss: 1.5666 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3620 - accuracy: 0.5357 - val_loss: 1.5633 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3593 - accuracy: 0.5357 - val_loss: 1.5603 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3466 - accuracy: 0.5893 - val_loss: 1.5554 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3438 - accuracy: 0.5714 - val_loss: 1.5483 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.3481 - accuracy: 0.5893 - val_loss: 1.5457 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3307 - accuracy: 0.5536 - val_loss: 1.5424 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3318 - accuracy: 0.6071 - val_loss: 1.5471 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3284 - accuracy: 0.5714 - val_loss: 1.5526 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3130 - accuracy: 0.5714 - val_loss: 1.5571 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2985 - accuracy: 0.5893 - val_loss: 1.5512 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3085 - accuracy: 0.5893 - val_loss: 1.5482 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2944 - accuracy: 0.6071 - val_loss: 1.5425 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2975 - accuracy: 0.5893 - val_loss: 1.5522 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2862 - accuracy: 0.6071 - val_loss: 1.5655 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2775 - accuracy: 0.5536 - val_loss: 1.5874 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.2789 - accuracy: 0.5714 - val_loss: 1.5980 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2803 - accuracy: 0.6071 - val_loss: 1.5980 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2613 - accuracy: 0.6786 - val_loss: 1.5945 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2593 - accuracy: 0.6429 - val_loss: 1.5927 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2560 - accuracy: 0.5357 - val_loss: 1.5988 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2418 - accuracy: 0.6607 - val_loss: 1.6084 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2507 - accuracy: 0.6429 - val_loss: 1.6040 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2420 - accuracy: 0.6071 - val_loss: 1.6074 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2470 - accuracy: 0.5893 - val_loss: 1.6122 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2250 - accuracy: 0.6250 - val_loss: 1.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2347 - accuracy: 0.5536 - val_loss: 1.6304 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2436 - accuracy: 0.5893 - val_loss: 1.6028 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2292 - accuracy: 0.6607 - val_loss: 1.5849 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2236 - accuracy: 0.6250 - val_loss: 1.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2225 - accuracy: 0.6964 - val_loss: 1.6015 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2248 - accuracy: 0.6071 - val_loss: 1.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2169 - accuracy: 0.6250 - val_loss: 1.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2157 - accuracy: 0.6429 - val_loss: 1.6261 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1963 - accuracy: 0.6607 - val_loss: 1.6221 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2092 - accuracy: 0.6607 - val_loss: 1.6145 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1980 - accuracy: 0.6429 - val_loss: 1.6123 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2080 - accuracy: 0.5893 - val_loss: 1.6096 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2014 - accuracy: 0.6429 - val_loss: 1.6116 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1973 - accuracy: 0.6250 - val_loss: 1.6216 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1915 - accuracy: 0.6964 - val_loss: 1.6351 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1880 - accuracy: 0.5714 - val_loss: 1.6570 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1835 - accuracy: 0.6964 - val_loss: 1.6640 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1849 - accuracy: 0.6607 - val_loss: 1.6657 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1765 - accuracy: 0.6429 - val_loss: 1.6662 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1776 - accuracy: 0.6250 - val_loss: 1.6656 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1792 - accuracy: 0.6429 - val_loss: 1.6613 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1719 - accuracy: 0.6429 - val_loss: 1.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1664 - accuracy: 0.6786 - val_loss: 1.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1664 - accuracy: 0.6964 - val_loss: 1.6899 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1712 - accuracy: 0.6250 - val_loss: 1.6999 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1680 - accuracy: 0.6607 - val_loss: 1.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1628 - accuracy: 0.6250 - val_loss: 1.6924 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1672 - accuracy: 0.6607 - val_loss: 1.6793 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1549 - accuracy: 0.6429 - val_loss: 1.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1534 - accuracy: 0.5714 - val_loss: 1.6645 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1569 - accuracy: 0.6607 - val_loss: 1.6677 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1444 - accuracy: 0.6607 - val_loss: 1.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1473 - accuracy: 0.6964 - val_loss: 1.6858 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1420 - accuracy: 0.6429 - val_loss: 1.6970 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1384 - accuracy: 0.5893 - val_loss: 1.7072 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1408 - accuracy: 0.5893 - val_loss: 1.7168 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1435 - accuracy: 0.6964 - val_loss: 1.7178 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1382 - accuracy: 0.6429 - val_loss: 1.7144 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1314 - accuracy: 0.6071 - val_loss: 1.7183 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1354 - accuracy: 0.6607 - val_loss: 1.7267 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1263 - accuracy: 0.6607 - val_loss: 1.7341 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1244 - accuracy: 0.6607 - val_loss: 1.7490 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1252 - accuracy: 0.6964 - val_loss: 1.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1172 - accuracy: 0.6607 - val_loss: 1.7697 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1253 - accuracy: 0.6429 - val_loss: 1.7666 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1235 - accuracy: 0.7500 - val_loss: 1.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1166 - accuracy: 0.7143 - val_loss: 1.7605 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1189 - accuracy: 0.6786 - val_loss: 1.7595 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1147 - accuracy: 0.6607 - val_loss: 1.7582 - val_accuracy: 0.0714\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1110 - accuracy: 0.6964 - val_loss: 1.7628 - val_accuracy: 0.0714\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1100 - accuracy: 0.6607 - val_loss: 1.7785 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1069 - accuracy: 0.6250 - val_loss: 1.7946 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1033 - accuracy: 0.6786 - val_loss: 1.8053 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1051 - accuracy: 0.6964 - val_loss: 1.8091 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0997 - accuracy: 0.6964 - val_loss: 1.7978 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1035 - accuracy: 0.6964 - val_loss: 1.7857 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1060 - accuracy: 0.6786 - val_loss: 1.7726 - val_accuracy: 0.0714\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1002 - accuracy: 0.7500 - val_loss: 1.7580 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0993 - accuracy: 0.7500 - val_loss: 1.7483 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1013 - accuracy: 0.6607 - val_loss: 1.7477 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1004 - accuracy: 0.6071 - val_loss: 1.7525 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1018 - accuracy: 0.7143 - val_loss: 1.7575 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0985 - accuracy: 0.6964 - val_loss: 1.7660 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0960 - accuracy: 0.7679 - val_loss: 1.7725 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0953 - accuracy: 0.7321 - val_loss: 1.7735 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0938 - accuracy: 0.6607 - val_loss: 1.7738 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0984 - accuracy: 0.6964 - val_loss: 1.7695 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0900 - accuracy: 0.7321 - val_loss: 1.7685 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0950 - accuracy: 0.6964 - val_loss: 1.7699 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0884 - accuracy: 0.7321 - val_loss: 1.7801 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0894 - accuracy: 0.7321 - val_loss: 1.7916 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0878 - accuracy: 0.7500 - val_loss: 1.7938 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0800 - accuracy: 0.7321 - val_loss: 1.7902 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0834 - accuracy: 0.7321 - val_loss: 1.7861 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0889 - accuracy: 0.6964 - val_loss: 1.7854 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0807 - accuracy: 0.7679 - val_loss: 1.7911 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0803 - accuracy: 0.7500 - val_loss: 1.8038 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0865 - accuracy: 0.7321 - val_loss: 1.8120 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0850 - accuracy: 0.7143 - val_loss: 1.8195 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0759 - accuracy: 0.7321 - val_loss: 1.8230 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0770 - accuracy: 0.7143 - val_loss: 1.8300 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0792 - accuracy: 0.6964 - val_loss: 1.8386 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0837 - accuracy: 0.6964 - val_loss: 1.8387 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0779 - accuracy: 0.7143 - val_loss: 1.8373 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0768 - accuracy: 0.7321 - val_loss: 1.8287 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0735 - accuracy: 0.8036 - val_loss: 1.8217 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0795 - accuracy: 0.7857 - val_loss: 1.8119 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0750 - accuracy: 0.7500 - val_loss: 1.8030 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0687 - accuracy: 0.7500 - val_loss: 1.8027 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0756 - accuracy: 0.8036 - val_loss: 1.8052 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0710 - accuracy: 0.8036 - val_loss: 1.8152 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0713 - accuracy: 0.8036 - val_loss: 1.8247 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0742 - accuracy: 0.7679 - val_loss: 1.8301 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0694 - accuracy: 0.7857 - val_loss: 1.8274 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0700 - accuracy: 0.7500 - val_loss: 1.8269 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0668 - accuracy: 0.7321 - val_loss: 1.8362 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0692 - accuracy: 0.8214 - val_loss: 1.8510 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0646 - accuracy: 0.7500 - val_loss: 1.8645 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0652 - accuracy: 0.7143 - val_loss: 1.8683 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0647 - accuracy: 0.7857 - val_loss: 1.8637 - val_accuracy: 0.1429\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0695 - accuracy: 0.7857 - val_loss: 1.8600 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0640 - accuracy: 0.7500 - val_loss: 1.8636 - val_accuracy: 0.1429\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0655 - accuracy: 0.6786 - val_loss: 1.8604 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0602 - accuracy: 0.7500 - val_loss: 1.8529 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.8529 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=240, batch_size=100, Scores: [1.852905511856079, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.852905511856079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9849 - accuracy: 0.1250 - val_loss: 1.0697 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9800 - accuracy: 0.1429 - val_loss: 1.0701 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9756 - accuracy: 0.1964 - val_loss: 1.0704 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9716 - accuracy: 0.2500 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9672 - accuracy: 0.2321 - val_loss: 1.0713 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9627 - accuracy: 0.2321 - val_loss: 1.0717 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9581 - accuracy: 0.3036 - val_loss: 1.0722 - val_accuracy: 0.0714\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9540 - accuracy: 0.2679 - val_loss: 1.0728 - val_accuracy: 0.0714\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9491 - accuracy: 0.3036 - val_loss: 1.0733 - val_accuracy: 0.0714\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9452 - accuracy: 0.3393 - val_loss: 1.0740 - val_accuracy: 0.0714\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9401 - accuracy: 0.3393 - val_loss: 1.0747 - val_accuracy: 0.0714\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9348 - accuracy: 0.3393 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9294 - accuracy: 0.3214 - val_loss: 1.0763 - val_accuracy: 0.0714\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9232 - accuracy: 0.3393 - val_loss: 1.0773 - val_accuracy: 0.0714\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9184 - accuracy: 0.3036 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9129 - accuracy: 0.3393 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9060 - accuracy: 0.3036 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9010 - accuracy: 0.3036 - val_loss: 1.0829 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8935 - accuracy: 0.3214 - val_loss: 1.0849 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8879 - accuracy: 0.3214 - val_loss: 1.0873 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8813 - accuracy: 0.3214 - val_loss: 1.0901 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8753 - accuracy: 0.3036 - val_loss: 1.0933 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8687 - accuracy: 0.3036 - val_loss: 1.0969 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8637 - accuracy: 0.3036 - val_loss: 1.1010 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8549 - accuracy: 0.3214 - val_loss: 1.1057 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8490 - accuracy: 0.3036 - val_loss: 1.1109 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8439 - accuracy: 0.3036 - val_loss: 1.1167 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8383 - accuracy: 0.3036 - val_loss: 1.1233 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8304 - accuracy: 0.2857 - val_loss: 1.1306 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8249 - accuracy: 0.2857 - val_loss: 1.1388 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8188 - accuracy: 0.2857 - val_loss: 1.1479 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8133 - accuracy: 0.2679 - val_loss: 1.1578 - val_accuracy: 0.2143\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8038 - accuracy: 0.2857 - val_loss: 1.1686 - val_accuracy: 0.2143\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8012 - accuracy: 0.2857 - val_loss: 1.1798 - val_accuracy: 0.2143\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7981 - accuracy: 0.2857 - val_loss: 1.1914 - val_accuracy: 0.2143\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7888 - accuracy: 0.2857 - val_loss: 1.2029 - val_accuracy: 0.2143\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7860 - accuracy: 0.2679 - val_loss: 1.2136 - val_accuracy: 0.2143\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7815 - accuracy: 0.3036 - val_loss: 1.2233 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7809 - accuracy: 0.2857 - val_loss: 1.2316 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7738 - accuracy: 0.3036 - val_loss: 1.2384 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7712 - accuracy: 0.3036 - val_loss: 1.2437 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7661 - accuracy: 0.3036 - val_loss: 1.2476 - val_accuracy: 0.0714\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7607 - accuracy: 0.3393 - val_loss: 1.2502 - val_accuracy: 0.0714\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7543 - accuracy: 0.3214 - val_loss: 1.2523 - val_accuracy: 0.0714\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7511 - accuracy: 0.3571 - val_loss: 1.2536 - val_accuracy: 0.0714\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7476 - accuracy: 0.3393 - val_loss: 1.2545 - val_accuracy: 0.0714\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7385 - accuracy: 0.3750 - val_loss: 1.2552 - val_accuracy: 0.0714\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7384 - accuracy: 0.3750 - val_loss: 1.2556 - val_accuracy: 0.0714\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7298 - accuracy: 0.3750 - val_loss: 1.2557 - val_accuracy: 0.0714\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7293 - accuracy: 0.3393 - val_loss: 1.2552 - val_accuracy: 0.0714\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7215 - accuracy: 0.3750 - val_loss: 1.2546 - val_accuracy: 0.0714\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7161 - accuracy: 0.3571 - val_loss: 1.2541 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7102 - accuracy: 0.3393 - val_loss: 1.2541 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7052 - accuracy: 0.3214 - val_loss: 1.2546 - val_accuracy: 0.0714\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7037 - accuracy: 0.3036 - val_loss: 1.2557 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6985 - accuracy: 0.3036 - val_loss: 1.2572 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6922 - accuracy: 0.3036 - val_loss: 1.2595 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6873 - accuracy: 0.3571 - val_loss: 1.2622 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.6848 - accuracy: 0.3571 - val_loss: 1.2661 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6809 - accuracy: 0.3214 - val_loss: 1.2702 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6754 - accuracy: 0.3750 - val_loss: 1.2744 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6667 - accuracy: 0.3571 - val_loss: 1.2789 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6683 - accuracy: 0.3750 - val_loss: 1.2833 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6572 - accuracy: 0.3214 - val_loss: 1.2882 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6525 - accuracy: 0.3750 - val_loss: 1.2940 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6478 - accuracy: 0.3750 - val_loss: 1.3009 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6405 - accuracy: 0.3929 - val_loss: 1.3084 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6413 - accuracy: 0.3750 - val_loss: 1.3170 - val_accuracy: 0.0714\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6355 - accuracy: 0.3571 - val_loss: 1.3255 - val_accuracy: 0.0714\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6238 - accuracy: 0.3929 - val_loss: 1.3339 - val_accuracy: 0.0714\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6226 - accuracy: 0.3929 - val_loss: 1.3422 - val_accuracy: 0.0714\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6197 - accuracy: 0.3929 - val_loss: 1.3499 - val_accuracy: 0.0714\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6120 - accuracy: 0.4107 - val_loss: 1.3583 - val_accuracy: 0.0714\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5989 - accuracy: 0.4286 - val_loss: 1.3666 - val_accuracy: 0.0714\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5989 - accuracy: 0.4107 - val_loss: 1.3764 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5902 - accuracy: 0.3929 - val_loss: 1.3868 - val_accuracy: 0.0714\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5904 - accuracy: 0.3571 - val_loss: 1.3945 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5775 - accuracy: 0.3750 - val_loss: 1.3999 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5792 - accuracy: 0.4107 - val_loss: 1.4049 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5708 - accuracy: 0.3929 - val_loss: 1.4083 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5675 - accuracy: 0.4107 - val_loss: 1.4126 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5644 - accuracy: 0.4107 - val_loss: 1.4156 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5546 - accuracy: 0.3929 - val_loss: 1.4184 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5513 - accuracy: 0.3929 - val_loss: 1.4203 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5388 - accuracy: 0.4107 - val_loss: 1.4188 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5445 - accuracy: 0.3929 - val_loss: 1.4206 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5310 - accuracy: 0.4107 - val_loss: 1.4249 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5219 - accuracy: 0.4107 - val_loss: 1.4314 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5213 - accuracy: 0.4107 - val_loss: 1.4380 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5252 - accuracy: 0.4107 - val_loss: 1.4465 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5119 - accuracy: 0.4107 - val_loss: 1.4514 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5044 - accuracy: 0.4464 - val_loss: 1.4508 - val_accuracy: 0.0714\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4950 - accuracy: 0.4464 - val_loss: 1.4549 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4936 - accuracy: 0.4643 - val_loss: 1.4619 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4871 - accuracy: 0.4286 - val_loss: 1.4712 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4771 - accuracy: 0.5000 - val_loss: 1.4762 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 0.4664 - accuracy: 0.4643 - val_loss: 1.4793 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4651 - accuracy: 0.4821 - val_loss: 1.4866 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4580 - accuracy: 0.4821 - val_loss: 1.4947 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4613 - accuracy: 0.4821 - val_loss: 1.5047 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4494 - accuracy: 0.4821 - val_loss: 1.5067 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4408 - accuracy: 0.5179 - val_loss: 1.5047 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4266 - accuracy: 0.5357 - val_loss: 1.5051 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4200 - accuracy: 0.5000 - val_loss: 1.5035 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4173 - accuracy: 0.4464 - val_loss: 1.5030 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4095 - accuracy: 0.4821 - val_loss: 1.4971 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4041 - accuracy: 0.4643 - val_loss: 1.4946 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4000 - accuracy: 0.5179 - val_loss: 1.4998 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3955 - accuracy: 0.4107 - val_loss: 1.5010 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3856 - accuracy: 0.5000 - val_loss: 1.4951 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3872 - accuracy: 0.5179 - val_loss: 1.4921 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3733 - accuracy: 0.5179 - val_loss: 1.4933 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3690 - accuracy: 0.5000 - val_loss: 1.5001 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3658 - accuracy: 0.5536 - val_loss: 1.5015 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3531 - accuracy: 0.5000 - val_loss: 1.4922 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3508 - accuracy: 0.5179 - val_loss: 1.4901 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3377 - accuracy: 0.5357 - val_loss: 1.4962 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3361 - accuracy: 0.5357 - val_loss: 1.5073 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3469 - accuracy: 0.5179 - val_loss: 1.5216 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3309 - accuracy: 0.4821 - val_loss: 1.5109 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3253 - accuracy: 0.5179 - val_loss: 1.4922 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3153 - accuracy: 0.5357 - val_loss: 1.4784 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3190 - accuracy: 0.5179 - val_loss: 1.4778 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3036 - accuracy: 0.5179 - val_loss: 1.4920 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3017 - accuracy: 0.5179 - val_loss: 1.5052 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3038 - accuracy: 0.5179 - val_loss: 1.4932 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2978 - accuracy: 0.5357 - val_loss: 1.4886 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2901 - accuracy: 0.5714 - val_loss: 1.4933 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2903 - accuracy: 0.5893 - val_loss: 1.4943 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2821 - accuracy: 0.6071 - val_loss: 1.4940 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2797 - accuracy: 0.5893 - val_loss: 1.4941 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2724 - accuracy: 0.6071 - val_loss: 1.4793 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2704 - accuracy: 0.6071 - val_loss: 1.4841 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2630 - accuracy: 0.5536 - val_loss: 1.4972 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2587 - accuracy: 0.6429 - val_loss: 1.5141 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2631 - accuracy: 0.5893 - val_loss: 1.5230 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2543 - accuracy: 0.6429 - val_loss: 1.5143 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2470 - accuracy: 0.6071 - val_loss: 1.5010 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2348 - accuracy: 0.6071 - val_loss: 1.4855 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2341 - accuracy: 0.6071 - val_loss: 1.4747 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2432 - accuracy: 0.5893 - val_loss: 1.4760 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2327 - accuracy: 0.5893 - val_loss: 1.4932 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2285 - accuracy: 0.6250 - val_loss: 1.5148 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2223 - accuracy: 0.6429 - val_loss: 1.5267 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2197 - accuracy: 0.6607 - val_loss: 1.5167 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2217 - accuracy: 0.7143 - val_loss: 1.5014 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2178 - accuracy: 0.6607 - val_loss: 1.5040 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2203 - accuracy: 0.6250 - val_loss: 1.5033 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2064 - accuracy: 0.6429 - val_loss: 1.5052 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2080 - accuracy: 0.6786 - val_loss: 1.5123 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2104 - accuracy: 0.6429 - val_loss: 1.5115 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1986 - accuracy: 0.6607 - val_loss: 1.5134 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1935 - accuracy: 0.7857 - val_loss: 1.5228 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1994 - accuracy: 0.7143 - val_loss: 1.5330 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1835 - accuracy: 0.7143 - val_loss: 1.5442 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1915 - accuracy: 0.6607 - val_loss: 1.5584 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1816 - accuracy: 0.6607 - val_loss: 1.5627 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1822 - accuracy: 0.7143 - val_loss: 1.5599 - val_accuracy: 0.1429\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1754 - accuracy: 0.6250 - val_loss: 1.5500 - val_accuracy: 0.1429\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1738 - accuracy: 0.6250 - val_loss: 1.5511 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1724 - accuracy: 0.6607 - val_loss: 1.5708 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1750 - accuracy: 0.6964 - val_loss: 1.5855 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1661 - accuracy: 0.6786 - val_loss: 1.5990 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1615 - accuracy: 0.6429 - val_loss: 1.6001 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1538 - accuracy: 0.6964 - val_loss: 1.6012 - val_accuracy: 0.0714\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1534 - accuracy: 0.6786 - val_loss: 1.6060 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1551 - accuracy: 0.6964 - val_loss: 1.6151 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1538 - accuracy: 0.6964 - val_loss: 1.6098 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1478 - accuracy: 0.6964 - val_loss: 1.6139 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1506 - accuracy: 0.6786 - val_loss: 1.6279 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1465 - accuracy: 0.6964 - val_loss: 1.6459 - val_accuracy: 0.0714\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1497 - accuracy: 0.7143 - val_loss: 1.6631 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1468 - accuracy: 0.6429 - val_loss: 1.6547 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1389 - accuracy: 0.7321 - val_loss: 1.6348 - val_accuracy: 0.1429\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1396 - accuracy: 0.6607 - val_loss: 1.6231 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1429 - accuracy: 0.6964 - val_loss: 1.6244 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1350 - accuracy: 0.7321 - val_loss: 1.6452 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1298 - accuracy: 0.7321 - val_loss: 1.6734 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1307 - accuracy: 0.7321 - val_loss: 1.6919 - val_accuracy: 0.1429\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1282 - accuracy: 0.6964 - val_loss: 1.6881 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1273 - accuracy: 0.6786 - val_loss: 1.6813 - val_accuracy: 0.1429\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1271 - accuracy: 0.6786 - val_loss: 1.6816 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1267 - accuracy: 0.6786 - val_loss: 1.6778 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1170 - accuracy: 0.6429 - val_loss: 1.6745 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1162 - accuracy: 0.6964 - val_loss: 1.6792 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1132 - accuracy: 0.6964 - val_loss: 1.6844 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1161 - accuracy: 0.6607 - val_loss: 1.6886 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1119 - accuracy: 0.6786 - val_loss: 1.6893 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1200 - accuracy: 0.7143 - val_loss: 1.6840 - val_accuracy: 0.1429\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1038 - accuracy: 0.6786 - val_loss: 1.6792 - val_accuracy: 0.1429\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1088 - accuracy: 0.7143 - val_loss: 1.6743 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1069 - accuracy: 0.6786 - val_loss: 1.6693 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1041 - accuracy: 0.7500 - val_loss: 1.6730 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0982 - accuracy: 0.7143 - val_loss: 1.6813 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1016 - accuracy: 0.7500 - val_loss: 1.6803 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1047 - accuracy: 0.6964 - val_loss: 1.6826 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1032 - accuracy: 0.7857 - val_loss: 1.6999 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1041 - accuracy: 0.7321 - val_loss: 1.7184 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0903 - accuracy: 0.7679 - val_loss: 1.7433 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1018 - accuracy: 0.7679 - val_loss: 1.7574 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0986 - accuracy: 0.6964 - val_loss: 1.7611 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0940 - accuracy: 0.7321 - val_loss: 1.7646 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0944 - accuracy: 0.6786 - val_loss: 1.7663 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0895 - accuracy: 0.6786 - val_loss: 1.7587 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0868 - accuracy: 0.7143 - val_loss: 1.7419 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0878 - accuracy: 0.6964 - val_loss: 1.7200 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0858 - accuracy: 0.7500 - val_loss: 1.7065 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0864 - accuracy: 0.7321 - val_loss: 1.7190 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0835 - accuracy: 0.7500 - val_loss: 1.7405 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0828 - accuracy: 0.7857 - val_loss: 1.7474 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0870 - accuracy: 0.7857 - val_loss: 1.7550 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0780 - accuracy: 0.7679 - val_loss: 1.7590 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0831 - accuracy: 0.7679 - val_loss: 1.7600 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0830 - accuracy: 0.7143 - val_loss: 1.7614 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0755 - accuracy: 0.7143 - val_loss: 1.7640 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0799 - accuracy: 0.7143 - val_loss: 1.7688 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0774 - accuracy: 0.7679 - val_loss: 1.7672 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0769 - accuracy: 0.7679 - val_loss: 1.7718 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0816 - accuracy: 0.7321 - val_loss: 1.7704 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0710 - accuracy: 0.7679 - val_loss: 1.7671 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0695 - accuracy: 0.7321 - val_loss: 1.7699 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0759 - accuracy: 0.7321 - val_loss: 1.7759 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0741 - accuracy: 0.6964 - val_loss: 1.7822 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0720 - accuracy: 0.7679 - val_loss: 1.7909 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0664 - accuracy: 0.7679 - val_loss: 1.7959 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0724 - accuracy: 0.8036 - val_loss: 1.7872 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0730 - accuracy: 0.7679 - val_loss: 1.7705 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0658 - accuracy: 0.7679 - val_loss: 1.7612 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0710 - accuracy: 0.7679 - val_loss: 1.7561 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0616 - accuracy: 0.7500 - val_loss: 1.7628 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0674 - accuracy: 0.8393 - val_loss: 1.7787 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0647 - accuracy: 0.8036 - val_loss: 1.7888 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0634 - accuracy: 0.7679 - val_loss: 1.7901 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0672 - accuracy: 0.6964 - val_loss: 1.7832 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0591 - accuracy: 0.8214 - val_loss: 1.7770 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0626 - accuracy: 0.7321 - val_loss: 1.7741 - val_accuracy: 0.1429\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0556 - accuracy: 0.8214 - val_loss: 1.7778 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0635 - accuracy: 0.7321 - val_loss: 1.7870 - val_accuracy: 0.1429\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0641 - accuracy: 0.7679 - val_loss: 1.8162 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0619 - accuracy: 0.8214 - val_loss: 1.8292 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.8292 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=240, batch_size=300, Scores: [1.8292282819747925, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.8292282819747925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9824 - accuracy: 0.1607 - val_loss: 1.0699 - val_accuracy: 0.1429\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9782 - accuracy: 0.1964 - val_loss: 1.0701 - val_accuracy: 0.1429\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9742 - accuracy: 0.2321 - val_loss: 1.0704 - val_accuracy: 0.1429\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9685 - accuracy: 0.2500 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9639 - accuracy: 0.2857 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9597 - accuracy: 0.3036 - val_loss: 1.0717 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9552 - accuracy: 0.2857 - val_loss: 1.0721 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9509 - accuracy: 0.3036 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9456 - accuracy: 0.2857 - val_loss: 1.0733 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9405 - accuracy: 0.3393 - val_loss: 1.0740 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9358 - accuracy: 0.3036 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9302 - accuracy: 0.3571 - val_loss: 1.0756 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9241 - accuracy: 0.3571 - val_loss: 1.0766 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9187 - accuracy: 0.3214 - val_loss: 1.0777 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9127 - accuracy: 0.3393 - val_loss: 1.0791 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.9050 - accuracy: 0.3393 - val_loss: 1.0806 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8997 - accuracy: 0.3571 - val_loss: 1.0824 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8906 - accuracy: 0.3393 - val_loss: 1.0845 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8863 - accuracy: 0.3393 - val_loss: 1.0869 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8793 - accuracy: 0.3214 - val_loss: 1.0896 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8738 - accuracy: 0.3214 - val_loss: 1.0926 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8662 - accuracy: 0.3214 - val_loss: 1.0959 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8617 - accuracy: 0.3036 - val_loss: 1.0995 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8532 - accuracy: 0.3214 - val_loss: 1.1030 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8495 - accuracy: 0.3214 - val_loss: 1.1064 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8441 - accuracy: 0.3036 - val_loss: 1.1094 - val_accuracy: 0.0714\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8383 - accuracy: 0.3214 - val_loss: 1.1120 - val_accuracy: 0.0714\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8315 - accuracy: 0.3036 - val_loss: 1.1143 - val_accuracy: 0.0714\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8280 - accuracy: 0.2857 - val_loss: 1.1164 - val_accuracy: 0.0714\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8243 - accuracy: 0.3036 - val_loss: 1.1184 - val_accuracy: 0.0714\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8179 - accuracy: 0.3214 - val_loss: 1.1207 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8131 - accuracy: 0.2857 - val_loss: 1.1232 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8054 - accuracy: 0.2857 - val_loss: 1.1263 - val_accuracy: 0.0714\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7998 - accuracy: 0.3036 - val_loss: 1.1299 - val_accuracy: 0.0714\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7975 - accuracy: 0.3036 - val_loss: 1.1342 - val_accuracy: 0.0714\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7932 - accuracy: 0.3214 - val_loss: 1.1388 - val_accuracy: 0.0714\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7863 - accuracy: 0.2857 - val_loss: 1.1436 - val_accuracy: 0.0714\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7815 - accuracy: 0.3036 - val_loss: 1.1488 - val_accuracy: 0.0714\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7774 - accuracy: 0.3214 - val_loss: 1.1541 - val_accuracy: 0.0714\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7724 - accuracy: 0.3036 - val_loss: 1.1597 - val_accuracy: 0.0714\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7689 - accuracy: 0.3214 - val_loss: 1.1654 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7637 - accuracy: 0.3393 - val_loss: 1.1712 - val_accuracy: 0.0714\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7590 - accuracy: 0.3393 - val_loss: 1.1771 - val_accuracy: 0.0714\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7521 - accuracy: 0.3571 - val_loss: 1.1832 - val_accuracy: 0.0714\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7503 - accuracy: 0.3393 - val_loss: 1.1892 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7490 - accuracy: 0.3393 - val_loss: 1.1948 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7418 - accuracy: 0.3750 - val_loss: 1.1998 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7372 - accuracy: 0.3750 - val_loss: 1.2045 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7354 - accuracy: 0.3929 - val_loss: 1.2086 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7320 - accuracy: 0.3750 - val_loss: 1.2120 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7227 - accuracy: 0.4107 - val_loss: 1.2149 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7230 - accuracy: 0.3571 - val_loss: 1.2177 - val_accuracy: 0.0714\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7181 - accuracy: 0.4107 - val_loss: 1.2205 - val_accuracy: 0.0714\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7132 - accuracy: 0.3929 - val_loss: 1.2235 - val_accuracy: 0.0714\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7063 - accuracy: 0.4107 - val_loss: 1.2266 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6997 - accuracy: 0.4107 - val_loss: 1.2302 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6915 - accuracy: 0.4107 - val_loss: 1.2341 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6889 - accuracy: 0.3929 - val_loss: 1.2385 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6860 - accuracy: 0.4286 - val_loss: 1.2432 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6846 - accuracy: 0.3929 - val_loss: 1.2482 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6780 - accuracy: 0.4286 - val_loss: 1.2537 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6723 - accuracy: 0.3929 - val_loss: 1.2592 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6684 - accuracy: 0.3929 - val_loss: 1.2647 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6589 - accuracy: 0.3929 - val_loss: 1.2706 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6555 - accuracy: 0.3750 - val_loss: 1.2771 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6429 - accuracy: 0.3750 - val_loss: 1.2840 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6399 - accuracy: 0.4107 - val_loss: 1.2912 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6370 - accuracy: 0.3750 - val_loss: 1.2988 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6297 - accuracy: 0.3929 - val_loss: 1.3066 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6259 - accuracy: 0.3929 - val_loss: 1.3146 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6181 - accuracy: 0.3929 - val_loss: 1.3236 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6161 - accuracy: 0.3929 - val_loss: 1.3333 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.6029 - accuracy: 0.4107 - val_loss: 1.3442 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6014 - accuracy: 0.3929 - val_loss: 1.3555 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.5938 - accuracy: 0.4107 - val_loss: 1.3673 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5883 - accuracy: 0.4107 - val_loss: 1.3785 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5882 - accuracy: 0.4286 - val_loss: 1.3905 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5790 - accuracy: 0.4286 - val_loss: 1.4014 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5749 - accuracy: 0.4107 - val_loss: 1.4116 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5713 - accuracy: 0.4286 - val_loss: 1.4214 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5627 - accuracy: 0.4464 - val_loss: 1.4311 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5651 - accuracy: 0.4286 - val_loss: 1.4392 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5534 - accuracy: 0.4464 - val_loss: 1.4449 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5470 - accuracy: 0.4464 - val_loss: 1.4479 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5431 - accuracy: 0.4286 - val_loss: 1.4506 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5350 - accuracy: 0.4464 - val_loss: 1.4532 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5352 - accuracy: 0.4464 - val_loss: 1.4564 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5183 - accuracy: 0.4464 - val_loss: 1.4618 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5182 - accuracy: 0.4821 - val_loss: 1.4675 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5078 - accuracy: 0.4821 - val_loss: 1.4710 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.4984 - accuracy: 0.4643 - val_loss: 1.4745 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5034 - accuracy: 0.4464 - val_loss: 1.4742 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4945 - accuracy: 0.4821 - val_loss: 1.4740 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.4838 - accuracy: 0.4286 - val_loss: 1.4762 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4745 - accuracy: 0.4821 - val_loss: 1.4796 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4751 - accuracy: 0.5000 - val_loss: 1.4830 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4653 - accuracy: 0.4643 - val_loss: 1.4854 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4569 - accuracy: 0.4821 - val_loss: 1.4896 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4536 - accuracy: 0.4643 - val_loss: 1.4966 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4465 - accuracy: 0.5000 - val_loss: 1.5024 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4365 - accuracy: 0.4821 - val_loss: 1.5072 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4424 - accuracy: 0.4643 - val_loss: 1.5115 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4297 - accuracy: 0.4464 - val_loss: 1.5137 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4196 - accuracy: 0.4821 - val_loss: 1.5207 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4217 - accuracy: 0.4643 - val_loss: 1.5330 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4104 - accuracy: 0.4464 - val_loss: 1.5411 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4051 - accuracy: 0.4286 - val_loss: 1.5392 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3886 - accuracy: 0.4643 - val_loss: 1.5364 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3964 - accuracy: 0.4821 - val_loss: 1.5366 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3870 - accuracy: 0.5000 - val_loss: 1.5374 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3751 - accuracy: 0.4821 - val_loss: 1.5381 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3651 - accuracy: 0.4464 - val_loss: 1.5383 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3565 - accuracy: 0.4464 - val_loss: 1.5404 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3547 - accuracy: 0.4821 - val_loss: 1.5436 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3541 - accuracy: 0.5357 - val_loss: 1.5467 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3456 - accuracy: 0.4643 - val_loss: 1.5525 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3386 - accuracy: 0.4821 - val_loss: 1.5458 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3397 - accuracy: 0.4464 - val_loss: 1.5347 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3323 - accuracy: 0.5179 - val_loss: 1.5274 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3212 - accuracy: 0.4107 - val_loss: 1.5231 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3231 - accuracy: 0.4821 - val_loss: 1.5277 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3101 - accuracy: 0.4464 - val_loss: 1.5368 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3059 - accuracy: 0.4643 - val_loss: 1.5446 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3047 - accuracy: 0.5357 - val_loss: 1.5495 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2920 - accuracy: 0.5000 - val_loss: 1.5534 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2850 - accuracy: 0.5179 - val_loss: 1.5528 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2852 - accuracy: 0.4821 - val_loss: 1.5471 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2850 - accuracy: 0.5179 - val_loss: 1.5501 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2759 - accuracy: 0.5000 - val_loss: 1.5614 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2770 - accuracy: 0.5357 - val_loss: 1.5704 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2645 - accuracy: 0.5714 - val_loss: 1.5813 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2635 - accuracy: 0.5179 - val_loss: 1.5910 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2509 - accuracy: 0.5357 - val_loss: 1.5993 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2519 - accuracy: 0.5179 - val_loss: 1.6039 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2523 - accuracy: 0.5536 - val_loss: 1.6014 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2479 - accuracy: 0.5179 - val_loss: 1.5986 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2462 - accuracy: 0.5714 - val_loss: 1.5957 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2432 - accuracy: 0.5714 - val_loss: 1.5934 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2299 - accuracy: 0.5536 - val_loss: 1.5953 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2307 - accuracy: 0.5714 - val_loss: 1.6015 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2265 - accuracy: 0.6071 - val_loss: 1.6092 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2258 - accuracy: 0.5893 - val_loss: 1.6180 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2128 - accuracy: 0.6071 - val_loss: 1.6215 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2112 - accuracy: 0.6071 - val_loss: 1.6224 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2122 - accuracy: 0.6071 - val_loss: 1.6183 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1995 - accuracy: 0.6250 - val_loss: 1.6132 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2038 - accuracy: 0.5714 - val_loss: 1.6076 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2003 - accuracy: 0.6071 - val_loss: 1.6033 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2018 - accuracy: 0.5536 - val_loss: 1.6058 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1962 - accuracy: 0.5714 - val_loss: 1.6064 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1829 - accuracy: 0.6607 - val_loss: 1.6122 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1853 - accuracy: 0.6071 - val_loss: 1.6259 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1798 - accuracy: 0.6071 - val_loss: 1.6386 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1771 - accuracy: 0.6071 - val_loss: 1.6437 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1764 - accuracy: 0.6250 - val_loss: 1.6497 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1809 - accuracy: 0.6071 - val_loss: 1.6509 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1744 - accuracy: 0.6429 - val_loss: 1.6510 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1691 - accuracy: 0.6250 - val_loss: 1.6465 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1613 - accuracy: 0.6071 - val_loss: 1.6489 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1644 - accuracy: 0.6250 - val_loss: 1.6595 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1503 - accuracy: 0.6250 - val_loss: 1.6783 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1629 - accuracy: 0.5714 - val_loss: 1.6999 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1524 - accuracy: 0.5893 - val_loss: 1.7120 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1587 - accuracy: 0.6250 - val_loss: 1.7145 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1481 - accuracy: 0.5536 - val_loss: 1.7073 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1502 - accuracy: 0.6786 - val_loss: 1.7047 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1457 - accuracy: 0.6964 - val_loss: 1.7038 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1418 - accuracy: 0.6786 - val_loss: 1.6934 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1389 - accuracy: 0.6786 - val_loss: 1.6825 - val_accuracy: 0.0714\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1427 - accuracy: 0.6250 - val_loss: 1.6837 - val_accuracy: 0.0714\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1385 - accuracy: 0.6250 - val_loss: 1.6928 - val_accuracy: 0.0714\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1409 - accuracy: 0.6071 - val_loss: 1.7022 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1368 - accuracy: 0.6607 - val_loss: 1.7022 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1377 - accuracy: 0.6786 - val_loss: 1.6932 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1289 - accuracy: 0.6071 - val_loss: 1.6799 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1313 - accuracy: 0.6607 - val_loss: 1.6690 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1240 - accuracy: 0.6607 - val_loss: 1.6712 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1268 - accuracy: 0.6786 - val_loss: 1.6829 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1315 - accuracy: 0.5893 - val_loss: 1.7031 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1205 - accuracy: 0.6429 - val_loss: 1.7153 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1239 - accuracy: 0.6786 - val_loss: 1.7169 - val_accuracy: 0.0714\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1207 - accuracy: 0.6964 - val_loss: 1.7025 - val_accuracy: 0.0714\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1249 - accuracy: 0.6429 - val_loss: 1.6920 - val_accuracy: 0.0714\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1219 - accuracy: 0.6607 - val_loss: 1.6899 - val_accuracy: 0.0714\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1189 - accuracy: 0.6964 - val_loss: 1.6927 - val_accuracy: 0.0714\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1161 - accuracy: 0.6250 - val_loss: 1.6938 - val_accuracy: 0.0714\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1116 - accuracy: 0.6607 - val_loss: 1.6930 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1162 - accuracy: 0.6429 - val_loss: 1.6845 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1138 - accuracy: 0.6429 - val_loss: 1.6739 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1102 - accuracy: 0.7321 - val_loss: 1.6759 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1076 - accuracy: 0.6786 - val_loss: 1.6842 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1135 - accuracy: 0.6071 - val_loss: 1.6976 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1078 - accuracy: 0.6607 - val_loss: 1.7133 - val_accuracy: 0.0714\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1077 - accuracy: 0.7143 - val_loss: 1.7295 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0971 - accuracy: 0.6250 - val_loss: 1.7357 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1078 - accuracy: 0.7143 - val_loss: 1.7357 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1055 - accuracy: 0.7143 - val_loss: 1.7142 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1023 - accuracy: 0.6429 - val_loss: 1.6962 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0992 - accuracy: 0.6607 - val_loss: 1.6886 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1029 - accuracy: 0.6964 - val_loss: 1.6869 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1066 - accuracy: 0.6964 - val_loss: 1.6856 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0992 - accuracy: 0.6964 - val_loss: 1.6920 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0928 - accuracy: 0.6607 - val_loss: 1.7027 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1007 - accuracy: 0.6607 - val_loss: 1.7106 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0951 - accuracy: 0.6786 - val_loss: 1.7140 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0904 - accuracy: 0.7321 - val_loss: 1.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0968 - accuracy: 0.6429 - val_loss: 1.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0943 - accuracy: 0.6786 - val_loss: 1.7209 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0901 - accuracy: 0.6786 - val_loss: 1.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0911 - accuracy: 0.6429 - val_loss: 1.7104 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0902 - accuracy: 0.7679 - val_loss: 1.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0900 - accuracy: 0.6607 - val_loss: 1.7125 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0803 - accuracy: 0.7679 - val_loss: 1.7143 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0870 - accuracy: 0.7500 - val_loss: 1.7111 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0819 - accuracy: 0.6786 - val_loss: 1.7001 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0786 - accuracy: 0.6964 - val_loss: 1.6946 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0831 - accuracy: 0.7143 - val_loss: 1.6937 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0791 - accuracy: 0.6429 - val_loss: 1.6959 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0834 - accuracy: 0.7679 - val_loss: 1.7026 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0812 - accuracy: 0.7679 - val_loss: 1.7136 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0840 - accuracy: 0.6786 - val_loss: 1.7360 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0792 - accuracy: 0.7500 - val_loss: 1.7541 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0842 - accuracy: 0.7500 - val_loss: 1.7593 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0755 - accuracy: 0.7321 - val_loss: 1.7584 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0739 - accuracy: 0.7143 - val_loss: 1.7445 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0784 - accuracy: 0.7500 - val_loss: 1.7317 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0756 - accuracy: 0.7500 - val_loss: 1.7270 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0747 - accuracy: 0.7679 - val_loss: 1.7312 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.0699 - accuracy: 0.8571 - val_loss: 1.7388 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0722 - accuracy: 0.7500 - val_loss: 1.7495 - val_accuracy: 0.0714\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0744 - accuracy: 0.7321 - val_loss: 1.7635 - val_accuracy: 0.0714\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0731 - accuracy: 0.6786 - val_loss: 1.7694 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0685 - accuracy: 0.7143 - val_loss: 1.7669 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0656 - accuracy: 0.7857 - val_loss: 1.7640 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0725 - accuracy: 0.6964 - val_loss: 1.7581 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0701 - accuracy: 0.7679 - val_loss: 1.7503 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0774 - accuracy: 0.7500 - val_loss: 1.7484 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0648 - accuracy: 0.8036 - val_loss: 1.7491 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0656 - accuracy: 0.7857 - val_loss: 1.7555 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0653 - accuracy: 0.7679 - val_loss: 1.7671 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.7671 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=240, batch_size=400, Scores: [1.7671478986740112, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.7671478986740112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9854 - accuracy: 0.0893 - val_loss: 1.0689 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9808 - accuracy: 0.1964 - val_loss: 1.0690 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9760 - accuracy: 0.2143 - val_loss: 1.0691 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9720 - accuracy: 0.3036 - val_loss: 1.0692 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9679 - accuracy: 0.2679 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9626 - accuracy: 0.2857 - val_loss: 1.0697 - val_accuracy: 0.1429\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9584 - accuracy: 0.2857 - val_loss: 1.0700 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9540 - accuracy: 0.3393 - val_loss: 1.0704 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9500 - accuracy: 0.3571 - val_loss: 1.0708 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.9449 - accuracy: 0.3393 - val_loss: 1.0714 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9396 - accuracy: 0.3393 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9346 - accuracy: 0.3571 - val_loss: 1.0728 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9288 - accuracy: 0.3571 - val_loss: 1.0736 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9234 - accuracy: 0.3393 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9171 - accuracy: 0.3750 - val_loss: 1.0759 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9122 - accuracy: 0.3750 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9061 - accuracy: 0.3393 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9003 - accuracy: 0.3571 - val_loss: 1.0810 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8940 - accuracy: 0.3393 - val_loss: 1.0833 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8873 - accuracy: 0.3571 - val_loss: 1.0859 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8798 - accuracy: 0.3393 - val_loss: 1.0889 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8742 - accuracy: 0.3393 - val_loss: 1.0923 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8676 - accuracy: 0.3571 - val_loss: 1.0961 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.8606 - accuracy: 0.3393 - val_loss: 1.1003 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8544 - accuracy: 0.3750 - val_loss: 1.1048 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8476 - accuracy: 0.3750 - val_loss: 1.1096 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8411 - accuracy: 0.3571 - val_loss: 1.1148 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8362 - accuracy: 0.3750 - val_loss: 1.1203 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8294 - accuracy: 0.3393 - val_loss: 1.1261 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8226 - accuracy: 0.3571 - val_loss: 1.1324 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8155 - accuracy: 0.3571 - val_loss: 1.1390 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8113 - accuracy: 0.3036 - val_loss: 1.1461 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8062 - accuracy: 0.2857 - val_loss: 1.1536 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8016 - accuracy: 0.2857 - val_loss: 1.1613 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7939 - accuracy: 0.2857 - val_loss: 1.1693 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7892 - accuracy: 0.2857 - val_loss: 1.1773 - val_accuracy: 0.2143\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7863 - accuracy: 0.2857 - val_loss: 1.1853 - val_accuracy: 0.2143\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7794 - accuracy: 0.2857 - val_loss: 1.1931 - val_accuracy: 0.2143\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7745 - accuracy: 0.3036 - val_loss: 1.2006 - val_accuracy: 0.2143\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7697 - accuracy: 0.3036 - val_loss: 1.2075 - val_accuracy: 0.2143\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7679 - accuracy: 0.3036 - val_loss: 1.2139 - val_accuracy: 0.2143\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7619 - accuracy: 0.3214 - val_loss: 1.2197 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7563 - accuracy: 0.3214 - val_loss: 1.2249 - val_accuracy: 0.2143\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7529 - accuracy: 0.3214 - val_loss: 1.2296 - val_accuracy: 0.2143\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7498 - accuracy: 0.3214 - val_loss: 1.2332 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7461 - accuracy: 0.3393 - val_loss: 1.2358 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7426 - accuracy: 0.3214 - val_loss: 1.2373 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7375 - accuracy: 0.3214 - val_loss: 1.2376 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7294 - accuracy: 0.3214 - val_loss: 1.2369 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7265 - accuracy: 0.3214 - val_loss: 1.2353 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7213 - accuracy: 0.3214 - val_loss: 1.2333 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7170 - accuracy: 0.3393 - val_loss: 1.2314 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7147 - accuracy: 0.3393 - val_loss: 1.2296 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7066 - accuracy: 0.3393 - val_loss: 1.2282 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7034 - accuracy: 0.3214 - val_loss: 1.2274 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.6976 - accuracy: 0.3036 - val_loss: 1.2275 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.6930 - accuracy: 0.3036 - val_loss: 1.2287 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.6903 - accuracy: 0.3571 - val_loss: 1.2314 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6857 - accuracy: 0.3393 - val_loss: 1.2351 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6807 - accuracy: 0.3393 - val_loss: 1.2394 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6755 - accuracy: 0.3571 - val_loss: 1.2440 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6681 - accuracy: 0.3214 - val_loss: 1.2491 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6652 - accuracy: 0.3214 - val_loss: 1.2548 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6650 - accuracy: 0.3036 - val_loss: 1.2611 - val_accuracy: 0.2143\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6530 - accuracy: 0.3214 - val_loss: 1.2679 - val_accuracy: 0.2143\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6522 - accuracy: 0.3214 - val_loss: 1.2746 - val_accuracy: 0.2143\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6483 - accuracy: 0.3214 - val_loss: 1.2811 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6412 - accuracy: 0.3036 - val_loss: 1.2883 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6394 - accuracy: 0.3214 - val_loss: 1.2960 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6349 - accuracy: 0.3214 - val_loss: 1.3043 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6221 - accuracy: 0.3214 - val_loss: 1.3131 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6155 - accuracy: 0.3571 - val_loss: 1.3218 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6123 - accuracy: 0.3571 - val_loss: 1.3304 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6127 - accuracy: 0.3750 - val_loss: 1.3387 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6040 - accuracy: 0.3929 - val_loss: 1.3476 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5970 - accuracy: 0.3571 - val_loss: 1.3562 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5930 - accuracy: 0.4107 - val_loss: 1.3653 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5890 - accuracy: 0.4107 - val_loss: 1.3735 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5811 - accuracy: 0.3750 - val_loss: 1.3804 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5787 - accuracy: 0.4107 - val_loss: 1.3868 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5770 - accuracy: 0.3929 - val_loss: 1.3923 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5682 - accuracy: 0.4107 - val_loss: 1.3975 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5574 - accuracy: 0.4107 - val_loss: 1.4028 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5522 - accuracy: 0.3929 - val_loss: 1.4058 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5500 - accuracy: 0.4464 - val_loss: 1.4088 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5415 - accuracy: 0.4286 - val_loss: 1.4105 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5319 - accuracy: 0.4643 - val_loss: 1.4122 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5359 - accuracy: 0.4107 - val_loss: 1.4136 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5180 - accuracy: 0.4286 - val_loss: 1.4163 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5175 - accuracy: 0.4286 - val_loss: 1.4185 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5167 - accuracy: 0.4464 - val_loss: 1.4223 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5064 - accuracy: 0.4643 - val_loss: 1.4258 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.4943 - accuracy: 0.4464 - val_loss: 1.4289 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4951 - accuracy: 0.4286 - val_loss: 1.4336 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.4865 - accuracy: 0.5000 - val_loss: 1.4390 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4779 - accuracy: 0.4286 - val_loss: 1.4450 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4721 - accuracy: 0.4107 - val_loss: 1.4520 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4655 - accuracy: 0.4643 - val_loss: 1.4587 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4618 - accuracy: 0.4643 - val_loss: 1.4655 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4477 - accuracy: 0.4821 - val_loss: 1.4701 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4464 - accuracy: 0.4821 - val_loss: 1.4735 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4312 - accuracy: 0.4643 - val_loss: 1.4775 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4312 - accuracy: 0.4821 - val_loss: 1.4788 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4253 - accuracy: 0.4464 - val_loss: 1.4788 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4086 - accuracy: 0.4643 - val_loss: 1.4784 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4133 - accuracy: 0.4821 - val_loss: 1.4780 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4081 - accuracy: 0.5179 - val_loss: 1.4749 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3995 - accuracy: 0.4643 - val_loss: 1.4677 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3945 - accuracy: 0.5714 - val_loss: 1.4626 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3791 - accuracy: 0.5179 - val_loss: 1.4660 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3718 - accuracy: 0.4643 - val_loss: 1.4687 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3637 - accuracy: 0.5000 - val_loss: 1.4745 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3587 - accuracy: 0.5000 - val_loss: 1.4800 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3553 - accuracy: 0.4643 - val_loss: 1.4785 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3473 - accuracy: 0.4464 - val_loss: 1.4709 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3444 - accuracy: 0.5000 - val_loss: 1.4646 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3356 - accuracy: 0.5536 - val_loss: 1.4614 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3265 - accuracy: 0.5000 - val_loss: 1.4648 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3283 - accuracy: 0.5714 - val_loss: 1.4704 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3190 - accuracy: 0.5714 - val_loss: 1.4777 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3130 - accuracy: 0.6071 - val_loss: 1.4816 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3080 - accuracy: 0.5536 - val_loss: 1.4848 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3013 - accuracy: 0.5357 - val_loss: 1.4864 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3006 - accuracy: 0.5714 - val_loss: 1.4877 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2868 - accuracy: 0.5893 - val_loss: 1.4887 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2811 - accuracy: 0.6071 - val_loss: 1.4872 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.2849 - accuracy: 0.5536 - val_loss: 1.4934 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2764 - accuracy: 0.6429 - val_loss: 1.4994 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2697 - accuracy: 0.5536 - val_loss: 1.5121 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2607 - accuracy: 0.5536 - val_loss: 1.5193 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2498 - accuracy: 0.5714 - val_loss: 1.5270 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2531 - accuracy: 0.5893 - val_loss: 1.5333 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2596 - accuracy: 0.5357 - val_loss: 1.5308 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2430 - accuracy: 0.5893 - val_loss: 1.5375 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2461 - accuracy: 0.6071 - val_loss: 1.5584 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2303 - accuracy: 0.5893 - val_loss: 1.5763 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2306 - accuracy: 0.5179 - val_loss: 1.5915 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2345 - accuracy: 0.5714 - val_loss: 1.5922 - val_accuracy: 0.2143\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2240 - accuracy: 0.6607 - val_loss: 1.6021 - val_accuracy: 0.2143\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2208 - accuracy: 0.5714 - val_loss: 1.6072 - val_accuracy: 0.2143\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2186 - accuracy: 0.5536 - val_loss: 1.6123 - val_accuracy: 0.2143\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2247 - accuracy: 0.5893 - val_loss: 1.6172 - val_accuracy: 0.2143\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2203 - accuracy: 0.5714 - val_loss: 1.6159 - val_accuracy: 0.2143\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2091 - accuracy: 0.6250 - val_loss: 1.6092 - val_accuracy: 0.1429\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2016 - accuracy: 0.6071 - val_loss: 1.6051 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2073 - accuracy: 0.6250 - val_loss: 1.6222 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2052 - accuracy: 0.5893 - val_loss: 1.6409 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1982 - accuracy: 0.5893 - val_loss: 1.6727 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2016 - accuracy: 0.6429 - val_loss: 1.7152 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1888 - accuracy: 0.6071 - val_loss: 1.7373 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1870 - accuracy: 0.6429 - val_loss: 1.7432 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1787 - accuracy: 0.6250 - val_loss: 1.7296 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1891 - accuracy: 0.6607 - val_loss: 1.7035 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1850 - accuracy: 0.6250 - val_loss: 1.6957 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1732 - accuracy: 0.6250 - val_loss: 1.7124 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1726 - accuracy: 0.5536 - val_loss: 1.7418 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1671 - accuracy: 0.6071 - val_loss: 1.7766 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1667 - accuracy: 0.6786 - val_loss: 1.7982 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1597 - accuracy: 0.6429 - val_loss: 1.7922 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1617 - accuracy: 0.6071 - val_loss: 1.7710 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1522 - accuracy: 0.6429 - val_loss: 1.7473 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1593 - accuracy: 0.6964 - val_loss: 1.7458 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1595 - accuracy: 0.6607 - val_loss: 1.7688 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1523 - accuracy: 0.6429 - val_loss: 1.8144 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1505 - accuracy: 0.6250 - val_loss: 1.8463 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1658 - accuracy: 0.5893 - val_loss: 1.8358 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1516 - accuracy: 0.6429 - val_loss: 1.8116 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1478 - accuracy: 0.6071 - val_loss: 1.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1361 - accuracy: 0.5714 - val_loss: 1.7919 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1439 - accuracy: 0.6429 - val_loss: 1.7847 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1397 - accuracy: 0.6250 - val_loss: 1.7915 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1350 - accuracy: 0.6429 - val_loss: 1.8037 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1303 - accuracy: 0.6964 - val_loss: 1.8241 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1358 - accuracy: 0.6250 - val_loss: 1.8436 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1356 - accuracy: 0.6071 - val_loss: 1.8459 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1255 - accuracy: 0.6250 - val_loss: 1.8526 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1249 - accuracy: 0.6250 - val_loss: 1.8570 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1295 - accuracy: 0.6607 - val_loss: 1.8681 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1206 - accuracy: 0.6786 - val_loss: 1.8681 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1177 - accuracy: 0.6607 - val_loss: 1.8548 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1241 - accuracy: 0.6786 - val_loss: 1.8378 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1100 - accuracy: 0.6250 - val_loss: 1.8145 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1086 - accuracy: 0.6964 - val_loss: 1.7980 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1110 - accuracy: 0.7143 - val_loss: 1.7907 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1197 - accuracy: 0.6250 - val_loss: 1.7920 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1089 - accuracy: 0.6250 - val_loss: 1.8112 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1190 - accuracy: 0.6786 - val_loss: 1.8357 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1115 - accuracy: 0.6607 - val_loss: 1.8634 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1130 - accuracy: 0.6786 - val_loss: 1.8914 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1057 - accuracy: 0.6607 - val_loss: 1.8949 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1016 - accuracy: 0.6607 - val_loss: 1.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1024 - accuracy: 0.6429 - val_loss: 1.8788 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0984 - accuracy: 0.6250 - val_loss: 1.8838 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0985 - accuracy: 0.6250 - val_loss: 1.8948 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1017 - accuracy: 0.6964 - val_loss: 1.9080 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0960 - accuracy: 0.6607 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0957 - accuracy: 0.7500 - val_loss: 1.9269 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0976 - accuracy: 0.6607 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0937 - accuracy: 0.7143 - val_loss: 1.9086 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0899 - accuracy: 0.6786 - val_loss: 1.8931 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0930 - accuracy: 0.6429 - val_loss: 1.8846 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0960 - accuracy: 0.6429 - val_loss: 1.8713 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0955 - accuracy: 0.6786 - val_loss: 1.8661 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0878 - accuracy: 0.7321 - val_loss: 1.8851 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0958 - accuracy: 0.6786 - val_loss: 1.8988 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0884 - accuracy: 0.6786 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0823 - accuracy: 0.6607 - val_loss: 1.9402 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0811 - accuracy: 0.6964 - val_loss: 1.9538 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0820 - accuracy: 0.7143 - val_loss: 1.9524 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0814 - accuracy: 0.7321 - val_loss: 1.9356 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0830 - accuracy: 0.7321 - val_loss: 1.9119 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0776 - accuracy: 0.7500 - val_loss: 1.9030 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0782 - accuracy: 0.6786 - val_loss: 1.9063 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0780 - accuracy: 0.6607 - val_loss: 1.9110 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0731 - accuracy: 0.6964 - val_loss: 1.9253 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0779 - accuracy: 0.7321 - val_loss: 1.9419 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0796 - accuracy: 0.7143 - val_loss: 1.9468 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0704 - accuracy: 0.7500 - val_loss: 1.9451 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0795 - accuracy: 0.7321 - val_loss: 1.9417 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0772 - accuracy: 0.7143 - val_loss: 1.9468 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0766 - accuracy: 0.7679 - val_loss: 1.9578 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0735 - accuracy: 0.7321 - val_loss: 1.9753 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0742 - accuracy: 0.7857 - val_loss: 2.0051 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.0692 - accuracy: 0.7321 - val_loss: 2.0279 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0708 - accuracy: 0.7143 - val_loss: 2.0465 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0677 - accuracy: 0.7143 - val_loss: 2.0415 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0704 - accuracy: 0.8036 - val_loss: 2.0274 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0649 - accuracy: 0.7679 - val_loss: 2.0115 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0712 - accuracy: 0.7143 - val_loss: 1.9941 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0667 - accuracy: 0.7679 - val_loss: 1.9946 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0656 - accuracy: 0.7679 - val_loss: 1.9901 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0664 - accuracy: 0.7500 - val_loss: 1.9823 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0674 - accuracy: 0.7857 - val_loss: 1.9857 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0658 - accuracy: 0.7321 - val_loss: 1.9882 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0643 - accuracy: 0.7321 - val_loss: 1.9930 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0678 - accuracy: 0.7857 - val_loss: 1.9823 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0653 - accuracy: 0.6786 - val_loss: 1.9783 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0649 - accuracy: 0.7143 - val_loss: 1.9833 - val_accuracy: 0.1429\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0591 - accuracy: 0.7321 - val_loss: 2.0022 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0622 - accuracy: 0.7679 - val_loss: 2.0271 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0271 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.2, lstm_units=240, wl= 7, epoch=240, batch_size=500, Scores: [2.02714204788208, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 2.02714204788208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9840 - accuracy: 0.1071 - val_loss: 1.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9829 - accuracy: 0.1607 - val_loss: 1.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9803 - accuracy: 0.1250 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9787 - accuracy: 0.1786 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9769 - accuracy: 0.1964 - val_loss: 1.0718 - val_accuracy: 0.0714\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9755 - accuracy: 0.2321 - val_loss: 1.0721 - val_accuracy: 0.0714\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9720 - accuracy: 0.2143 - val_loss: 1.0724 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9698 - accuracy: 0.2321 - val_loss: 1.0727 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9686 - accuracy: 0.2143 - val_loss: 1.0731 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9662 - accuracy: 0.2143 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9643 - accuracy: 0.2321 - val_loss: 1.0738 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9656 - accuracy: 0.1786 - val_loss: 1.0742 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9625 - accuracy: 0.2321 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9584 - accuracy: 0.2679 - val_loss: 1.0750 - val_accuracy: 0.0714\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9576 - accuracy: 0.2500 - val_loss: 1.0755 - val_accuracy: 0.0714\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9559 - accuracy: 0.2321 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9531 - accuracy: 0.2500 - val_loss: 1.0763 - val_accuracy: 0.0714\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9530 - accuracy: 0.1786 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9486 - accuracy: 0.2321 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9482 - accuracy: 0.2679 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9441 - accuracy: 0.2321 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9421 - accuracy: 0.2679 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9403 - accuracy: 0.2321 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9369 - accuracy: 0.2679 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9356 - accuracy: 0.2500 - val_loss: 1.0802 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9328 - accuracy: 0.2679 - val_loss: 1.0808 - val_accuracy: 0.0714\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9307 - accuracy: 0.3036 - val_loss: 1.0813 - val_accuracy: 0.0714\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9264 - accuracy: 0.2857 - val_loss: 1.0819 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9248 - accuracy: 0.2857 - val_loss: 1.0825 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9194 - accuracy: 0.2679 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9175 - accuracy: 0.2857 - val_loss: 1.0838 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9152 - accuracy: 0.2679 - val_loss: 1.0845 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0845 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=32, batch_size=100, Scores: [1.084541916847229, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.084541916847229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9823 - accuracy: 0.0893 - val_loss: 1.0749 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9819 - accuracy: 0.0714 - val_loss: 1.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9794 - accuracy: 0.0714 - val_loss: 1.0759 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9767 - accuracy: 0.1071 - val_loss: 1.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9751 - accuracy: 0.1429 - val_loss: 1.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9726 - accuracy: 0.1429 - val_loss: 1.0775 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9707 - accuracy: 0.1607 - val_loss: 1.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9680 - accuracy: 0.2143 - val_loss: 1.0787 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9656 - accuracy: 0.1607 - val_loss: 1.0793 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9634 - accuracy: 0.2321 - val_loss: 1.0799 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9610 - accuracy: 0.2321 - val_loss: 1.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9619 - accuracy: 0.1964 - val_loss: 1.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9582 - accuracy: 0.2679 - val_loss: 1.0817 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9561 - accuracy: 0.2500 - val_loss: 1.0823 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9525 - accuracy: 0.2321 - val_loss: 1.0829 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9484 - accuracy: 0.2143 - val_loss: 1.0836 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9459 - accuracy: 0.2143 - val_loss: 1.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9452 - accuracy: 0.2500 - val_loss: 1.0849 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9425 - accuracy: 0.1786 - val_loss: 1.0856 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9392 - accuracy: 0.1786 - val_loss: 1.0863 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9376 - accuracy: 0.1786 - val_loss: 1.0870 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9364 - accuracy: 0.2321 - val_loss: 1.0877 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9301 - accuracy: 0.2321 - val_loss: 1.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9290 - accuracy: 0.2500 - val_loss: 1.0893 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9249 - accuracy: 0.1964 - val_loss: 1.0902 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9225 - accuracy: 0.2143 - val_loss: 1.0910 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9197 - accuracy: 0.2143 - val_loss: 1.0919 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9168 - accuracy: 0.2321 - val_loss: 1.0929 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9142 - accuracy: 0.2500 - val_loss: 1.0939 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9074 - accuracy: 0.2143 - val_loss: 1.0950 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9049 - accuracy: 0.2143 - val_loss: 1.0962 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9022 - accuracy: 0.1964 - val_loss: 1.0975 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0975 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=32, batch_size=300, Scores: [1.097495198249817, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.097495198249817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9835 - accuracy: 0.2321 - val_loss: 1.0713 - val_accuracy: 0.1429\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9805 - accuracy: 0.1429 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9787 - accuracy: 0.2321 - val_loss: 1.0719 - val_accuracy: 0.2143\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9780 - accuracy: 0.2143 - val_loss: 1.0723 - val_accuracy: 0.2143\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9759 - accuracy: 0.1786 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9724 - accuracy: 0.3750 - val_loss: 1.0731 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9731 - accuracy: 0.2321 - val_loss: 1.0735 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9689 - accuracy: 0.3214 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9680 - accuracy: 0.2143 - val_loss: 1.0743 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9671 - accuracy: 0.1964 - val_loss: 1.0747 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9642 - accuracy: 0.2321 - val_loss: 1.0751 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9610 - accuracy: 0.3393 - val_loss: 1.0755 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9606 - accuracy: 0.2500 - val_loss: 1.0760 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9559 - accuracy: 0.2679 - val_loss: 1.0764 - val_accuracy: 0.0714\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9558 - accuracy: 0.3214 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9530 - accuracy: 0.2857 - val_loss: 1.0773 - val_accuracy: 0.0714\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9501 - accuracy: 0.2679 - val_loss: 1.0778 - val_accuracy: 0.0714\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9480 - accuracy: 0.2500 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9459 - accuracy: 0.3036 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9443 - accuracy: 0.3393 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9404 - accuracy: 0.3036 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9401 - accuracy: 0.3214 - val_loss: 1.0802 - val_accuracy: 0.0714\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9369 - accuracy: 0.3214 - val_loss: 1.0807 - val_accuracy: 0.0714\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9334 - accuracy: 0.3214 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9324 - accuracy: 0.3214 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9280 - accuracy: 0.4107 - val_loss: 1.0822 - val_accuracy: 0.0714\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9246 - accuracy: 0.3571 - val_loss: 1.0827 - val_accuracy: 0.0714\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9218 - accuracy: 0.3571 - val_loss: 1.0833 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9165 - accuracy: 0.3750 - val_loss: 1.0839 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9137 - accuracy: 0.3750 - val_loss: 1.0845 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9126 - accuracy: 0.3571 - val_loss: 1.0851 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9068 - accuracy: 0.3571 - val_loss: 1.0857 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0857 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=32, batch_size=400, Scores: [1.0856904983520508, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.0856904983520508\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9855 - accuracy: 0.0179 - val_loss: 1.0691 - val_accuracy: 0.2857\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.9810 - accuracy: 0.1071 - val_loss: 1.0699 - val_accuracy: 0.2857\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9791 - accuracy: 0.1607 - val_loss: 1.0707 - val_accuracy: 0.2857\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9771 - accuracy: 0.2143 - val_loss: 1.0715 - val_accuracy: 0.2857\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9748 - accuracy: 0.1429 - val_loss: 1.0722 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9743 - accuracy: 0.2321 - val_loss: 1.0730 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9687 - accuracy: 0.2500 - val_loss: 1.0738 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9674 - accuracy: 0.2143 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9669 - accuracy: 0.2857 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9637 - accuracy: 0.2857 - val_loss: 1.0762 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9617 - accuracy: 0.2679 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9613 - accuracy: 0.3036 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9577 - accuracy: 0.2857 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9543 - accuracy: 0.3571 - val_loss: 1.0795 - val_accuracy: 0.0714\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9535 - accuracy: 0.3214 - val_loss: 1.0804 - val_accuracy: 0.0714\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9487 - accuracy: 0.2857 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9470 - accuracy: 0.3214 - val_loss: 1.0820 - val_accuracy: 0.0714\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9457 - accuracy: 0.3393 - val_loss: 1.0829 - val_accuracy: 0.0714\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9418 - accuracy: 0.3036 - val_loss: 1.0837 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9393 - accuracy: 0.3393 - val_loss: 1.0846 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9353 - accuracy: 0.3750 - val_loss: 1.0855 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9353 - accuracy: 0.3214 - val_loss: 1.0864 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9302 - accuracy: 0.3750 - val_loss: 1.0874 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 0.9289 - accuracy: 0.3393 - val_loss: 1.0883 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9235 - accuracy: 0.3393 - val_loss: 1.0892 - val_accuracy: 0.1429\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9204 - accuracy: 0.3571 - val_loss: 1.0901 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9183 - accuracy: 0.3393 - val_loss: 1.0911 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9151 - accuracy: 0.3393 - val_loss: 1.0920 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9152 - accuracy: 0.3214 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9068 - accuracy: 0.3571 - val_loss: 1.0940 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9049 - accuracy: 0.3393 - val_loss: 1.0950 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9018 - accuracy: 0.2857 - val_loss: 1.0960 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0960 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=32, batch_size=500, Scores: [1.096008062362671, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.096008062362671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9803 - accuracy: 0.0893 - val_loss: 1.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9798 - accuracy: 0.2143 - val_loss: 1.0694 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9774 - accuracy: 0.1964 - val_loss: 1.0698 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9761 - accuracy: 0.2500 - val_loss: 1.0703 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9749 - accuracy: 0.2321 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9705 - accuracy: 0.2321 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9696 - accuracy: 0.2500 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9679 - accuracy: 0.3214 - val_loss: 1.0721 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9651 - accuracy: 0.3571 - val_loss: 1.0726 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9628 - accuracy: 0.3571 - val_loss: 1.0731 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9617 - accuracy: 0.2857 - val_loss: 1.0736 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9590 - accuracy: 0.3571 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9577 - accuracy: 0.3393 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9556 - accuracy: 0.3036 - val_loss: 1.0752 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9541 - accuracy: 0.2857 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9494 - accuracy: 0.3393 - val_loss: 1.0763 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9485 - accuracy: 0.3393 - val_loss: 1.0769 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9448 - accuracy: 0.2857 - val_loss: 1.0774 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9445 - accuracy: 0.3393 - val_loss: 1.0780 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9422 - accuracy: 0.3036 - val_loss: 1.0785 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9388 - accuracy: 0.3214 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9360 - accuracy: 0.3214 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9332 - accuracy: 0.3214 - val_loss: 1.0801 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9298 - accuracy: 0.3214 - val_loss: 1.0806 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9254 - accuracy: 0.3214 - val_loss: 1.0811 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9239 - accuracy: 0.2679 - val_loss: 1.0817 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9215 - accuracy: 0.3036 - val_loss: 1.0823 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9179 - accuracy: 0.3036 - val_loss: 1.0829 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9140 - accuracy: 0.2857 - val_loss: 1.0836 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9088 - accuracy: 0.3393 - val_loss: 1.0843 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9096 - accuracy: 0.3036 - val_loss: 1.0850 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9052 - accuracy: 0.3036 - val_loss: 1.0858 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9043 - accuracy: 0.2679 - val_loss: 1.0866 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8965 - accuracy: 0.3571 - val_loss: 1.0876 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8922 - accuracy: 0.2857 - val_loss: 1.0886 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8904 - accuracy: 0.3036 - val_loss: 1.0897 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8842 - accuracy: 0.3214 - val_loss: 1.0909 - val_accuracy: 0.1429\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8836 - accuracy: 0.3393 - val_loss: 1.0921 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8776 - accuracy: 0.2857 - val_loss: 1.0935 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8769 - accuracy: 0.3036 - val_loss: 1.0950 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8730 - accuracy: 0.2679 - val_loss: 1.0966 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8709 - accuracy: 0.3036 - val_loss: 1.0984 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8636 - accuracy: 0.2857 - val_loss: 1.1003 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8639 - accuracy: 0.3214 - val_loss: 1.1023 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8597 - accuracy: 0.3214 - val_loss: 1.1044 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8496 - accuracy: 0.3393 - val_loss: 1.1066 - val_accuracy: 0.2143\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8504 - accuracy: 0.3393 - val_loss: 1.1088 - val_accuracy: 0.2143\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8502 - accuracy: 0.3571 - val_loss: 1.1111 - val_accuracy: 0.2143\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8463 - accuracy: 0.3393 - val_loss: 1.1134 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8417 - accuracy: 0.3214 - val_loss: 1.1156 - val_accuracy: 0.1429\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8415 - accuracy: 0.2857 - val_loss: 1.1177 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8338 - accuracy: 0.3036 - val_loss: 1.1197 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8304 - accuracy: 0.3393 - val_loss: 1.1217 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8289 - accuracy: 0.3214 - val_loss: 1.1237 - val_accuracy: 0.1429\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8287 - accuracy: 0.3214 - val_loss: 1.1256 - val_accuracy: 0.1429\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8214 - accuracy: 0.3214 - val_loss: 1.1277 - val_accuracy: 0.1429\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8232 - accuracy: 0.3214 - val_loss: 1.1297 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8205 - accuracy: 0.3036 - val_loss: 1.1319 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8139 - accuracy: 0.3393 - val_loss: 1.1342 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8111 - accuracy: 0.3036 - val_loss: 1.1366 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8129 - accuracy: 0.3214 - val_loss: 1.1391 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8015 - accuracy: 0.3571 - val_loss: 1.1417 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7999 - accuracy: 0.3393 - val_loss: 1.1443 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7998 - accuracy: 0.3036 - val_loss: 1.1470 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1470 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=64, batch_size=100, Scores: [1.1470212936401367, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1470212936401367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9814 - accuracy: 0.1429 - val_loss: 1.0680 - val_accuracy: 0.0714\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9799 - accuracy: 0.2143 - val_loss: 1.0682 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9767 - accuracy: 0.2679 - val_loss: 1.0683 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9746 - accuracy: 0.2321 - val_loss: 1.0685 - val_accuracy: 0.0714\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9720 - accuracy: 0.2857 - val_loss: 1.0687 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9708 - accuracy: 0.1964 - val_loss: 1.0689 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9681 - accuracy: 0.2321 - val_loss: 1.0691 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9670 - accuracy: 0.2143 - val_loss: 1.0694 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.9653 - accuracy: 0.2857 - val_loss: 1.0696 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.9611 - accuracy: 0.2679 - val_loss: 1.0699 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9596 - accuracy: 0.2679 - val_loss: 1.0701 - val_accuracy: 0.0714\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9602 - accuracy: 0.2500 - val_loss: 1.0704 - val_accuracy: 0.0714\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9571 - accuracy: 0.2143 - val_loss: 1.0707 - val_accuracy: 0.0714\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9513 - accuracy: 0.2679 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9507 - accuracy: 0.2857 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9510 - accuracy: 0.2679 - val_loss: 1.0714 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9469 - accuracy: 0.3214 - val_loss: 1.0717 - val_accuracy: 0.0714\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9451 - accuracy: 0.2321 - val_loss: 1.0719 - val_accuracy: 0.0714\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9417 - accuracy: 0.2679 - val_loss: 1.0722 - val_accuracy: 0.0714\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9377 - accuracy: 0.2321 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9396 - accuracy: 0.2321 - val_loss: 1.0728 - val_accuracy: 0.0714\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9332 - accuracy: 0.2679 - val_loss: 1.0731 - val_accuracy: 0.0714\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9310 - accuracy: 0.2857 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9293 - accuracy: 0.2321 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9271 - accuracy: 0.2321 - val_loss: 1.0740 - val_accuracy: 0.0714\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9228 - accuracy: 0.2679 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9206 - accuracy: 0.2500 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9169 - accuracy: 0.2679 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9129 - accuracy: 0.2500 - val_loss: 1.0754 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9086 - accuracy: 0.2500 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9065 - accuracy: 0.2679 - val_loss: 1.0762 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9049 - accuracy: 0.2857 - val_loss: 1.0767 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8999 - accuracy: 0.2857 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8979 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8962 - accuracy: 0.2679 - val_loss: 1.0787 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8933 - accuracy: 0.2857 - val_loss: 1.0796 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.8865 - accuracy: 0.2857 - val_loss: 1.0806 - val_accuracy: 0.1429\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8855 - accuracy: 0.2857 - val_loss: 1.0817 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8767 - accuracy: 0.2500 - val_loss: 1.0829 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8743 - accuracy: 0.2500 - val_loss: 1.0843 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8741 - accuracy: 0.2679 - val_loss: 1.0858 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8662 - accuracy: 0.2679 - val_loss: 1.0875 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8667 - accuracy: 0.2679 - val_loss: 1.0894 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8600 - accuracy: 0.2857 - val_loss: 1.0914 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8539 - accuracy: 0.3036 - val_loss: 1.0937 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8508 - accuracy: 0.3214 - val_loss: 1.0962 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8420 - accuracy: 0.3036 - val_loss: 1.0989 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8403 - accuracy: 0.2679 - val_loss: 1.1019 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8382 - accuracy: 0.3036 - val_loss: 1.1051 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8366 - accuracy: 0.2857 - val_loss: 1.1087 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8277 - accuracy: 0.2857 - val_loss: 1.1125 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8303 - accuracy: 0.2857 - val_loss: 1.1165 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8207 - accuracy: 0.3036 - val_loss: 1.1207 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8174 - accuracy: 0.3214 - val_loss: 1.1251 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8150 - accuracy: 0.2857 - val_loss: 1.1298 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8110 - accuracy: 0.3036 - val_loss: 1.1347 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8095 - accuracy: 0.3393 - val_loss: 1.1395 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8056 - accuracy: 0.2857 - val_loss: 1.1443 - val_accuracy: 0.2143\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8050 - accuracy: 0.3036 - val_loss: 1.1490 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8062 - accuracy: 0.3393 - val_loss: 1.1537 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7973 - accuracy: 0.3571 - val_loss: 1.1583 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7882 - accuracy: 0.3393 - val_loss: 1.1629 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7817 - accuracy: 0.3571 - val_loss: 1.1674 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7820 - accuracy: 0.3571 - val_loss: 1.1716 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1716 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=64, batch_size=300, Scores: [1.1716318130493164, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1716318130493164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9818 - accuracy: 0.1786 - val_loss: 1.0683 - val_accuracy: 0.1429\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9805 - accuracy: 0.1607 - val_loss: 1.0688 - val_accuracy: 0.1429\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9787 - accuracy: 0.2143 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9783 - accuracy: 0.1964 - val_loss: 1.0700 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9742 - accuracy: 0.1964 - val_loss: 1.0706 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9728 - accuracy: 0.2500 - val_loss: 1.0712 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9702 - accuracy: 0.1964 - val_loss: 1.0719 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9692 - accuracy: 0.3214 - val_loss: 1.0726 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9657 - accuracy: 0.2500 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9658 - accuracy: 0.3393 - val_loss: 1.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9625 - accuracy: 0.3393 - val_loss: 1.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9617 - accuracy: 0.3393 - val_loss: 1.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9610 - accuracy: 0.3036 - val_loss: 1.0763 - val_accuracy: 0.0714\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9581 - accuracy: 0.3393 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9564 - accuracy: 0.3571 - val_loss: 1.0778 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9537 - accuracy: 0.3929 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9513 - accuracy: 0.3393 - val_loss: 1.0793 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9494 - accuracy: 0.3750 - val_loss: 1.0801 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9468 - accuracy: 0.3929 - val_loss: 1.0809 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9440 - accuracy: 0.3214 - val_loss: 1.0817 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9446 - accuracy: 0.3393 - val_loss: 1.0825 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9409 - accuracy: 0.2857 - val_loss: 1.0833 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9392 - accuracy: 0.3393 - val_loss: 1.0842 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9347 - accuracy: 0.3750 - val_loss: 1.0851 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9330 - accuracy: 0.3571 - val_loss: 1.0861 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9293 - accuracy: 0.3214 - val_loss: 1.0870 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9275 - accuracy: 0.3750 - val_loss: 1.0880 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9234 - accuracy: 0.3393 - val_loss: 1.0891 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9207 - accuracy: 0.3393 - val_loss: 1.0902 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9176 - accuracy: 0.3214 - val_loss: 1.0913 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9148 - accuracy: 0.3571 - val_loss: 1.0925 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9124 - accuracy: 0.3750 - val_loss: 1.0937 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9079 - accuracy: 0.3571 - val_loss: 1.0950 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9060 - accuracy: 0.3214 - val_loss: 1.0964 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9071 - accuracy: 0.2857 - val_loss: 1.0977 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9010 - accuracy: 0.2857 - val_loss: 1.0992 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8965 - accuracy: 0.3036 - val_loss: 1.1007 - val_accuracy: 0.1429\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8962 - accuracy: 0.3571 - val_loss: 1.1023 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8904 - accuracy: 0.3036 - val_loss: 1.1039 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8874 - accuracy: 0.3571 - val_loss: 1.1055 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8815 - accuracy: 0.3214 - val_loss: 1.1072 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8808 - accuracy: 0.3036 - val_loss: 1.1090 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8767 - accuracy: 0.3214 - val_loss: 1.1108 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8769 - accuracy: 0.3036 - val_loss: 1.1126 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8648 - accuracy: 0.3036 - val_loss: 1.1144 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8623 - accuracy: 0.2857 - val_loss: 1.1164 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8621 - accuracy: 0.3214 - val_loss: 1.1183 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8558 - accuracy: 0.3214 - val_loss: 1.1202 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8548 - accuracy: 0.3036 - val_loss: 1.1220 - val_accuracy: 0.1429\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8475 - accuracy: 0.3214 - val_loss: 1.1238 - val_accuracy: 0.1429\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8445 - accuracy: 0.3571 - val_loss: 1.1256 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8393 - accuracy: 0.3393 - val_loss: 1.1274 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8398 - accuracy: 0.3036 - val_loss: 1.1291 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8368 - accuracy: 0.3393 - val_loss: 1.1308 - val_accuracy: 0.1429\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8259 - accuracy: 0.3393 - val_loss: 1.1327 - val_accuracy: 0.1429\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8216 - accuracy: 0.2857 - val_loss: 1.1345 - val_accuracy: 0.1429\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8198 - accuracy: 0.2857 - val_loss: 1.1365 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8223 - accuracy: 0.3393 - val_loss: 1.1383 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8213 - accuracy: 0.3036 - val_loss: 1.1401 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8158 - accuracy: 0.3571 - val_loss: 1.1419 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8141 - accuracy: 0.2857 - val_loss: 1.1440 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8049 - accuracy: 0.3214 - val_loss: 1.1464 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7981 - accuracy: 0.3036 - val_loss: 1.1490 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7990 - accuracy: 0.3036 - val_loss: 1.1520 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1520 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=64, batch_size=400, Scores: [1.1520012617111206, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1520012617111206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9829 - accuracy: 0.1607 - val_loss: 1.0723 - val_accuracy: 0.2143\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9834 - accuracy: 0.1786 - val_loss: 1.0728 - val_accuracy: 0.2143\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9798 - accuracy: 0.2500 - val_loss: 1.0734 - val_accuracy: 0.2143\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9776 - accuracy: 0.1964 - val_loss: 1.0740 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9740 - accuracy: 0.3036 - val_loss: 1.0745 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9727 - accuracy: 0.2857 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9726 - accuracy: 0.2321 - val_loss: 1.0757 - val_accuracy: 0.2143\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9694 - accuracy: 0.2143 - val_loss: 1.0763 - val_accuracy: 0.2143\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9651 - accuracy: 0.3393 - val_loss: 1.0769 - val_accuracy: 0.2143\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9637 - accuracy: 0.2857 - val_loss: 1.0775 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9621 - accuracy: 0.3393 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9601 - accuracy: 0.3393 - val_loss: 1.0787 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9570 - accuracy: 0.2679 - val_loss: 1.0793 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9553 - accuracy: 0.2857 - val_loss: 1.0799 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9518 - accuracy: 0.3214 - val_loss: 1.0805 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9490 - accuracy: 0.3036 - val_loss: 1.0812 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9465 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9450 - accuracy: 0.3214 - val_loss: 1.0825 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9419 - accuracy: 0.3393 - val_loss: 1.0832 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9395 - accuracy: 0.3214 - val_loss: 1.0839 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9360 - accuracy: 0.2857 - val_loss: 1.0846 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9335 - accuracy: 0.3214 - val_loss: 1.0854 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9331 - accuracy: 0.3036 - val_loss: 1.0862 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9257 - accuracy: 0.3214 - val_loss: 1.0870 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9235 - accuracy: 0.3571 - val_loss: 1.0878 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9249 - accuracy: 0.3036 - val_loss: 1.0887 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9193 - accuracy: 0.3393 - val_loss: 1.0896 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9151 - accuracy: 0.3929 - val_loss: 1.0906 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9128 - accuracy: 0.3214 - val_loss: 1.0917 - val_accuracy: 0.2143\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9099 - accuracy: 0.2500 - val_loss: 1.0927 - val_accuracy: 0.2143\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9064 - accuracy: 0.3214 - val_loss: 1.0939 - val_accuracy: 0.2143\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9014 - accuracy: 0.3393 - val_loss: 1.0951 - val_accuracy: 0.2143\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9007 - accuracy: 0.3393 - val_loss: 1.0965 - val_accuracy: 0.2143\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8921 - accuracy: 0.3214 - val_loss: 1.0978 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8962 - accuracy: 0.2857 - val_loss: 1.0992 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8932 - accuracy: 0.3214 - val_loss: 1.1007 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8878 - accuracy: 0.3214 - val_loss: 1.1021 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8853 - accuracy: 0.3393 - val_loss: 1.1036 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8827 - accuracy: 0.3214 - val_loss: 1.1050 - val_accuracy: 0.2143\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8778 - accuracy: 0.3393 - val_loss: 1.1063 - val_accuracy: 0.2143\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8736 - accuracy: 0.2857 - val_loss: 1.1077 - val_accuracy: 0.2143\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8673 - accuracy: 0.3214 - val_loss: 1.1090 - val_accuracy: 0.2143\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8669 - accuracy: 0.2679 - val_loss: 1.1103 - val_accuracy: 0.2143\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8598 - accuracy: 0.2679 - val_loss: 1.1115 - val_accuracy: 0.2143\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8606 - accuracy: 0.2679 - val_loss: 1.1126 - val_accuracy: 0.2143\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8565 - accuracy: 0.2857 - val_loss: 1.1135 - val_accuracy: 0.2143\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8502 - accuracy: 0.3036 - val_loss: 1.1145 - val_accuracy: 0.2143\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8508 - accuracy: 0.2679 - val_loss: 1.1155 - val_accuracy: 0.2143\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8510 - accuracy: 0.2857 - val_loss: 1.1165 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8471 - accuracy: 0.2857 - val_loss: 1.1177 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8423 - accuracy: 0.2500 - val_loss: 1.1190 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8389 - accuracy: 0.3036 - val_loss: 1.1205 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8348 - accuracy: 0.2500 - val_loss: 1.1221 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8332 - accuracy: 0.2679 - val_loss: 1.1240 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8325 - accuracy: 0.2857 - val_loss: 1.1263 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8290 - accuracy: 0.2857 - val_loss: 1.1288 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8235 - accuracy: 0.3036 - val_loss: 1.1314 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8170 - accuracy: 0.2857 - val_loss: 1.1343 - val_accuracy: 0.2143\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8158 - accuracy: 0.3036 - val_loss: 1.1374 - val_accuracy: 0.2143\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8116 - accuracy: 0.3214 - val_loss: 1.1409 - val_accuracy: 0.2143\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8156 - accuracy: 0.3036 - val_loss: 1.1448 - val_accuracy: 0.2143\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8026 - accuracy: 0.3214 - val_loss: 1.1489 - val_accuracy: 0.2143\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8052 - accuracy: 0.3036 - val_loss: 1.1530 - val_accuracy: 0.2143\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8032 - accuracy: 0.3393 - val_loss: 1.1572 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1572 - accuracy: 0.2143\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=64, batch_size=500, Scores: [1.15716552734375, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.15716552734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9832 - accuracy: 0.1250 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9814 - accuracy: 0.1429 - val_loss: 1.0754 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9779 - accuracy: 0.2500 - val_loss: 1.0762 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9747 - accuracy: 0.2321 - val_loss: 1.0771 - val_accuracy: 0.2143\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9739 - accuracy: 0.2679 - val_loss: 1.0780 - val_accuracy: 0.2143\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9705 - accuracy: 0.2143 - val_loss: 1.0789 - val_accuracy: 0.2143\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9684 - accuracy: 0.3036 - val_loss: 1.0798 - val_accuracy: 0.2143\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9677 - accuracy: 0.2500 - val_loss: 1.0808 - val_accuracy: 0.2143\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9647 - accuracy: 0.2857 - val_loss: 1.0818 - val_accuracy: 0.2143\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9627 - accuracy: 0.3036 - val_loss: 1.0828 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9605 - accuracy: 0.3036 - val_loss: 1.0839 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9586 - accuracy: 0.2500 - val_loss: 1.0849 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9577 - accuracy: 0.2679 - val_loss: 1.0860 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9543 - accuracy: 0.3036 - val_loss: 1.0871 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9523 - accuracy: 0.2679 - val_loss: 1.0883 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9499 - accuracy: 0.3036 - val_loss: 1.0895 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9471 - accuracy: 0.3393 - val_loss: 1.0907 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9479 - accuracy: 0.3393 - val_loss: 1.0920 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9426 - accuracy: 0.3214 - val_loss: 1.0933 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9411 - accuracy: 0.2857 - val_loss: 1.0946 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9381 - accuracy: 0.3214 - val_loss: 1.0960 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9364 - accuracy: 0.2500 - val_loss: 1.0974 - val_accuracy: 0.2143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9337 - accuracy: 0.2857 - val_loss: 1.0989 - val_accuracy: 0.2143\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9303 - accuracy: 0.3393 - val_loss: 1.1005 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9283 - accuracy: 0.2679 - val_loss: 1.1021 - val_accuracy: 0.2143\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9243 - accuracy: 0.2857 - val_loss: 1.1038 - val_accuracy: 0.2143\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9219 - accuracy: 0.3393 - val_loss: 1.1056 - val_accuracy: 0.2143\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9192 - accuracy: 0.2857 - val_loss: 1.1074 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9165 - accuracy: 0.3214 - val_loss: 1.1093 - val_accuracy: 0.2143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9136 - accuracy: 0.3393 - val_loss: 1.1113 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9084 - accuracy: 0.3393 - val_loss: 1.1134 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9090 - accuracy: 0.3036 - val_loss: 1.1156 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9022 - accuracy: 0.3214 - val_loss: 1.1178 - val_accuracy: 0.2143\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9026 - accuracy: 0.3036 - val_loss: 1.1201 - val_accuracy: 0.2143\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9000 - accuracy: 0.2857 - val_loss: 1.1224 - val_accuracy: 0.2143\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8957 - accuracy: 0.3393 - val_loss: 1.1248 - val_accuracy: 0.2143\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8910 - accuracy: 0.3214 - val_loss: 1.1272 - val_accuracy: 0.2143\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8863 - accuracy: 0.2857 - val_loss: 1.1297 - val_accuracy: 0.2143\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8871 - accuracy: 0.3214 - val_loss: 1.1321 - val_accuracy: 0.2143\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8848 - accuracy: 0.3393 - val_loss: 1.1345 - val_accuracy: 0.2143\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8758 - accuracy: 0.3036 - val_loss: 1.1369 - val_accuracy: 0.2143\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8756 - accuracy: 0.3393 - val_loss: 1.1393 - val_accuracy: 0.2143\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8712 - accuracy: 0.3214 - val_loss: 1.1416 - val_accuracy: 0.2143\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8726 - accuracy: 0.2857 - val_loss: 1.1438 - val_accuracy: 0.2143\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8611 - accuracy: 0.3214 - val_loss: 1.1459 - val_accuracy: 0.2143\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8612 - accuracy: 0.3393 - val_loss: 1.1478 - val_accuracy: 0.2143\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8574 - accuracy: 0.3393 - val_loss: 1.1495 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8553 - accuracy: 0.3571 - val_loss: 1.1511 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8513 - accuracy: 0.3214 - val_loss: 1.1526 - val_accuracy: 0.2143\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8461 - accuracy: 0.2679 - val_loss: 1.1539 - val_accuracy: 0.2143\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8425 - accuracy: 0.3393 - val_loss: 1.1551 - val_accuracy: 0.2143\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8408 - accuracy: 0.3571 - val_loss: 1.1562 - val_accuracy: 0.2143\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8346 - accuracy: 0.3571 - val_loss: 1.1572 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8298 - accuracy: 0.3393 - val_loss: 1.1581 - val_accuracy: 0.2143\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8206 - accuracy: 0.3571 - val_loss: 1.1589 - val_accuracy: 0.2143\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8212 - accuracy: 0.3214 - val_loss: 1.1598 - val_accuracy: 0.2143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8205 - accuracy: 0.3750 - val_loss: 1.1606 - val_accuracy: 0.2143\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.8173 - accuracy: 0.3571 - val_loss: 1.1616 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8101 - accuracy: 0.3929 - val_loss: 1.1628 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8084 - accuracy: 0.3393 - val_loss: 1.1642 - val_accuracy: 0.2143\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8034 - accuracy: 0.3393 - val_loss: 1.1656 - val_accuracy: 0.2857\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8076 - accuracy: 0.3929 - val_loss: 1.1672 - val_accuracy: 0.2857\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7970 - accuracy: 0.3571 - val_loss: 1.1688 - val_accuracy: 0.2857\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7916 - accuracy: 0.3571 - val_loss: 1.1706 - val_accuracy: 0.2857\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7970 - accuracy: 0.3571 - val_loss: 1.1723 - val_accuracy: 0.2857\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7940 - accuracy: 0.3750 - val_loss: 1.1742 - val_accuracy: 0.2857\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7865 - accuracy: 0.3214 - val_loss: 1.1764 - val_accuracy: 0.2857\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7793 - accuracy: 0.3393 - val_loss: 1.1791 - val_accuracy: 0.2857\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7828 - accuracy: 0.3571 - val_loss: 1.1819 - val_accuracy: 0.2857\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7735 - accuracy: 0.3214 - val_loss: 1.1847 - val_accuracy: 0.2857\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7751 - accuracy: 0.3214 - val_loss: 1.1873 - val_accuracy: 0.2857\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7689 - accuracy: 0.3214 - val_loss: 1.1900 - val_accuracy: 0.3571\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7675 - accuracy: 0.3393 - val_loss: 1.1928 - val_accuracy: 0.3571\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7703 - accuracy: 0.3393 - val_loss: 1.1956 - val_accuracy: 0.2857\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7642 - accuracy: 0.3393 - val_loss: 1.1987 - val_accuracy: 0.2857\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7583 - accuracy: 0.3214 - val_loss: 1.2017 - val_accuracy: 0.2857\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7603 - accuracy: 0.3393 - val_loss: 1.2047 - val_accuracy: 0.2143\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7557 - accuracy: 0.3393 - val_loss: 1.2076 - val_accuracy: 0.2143\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7505 - accuracy: 0.3750 - val_loss: 1.2105 - val_accuracy: 0.2857\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7466 - accuracy: 0.3750 - val_loss: 1.2132 - val_accuracy: 0.2857\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7435 - accuracy: 0.3571 - val_loss: 1.2157 - val_accuracy: 0.2857\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7369 - accuracy: 0.3571 - val_loss: 1.2184 - val_accuracy: 0.2143\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7453 - accuracy: 0.3393 - val_loss: 1.2212 - val_accuracy: 0.2143\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7407 - accuracy: 0.3214 - val_loss: 1.2238 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7372 - accuracy: 0.3214 - val_loss: 1.2266 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7298 - accuracy: 0.3214 - val_loss: 1.2296 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7344 - accuracy: 0.3214 - val_loss: 1.2324 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7260 - accuracy: 0.3214 - val_loss: 1.2352 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7221 - accuracy: 0.3036 - val_loss: 1.2377 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7261 - accuracy: 0.3036 - val_loss: 1.2398 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7170 - accuracy: 0.3214 - val_loss: 1.2416 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7130 - accuracy: 0.3571 - val_loss: 1.2430 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7027 - accuracy: 0.3393 - val_loss: 1.2445 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7140 - accuracy: 0.3214 - val_loss: 1.2453 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7116 - accuracy: 0.3214 - val_loss: 1.2460 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7111 - accuracy: 0.3214 - val_loss: 1.2463 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7035 - accuracy: 0.3214 - val_loss: 1.2465 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6944 - accuracy: 0.3214 - val_loss: 1.2465 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6965 - accuracy: 0.3393 - val_loss: 1.2467 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6893 - accuracy: 0.3214 - val_loss: 1.2475 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2475 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=100, batch_size=100, Scores: [1.2474673986434937, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2474673986434937\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9866 - accuracy: 0.1429 - val_loss: 1.0680 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9844 - accuracy: 0.1607 - val_loss: 1.0682 - val_accuracy: 0.2857\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9824 - accuracy: 0.1964 - val_loss: 1.0684 - val_accuracy: 0.2143\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9800 - accuracy: 0.1429 - val_loss: 1.0687 - val_accuracy: 0.2857\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9787 - accuracy: 0.1964 - val_loss: 1.0690 - val_accuracy: 0.2857\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9762 - accuracy: 0.1964 - val_loss: 1.0693 - val_accuracy: 0.2857\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9729 - accuracy: 0.2321 - val_loss: 1.0696 - val_accuracy: 0.2857\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9712 - accuracy: 0.1786 - val_loss: 1.0700 - val_accuracy: 0.2143\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9683 - accuracy: 0.2143 - val_loss: 1.0703 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9667 - accuracy: 0.2500 - val_loss: 1.0706 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9640 - accuracy: 0.1964 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9617 - accuracy: 0.2321 - val_loss: 1.0713 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9617 - accuracy: 0.2143 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9577 - accuracy: 0.2679 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9549 - accuracy: 0.2500 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9523 - accuracy: 0.3036 - val_loss: 1.0726 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9511 - accuracy: 0.2500 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9486 - accuracy: 0.2857 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9445 - accuracy: 0.2143 - val_loss: 1.0738 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9448 - accuracy: 0.2500 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9425 - accuracy: 0.2857 - val_loss: 1.0745 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9391 - accuracy: 0.2857 - val_loss: 1.0749 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9352 - accuracy: 0.2500 - val_loss: 1.0752 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9341 - accuracy: 0.2679 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9309 - accuracy: 0.2857 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9262 - accuracy: 0.3036 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9251 - accuracy: 0.3036 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9241 - accuracy: 0.2857 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9173 - accuracy: 0.2679 - val_loss: 1.0783 - val_accuracy: 0.0714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9175 - accuracy: 0.2857 - val_loss: 1.0790 - val_accuracy: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9129 - accuracy: 0.3214 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9080 - accuracy: 0.3393 - val_loss: 1.0805 - val_accuracy: 0.0714\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9056 - accuracy: 0.3214 - val_loss: 1.0814 - val_accuracy: 0.0714\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9028 - accuracy: 0.2857 - val_loss: 1.0825 - val_accuracy: 0.0714\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8965 - accuracy: 0.2143 - val_loss: 1.0836 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8974 - accuracy: 0.3214 - val_loss: 1.0849 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8917 - accuracy: 0.3036 - val_loss: 1.0863 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8908 - accuracy: 0.3036 - val_loss: 1.0879 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8853 - accuracy: 0.3214 - val_loss: 1.0896 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8803 - accuracy: 0.2500 - val_loss: 1.0915 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8799 - accuracy: 0.3214 - val_loss: 1.0935 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8750 - accuracy: 0.2500 - val_loss: 1.0957 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8707 - accuracy: 0.2857 - val_loss: 1.0981 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8686 - accuracy: 0.2679 - val_loss: 1.1006 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8606 - accuracy: 0.2679 - val_loss: 1.1031 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8599 - accuracy: 0.2857 - val_loss: 1.1058 - val_accuracy: 0.2143\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8557 - accuracy: 0.2857 - val_loss: 1.1086 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8537 - accuracy: 0.2679 - val_loss: 1.1114 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8510 - accuracy: 0.2857 - val_loss: 1.1143 - val_accuracy: 0.2143\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8459 - accuracy: 0.2857 - val_loss: 1.1172 - val_accuracy: 0.2143\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8442 - accuracy: 0.3036 - val_loss: 1.1201 - val_accuracy: 0.2143\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8386 - accuracy: 0.3036 - val_loss: 1.1231 - val_accuracy: 0.2143\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8318 - accuracy: 0.3036 - val_loss: 1.1261 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8298 - accuracy: 0.3036 - val_loss: 1.1293 - val_accuracy: 0.2143\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8251 - accuracy: 0.3571 - val_loss: 1.1326 - val_accuracy: 0.2143\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8220 - accuracy: 0.3214 - val_loss: 1.1360 - val_accuracy: 0.2143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8150 - accuracy: 0.3214 - val_loss: 1.1395 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8153 - accuracy: 0.3750 - val_loss: 1.1431 - val_accuracy: 0.1429\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8129 - accuracy: 0.2857 - val_loss: 1.1468 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8069 - accuracy: 0.3393 - val_loss: 1.1508 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8030 - accuracy: 0.3214 - val_loss: 1.1548 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8000 - accuracy: 0.3214 - val_loss: 1.1589 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7965 - accuracy: 0.3750 - val_loss: 1.1631 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7942 - accuracy: 0.3750 - val_loss: 1.1675 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7896 - accuracy: 0.4107 - val_loss: 1.1720 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7867 - accuracy: 0.3571 - val_loss: 1.1765 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 0.7828 - accuracy: 0.3393 - val_loss: 1.1810 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7872 - accuracy: 0.3393 - val_loss: 1.1854 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7789 - accuracy: 0.3571 - val_loss: 1.1899 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7781 - accuracy: 0.3571 - val_loss: 1.1947 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7807 - accuracy: 0.3750 - val_loss: 1.1992 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7745 - accuracy: 0.3750 - val_loss: 1.2038 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7701 - accuracy: 0.3571 - val_loss: 1.2082 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7675 - accuracy: 0.3929 - val_loss: 1.2126 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7666 - accuracy: 0.3393 - val_loss: 1.2169 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7603 - accuracy: 0.3750 - val_loss: 1.2210 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7526 - accuracy: 0.3571 - val_loss: 1.2249 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7610 - accuracy: 0.3393 - val_loss: 1.2285 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7575 - accuracy: 0.3929 - val_loss: 1.2319 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7478 - accuracy: 0.3571 - val_loss: 1.2351 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7472 - accuracy: 0.3571 - val_loss: 1.2382 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7456 - accuracy: 0.3571 - val_loss: 1.2412 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7402 - accuracy: 0.3571 - val_loss: 1.2442 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7402 - accuracy: 0.3929 - val_loss: 1.2471 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7461 - accuracy: 0.3571 - val_loss: 1.2497 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7340 - accuracy: 0.3929 - val_loss: 1.2522 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7263 - accuracy: 0.3750 - val_loss: 1.2547 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7233 - accuracy: 0.3571 - val_loss: 1.2573 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7220 - accuracy: 0.3929 - val_loss: 1.2602 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7309 - accuracy: 0.3571 - val_loss: 1.2626 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7239 - accuracy: 0.3929 - val_loss: 1.2651 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7146 - accuracy: 0.3750 - val_loss: 1.2678 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7148 - accuracy: 0.3571 - val_loss: 1.2703 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7116 - accuracy: 0.3750 - val_loss: 1.2725 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7127 - accuracy: 0.3571 - val_loss: 1.2745 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7058 - accuracy: 0.3929 - val_loss: 1.2761 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7015 - accuracy: 0.3929 - val_loss: 1.2779 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7042 - accuracy: 0.3750 - val_loss: 1.2793 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.6987 - accuracy: 0.3571 - val_loss: 1.2809 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6988 - accuracy: 0.3750 - val_loss: 1.2827 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2827 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=100, batch_size=300, Scores: [1.2826902866363525, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2826902866363525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9827 - accuracy: 0.1250 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.9807 - accuracy: 0.1071 - val_loss: 1.0713 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9795 - accuracy: 0.1250 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9781 - accuracy: 0.1429 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9733 - accuracy: 0.2143 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9718 - accuracy: 0.2143 - val_loss: 1.0727 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9699 - accuracy: 0.2143 - val_loss: 1.0731 - val_accuracy: 0.2143\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9693 - accuracy: 0.2500 - val_loss: 1.0735 - val_accuracy: 0.2143\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9656 - accuracy: 0.2321 - val_loss: 1.0739 - val_accuracy: 0.2143\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9654 - accuracy: 0.1786 - val_loss: 1.0744 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9629 - accuracy: 0.1964 - val_loss: 1.0748 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9597 - accuracy: 0.2321 - val_loss: 1.0752 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9577 - accuracy: 0.3036 - val_loss: 1.0756 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9555 - accuracy: 0.3036 - val_loss: 1.0760 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9544 - accuracy: 0.3214 - val_loss: 1.0764 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9513 - accuracy: 0.3036 - val_loss: 1.0768 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9483 - accuracy: 0.3036 - val_loss: 1.0772 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9459 - accuracy: 0.3036 - val_loss: 1.0776 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9435 - accuracy: 0.2857 - val_loss: 1.0780 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9420 - accuracy: 0.3393 - val_loss: 1.0784 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9378 - accuracy: 0.3393 - val_loss: 1.0788 - val_accuracy: 0.2857\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9362 - accuracy: 0.2857 - val_loss: 1.0792 - val_accuracy: 0.2857\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9334 - accuracy: 0.3036 - val_loss: 1.0796 - val_accuracy: 0.2857\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9310 - accuracy: 0.2679 - val_loss: 1.0801 - val_accuracy: 0.2857\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9266 - accuracy: 0.2857 - val_loss: 1.0805 - val_accuracy: 0.2857\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9227 - accuracy: 0.3214 - val_loss: 1.0809 - val_accuracy: 0.2857\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9201 - accuracy: 0.2857 - val_loss: 1.0813 - val_accuracy: 0.2857\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9182 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.2857\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9157 - accuracy: 0.3036 - val_loss: 1.0823 - val_accuracy: 0.2857\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9105 - accuracy: 0.3036 - val_loss: 1.0828 - val_accuracy: 0.2857\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9085 - accuracy: 0.3036 - val_loss: 1.0834 - val_accuracy: 0.2857\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9066 - accuracy: 0.2321 - val_loss: 1.0840 - val_accuracy: 0.2857\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9007 - accuracy: 0.3036 - val_loss: 1.0847 - val_accuracy: 0.2857\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8998 - accuracy: 0.2500 - val_loss: 1.0855 - val_accuracy: 0.2857\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.8926 - accuracy: 0.3036 - val_loss: 1.0863 - val_accuracy: 0.3571\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8904 - accuracy: 0.2679 - val_loss: 1.0873 - val_accuracy: 0.3571\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8875 - accuracy: 0.2857 - val_loss: 1.0883 - val_accuracy: 0.3571\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8829 - accuracy: 0.2679 - val_loss: 1.0894 - val_accuracy: 0.3571\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8796 - accuracy: 0.3393 - val_loss: 1.0907 - val_accuracy: 0.3571\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8773 - accuracy: 0.2500 - val_loss: 1.0921 - val_accuracy: 0.3571\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8737 - accuracy: 0.2679 - val_loss: 1.0935 - val_accuracy: 0.3571\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8689 - accuracy: 0.2857 - val_loss: 1.0951 - val_accuracy: 0.3571\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8704 - accuracy: 0.2500 - val_loss: 1.0968 - val_accuracy: 0.3571\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8648 - accuracy: 0.3393 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8606 - accuracy: 0.2857 - val_loss: 1.1006 - val_accuracy: 0.3571\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8540 - accuracy: 0.3036 - val_loss: 1.1026 - val_accuracy: 0.3571\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8532 - accuracy: 0.3036 - val_loss: 1.1047 - val_accuracy: 0.3571\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8446 - accuracy: 0.3036 - val_loss: 1.1069 - val_accuracy: 0.3571\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8468 - accuracy: 0.3036 - val_loss: 1.1092 - val_accuracy: 0.2857\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8427 - accuracy: 0.2857 - val_loss: 1.1115 - val_accuracy: 0.2857\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8397 - accuracy: 0.3036 - val_loss: 1.1140 - val_accuracy: 0.2857\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8378 - accuracy: 0.3214 - val_loss: 1.1166 - val_accuracy: 0.2857\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8370 - accuracy: 0.2857 - val_loss: 1.1193 - val_accuracy: 0.2857\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8337 - accuracy: 0.2679 - val_loss: 1.1220 - val_accuracy: 0.2857\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8273 - accuracy: 0.2857 - val_loss: 1.1249 - val_accuracy: 0.2857\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8227 - accuracy: 0.3214 - val_loss: 1.1278 - val_accuracy: 0.2857\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8230 - accuracy: 0.3036 - val_loss: 1.1309 - val_accuracy: 0.2143\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8202 - accuracy: 0.3036 - val_loss: 1.1341 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8110 - accuracy: 0.3036 - val_loss: 1.1374 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8084 - accuracy: 0.3036 - val_loss: 1.1409 - val_accuracy: 0.2143\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8116 - accuracy: 0.3036 - val_loss: 1.1445 - val_accuracy: 0.2143\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7995 - accuracy: 0.3393 - val_loss: 1.1483 - val_accuracy: 0.2143\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7999 - accuracy: 0.3036 - val_loss: 1.1522 - val_accuracy: 0.2143\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7997 - accuracy: 0.3036 - val_loss: 1.1561 - val_accuracy: 0.2143\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7985 - accuracy: 0.3036 - val_loss: 1.1600 - val_accuracy: 0.2143\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7939 - accuracy: 0.2857 - val_loss: 1.1638 - val_accuracy: 0.2143\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7925 - accuracy: 0.3393 - val_loss: 1.1675 - val_accuracy: 0.2143\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7883 - accuracy: 0.3214 - val_loss: 1.1710 - val_accuracy: 0.2143\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7801 - accuracy: 0.3036 - val_loss: 1.1744 - val_accuracy: 0.2143\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7810 - accuracy: 0.3393 - val_loss: 1.1779 - val_accuracy: 0.2143\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7792 - accuracy: 0.3214 - val_loss: 1.1811 - val_accuracy: 0.2143\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7775 - accuracy: 0.3036 - val_loss: 1.1842 - val_accuracy: 0.2143\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7711 - accuracy: 0.2857 - val_loss: 1.1872 - val_accuracy: 0.2143\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7714 - accuracy: 0.3036 - val_loss: 1.1900 - val_accuracy: 0.2143\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7669 - accuracy: 0.3393 - val_loss: 1.1926 - val_accuracy: 0.2143\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7550 - accuracy: 0.3214 - val_loss: 1.1951 - val_accuracy: 0.2143\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7615 - accuracy: 0.3036 - val_loss: 1.1977 - val_accuracy: 0.2143\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7551 - accuracy: 0.3393 - val_loss: 1.1998 - val_accuracy: 0.2143\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7580 - accuracy: 0.2857 - val_loss: 1.2016 - val_accuracy: 0.2143\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7480 - accuracy: 0.3571 - val_loss: 1.2028 - val_accuracy: 0.2143\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7515 - accuracy: 0.3750 - val_loss: 1.2043 - val_accuracy: 0.2143\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7417 - accuracy: 0.3393 - val_loss: 1.2053 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7420 - accuracy: 0.3393 - val_loss: 1.2060 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7372 - accuracy: 0.3571 - val_loss: 1.2066 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7326 - accuracy: 0.3214 - val_loss: 1.2074 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7368 - accuracy: 0.3393 - val_loss: 1.2085 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7268 - accuracy: 0.3393 - val_loss: 1.2096 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7339 - accuracy: 0.3571 - val_loss: 1.2106 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7251 - accuracy: 0.3393 - val_loss: 1.2120 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7208 - accuracy: 0.2679 - val_loss: 1.2133 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7145 - accuracy: 0.3571 - val_loss: 1.2144 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7099 - accuracy: 0.3214 - val_loss: 1.2156 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7121 - accuracy: 0.3214 - val_loss: 1.2168 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7042 - accuracy: 0.3750 - val_loss: 1.2180 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7014 - accuracy: 0.3393 - val_loss: 1.2189 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7057 - accuracy: 0.3750 - val_loss: 1.2195 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7030 - accuracy: 0.3571 - val_loss: 1.2207 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6999 - accuracy: 0.3571 - val_loss: 1.2221 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6909 - accuracy: 0.3393 - val_loss: 1.2235 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.6951 - accuracy: 0.3214 - val_loss: 1.2252 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2252 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=100, batch_size=400, Scores: [1.2252142429351807, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2252142429351807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9829 - accuracy: 0.1250 - val_loss: 1.0693 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9802 - accuracy: 0.1964 - val_loss: 1.0696 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9777 - accuracy: 0.1964 - val_loss: 1.0700 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9759 - accuracy: 0.2143 - val_loss: 1.0704 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9741 - accuracy: 0.1607 - val_loss: 1.0708 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9706 - accuracy: 0.1786 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9684 - accuracy: 0.1964 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9663 - accuracy: 0.2679 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9663 - accuracy: 0.2679 - val_loss: 1.0724 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9646 - accuracy: 0.2857 - val_loss: 1.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9609 - accuracy: 0.3214 - val_loss: 1.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9607 - accuracy: 0.2500 - val_loss: 1.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9572 - accuracy: 0.3036 - val_loss: 1.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9554 - accuracy: 0.2679 - val_loss: 1.0743 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9534 - accuracy: 0.2321 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.9501 - accuracy: 0.3036 - val_loss: 1.0752 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9515 - accuracy: 0.2500 - val_loss: 1.0756 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9434 - accuracy: 0.3036 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9422 - accuracy: 0.2321 - val_loss: 1.0765 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9380 - accuracy: 0.2857 - val_loss: 1.0769 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9391 - accuracy: 0.3214 - val_loss: 1.0774 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9369 - accuracy: 0.3571 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9303 - accuracy: 0.3214 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.9296 - accuracy: 0.3571 - val_loss: 1.0789 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9273 - accuracy: 0.2679 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9231 - accuracy: 0.3393 - val_loss: 1.0801 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9211 - accuracy: 0.3214 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9156 - accuracy: 0.3571 - val_loss: 1.0814 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9171 - accuracy: 0.3393 - val_loss: 1.0821 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9080 - accuracy: 0.3393 - val_loss: 1.0829 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9105 - accuracy: 0.3571 - val_loss: 1.0837 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9067 - accuracy: 0.3393 - val_loss: 1.0847 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9021 - accuracy: 0.3214 - val_loss: 1.0857 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8989 - accuracy: 0.3393 - val_loss: 1.0868 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8979 - accuracy: 0.3393 - val_loss: 1.0880 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8897 - accuracy: 0.3214 - val_loss: 1.0892 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8867 - accuracy: 0.3036 - val_loss: 1.0906 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8867 - accuracy: 0.3571 - val_loss: 1.0921 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8779 - accuracy: 0.3571 - val_loss: 1.0937 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8793 - accuracy: 0.3036 - val_loss: 1.0953 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8724 - accuracy: 0.3929 - val_loss: 1.0971 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8745 - accuracy: 0.3393 - val_loss: 1.0990 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8681 - accuracy: 0.3036 - val_loss: 1.1010 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8655 - accuracy: 0.3214 - val_loss: 1.1032 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8677 - accuracy: 0.3214 - val_loss: 1.1055 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8552 - accuracy: 0.3750 - val_loss: 1.1078 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8543 - accuracy: 0.3036 - val_loss: 1.1103 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8510 - accuracy: 0.3214 - val_loss: 1.1127 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8476 - accuracy: 0.3571 - val_loss: 1.1152 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8430 - accuracy: 0.3571 - val_loss: 1.1177 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8433 - accuracy: 0.3393 - val_loss: 1.1202 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8402 - accuracy: 0.3571 - val_loss: 1.1228 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8305 - accuracy: 0.3750 - val_loss: 1.1255 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8269 - accuracy: 0.3750 - val_loss: 1.1282 - val_accuracy: 0.2143\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8245 - accuracy: 0.3750 - val_loss: 1.1311 - val_accuracy: 0.2143\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8251 - accuracy: 0.3750 - val_loss: 1.1339 - val_accuracy: 0.2143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8164 - accuracy: 0.3750 - val_loss: 1.1370 - val_accuracy: 0.2143\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8197 - accuracy: 0.3571 - val_loss: 1.1402 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8134 - accuracy: 0.3571 - val_loss: 1.1437 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8093 - accuracy: 0.3750 - val_loss: 1.1473 - val_accuracy: 0.2143\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8031 - accuracy: 0.3929 - val_loss: 1.1511 - val_accuracy: 0.2143\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7936 - accuracy: 0.3571 - val_loss: 1.1550 - val_accuracy: 0.2143\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7911 - accuracy: 0.3750 - val_loss: 1.1591 - val_accuracy: 0.2143\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7940 - accuracy: 0.3571 - val_loss: 1.1634 - val_accuracy: 0.2143\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7955 - accuracy: 0.3393 - val_loss: 1.1677 - val_accuracy: 0.2143\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7879 - accuracy: 0.3571 - val_loss: 1.1721 - val_accuracy: 0.2143\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7734 - accuracy: 0.3393 - val_loss: 1.1769 - val_accuracy: 0.2143\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7774 - accuracy: 0.3214 - val_loss: 1.1819 - val_accuracy: 0.2143\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7751 - accuracy: 0.3750 - val_loss: 1.1870 - val_accuracy: 0.2143\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7742 - accuracy: 0.3393 - val_loss: 1.1919 - val_accuracy: 0.2143\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7768 - accuracy: 0.3393 - val_loss: 1.1968 - val_accuracy: 0.2143\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7656 - accuracy: 0.3214 - val_loss: 1.2014 - val_accuracy: 0.2143\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7653 - accuracy: 0.3393 - val_loss: 1.2060 - val_accuracy: 0.2143\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7592 - accuracy: 0.3214 - val_loss: 1.2106 - val_accuracy: 0.2143\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7589 - accuracy: 0.3214 - val_loss: 1.2151 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7422 - accuracy: 0.3571 - val_loss: 1.2194 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7547 - accuracy: 0.3214 - val_loss: 1.2233 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7467 - accuracy: 0.3214 - val_loss: 1.2272 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7463 - accuracy: 0.3393 - val_loss: 1.2307 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7454 - accuracy: 0.3393 - val_loss: 1.2343 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7384 - accuracy: 0.3214 - val_loss: 1.2376 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7384 - accuracy: 0.3393 - val_loss: 1.2408 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7396 - accuracy: 0.3214 - val_loss: 1.2440 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7360 - accuracy: 0.3214 - val_loss: 1.2469 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7336 - accuracy: 0.3393 - val_loss: 1.2492 - val_accuracy: 0.2143\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7260 - accuracy: 0.3214 - val_loss: 1.2511 - val_accuracy: 0.2143\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7154 - accuracy: 0.3214 - val_loss: 1.2533 - val_accuracy: 0.2143\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7263 - accuracy: 0.3214 - val_loss: 1.2553 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7120 - accuracy: 0.3393 - val_loss: 1.2575 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7088 - accuracy: 0.3036 - val_loss: 1.2598 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7127 - accuracy: 0.3036 - val_loss: 1.2618 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7091 - accuracy: 0.3214 - val_loss: 1.2642 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6989 - accuracy: 0.3214 - val_loss: 1.2671 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6911 - accuracy: 0.3750 - val_loss: 1.2701 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6999 - accuracy: 0.3750 - val_loss: 1.2731 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7008 - accuracy: 0.3393 - val_loss: 1.2760 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6957 - accuracy: 0.3214 - val_loss: 1.2790 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6971 - accuracy: 0.3036 - val_loss: 1.2818 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.6820 - accuracy: 0.3214 - val_loss: 1.2842 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6871 - accuracy: 0.3214 - val_loss: 1.2866 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2866 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=100, batch_size=500, Scores: [1.2866038084030151, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2866038084030151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9847 - accuracy: 0.0536 - val_loss: 1.0698 - val_accuracy: 0.2143\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9831 - accuracy: 0.0714 - val_loss: 1.0703 - val_accuracy: 0.2143\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9805 - accuracy: 0.1071 - val_loss: 1.0708 - val_accuracy: 0.2143\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9805 - accuracy: 0.1786 - val_loss: 1.0713 - val_accuracy: 0.1429\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9764 - accuracy: 0.1429 - val_loss: 1.0718 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9746 - accuracy: 0.1607 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9729 - accuracy: 0.2143 - val_loss: 1.0728 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9698 - accuracy: 0.2500 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9671 - accuracy: 0.2679 - val_loss: 1.0739 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9665 - accuracy: 0.1964 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9659 - accuracy: 0.2500 - val_loss: 1.0750 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9619 - accuracy: 0.2143 - val_loss: 1.0756 - val_accuracy: 0.1429\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9607 - accuracy: 0.2679 - val_loss: 1.0762 - val_accuracy: 0.1429\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9577 - accuracy: 0.2500 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9575 - accuracy: 0.2679 - val_loss: 1.0774 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9521 - accuracy: 0.2679 - val_loss: 1.0780 - val_accuracy: 0.2143\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9522 - accuracy: 0.3393 - val_loss: 1.0787 - val_accuracy: 0.2143\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9504 - accuracy: 0.3214 - val_loss: 1.0794 - val_accuracy: 0.2143\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9496 - accuracy: 0.3036 - val_loss: 1.0800 - val_accuracy: 0.2143\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9452 - accuracy: 0.3214 - val_loss: 1.0807 - val_accuracy: 0.2143\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9421 - accuracy: 0.3036 - val_loss: 1.0815 - val_accuracy: 0.2143\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9388 - accuracy: 0.3036 - val_loss: 1.0822 - val_accuracy: 0.2143\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9377 - accuracy: 0.3214 - val_loss: 1.0830 - val_accuracy: 0.2143\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9340 - accuracy: 0.3036 - val_loss: 1.0837 - val_accuracy: 0.2143\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9330 - accuracy: 0.2679 - val_loss: 1.0845 - val_accuracy: 0.2143\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9302 - accuracy: 0.2857 - val_loss: 1.0854 - val_accuracy: 0.2143\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9259 - accuracy: 0.2679 - val_loss: 1.0862 - val_accuracy: 0.2143\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9255 - accuracy: 0.3036 - val_loss: 1.0872 - val_accuracy: 0.2143\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9221 - accuracy: 0.2321 - val_loss: 1.0881 - val_accuracy: 0.2143\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9190 - accuracy: 0.3214 - val_loss: 1.0891 - val_accuracy: 0.2143\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9147 - accuracy: 0.2679 - val_loss: 1.0902 - val_accuracy: 0.2143\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9149 - accuracy: 0.2679 - val_loss: 1.0913 - val_accuracy: 0.2143\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9096 - accuracy: 0.2321 - val_loss: 1.0924 - val_accuracy: 0.2143\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9059 - accuracy: 0.2679 - val_loss: 1.0936 - val_accuracy: 0.2143\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9003 - accuracy: 0.3393 - val_loss: 1.0949 - val_accuracy: 0.2143\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8970 - accuracy: 0.2679 - val_loss: 1.0963 - val_accuracy: 0.2143\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8927 - accuracy: 0.3036 - val_loss: 1.0977 - val_accuracy: 0.2143\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8922 - accuracy: 0.2857 - val_loss: 1.0993 - val_accuracy: 0.2143\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8886 - accuracy: 0.2857 - val_loss: 1.1009 - val_accuracy: 0.2143\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8826 - accuracy: 0.3393 - val_loss: 1.1025 - val_accuracy: 0.2143\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8775 - accuracy: 0.3036 - val_loss: 1.1043 - val_accuracy: 0.2143\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8740 - accuracy: 0.3393 - val_loss: 1.1061 - val_accuracy: 0.2143\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8725 - accuracy: 0.2857 - val_loss: 1.1081 - val_accuracy: 0.2143\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8649 - accuracy: 0.3393 - val_loss: 1.1101 - val_accuracy: 0.2143\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8618 - accuracy: 0.2857 - val_loss: 1.1123 - val_accuracy: 0.2143\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8614 - accuracy: 0.3036 - val_loss: 1.1146 - val_accuracy: 0.2143\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8554 - accuracy: 0.3214 - val_loss: 1.1170 - val_accuracy: 0.2143\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8468 - accuracy: 0.3571 - val_loss: 1.1196 - val_accuracy: 0.2143\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8450 - accuracy: 0.3214 - val_loss: 1.1222 - val_accuracy: 0.2143\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8415 - accuracy: 0.2679 - val_loss: 1.1249 - val_accuracy: 0.2143\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8362 - accuracy: 0.2857 - val_loss: 1.1277 - val_accuracy: 0.2143\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8307 - accuracy: 0.3571 - val_loss: 1.1305 - val_accuracy: 0.2143\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8341 - accuracy: 0.3214 - val_loss: 1.1333 - val_accuracy: 0.2143\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8278 - accuracy: 0.3393 - val_loss: 1.1360 - val_accuracy: 0.2143\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8189 - accuracy: 0.3214 - val_loss: 1.1389 - val_accuracy: 0.2143\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8171 - accuracy: 0.3571 - val_loss: 1.1418 - val_accuracy: 0.2143\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8121 - accuracy: 0.3214 - val_loss: 1.1447 - val_accuracy: 0.2143\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8104 - accuracy: 0.3214 - val_loss: 1.1476 - val_accuracy: 0.2143\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8049 - accuracy: 0.3214 - val_loss: 1.1504 - val_accuracy: 0.2143\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8019 - accuracy: 0.3750 - val_loss: 1.1533 - val_accuracy: 0.2143\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7984 - accuracy: 0.3750 - val_loss: 1.1564 - val_accuracy: 0.2143\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7953 - accuracy: 0.3750 - val_loss: 1.1595 - val_accuracy: 0.2143\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7940 - accuracy: 0.3571 - val_loss: 1.1627 - val_accuracy: 0.2143\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7916 - accuracy: 0.4107 - val_loss: 1.1660 - val_accuracy: 0.2143\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7870 - accuracy: 0.3929 - val_loss: 1.1695 - val_accuracy: 0.2143\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7834 - accuracy: 0.3929 - val_loss: 1.1732 - val_accuracy: 0.2143\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7789 - accuracy: 0.4107 - val_loss: 1.1770 - val_accuracy: 0.2143\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7730 - accuracy: 0.3750 - val_loss: 1.1811 - val_accuracy: 0.2143\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7704 - accuracy: 0.3214 - val_loss: 1.1852 - val_accuracy: 0.2143\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7665 - accuracy: 0.3929 - val_loss: 1.1895 - val_accuracy: 0.2143\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7644 - accuracy: 0.3393 - val_loss: 1.1937 - val_accuracy: 0.2143\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7522 - accuracy: 0.3750 - val_loss: 1.1980 - val_accuracy: 0.2143\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7582 - accuracy: 0.3571 - val_loss: 1.2026 - val_accuracy: 0.2143\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7500 - accuracy: 0.3750 - val_loss: 1.2071 - val_accuracy: 0.2143\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7563 - accuracy: 0.3393 - val_loss: 1.2114 - val_accuracy: 0.2143\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7471 - accuracy: 0.3750 - val_loss: 1.2157 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7398 - accuracy: 0.3750 - val_loss: 1.2197 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7444 - accuracy: 0.3750 - val_loss: 1.2236 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7454 - accuracy: 0.3571 - val_loss: 1.2274 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7453 - accuracy: 0.3393 - val_loss: 1.2308 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7325 - accuracy: 0.3214 - val_loss: 1.2340 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7368 - accuracy: 0.3393 - val_loss: 1.2370 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7339 - accuracy: 0.3393 - val_loss: 1.2398 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7350 - accuracy: 0.3214 - val_loss: 1.2420 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7188 - accuracy: 0.3214 - val_loss: 1.2438 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7270 - accuracy: 0.3393 - val_loss: 1.2450 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7203 - accuracy: 0.3571 - val_loss: 1.2460 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7185 - accuracy: 0.4107 - val_loss: 1.2474 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7175 - accuracy: 0.3214 - val_loss: 1.2488 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7110 - accuracy: 0.3036 - val_loss: 1.2505 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7074 - accuracy: 0.3393 - val_loss: 1.2522 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7038 - accuracy: 0.3929 - val_loss: 1.2538 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7047 - accuracy: 0.3393 - val_loss: 1.2557 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6979 - accuracy: 0.4286 - val_loss: 1.2576 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6979 - accuracy: 0.3929 - val_loss: 1.2605 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7026 - accuracy: 0.3929 - val_loss: 1.2631 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6931 - accuracy: 0.4107 - val_loss: 1.2660 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6967 - accuracy: 0.3929 - val_loss: 1.2688 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6875 - accuracy: 0.3750 - val_loss: 1.2715 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6856 - accuracy: 0.3571 - val_loss: 1.2741 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6906 - accuracy: 0.3929 - val_loss: 1.2762 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6837 - accuracy: 0.4107 - val_loss: 1.2784 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6867 - accuracy: 0.4464 - val_loss: 1.2807 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6805 - accuracy: 0.4107 - val_loss: 1.2823 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6739 - accuracy: 0.3929 - val_loss: 1.2845 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6777 - accuracy: 0.4286 - val_loss: 1.2870 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6822 - accuracy: 0.4464 - val_loss: 1.2895 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6760 - accuracy: 0.4286 - val_loss: 1.2921 - val_accuracy: 0.1429\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6610 - accuracy: 0.3929 - val_loss: 1.2949 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6575 - accuracy: 0.4464 - val_loss: 1.2976 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6573 - accuracy: 0.4107 - val_loss: 1.3004 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.6546 - accuracy: 0.4286 - val_loss: 1.3029 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6480 - accuracy: 0.4107 - val_loss: 1.3057 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.6477 - accuracy: 0.4286 - val_loss: 1.3091 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6573 - accuracy: 0.4286 - val_loss: 1.3128 - val_accuracy: 0.1429\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6454 - accuracy: 0.3929 - val_loss: 1.3160 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6378 - accuracy: 0.4286 - val_loss: 1.3189 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6419 - accuracy: 0.4107 - val_loss: 1.3208 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6359 - accuracy: 0.4286 - val_loss: 1.3229 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6287 - accuracy: 0.4643 - val_loss: 1.3254 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6268 - accuracy: 0.4643 - val_loss: 1.3276 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6284 - accuracy: 0.4107 - val_loss: 1.3297 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.6294 - accuracy: 0.4464 - val_loss: 1.3322 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6312 - accuracy: 0.4286 - val_loss: 1.3345 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6141 - accuracy: 0.4643 - val_loss: 1.3375 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6075 - accuracy: 0.5000 - val_loss: 1.3408 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6308 - accuracy: 0.4464 - val_loss: 1.3452 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6079 - accuracy: 0.4107 - val_loss: 1.3496 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3496 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=128, batch_size=100, Scores: [1.3496216535568237, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.3496216535568237\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9848 - accuracy: 0.0893 - val_loss: 1.0722 - val_accuracy: 0.2143\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9832 - accuracy: 0.1250 - val_loss: 1.0725 - val_accuracy: 0.2143\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9809 - accuracy: 0.1429 - val_loss: 1.0728 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9806 - accuracy: 0.1786 - val_loss: 1.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9781 - accuracy: 0.1250 - val_loss: 1.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9764 - accuracy: 0.1607 - val_loss: 1.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9731 - accuracy: 0.2321 - val_loss: 1.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9722 - accuracy: 0.1964 - val_loss: 1.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9698 - accuracy: 0.2143 - val_loss: 1.0747 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9661 - accuracy: 0.2500 - val_loss: 1.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9651 - accuracy: 0.1964 - val_loss: 1.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9629 - accuracy: 0.2321 - val_loss: 1.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9609 - accuracy: 0.2321 - val_loss: 1.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9596 - accuracy: 0.1786 - val_loss: 1.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9550 - accuracy: 0.2500 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9556 - accuracy: 0.2321 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9521 - accuracy: 0.2321 - val_loss: 1.0774 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9516 - accuracy: 0.2857 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9494 - accuracy: 0.2857 - val_loss: 1.0780 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9471 - accuracy: 0.3214 - val_loss: 1.0783 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9433 - accuracy: 0.2679 - val_loss: 1.0785 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9389 - accuracy: 0.2679 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9401 - accuracy: 0.3571 - val_loss: 1.0790 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9364 - accuracy: 0.2679 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9337 - accuracy: 0.3214 - val_loss: 1.0793 - val_accuracy: 0.0714\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9306 - accuracy: 0.2679 - val_loss: 1.0795 - val_accuracy: 0.0714\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9295 - accuracy: 0.2321 - val_loss: 1.0796 - val_accuracy: 0.0714\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9256 - accuracy: 0.3393 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9208 - accuracy: 0.3036 - val_loss: 1.0798 - val_accuracy: 0.0714\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9187 - accuracy: 0.3036 - val_loss: 1.0799 - val_accuracy: 0.0714\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9150 - accuracy: 0.3214 - val_loss: 1.0799 - val_accuracy: 0.0714\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9126 - accuracy: 0.2679 - val_loss: 1.0800 - val_accuracy: 0.0714\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9086 - accuracy: 0.3214 - val_loss: 1.0800 - val_accuracy: 0.0714\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9061 - accuracy: 0.2857 - val_loss: 1.0801 - val_accuracy: 0.0714\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9003 - accuracy: 0.3571 - val_loss: 1.0802 - val_accuracy: 0.0714\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8976 - accuracy: 0.2857 - val_loss: 1.0802 - val_accuracy: 0.0714\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8937 - accuracy: 0.2857 - val_loss: 1.0803 - val_accuracy: 0.0714\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8943 - accuracy: 0.3571 - val_loss: 1.0804 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8890 - accuracy: 0.3036 - val_loss: 1.0806 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8805 - accuracy: 0.2679 - val_loss: 1.0809 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8781 - accuracy: 0.3214 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8779 - accuracy: 0.3214 - val_loss: 1.0815 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8714 - accuracy: 0.3929 - val_loss: 1.0820 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8653 - accuracy: 0.2857 - val_loss: 1.0825 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8642 - accuracy: 0.3393 - val_loss: 1.0832 - val_accuracy: 0.0714\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8599 - accuracy: 0.3393 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8544 - accuracy: 0.3393 - val_loss: 1.0851 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8490 - accuracy: 0.3571 - val_loss: 1.0863 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8423 - accuracy: 0.3571 - val_loss: 1.0876 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8401 - accuracy: 0.3571 - val_loss: 1.0891 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8410 - accuracy: 0.3393 - val_loss: 1.0908 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8395 - accuracy: 0.3214 - val_loss: 1.0925 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8363 - accuracy: 0.3036 - val_loss: 1.0943 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8307 - accuracy: 0.3571 - val_loss: 1.0964 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8278 - accuracy: 0.3393 - val_loss: 1.0987 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8253 - accuracy: 0.3393 - val_loss: 1.1012 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8181 - accuracy: 0.3214 - val_loss: 1.1039 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8129 - accuracy: 0.3750 - val_loss: 1.1066 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8097 - accuracy: 0.4107 - val_loss: 1.1097 - val_accuracy: 0.0714\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8072 - accuracy: 0.3214 - val_loss: 1.1130 - val_accuracy: 0.0714\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8024 - accuracy: 0.3571 - val_loss: 1.1166 - val_accuracy: 0.0714\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8024 - accuracy: 0.3214 - val_loss: 1.1204 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7962 - accuracy: 0.3393 - val_loss: 1.1246 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7950 - accuracy: 0.3393 - val_loss: 1.1290 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7896 - accuracy: 0.3214 - val_loss: 1.1337 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7912 - accuracy: 0.3214 - val_loss: 1.1385 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7844 - accuracy: 0.3929 - val_loss: 1.1435 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7845 - accuracy: 0.3036 - val_loss: 1.1486 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7835 - accuracy: 0.3036 - val_loss: 1.1539 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7770 - accuracy: 0.3214 - val_loss: 1.1593 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7680 - accuracy: 0.3214 - val_loss: 1.1645 - val_accuracy: 0.0714\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7709 - accuracy: 0.3214 - val_loss: 1.1699 - val_accuracy: 0.0714\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7647 - accuracy: 0.3750 - val_loss: 1.1751 - val_accuracy: 0.0714\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7613 - accuracy: 0.3214 - val_loss: 1.1802 - val_accuracy: 0.0714\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7566 - accuracy: 0.4107 - val_loss: 1.1852 - val_accuracy: 0.0714\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7574 - accuracy: 0.3571 - val_loss: 1.1900 - val_accuracy: 0.0714\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7589 - accuracy: 0.3036 - val_loss: 1.1944 - val_accuracy: 0.0714\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7542 - accuracy: 0.3214 - val_loss: 1.1981 - val_accuracy: 0.0714\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7523 - accuracy: 0.3571 - val_loss: 1.2014 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7457 - accuracy: 0.3214 - val_loss: 1.2044 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7457 - accuracy: 0.3214 - val_loss: 1.2071 - val_accuracy: 0.0714\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7376 - accuracy: 0.3393 - val_loss: 1.2096 - val_accuracy: 0.0714\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7432 - accuracy: 0.3214 - val_loss: 1.2120 - val_accuracy: 0.0714\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7354 - accuracy: 0.3750 - val_loss: 1.2142 - val_accuracy: 0.0714\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7256 - accuracy: 0.3393 - val_loss: 1.2162 - val_accuracy: 0.0714\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7295 - accuracy: 0.3214 - val_loss: 1.2180 - val_accuracy: 0.0714\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7313 - accuracy: 0.3571 - val_loss: 1.2197 - val_accuracy: 0.0714\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7289 - accuracy: 0.3214 - val_loss: 1.2214 - val_accuracy: 0.0714\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7239 - accuracy: 0.3571 - val_loss: 1.2231 - val_accuracy: 0.0714\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7204 - accuracy: 0.3393 - val_loss: 1.2245 - val_accuracy: 0.0714\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7237 - accuracy: 0.3214 - val_loss: 1.2255 - val_accuracy: 0.0714\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7131 - accuracy: 0.3750 - val_loss: 1.2263 - val_accuracy: 0.0714\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7128 - accuracy: 0.3571 - val_loss: 1.2273 - val_accuracy: 0.0714\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7119 - accuracy: 0.3393 - val_loss: 1.2284 - val_accuracy: 0.0714\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7076 - accuracy: 0.3750 - val_loss: 1.2295 - val_accuracy: 0.0714\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7046 - accuracy: 0.3571 - val_loss: 1.2309 - val_accuracy: 0.0714\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7017 - accuracy: 0.3750 - val_loss: 1.2320 - val_accuracy: 0.0714\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6932 - accuracy: 0.3929 - val_loss: 1.2331 - val_accuracy: 0.0714\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6910 - accuracy: 0.3571 - val_loss: 1.2345 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6936 - accuracy: 0.3393 - val_loss: 1.2362 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6931 - accuracy: 0.3393 - val_loss: 1.2381 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6951 - accuracy: 0.3393 - val_loss: 1.2402 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6736 - accuracy: 0.3750 - val_loss: 1.2424 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6761 - accuracy: 0.3750 - val_loss: 1.2447 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6822 - accuracy: 0.3571 - val_loss: 1.2474 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 0.6757 - accuracy: 0.3929 - val_loss: 1.2504 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6735 - accuracy: 0.3393 - val_loss: 1.2537 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6616 - accuracy: 0.3571 - val_loss: 1.2572 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6648 - accuracy: 0.3750 - val_loss: 1.2606 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6674 - accuracy: 0.3393 - val_loss: 1.2644 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6590 - accuracy: 0.3393 - val_loss: 1.2680 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6579 - accuracy: 0.3393 - val_loss: 1.2718 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6522 - accuracy: 0.3929 - val_loss: 1.2755 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6456 - accuracy: 0.3750 - val_loss: 1.2796 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6436 - accuracy: 0.3929 - val_loss: 1.2834 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6482 - accuracy: 0.3929 - val_loss: 1.2870 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6404 - accuracy: 0.4107 - val_loss: 1.2908 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6341 - accuracy: 0.3929 - val_loss: 1.2953 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6404 - accuracy: 0.3750 - val_loss: 1.2996 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6284 - accuracy: 0.4107 - val_loss: 1.3042 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6304 - accuracy: 0.4107 - val_loss: 1.3093 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6214 - accuracy: 0.4107 - val_loss: 1.3149 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6140 - accuracy: 0.4107 - val_loss: 1.3210 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6091 - accuracy: 0.4107 - val_loss: 1.3270 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6147 - accuracy: 0.3571 - val_loss: 1.3325 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6087 - accuracy: 0.3929 - val_loss: 1.3387 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6020 - accuracy: 0.3750 - val_loss: 1.3447 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6058 - accuracy: 0.4286 - val_loss: 1.3494 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3494 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=128, batch_size=300, Scores: [1.3493843078613281, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.3493843078613281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9840 - accuracy: 0.1429 - val_loss: 1.0700 - val_accuracy: 0.2857\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9825 - accuracy: 0.2143 - val_loss: 1.0708 - val_accuracy: 0.3571\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9803 - accuracy: 0.1250 - val_loss: 1.0716 - val_accuracy: 0.3571\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9771 - accuracy: 0.1964 - val_loss: 1.0724 - val_accuracy: 0.2143\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9744 - accuracy: 0.1964 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9728 - accuracy: 0.2500 - val_loss: 1.0740 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9691 - accuracy: 0.2500 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9680 - accuracy: 0.1786 - val_loss: 1.0757 - val_accuracy: 0.1429\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9670 - accuracy: 0.2679 - val_loss: 1.0766 - val_accuracy: 0.1429\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9642 - accuracy: 0.2679 - val_loss: 1.0775 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9599 - accuracy: 0.2500 - val_loss: 1.0784 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9591 - accuracy: 0.2500 - val_loss: 1.0794 - val_accuracy: 0.1429\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9569 - accuracy: 0.2679 - val_loss: 1.0803 - val_accuracy: 0.1429\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9558 - accuracy: 0.2679 - val_loss: 1.0813 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9531 - accuracy: 0.3036 - val_loss: 1.0823 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9518 - accuracy: 0.2679 - val_loss: 1.0834 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9473 - accuracy: 0.2321 - val_loss: 1.0844 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9483 - accuracy: 0.2679 - val_loss: 1.0856 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9429 - accuracy: 0.2857 - val_loss: 1.0868 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9428 - accuracy: 0.2679 - val_loss: 1.0880 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9385 - accuracy: 0.2857 - val_loss: 1.0893 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9358 - accuracy: 0.2500 - val_loss: 1.0907 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9329 - accuracy: 0.3036 - val_loss: 1.0921 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9316 - accuracy: 0.2500 - val_loss: 1.0936 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9284 - accuracy: 0.2857 - val_loss: 1.0952 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9229 - accuracy: 0.3214 - val_loss: 1.0969 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9222 - accuracy: 0.2679 - val_loss: 1.0986 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9236 - accuracy: 0.3036 - val_loss: 1.1005 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9185 - accuracy: 0.2857 - val_loss: 1.1024 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9165 - accuracy: 0.2857 - val_loss: 1.1044 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9123 - accuracy: 0.2857 - val_loss: 1.1066 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9086 - accuracy: 0.2857 - val_loss: 1.1088 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9068 - accuracy: 0.2857 - val_loss: 1.1111 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9034 - accuracy: 0.2679 - val_loss: 1.1134 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9022 - accuracy: 0.2500 - val_loss: 1.1158 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8988 - accuracy: 0.2857 - val_loss: 1.1183 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8957 - accuracy: 0.2679 - val_loss: 1.1208 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8908 - accuracy: 0.3036 - val_loss: 1.1232 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8895 - accuracy: 0.2857 - val_loss: 1.1255 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8852 - accuracy: 0.2857 - val_loss: 1.1277 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8869 - accuracy: 0.2679 - val_loss: 1.1297 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8765 - accuracy: 0.3036 - val_loss: 1.1316 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8792 - accuracy: 0.2857 - val_loss: 1.1332 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.8759 - accuracy: 0.3036 - val_loss: 1.1346 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8723 - accuracy: 0.2857 - val_loss: 1.1356 - val_accuracy: 0.0714\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8712 - accuracy: 0.2679 - val_loss: 1.1365 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8614 - accuracy: 0.2857 - val_loss: 1.1372 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8637 - accuracy: 0.3214 - val_loss: 1.1380 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8592 - accuracy: 0.3036 - val_loss: 1.1387 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8586 - accuracy: 0.3036 - val_loss: 1.1393 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8523 - accuracy: 0.3036 - val_loss: 1.1401 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8441 - accuracy: 0.3571 - val_loss: 1.1409 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8480 - accuracy: 0.3214 - val_loss: 1.1419 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8395 - accuracy: 0.2857 - val_loss: 1.1430 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8348 - accuracy: 0.3036 - val_loss: 1.1442 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8312 - accuracy: 0.3214 - val_loss: 1.1457 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8310 - accuracy: 0.3036 - val_loss: 1.1474 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8251 - accuracy: 0.3571 - val_loss: 1.1493 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8208 - accuracy: 0.3214 - val_loss: 1.1515 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8227 - accuracy: 0.3214 - val_loss: 1.1538 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8145 - accuracy: 0.3214 - val_loss: 1.1564 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8100 - accuracy: 0.3036 - val_loss: 1.1591 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8095 - accuracy: 0.3036 - val_loss: 1.1620 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8051 - accuracy: 0.3036 - val_loss: 1.1649 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8041 - accuracy: 0.3214 - val_loss: 1.1680 - val_accuracy: 0.2143\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7997 - accuracy: 0.2857 - val_loss: 1.1714 - val_accuracy: 0.2143\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7922 - accuracy: 0.3036 - val_loss: 1.1749 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7958 - accuracy: 0.3214 - val_loss: 1.1785 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7842 - accuracy: 0.3571 - val_loss: 1.1823 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7830 - accuracy: 0.3571 - val_loss: 1.1862 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7831 - accuracy: 0.3214 - val_loss: 1.1902 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7825 - accuracy: 0.3036 - val_loss: 1.1941 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7773 - accuracy: 0.3214 - val_loss: 1.1983 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7694 - accuracy: 0.3571 - val_loss: 1.2020 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7697 - accuracy: 0.3036 - val_loss: 1.2057 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7693 - accuracy: 0.3393 - val_loss: 1.2089 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7623 - accuracy: 0.3393 - val_loss: 1.2118 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7600 - accuracy: 0.3036 - val_loss: 1.2146 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7546 - accuracy: 0.3393 - val_loss: 1.2172 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7541 - accuracy: 0.3214 - val_loss: 1.2195 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7467 - accuracy: 0.3214 - val_loss: 1.2217 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7459 - accuracy: 0.3214 - val_loss: 1.2237 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7449 - accuracy: 0.3214 - val_loss: 1.2262 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7440 - accuracy: 0.3571 - val_loss: 1.2280 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7407 - accuracy: 0.3214 - val_loss: 1.2292 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7315 - accuracy: 0.3214 - val_loss: 1.2304 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7307 - accuracy: 0.3750 - val_loss: 1.2318 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7320 - accuracy: 0.3214 - val_loss: 1.2334 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7263 - accuracy: 0.3393 - val_loss: 1.2355 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7237 - accuracy: 0.3036 - val_loss: 1.2370 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7320 - accuracy: 0.3036 - val_loss: 1.2390 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7126 - accuracy: 0.3393 - val_loss: 1.2413 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7160 - accuracy: 0.3750 - val_loss: 1.2429 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7166 - accuracy: 0.3750 - val_loss: 1.2438 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7132 - accuracy: 0.3393 - val_loss: 1.2453 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7104 - accuracy: 0.3214 - val_loss: 1.2463 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7073 - accuracy: 0.3571 - val_loss: 1.2463 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6978 - accuracy: 0.3571 - val_loss: 1.2460 - val_accuracy: 0.0714\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6963 - accuracy: 0.3393 - val_loss: 1.2459 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7015 - accuracy: 0.3393 - val_loss: 1.2450 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6948 - accuracy: 0.3036 - val_loss: 1.2440 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6936 - accuracy: 0.3393 - val_loss: 1.2446 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6840 - accuracy: 0.3214 - val_loss: 1.2459 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6949 - accuracy: 0.3393 - val_loss: 1.2469 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6776 - accuracy: 0.3571 - val_loss: 1.2483 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6821 - accuracy: 0.3214 - val_loss: 1.2499 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6804 - accuracy: 0.3750 - val_loss: 1.2513 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6836 - accuracy: 0.3750 - val_loss: 1.2529 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6770 - accuracy: 0.3750 - val_loss: 1.2538 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6786 - accuracy: 0.3571 - val_loss: 1.2552 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6658 - accuracy: 0.3750 - val_loss: 1.2577 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6561 - accuracy: 0.3750 - val_loss: 1.2601 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6571 - accuracy: 0.3750 - val_loss: 1.2628 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6538 - accuracy: 0.4286 - val_loss: 1.2661 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6558 - accuracy: 0.4286 - val_loss: 1.2685 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6530 - accuracy: 0.3750 - val_loss: 1.2708 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6371 - accuracy: 0.3929 - val_loss: 1.2733 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6461 - accuracy: 0.3750 - val_loss: 1.2740 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6480 - accuracy: 0.4286 - val_loss: 1.2741 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6493 - accuracy: 0.3929 - val_loss: 1.2753 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6367 - accuracy: 0.3929 - val_loss: 1.2763 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6374 - accuracy: 0.3929 - val_loss: 1.2769 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6263 - accuracy: 0.4286 - val_loss: 1.2790 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6208 - accuracy: 0.4286 - val_loss: 1.2820 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6290 - accuracy: 0.4464 - val_loss: 1.2857 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6146 - accuracy: 0.4643 - val_loss: 1.2896 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6229 - accuracy: 0.4643 - val_loss: 1.2942 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6080 - accuracy: 0.4286 - val_loss: 1.2984 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2984 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=128, batch_size=400, Scores: [1.2983970642089844, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2983970642089844\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9835 - accuracy: 0.1786 - val_loss: 1.0717 - val_accuracy: 0.0714\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9809 - accuracy: 0.1250 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9793 - accuracy: 0.1607 - val_loss: 1.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9770 - accuracy: 0.2500 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9765 - accuracy: 0.1964 - val_loss: 1.0741 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9736 - accuracy: 0.2500 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9719 - accuracy: 0.3036 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9708 - accuracy: 0.2500 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9689 - accuracy: 0.2857 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9669 - accuracy: 0.2679 - val_loss: 1.0775 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9656 - accuracy: 0.3214 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9644 - accuracy: 0.3214 - val_loss: 1.0789 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9600 - accuracy: 0.2857 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9595 - accuracy: 0.2857 - val_loss: 1.0804 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9568 - accuracy: 0.3214 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9561 - accuracy: 0.3571 - val_loss: 1.0820 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9537 - accuracy: 0.3571 - val_loss: 1.0828 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9524 - accuracy: 0.3393 - val_loss: 1.0837 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9491 - accuracy: 0.2857 - val_loss: 1.0845 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9472 - accuracy: 0.3393 - val_loss: 1.0854 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9431 - accuracy: 0.3036 - val_loss: 1.0863 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9430 - accuracy: 0.3393 - val_loss: 1.0872 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9391 - accuracy: 0.3214 - val_loss: 1.0882 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9360 - accuracy: 0.3571 - val_loss: 1.0891 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9332 - accuracy: 0.3571 - val_loss: 1.0901 - val_accuracy: 0.0714\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9314 - accuracy: 0.3571 - val_loss: 1.0912 - val_accuracy: 0.0714\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9301 - accuracy: 0.3393 - val_loss: 1.0922 - val_accuracy: 0.0714\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9282 - accuracy: 0.3750 - val_loss: 1.0933 - val_accuracy: 0.0714\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9240 - accuracy: 0.3571 - val_loss: 1.0944 - val_accuracy: 0.0714\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9218 - accuracy: 0.3571 - val_loss: 1.0955 - val_accuracy: 0.0714\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9181 - accuracy: 0.3393 - val_loss: 1.0967 - val_accuracy: 0.0714\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9194 - accuracy: 0.3393 - val_loss: 1.0979 - val_accuracy: 0.0714\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9138 - accuracy: 0.3393 - val_loss: 1.0992 - val_accuracy: 0.0714\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9079 - accuracy: 0.3393 - val_loss: 1.1005 - val_accuracy: 0.0714\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9077 - accuracy: 0.3214 - val_loss: 1.1019 - val_accuracy: 0.0714\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9013 - accuracy: 0.3571 - val_loss: 1.1033 - val_accuracy: 0.0714\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9021 - accuracy: 0.3036 - val_loss: 1.1049 - val_accuracy: 0.0714\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8993 - accuracy: 0.3571 - val_loss: 1.1064 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8931 - accuracy: 0.3036 - val_loss: 1.1081 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8894 - accuracy: 0.3393 - val_loss: 1.1098 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8857 - accuracy: 0.3571 - val_loss: 1.1115 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8848 - accuracy: 0.3214 - val_loss: 1.1133 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.8807 - accuracy: 0.3036 - val_loss: 1.1152 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8751 - accuracy: 0.3393 - val_loss: 1.1171 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8773 - accuracy: 0.2679 - val_loss: 1.1192 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8704 - accuracy: 0.3214 - val_loss: 1.1213 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8660 - accuracy: 0.3036 - val_loss: 1.1235 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8614 - accuracy: 0.3036 - val_loss: 1.1257 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8618 - accuracy: 0.3036 - val_loss: 1.1280 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8572 - accuracy: 0.3036 - val_loss: 1.1302 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8579 - accuracy: 0.2857 - val_loss: 1.1325 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8546 - accuracy: 0.2857 - val_loss: 1.1348 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8475 - accuracy: 0.3393 - val_loss: 1.1372 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8439 - accuracy: 0.2857 - val_loss: 1.1395 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8387 - accuracy: 0.3393 - val_loss: 1.1420 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8339 - accuracy: 0.3036 - val_loss: 1.1445 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8279 - accuracy: 0.2857 - val_loss: 1.1470 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8265 - accuracy: 0.3214 - val_loss: 1.1495 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8252 - accuracy: 0.3393 - val_loss: 1.1522 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8201 - accuracy: 0.3214 - val_loss: 1.1550 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8160 - accuracy: 0.3393 - val_loss: 1.1581 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8118 - accuracy: 0.2857 - val_loss: 1.1614 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8082 - accuracy: 0.3571 - val_loss: 1.1648 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8071 - accuracy: 0.3393 - val_loss: 1.1682 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8020 - accuracy: 0.3929 - val_loss: 1.1719 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7996 - accuracy: 0.3571 - val_loss: 1.1756 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7958 - accuracy: 0.3214 - val_loss: 1.1793 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7885 - accuracy: 0.3214 - val_loss: 1.1830 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7892 - accuracy: 0.3571 - val_loss: 1.1869 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7882 - accuracy: 0.3393 - val_loss: 1.1905 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7806 - accuracy: 0.3571 - val_loss: 1.1940 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7780 - accuracy: 0.3571 - val_loss: 1.1977 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7765 - accuracy: 0.3571 - val_loss: 1.2015 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7673 - accuracy: 0.3393 - val_loss: 1.2052 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7690 - accuracy: 0.3571 - val_loss: 1.2091 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7672 - accuracy: 0.3571 - val_loss: 1.2130 - val_accuracy: 0.2143\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7675 - accuracy: 0.3214 - val_loss: 1.2173 - val_accuracy: 0.2143\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7569 - accuracy: 0.3571 - val_loss: 1.2214 - val_accuracy: 0.2143\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7514 - accuracy: 0.3393 - val_loss: 1.2257 - val_accuracy: 0.2143\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7516 - accuracy: 0.3571 - val_loss: 1.2298 - val_accuracy: 0.2143\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7525 - accuracy: 0.3214 - val_loss: 1.2340 - val_accuracy: 0.2143\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7500 - accuracy: 0.3393 - val_loss: 1.2383 - val_accuracy: 0.2143\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7461 - accuracy: 0.3571 - val_loss: 1.2425 - val_accuracy: 0.2143\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7480 - accuracy: 0.3571 - val_loss: 1.2470 - val_accuracy: 0.2143\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7436 - accuracy: 0.3393 - val_loss: 1.2514 - val_accuracy: 0.2143\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7417 - accuracy: 0.3393 - val_loss: 1.2557 - val_accuracy: 0.2143\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7311 - accuracy: 0.3571 - val_loss: 1.2600 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7366 - accuracy: 0.3571 - val_loss: 1.2640 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7258 - accuracy: 0.3393 - val_loss: 1.2676 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7263 - accuracy: 0.3750 - val_loss: 1.2713 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7260 - accuracy: 0.3214 - val_loss: 1.2746 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7124 - accuracy: 0.3571 - val_loss: 1.2778 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7156 - accuracy: 0.3393 - val_loss: 1.2806 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7113 - accuracy: 0.3750 - val_loss: 1.2831 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7140 - accuracy: 0.3571 - val_loss: 1.2861 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7050 - accuracy: 0.3929 - val_loss: 1.2892 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7037 - accuracy: 0.3929 - val_loss: 1.2921 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7043 - accuracy: 0.3929 - val_loss: 1.2950 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6981 - accuracy: 0.3929 - val_loss: 1.2985 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6992 - accuracy: 0.3750 - val_loss: 1.3017 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6897 - accuracy: 0.3929 - val_loss: 1.3044 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6908 - accuracy: 0.4286 - val_loss: 1.3062 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6880 - accuracy: 0.3750 - val_loss: 1.3068 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6858 - accuracy: 0.4107 - val_loss: 1.3074 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6804 - accuracy: 0.3750 - val_loss: 1.3086 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6837 - accuracy: 0.4464 - val_loss: 1.3093 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6819 - accuracy: 0.4107 - val_loss: 1.3110 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6664 - accuracy: 0.4107 - val_loss: 1.3130 - val_accuracy: 0.1429\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6796 - accuracy: 0.3571 - val_loss: 1.3152 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6666 - accuracy: 0.4107 - val_loss: 1.3172 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6632 - accuracy: 0.4286 - val_loss: 1.3194 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6572 - accuracy: 0.4107 - val_loss: 1.3213 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6593 - accuracy: 0.4107 - val_loss: 1.3238 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6579 - accuracy: 0.4107 - val_loss: 1.3261 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6480 - accuracy: 0.4286 - val_loss: 1.3281 - val_accuracy: 0.1429\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6513 - accuracy: 0.4286 - val_loss: 1.3303 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6429 - accuracy: 0.4286 - val_loss: 1.3316 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6475 - accuracy: 0.4286 - val_loss: 1.3329 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6430 - accuracy: 0.4286 - val_loss: 1.3353 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6327 - accuracy: 0.4107 - val_loss: 1.3383 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6351 - accuracy: 0.4286 - val_loss: 1.3420 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6314 - accuracy: 0.4464 - val_loss: 1.3462 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6345 - accuracy: 0.4107 - val_loss: 1.3527 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6252 - accuracy: 0.3929 - val_loss: 1.3598 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6103 - accuracy: 0.3750 - val_loss: 1.3671 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6118 - accuracy: 0.3929 - val_loss: 1.3745 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.6172 - accuracy: 0.4107 - val_loss: 1.3800 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6068 - accuracy: 0.3929 - val_loss: 1.3838 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3838 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=128, batch_size=500, Scores: [1.383787989616394, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.383787989616394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9877 - accuracy: 0.1786 - val_loss: 1.0726 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9849 - accuracy: 0.1429 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9796 - accuracy: 0.1607 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9807 - accuracy: 0.1429 - val_loss: 1.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9791 - accuracy: 0.1964 - val_loss: 1.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9748 - accuracy: 0.2143 - val_loss: 1.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9732 - accuracy: 0.2679 - val_loss: 1.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9714 - accuracy: 0.2321 - val_loss: 1.0761 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9696 - accuracy: 0.2679 - val_loss: 1.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9667 - accuracy: 0.2500 - val_loss: 1.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9636 - accuracy: 0.3214 - val_loss: 1.0777 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9633 - accuracy: 0.2143 - val_loss: 1.0783 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9609 - accuracy: 0.2143 - val_loss: 1.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9597 - accuracy: 0.2143 - val_loss: 1.0794 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9570 - accuracy: 0.2679 - val_loss: 1.0800 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9537 - accuracy: 0.2143 - val_loss: 1.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9520 - accuracy: 0.2679 - val_loss: 1.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9488 - accuracy: 0.1964 - val_loss: 1.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9467 - accuracy: 0.2321 - val_loss: 1.0821 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9440 - accuracy: 0.2679 - val_loss: 1.0826 - val_accuracy: 0.0714\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9415 - accuracy: 0.2857 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9414 - accuracy: 0.2500 - val_loss: 1.0835 - val_accuracy: 0.0714\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9359 - accuracy: 0.2857 - val_loss: 1.0840 - val_accuracy: 0.0714\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9340 - accuracy: 0.2679 - val_loss: 1.0845 - val_accuracy: 0.0714\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9301 - accuracy: 0.2500 - val_loss: 1.0849 - val_accuracy: 0.0714\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9284 - accuracy: 0.2857 - val_loss: 1.0853 - val_accuracy: 0.0714\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9256 - accuracy: 0.2679 - val_loss: 1.0858 - val_accuracy: 0.0714\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9215 - accuracy: 0.3214 - val_loss: 1.0862 - val_accuracy: 0.0714\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9191 - accuracy: 0.2679 - val_loss: 1.0867 - val_accuracy: 0.0714\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9156 - accuracy: 0.3036 - val_loss: 1.0872 - val_accuracy: 0.0714\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9105 - accuracy: 0.2679 - val_loss: 1.0876 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9096 - accuracy: 0.3036 - val_loss: 1.0881 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9037 - accuracy: 0.2857 - val_loss: 1.0887 - val_accuracy: 0.0714\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9036 - accuracy: 0.2679 - val_loss: 1.0892 - val_accuracy: 0.0714\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8964 - accuracy: 0.3393 - val_loss: 1.0899 - val_accuracy: 0.0714\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8974 - accuracy: 0.2857 - val_loss: 1.0905 - val_accuracy: 0.0714\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8940 - accuracy: 0.2321 - val_loss: 1.0912 - val_accuracy: 0.0714\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8907 - accuracy: 0.2500 - val_loss: 1.0920 - val_accuracy: 0.0714\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8826 - accuracy: 0.3571 - val_loss: 1.0929 - val_accuracy: 0.0714\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8803 - accuracy: 0.3036 - val_loss: 1.0938 - val_accuracy: 0.0714\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8720 - accuracy: 0.3036 - val_loss: 1.0949 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8740 - accuracy: 0.2857 - val_loss: 1.0961 - val_accuracy: 0.0714\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8714 - accuracy: 0.3571 - val_loss: 1.0974 - val_accuracy: 0.0714\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8643 - accuracy: 0.2679 - val_loss: 1.0989 - val_accuracy: 0.0714\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8644 - accuracy: 0.3214 - val_loss: 1.1005 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8551 - accuracy: 0.3393 - val_loss: 1.1024 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8539 - accuracy: 0.3393 - val_loss: 1.1044 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8477 - accuracy: 0.3036 - val_loss: 1.1066 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8419 - accuracy: 0.3571 - val_loss: 1.1091 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8402 - accuracy: 0.3214 - val_loss: 1.1117 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8393 - accuracy: 0.3214 - val_loss: 1.1145 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8357 - accuracy: 0.3571 - val_loss: 1.1176 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8296 - accuracy: 0.3750 - val_loss: 1.1209 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8277 - accuracy: 0.3214 - val_loss: 1.1244 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8279 - accuracy: 0.3393 - val_loss: 1.1280 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8245 - accuracy: 0.3036 - val_loss: 1.1318 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8173 - accuracy: 0.3214 - val_loss: 1.1359 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8133 - accuracy: 0.3036 - val_loss: 1.1402 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8122 - accuracy: 0.3214 - val_loss: 1.1447 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8062 - accuracy: 0.3036 - val_loss: 1.1494 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8056 - accuracy: 0.3214 - val_loss: 1.1542 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7989 - accuracy: 0.3393 - val_loss: 1.1593 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8016 - accuracy: 0.3393 - val_loss: 1.1645 - val_accuracy: 0.1429\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7923 - accuracy: 0.3571 - val_loss: 1.1698 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7922 - accuracy: 0.3393 - val_loss: 1.1752 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7892 - accuracy: 0.3750 - val_loss: 1.1807 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7804 - accuracy: 0.4107 - val_loss: 1.1864 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7857 - accuracy: 0.3571 - val_loss: 1.1920 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7829 - accuracy: 0.3393 - val_loss: 1.1977 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7818 - accuracy: 0.3393 - val_loss: 1.2032 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7752 - accuracy: 0.3571 - val_loss: 1.2085 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7776 - accuracy: 0.3571 - val_loss: 1.2137 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7740 - accuracy: 0.3750 - val_loss: 1.2186 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7702 - accuracy: 0.4107 - val_loss: 1.2234 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7610 - accuracy: 0.3393 - val_loss: 1.2278 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7659 - accuracy: 0.3750 - val_loss: 1.2320 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7647 - accuracy: 0.3571 - val_loss: 1.2358 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7605 - accuracy: 0.3571 - val_loss: 1.2395 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7512 - accuracy: 0.3393 - val_loss: 1.2432 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7543 - accuracy: 0.3393 - val_loss: 1.2467 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7492 - accuracy: 0.3571 - val_loss: 1.2499 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7437 - accuracy: 0.3393 - val_loss: 1.2527 - val_accuracy: 0.1429\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7366 - accuracy: 0.3571 - val_loss: 1.2552 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7417 - accuracy: 0.3571 - val_loss: 1.2572 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7351 - accuracy: 0.3393 - val_loss: 1.2589 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7487 - accuracy: 0.3571 - val_loss: 1.2603 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7445 - accuracy: 0.3393 - val_loss: 1.2614 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7282 - accuracy: 0.3750 - val_loss: 1.2624 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7414 - accuracy: 0.3214 - val_loss: 1.2636 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7283 - accuracy: 0.3393 - val_loss: 1.2644 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7197 - accuracy: 0.3929 - val_loss: 1.2654 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7182 - accuracy: 0.3750 - val_loss: 1.2662 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7219 - accuracy: 0.3571 - val_loss: 1.2667 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7175 - accuracy: 0.3929 - val_loss: 1.2667 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7209 - accuracy: 0.3214 - val_loss: 1.2672 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7102 - accuracy: 0.3571 - val_loss: 1.2683 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7057 - accuracy: 0.3750 - val_loss: 1.2692 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7077 - accuracy: 0.3214 - val_loss: 1.2702 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7056 - accuracy: 0.3750 - val_loss: 1.2713 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7063 - accuracy: 0.3571 - val_loss: 1.2729 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6928 - accuracy: 0.3036 - val_loss: 1.2749 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6960 - accuracy: 0.3750 - val_loss: 1.2770 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6979 - accuracy: 0.3571 - val_loss: 1.2791 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6930 - accuracy: 0.3393 - val_loss: 1.2815 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.6863 - accuracy: 0.3750 - val_loss: 1.2835 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6811 - accuracy: 0.3571 - val_loss: 1.2861 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6810 - accuracy: 0.3393 - val_loss: 1.2886 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6786 - accuracy: 0.3214 - val_loss: 1.2914 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6851 - accuracy: 0.3571 - val_loss: 1.2938 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6766 - accuracy: 0.3571 - val_loss: 1.2960 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.6729 - accuracy: 0.3750 - val_loss: 1.2983 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6742 - accuracy: 0.3571 - val_loss: 1.3009 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6686 - accuracy: 0.3393 - val_loss: 1.3032 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6619 - accuracy: 0.3929 - val_loss: 1.3054 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6628 - accuracy: 0.3571 - val_loss: 1.3085 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6574 - accuracy: 0.3750 - val_loss: 1.3124 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6539 - accuracy: 0.3750 - val_loss: 1.3172 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6640 - accuracy: 0.3929 - val_loss: 1.3209 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6420 - accuracy: 0.4286 - val_loss: 1.3248 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6478 - accuracy: 0.3929 - val_loss: 1.3287 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6366 - accuracy: 0.4107 - val_loss: 1.3327 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6384 - accuracy: 0.4107 - val_loss: 1.3367 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6463 - accuracy: 0.4107 - val_loss: 1.3405 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6300 - accuracy: 0.4821 - val_loss: 1.3437 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6243 - accuracy: 0.4286 - val_loss: 1.3457 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6241 - accuracy: 0.4643 - val_loss: 1.3469 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6201 - accuracy: 0.4643 - val_loss: 1.3483 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6215 - accuracy: 0.4286 - val_loss: 1.3494 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6166 - accuracy: 0.3393 - val_loss: 1.3509 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6100 - accuracy: 0.4286 - val_loss: 1.3517 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.6074 - accuracy: 0.4464 - val_loss: 1.3532 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6091 - accuracy: 0.4286 - val_loss: 1.3547 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6022 - accuracy: 0.4286 - val_loss: 1.3559 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5992 - accuracy: 0.4286 - val_loss: 1.3578 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5961 - accuracy: 0.4821 - val_loss: 1.3597 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5965 - accuracy: 0.4464 - val_loss: 1.3629 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5823 - accuracy: 0.3929 - val_loss: 1.3671 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5683 - accuracy: 0.4286 - val_loss: 1.3712 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.5831 - accuracy: 0.4286 - val_loss: 1.3750 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5737 - accuracy: 0.4286 - val_loss: 1.3776 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5673 - accuracy: 0.3929 - val_loss: 1.3799 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5745 - accuracy: 0.4464 - val_loss: 1.3822 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5684 - accuracy: 0.4286 - val_loss: 1.3839 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5619 - accuracy: 0.4107 - val_loss: 1.3864 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5605 - accuracy: 0.3929 - val_loss: 1.3895 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5521 - accuracy: 0.4286 - val_loss: 1.3921 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5582 - accuracy: 0.4643 - val_loss: 1.3957 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5594 - accuracy: 0.4464 - val_loss: 1.3989 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5399 - accuracy: 0.4464 - val_loss: 1.4004 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5498 - accuracy: 0.4464 - val_loss: 1.4032 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5283 - accuracy: 0.3929 - val_loss: 1.4075 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5293 - accuracy: 0.4286 - val_loss: 1.4131 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5300 - accuracy: 0.3929 - val_loss: 1.4168 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5236 - accuracy: 0.5000 - val_loss: 1.4215 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5194 - accuracy: 0.4821 - val_loss: 1.4253 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5349 - accuracy: 0.4286 - val_loss: 1.4300 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5146 - accuracy: 0.4286 - val_loss: 1.4333 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5007 - accuracy: 0.3929 - val_loss: 1.4348 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5212 - accuracy: 0.4286 - val_loss: 1.4325 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5085 - accuracy: 0.4107 - val_loss: 1.4305 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4987 - accuracy: 0.4107 - val_loss: 1.4281 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5094 - accuracy: 0.4464 - val_loss: 1.4262 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4842 - accuracy: 0.4107 - val_loss: 1.4250 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4815 - accuracy: 0.4464 - val_loss: 1.4257 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4845 - accuracy: 0.4107 - val_loss: 1.4304 - val_accuracy: 0.0714\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4966 - accuracy: 0.4107 - val_loss: 1.4315 - val_accuracy: 0.0714\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4951 - accuracy: 0.3929 - val_loss: 1.4322 - val_accuracy: 0.0714\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4907 - accuracy: 0.4107 - val_loss: 1.4346 - val_accuracy: 0.0714\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4719 - accuracy: 0.4643 - val_loss: 1.4376 - val_accuracy: 0.0714\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4817 - accuracy: 0.4107 - val_loss: 1.4400 - val_accuracy: 0.0714\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4624 - accuracy: 0.4643 - val_loss: 1.4412 - val_accuracy: 0.0714\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4691 - accuracy: 0.4821 - val_loss: 1.4403 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4724 - accuracy: 0.4643 - val_loss: 1.4398 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4644 - accuracy: 0.4643 - val_loss: 1.4409 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4623 - accuracy: 0.5000 - val_loss: 1.4447 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4579 - accuracy: 0.4643 - val_loss: 1.4497 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4684 - accuracy: 0.4286 - val_loss: 1.4512 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4472 - accuracy: 0.4107 - val_loss: 1.4509 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4353 - accuracy: 0.3571 - val_loss: 1.4472 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4312 - accuracy: 0.4464 - val_loss: 1.4484 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4388 - accuracy: 0.4107 - val_loss: 1.4478 - val_accuracy: 0.0714\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4298 - accuracy: 0.4643 - val_loss: 1.4478 - val_accuracy: 0.0714\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4379 - accuracy: 0.5000 - val_loss: 1.4496 - val_accuracy: 0.0714\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4457 - accuracy: 0.4643 - val_loss: 1.4568 - val_accuracy: 0.0714\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4254 - accuracy: 0.5179 - val_loss: 1.4643 - val_accuracy: 0.0714\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4203 - accuracy: 0.5179 - val_loss: 1.4747 - val_accuracy: 0.0714\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4069 - accuracy: 0.4107 - val_loss: 1.4826 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4153 - accuracy: 0.4464 - val_loss: 1.4886 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4191 - accuracy: 0.5000 - val_loss: 1.4849 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4041 - accuracy: 0.5536 - val_loss: 1.4740 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4116 - accuracy: 0.5000 - val_loss: 1.4607 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3866 - accuracy: 0.5179 - val_loss: 1.4523 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4143 - accuracy: 0.4286 - val_loss: 1.4475 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4057 - accuracy: 0.5000 - val_loss: 1.4510 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4028 - accuracy: 0.4643 - val_loss: 1.4569 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3963 - accuracy: 0.5179 - val_loss: 1.4634 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4040 - accuracy: 0.5357 - val_loss: 1.4629 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4212 - accuracy: 0.5357 - val_loss: 1.4532 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.3939 - accuracy: 0.5000 - val_loss: 1.4445 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3891 - accuracy: 0.5179 - val_loss: 1.4389 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3756 - accuracy: 0.5536 - val_loss: 1.4370 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3839 - accuracy: 0.4643 - val_loss: 1.4374 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3687 - accuracy: 0.4821 - val_loss: 1.4437 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3714 - accuracy: 0.5179 - val_loss: 1.4489 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3688 - accuracy: 0.4821 - val_loss: 1.4535 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3669 - accuracy: 0.5536 - val_loss: 1.4584 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3619 - accuracy: 0.5893 - val_loss: 1.4617 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3691 - accuracy: 0.5714 - val_loss: 1.4587 - val_accuracy: 0.1429\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3531 - accuracy: 0.5714 - val_loss: 1.4505 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3670 - accuracy: 0.5179 - val_loss: 1.4430 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3383 - accuracy: 0.5357 - val_loss: 1.4347 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3606 - accuracy: 0.5357 - val_loss: 1.4280 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3572 - accuracy: 0.4643 - val_loss: 1.4220 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3588 - accuracy: 0.5000 - val_loss: 1.4205 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3484 - accuracy: 0.5179 - val_loss: 1.4195 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3479 - accuracy: 0.5357 - val_loss: 1.4242 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3471 - accuracy: 0.6071 - val_loss: 1.4332 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3179 - accuracy: 0.4821 - val_loss: 1.4452 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.3590 - accuracy: 0.5536 - val_loss: 1.4526 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3390 - accuracy: 0.5536 - val_loss: 1.4522 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3517 - accuracy: 0.6250 - val_loss: 1.4485 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3355 - accuracy: 0.5536 - val_loss: 1.4436 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3496 - accuracy: 0.4107 - val_loss: 1.4409 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3325 - accuracy: 0.5893 - val_loss: 1.4399 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3270 - accuracy: 0.5714 - val_loss: 1.4389 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.3254 - accuracy: 0.5893 - val_loss: 1.4399 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3313 - accuracy: 0.5536 - val_loss: 1.4404 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3193 - accuracy: 0.5714 - val_loss: 1.4411 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3229 - accuracy: 0.5536 - val_loss: 1.4450 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3173 - accuracy: 0.5893 - val_loss: 1.4494 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3090 - accuracy: 0.5179 - val_loss: 1.4516 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3108 - accuracy: 0.5714 - val_loss: 1.4557 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3126 - accuracy: 0.5536 - val_loss: 1.4605 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3095 - accuracy: 0.6071 - val_loss: 1.4651 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2951 - accuracy: 0.6429 - val_loss: 1.4672 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2940 - accuracy: 0.5179 - val_loss: 1.4658 - val_accuracy: 0.1429\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3242 - accuracy: 0.5179 - val_loss: 1.4593 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2903 - accuracy: 0.5893 - val_loss: 1.4535 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3118 - accuracy: 0.5536 - val_loss: 1.4488 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3033 - accuracy: 0.5714 - val_loss: 1.4404 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4404 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=240, batch_size=100, Scores: [1.4403526782989502, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.4403526782989502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9862 - accuracy: 0.0357 - val_loss: 1.0729 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9835 - accuracy: 0.0893 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9819 - accuracy: 0.1250 - val_loss: 1.0739 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9804 - accuracy: 0.1071 - val_loss: 1.0744 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9764 - accuracy: 0.1429 - val_loss: 1.0749 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9764 - accuracy: 0.1071 - val_loss: 1.0753 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9704 - accuracy: 0.1786 - val_loss: 1.0758 - val_accuracy: 0.0714\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9684 - accuracy: 0.1786 - val_loss: 1.0763 - val_accuracy: 0.0714\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9670 - accuracy: 0.1429 - val_loss: 1.0767 - val_accuracy: 0.0714\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9642 - accuracy: 0.1964 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9626 - accuracy: 0.1964 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9603 - accuracy: 0.2857 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9564 - accuracy: 0.2679 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9547 - accuracy: 0.2679 - val_loss: 1.0790 - val_accuracy: 0.0714\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9528 - accuracy: 0.3036 - val_loss: 1.0795 - val_accuracy: 0.0714\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9516 - accuracy: 0.2679 - val_loss: 1.0799 - val_accuracy: 0.0714\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9462 - accuracy: 0.3393 - val_loss: 1.0804 - val_accuracy: 0.0714\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9463 - accuracy: 0.2857 - val_loss: 1.0809 - val_accuracy: 0.0714\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9433 - accuracy: 0.3571 - val_loss: 1.0813 - val_accuracy: 0.0714\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9423 - accuracy: 0.3571 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9377 - accuracy: 0.2857 - val_loss: 1.0822 - val_accuracy: 0.0714\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9335 - accuracy: 0.3393 - val_loss: 1.0826 - val_accuracy: 0.0714\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9330 - accuracy: 0.2857 - val_loss: 1.0830 - val_accuracy: 0.0714\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9275 - accuracy: 0.2500 - val_loss: 1.0834 - val_accuracy: 0.0714\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9251 - accuracy: 0.3036 - val_loss: 1.0838 - val_accuracy: 0.0714\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9239 - accuracy: 0.3214 - val_loss: 1.0842 - val_accuracy: 0.0714\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9200 - accuracy: 0.2679 - val_loss: 1.0846 - val_accuracy: 0.0714\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9182 - accuracy: 0.3036 - val_loss: 1.0850 - val_accuracy: 0.0714\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9111 - accuracy: 0.3214 - val_loss: 1.0854 - val_accuracy: 0.0714\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9095 - accuracy: 0.3393 - val_loss: 1.0859 - val_accuracy: 0.0714\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9059 - accuracy: 0.3036 - val_loss: 1.0863 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9035 - accuracy: 0.3036 - val_loss: 1.0868 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8977 - accuracy: 0.3214 - val_loss: 1.0874 - val_accuracy: 0.0714\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8969 - accuracy: 0.3571 - val_loss: 1.0880 - val_accuracy: 0.0714\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8886 - accuracy: 0.3214 - val_loss: 1.0887 - val_accuracy: 0.0714\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8870 - accuracy: 0.3214 - val_loss: 1.0895 - val_accuracy: 0.0714\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8873 - accuracy: 0.3393 - val_loss: 1.0903 - val_accuracy: 0.0714\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8778 - accuracy: 0.3393 - val_loss: 1.0913 - val_accuracy: 0.0714\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8700 - accuracy: 0.3571 - val_loss: 1.0924 - val_accuracy: 0.0714\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8702 - accuracy: 0.3393 - val_loss: 1.0937 - val_accuracy: 0.0714\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8699 - accuracy: 0.3214 - val_loss: 1.0951 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8690 - accuracy: 0.3036 - val_loss: 1.0967 - val_accuracy: 0.0714\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8596 - accuracy: 0.3214 - val_loss: 1.0985 - val_accuracy: 0.0714\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8580 - accuracy: 0.3036 - val_loss: 1.1005 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8587 - accuracy: 0.3393 - val_loss: 1.1026 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8507 - accuracy: 0.3214 - val_loss: 1.1048 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8450 - accuracy: 0.3036 - val_loss: 1.1073 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8486 - accuracy: 0.2857 - val_loss: 1.1098 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8426 - accuracy: 0.3036 - val_loss: 1.1126 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8379 - accuracy: 0.3214 - val_loss: 1.1155 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8340 - accuracy: 0.3036 - val_loss: 1.1185 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8315 - accuracy: 0.3214 - val_loss: 1.1217 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8322 - accuracy: 0.3036 - val_loss: 1.1250 - val_accuracy: 0.2143\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8323 - accuracy: 0.3036 - val_loss: 1.1284 - val_accuracy: 0.2143\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8223 - accuracy: 0.3036 - val_loss: 1.1320 - val_accuracy: 0.2143\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8179 - accuracy: 0.3214 - val_loss: 1.1357 - val_accuracy: 0.2143\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8155 - accuracy: 0.3393 - val_loss: 1.1396 - val_accuracy: 0.2143\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8130 - accuracy: 0.3214 - val_loss: 1.1436 - val_accuracy: 0.2143\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8130 - accuracy: 0.3214 - val_loss: 1.1478 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8075 - accuracy: 0.3393 - val_loss: 1.1523 - val_accuracy: 0.2143\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7981 - accuracy: 0.3571 - val_loss: 1.1570 - val_accuracy: 0.2143\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7998 - accuracy: 0.3571 - val_loss: 1.1619 - val_accuracy: 0.2143\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8016 - accuracy: 0.3393 - val_loss: 1.1669 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7984 - accuracy: 0.3393 - val_loss: 1.1720 - val_accuracy: 0.2143\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7905 - accuracy: 0.2857 - val_loss: 1.1773 - val_accuracy: 0.2143\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7887 - accuracy: 0.3571 - val_loss: 1.1826 - val_accuracy: 0.2143\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7856 - accuracy: 0.3036 - val_loss: 1.1879 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7816 - accuracy: 0.3393 - val_loss: 1.1933 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7869 - accuracy: 0.3929 - val_loss: 1.1987 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7752 - accuracy: 0.3750 - val_loss: 1.2039 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7764 - accuracy: 0.2679 - val_loss: 1.2092 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7718 - accuracy: 0.3214 - val_loss: 1.2146 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7642 - accuracy: 0.3571 - val_loss: 1.2194 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7687 - accuracy: 0.3393 - val_loss: 1.2241 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7587 - accuracy: 0.3393 - val_loss: 1.2284 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7644 - accuracy: 0.3036 - val_loss: 1.2325 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7557 - accuracy: 0.3393 - val_loss: 1.2364 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7547 - accuracy: 0.3393 - val_loss: 1.2399 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7487 - accuracy: 0.3393 - val_loss: 1.2432 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7441 - accuracy: 0.3393 - val_loss: 1.2463 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7469 - accuracy: 0.3571 - val_loss: 1.2490 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7397 - accuracy: 0.3214 - val_loss: 1.2518 - val_accuracy: 0.1429\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7421 - accuracy: 0.3393 - val_loss: 1.2544 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7345 - accuracy: 0.3571 - val_loss: 1.2571 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7392 - accuracy: 0.3393 - val_loss: 1.2596 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7362 - accuracy: 0.3929 - val_loss: 1.2621 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7346 - accuracy: 0.3571 - val_loss: 1.2645 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7257 - accuracy: 0.3571 - val_loss: 1.2669 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7266 - accuracy: 0.3571 - val_loss: 1.2693 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7161 - accuracy: 0.3214 - val_loss: 1.2718 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7173 - accuracy: 0.3750 - val_loss: 1.2745 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7215 - accuracy: 0.3393 - val_loss: 1.2772 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7147 - accuracy: 0.3393 - val_loss: 1.2800 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7141 - accuracy: 0.3571 - val_loss: 1.2829 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.7083 - accuracy: 0.3750 - val_loss: 1.2856 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7095 - accuracy: 0.3214 - val_loss: 1.2884 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7065 - accuracy: 0.3571 - val_loss: 1.2913 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7059 - accuracy: 0.3393 - val_loss: 1.2944 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7048 - accuracy: 0.3571 - val_loss: 1.2979 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6940 - accuracy: 0.3750 - val_loss: 1.3014 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6978 - accuracy: 0.3750 - val_loss: 1.3046 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6981 - accuracy: 0.3929 - val_loss: 1.3081 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6994 - accuracy: 0.3571 - val_loss: 1.3116 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6890 - accuracy: 0.3929 - val_loss: 1.3154 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6795 - accuracy: 0.3750 - val_loss: 1.3196 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6823 - accuracy: 0.3929 - val_loss: 1.3234 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6782 - accuracy: 0.3571 - val_loss: 1.3279 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6743 - accuracy: 0.4286 - val_loss: 1.3325 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6801 - accuracy: 0.3929 - val_loss: 1.3371 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6736 - accuracy: 0.3750 - val_loss: 1.3416 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6747 - accuracy: 0.4107 - val_loss: 1.3454 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6722 - accuracy: 0.4107 - val_loss: 1.3493 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6644 - accuracy: 0.3929 - val_loss: 1.3524 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6638 - accuracy: 0.3750 - val_loss: 1.3557 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6635 - accuracy: 0.4286 - val_loss: 1.3586 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6571 - accuracy: 0.4107 - val_loss: 1.3612 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6580 - accuracy: 0.3929 - val_loss: 1.3629 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6549 - accuracy: 0.4286 - val_loss: 1.3647 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6560 - accuracy: 0.4107 - val_loss: 1.3669 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6545 - accuracy: 0.4643 - val_loss: 1.3688 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6567 - accuracy: 0.4107 - val_loss: 1.3707 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6399 - accuracy: 0.4107 - val_loss: 1.3730 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6451 - accuracy: 0.3750 - val_loss: 1.3755 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6394 - accuracy: 0.4286 - val_loss: 1.3785 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6330 - accuracy: 0.3929 - val_loss: 1.3816 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6319 - accuracy: 0.4107 - val_loss: 1.3855 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6342 - accuracy: 0.4286 - val_loss: 1.3892 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6258 - accuracy: 0.4286 - val_loss: 1.3939 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6328 - accuracy: 0.4821 - val_loss: 1.3992 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6372 - accuracy: 0.4107 - val_loss: 1.4032 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6246 - accuracy: 0.4286 - val_loss: 1.4062 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6224 - accuracy: 0.4107 - val_loss: 1.4083 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6203 - accuracy: 0.4286 - val_loss: 1.4084 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6154 - accuracy: 0.4643 - val_loss: 1.4084 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6026 - accuracy: 0.4286 - val_loss: 1.4082 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6007 - accuracy: 0.4464 - val_loss: 1.4080 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5967 - accuracy: 0.4286 - val_loss: 1.4101 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.5995 - accuracy: 0.3750 - val_loss: 1.4132 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5986 - accuracy: 0.4107 - val_loss: 1.4162 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5894 - accuracy: 0.4286 - val_loss: 1.4193 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5983 - accuracy: 0.4643 - val_loss: 1.4231 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5916 - accuracy: 0.4643 - val_loss: 1.4268 - val_accuracy: 0.1429\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5905 - accuracy: 0.4286 - val_loss: 1.4295 - val_accuracy: 0.1429\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.5743 - accuracy: 0.4643 - val_loss: 1.4328 - val_accuracy: 0.1429\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5795 - accuracy: 0.4643 - val_loss: 1.4357 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5732 - accuracy: 0.3929 - val_loss: 1.4381 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5678 - accuracy: 0.4107 - val_loss: 1.4398 - val_accuracy: 0.2143\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5635 - accuracy: 0.4821 - val_loss: 1.4416 - val_accuracy: 0.2143\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5697 - accuracy: 0.4107 - val_loss: 1.4431 - val_accuracy: 0.2143\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5620 - accuracy: 0.4107 - val_loss: 1.4453 - val_accuracy: 0.2143\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5585 - accuracy: 0.4286 - val_loss: 1.4472 - val_accuracy: 0.2143\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5564 - accuracy: 0.4464 - val_loss: 1.4494 - val_accuracy: 0.2143\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.5512 - accuracy: 0.4821 - val_loss: 1.4532 - val_accuracy: 0.2143\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5585 - accuracy: 0.4286 - val_loss: 1.4569 - val_accuracy: 0.2143\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.5464 - accuracy: 0.4286 - val_loss: 1.4605 - val_accuracy: 0.2143\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5428 - accuracy: 0.4286 - val_loss: 1.4639 - val_accuracy: 0.2143\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5361 - accuracy: 0.3750 - val_loss: 1.4676 - val_accuracy: 0.2143\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5434 - accuracy: 0.4107 - val_loss: 1.4709 - val_accuracy: 0.2143\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5412 - accuracy: 0.4286 - val_loss: 1.4731 - val_accuracy: 0.2143\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5463 - accuracy: 0.4464 - val_loss: 1.4769 - val_accuracy: 0.2143\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5209 - accuracy: 0.4643 - val_loss: 1.4808 - val_accuracy: 0.2143\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5182 - accuracy: 0.4107 - val_loss: 1.4854 - val_accuracy: 0.2143\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5118 - accuracy: 0.4464 - val_loss: 1.4890 - val_accuracy: 0.2143\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5124 - accuracy: 0.4821 - val_loss: 1.4946 - val_accuracy: 0.2143\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5118 - accuracy: 0.5179 - val_loss: 1.5026 - val_accuracy: 0.2143\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5013 - accuracy: 0.3929 - val_loss: 1.5100 - val_accuracy: 0.2143\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.5095 - accuracy: 0.4107 - val_loss: 1.5182 - val_accuracy: 0.2143\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5017 - accuracy: 0.4107 - val_loss: 1.5253 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5006 - accuracy: 0.4107 - val_loss: 1.5308 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4918 - accuracy: 0.4286 - val_loss: 1.5352 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4883 - accuracy: 0.4107 - val_loss: 1.5365 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4901 - accuracy: 0.4643 - val_loss: 1.5374 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4820 - accuracy: 0.4107 - val_loss: 1.5408 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4838 - accuracy: 0.4643 - val_loss: 1.5430 - val_accuracy: 0.2143\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4934 - accuracy: 0.4286 - val_loss: 1.5470 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4749 - accuracy: 0.4464 - val_loss: 1.5481 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4817 - accuracy: 0.4286 - val_loss: 1.5480 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4787 - accuracy: 0.4286 - val_loss: 1.5466 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4543 - accuracy: 0.4464 - val_loss: 1.5454 - val_accuracy: 0.2143\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4661 - accuracy: 0.4643 - val_loss: 1.5456 - val_accuracy: 0.2143\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4572 - accuracy: 0.4821 - val_loss: 1.5446 - val_accuracy: 0.2143\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.4682 - accuracy: 0.4643 - val_loss: 1.5450 - val_accuracy: 0.2143\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4484 - accuracy: 0.4643 - val_loss: 1.5494 - val_accuracy: 0.2143\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4492 - accuracy: 0.4821 - val_loss: 1.5558 - val_accuracy: 0.2143\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4561 - accuracy: 0.4107 - val_loss: 1.5607 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4390 - accuracy: 0.5536 - val_loss: 1.5645 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4682 - accuracy: 0.4107 - val_loss: 1.5632 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4354 - accuracy: 0.4643 - val_loss: 1.5620 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4239 - accuracy: 0.5357 - val_loss: 1.5599 - val_accuracy: 0.2143\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4329 - accuracy: 0.4643 - val_loss: 1.5610 - val_accuracy: 0.2143\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4281 - accuracy: 0.4643 - val_loss: 1.5651 - val_accuracy: 0.2143\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4271 - accuracy: 0.5536 - val_loss: 1.5703 - val_accuracy: 0.2143\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4263 - accuracy: 0.4821 - val_loss: 1.5751 - val_accuracy: 0.2143\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4095 - accuracy: 0.4286 - val_loss: 1.5770 - val_accuracy: 0.2143\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4155 - accuracy: 0.5000 - val_loss: 1.5741 - val_accuracy: 0.2143\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4190 - accuracy: 0.5179 - val_loss: 1.5697 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4106 - accuracy: 0.4643 - val_loss: 1.5642 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4071 - accuracy: 0.4821 - val_loss: 1.5592 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4199 - accuracy: 0.4107 - val_loss: 1.5557 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3990 - accuracy: 0.4643 - val_loss: 1.5528 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3892 - accuracy: 0.4821 - val_loss: 1.5492 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3821 - accuracy: 0.4643 - val_loss: 1.5454 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3971 - accuracy: 0.4286 - val_loss: 1.5434 - val_accuracy: 0.2143\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3958 - accuracy: 0.5000 - val_loss: 1.5421 - val_accuracy: 0.2143\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4000 - accuracy: 0.5000 - val_loss: 1.5414 - val_accuracy: 0.2143\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3840 - accuracy: 0.4643 - val_loss: 1.5465 - val_accuracy: 0.2143\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3736 - accuracy: 0.4464 - val_loss: 1.5519 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3594 - accuracy: 0.4643 - val_loss: 1.5556 - val_accuracy: 0.1429\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3789 - accuracy: 0.4643 - val_loss: 1.5588 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3652 - accuracy: 0.5179 - val_loss: 1.5648 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3624 - accuracy: 0.5000 - val_loss: 1.5716 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3678 - accuracy: 0.4643 - val_loss: 1.5742 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3510 - accuracy: 0.5357 - val_loss: 1.5773 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3433 - accuracy: 0.4821 - val_loss: 1.5807 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3507 - accuracy: 0.4821 - val_loss: 1.5816 - val_accuracy: 0.2143\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3591 - accuracy: 0.5179 - val_loss: 1.5828 - val_accuracy: 0.2143\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3273 - accuracy: 0.5000 - val_loss: 1.5812 - val_accuracy: 0.2143\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3496 - accuracy: 0.5179 - val_loss: 1.5763 - val_accuracy: 0.2143\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3464 - accuracy: 0.4821 - val_loss: 1.5670 - val_accuracy: 0.2143\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3489 - accuracy: 0.4464 - val_loss: 1.5614 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3369 - accuracy: 0.4821 - val_loss: 1.5579 - val_accuracy: 0.2143\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3400 - accuracy: 0.5536 - val_loss: 1.5580 - val_accuracy: 0.2143\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3145 - accuracy: 0.4821 - val_loss: 1.5604 - val_accuracy: 0.2143\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3301 - accuracy: 0.5000 - val_loss: 1.5648 - val_accuracy: 0.2143\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3236 - accuracy: 0.5714 - val_loss: 1.5676 - val_accuracy: 0.2143\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3302 - accuracy: 0.5000 - val_loss: 1.5722 - val_accuracy: 0.2143\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3166 - accuracy: 0.5179 - val_loss: 1.5760 - val_accuracy: 0.2143\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3209 - accuracy: 0.5179 - val_loss: 1.5785 - val_accuracy: 0.2143\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3223 - accuracy: 0.5714 - val_loss: 1.5793 - val_accuracy: 0.2143\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3123 - accuracy: 0.5536 - val_loss: 1.5801 - val_accuracy: 0.2143\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2875 - accuracy: 0.6429 - val_loss: 1.5815 - val_accuracy: 0.2143\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3042 - accuracy: 0.5714 - val_loss: 1.5873 - val_accuracy: 0.2143\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3029 - accuracy: 0.5000 - val_loss: 1.5901 - val_accuracy: 0.2143\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3046 - accuracy: 0.5714 - val_loss: 1.5940 - val_accuracy: 0.2143\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2810 - accuracy: 0.5714 - val_loss: 1.5963 - val_accuracy: 0.2143\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2982 - accuracy: 0.4643 - val_loss: 1.5975 - val_accuracy: 0.2143\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2951 - accuracy: 0.5714 - val_loss: 1.6024 - val_accuracy: 0.2143\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2858 - accuracy: 0.5357 - val_loss: 1.6064 - val_accuracy: 0.2143\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3028 - accuracy: 0.5357 - val_loss: 1.6095 - val_accuracy: 0.2143\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2782 - accuracy: 0.5893 - val_loss: 1.6154 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.6154 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=240, batch_size=300, Scores: [1.6154197454452515, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.6154197454452515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9842 - accuracy: 0.0714 - val_loss: 1.0676 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9838 - accuracy: 0.0893 - val_loss: 1.0682 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9824 - accuracy: 0.1607 - val_loss: 1.0688 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9796 - accuracy: 0.1607 - val_loss: 1.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9779 - accuracy: 0.2143 - val_loss: 1.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9762 - accuracy: 0.1607 - val_loss: 1.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9739 - accuracy: 0.2321 - val_loss: 1.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9731 - accuracy: 0.2321 - val_loss: 1.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9705 - accuracy: 0.1964 - val_loss: 1.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9696 - accuracy: 0.2500 - val_loss: 1.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9673 - accuracy: 0.2500 - val_loss: 1.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.9635 - accuracy: 0.2679 - val_loss: 1.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9633 - accuracy: 0.2143 - val_loss: 1.0752 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9627 - accuracy: 0.2143 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9585 - accuracy: 0.2857 - val_loss: 1.0765 - val_accuracy: 0.0714\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9568 - accuracy: 0.2857 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9559 - accuracy: 0.2321 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9530 - accuracy: 0.2500 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9515 - accuracy: 0.2321 - val_loss: 1.0793 - val_accuracy: 0.0714\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9508 - accuracy: 0.2500 - val_loss: 1.0800 - val_accuracy: 0.0714\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9464 - accuracy: 0.2857 - val_loss: 1.0807 - val_accuracy: 0.0714\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9458 - accuracy: 0.2857 - val_loss: 1.0814 - val_accuracy: 0.0714\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9412 - accuracy: 0.3036 - val_loss: 1.0821 - val_accuracy: 0.0714\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9424 - accuracy: 0.2500 - val_loss: 1.0828 - val_accuracy: 0.0714\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9387 - accuracy: 0.2679 - val_loss: 1.0835 - val_accuracy: 0.0714\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9357 - accuracy: 0.2321 - val_loss: 1.0843 - val_accuracy: 0.0714\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9351 - accuracy: 0.2500 - val_loss: 1.0849 - val_accuracy: 0.0714\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9321 - accuracy: 0.2857 - val_loss: 1.0856 - val_accuracy: 0.0714\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9277 - accuracy: 0.2679 - val_loss: 1.0862 - val_accuracy: 0.0714\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9250 - accuracy: 0.2857 - val_loss: 1.0869 - val_accuracy: 0.0714\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9213 - accuracy: 0.3036 - val_loss: 1.0876 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9208 - accuracy: 0.3393 - val_loss: 1.0882 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9159 - accuracy: 0.3036 - val_loss: 1.0888 - val_accuracy: 0.0714\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9133 - accuracy: 0.2679 - val_loss: 1.0894 - val_accuracy: 0.0714\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9117 - accuracy: 0.3036 - val_loss: 1.0900 - val_accuracy: 0.0714\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9088 - accuracy: 0.3036 - val_loss: 1.0906 - val_accuracy: 0.0714\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9029 - accuracy: 0.3036 - val_loss: 1.0912 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8978 - accuracy: 0.2857 - val_loss: 1.0918 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8974 - accuracy: 0.2857 - val_loss: 1.0924 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8917 - accuracy: 0.3393 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8952 - accuracy: 0.3393 - val_loss: 1.0935 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8868 - accuracy: 0.3214 - val_loss: 1.0942 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8823 - accuracy: 0.3393 - val_loss: 1.0948 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8812 - accuracy: 0.2857 - val_loss: 1.0955 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8752 - accuracy: 0.3036 - val_loss: 1.0962 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8701 - accuracy: 0.3214 - val_loss: 1.0970 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8666 - accuracy: 0.3750 - val_loss: 1.0978 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8632 - accuracy: 0.3214 - val_loss: 1.0988 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8582 - accuracy: 0.3571 - val_loss: 1.0997 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8541 - accuracy: 0.2857 - val_loss: 1.1008 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8555 - accuracy: 0.3393 - val_loss: 1.1020 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8432 - accuracy: 0.3393 - val_loss: 1.1033 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8417 - accuracy: 0.2857 - val_loss: 1.1048 - val_accuracy: 0.0714\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8394 - accuracy: 0.3214 - val_loss: 1.1064 - val_accuracy: 0.0714\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8319 - accuracy: 0.3036 - val_loss: 1.1082 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8320 - accuracy: 0.3393 - val_loss: 1.1101 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8237 - accuracy: 0.3036 - val_loss: 1.1122 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8226 - accuracy: 0.3214 - val_loss: 1.1144 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8192 - accuracy: 0.3214 - val_loss: 1.1167 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8160 - accuracy: 0.3214 - val_loss: 1.1192 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8073 - accuracy: 0.2857 - val_loss: 1.1220 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8072 - accuracy: 0.3036 - val_loss: 1.1249 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8049 - accuracy: 0.3214 - val_loss: 1.1281 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8022 - accuracy: 0.3036 - val_loss: 1.1315 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7988 - accuracy: 0.3393 - val_loss: 1.1350 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7933 - accuracy: 0.3393 - val_loss: 1.1387 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7877 - accuracy: 0.3571 - val_loss: 1.1428 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7927 - accuracy: 0.3393 - val_loss: 1.1470 - val_accuracy: 0.0714\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7842 - accuracy: 0.3750 - val_loss: 1.1513 - val_accuracy: 0.0714\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7783 - accuracy: 0.3393 - val_loss: 1.1559 - val_accuracy: 0.0714\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7751 - accuracy: 0.3393 - val_loss: 1.1605 - val_accuracy: 0.0714\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7713 - accuracy: 0.3929 - val_loss: 1.1652 - val_accuracy: 0.0714\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7707 - accuracy: 0.3393 - val_loss: 1.1700 - val_accuracy: 0.0714\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7717 - accuracy: 0.3929 - val_loss: 1.1750 - val_accuracy: 0.0714\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7672 - accuracy: 0.3571 - val_loss: 1.1800 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7598 - accuracy: 0.3750 - val_loss: 1.1849 - val_accuracy: 0.0714\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7551 - accuracy: 0.3571 - val_loss: 1.1897 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.7616 - accuracy: 0.3571 - val_loss: 1.1946 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7523 - accuracy: 0.3750 - val_loss: 1.1995 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7477 - accuracy: 0.3929 - val_loss: 1.2043 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7499 - accuracy: 0.3750 - val_loss: 1.2090 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7465 - accuracy: 0.3393 - val_loss: 1.2134 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7388 - accuracy: 0.3929 - val_loss: 1.2177 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7397 - accuracy: 0.3750 - val_loss: 1.2218 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.7390 - accuracy: 0.3750 - val_loss: 1.2257 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7353 - accuracy: 0.3571 - val_loss: 1.2292 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7236 - accuracy: 0.3750 - val_loss: 1.2327 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7345 - accuracy: 0.3393 - val_loss: 1.2361 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7256 - accuracy: 0.3393 - val_loss: 1.2395 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7264 - accuracy: 0.4107 - val_loss: 1.2428 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7245 - accuracy: 0.3750 - val_loss: 1.2461 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7146 - accuracy: 0.3929 - val_loss: 1.2495 - val_accuracy: 0.0714\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7122 - accuracy: 0.3929 - val_loss: 1.2526 - val_accuracy: 0.0714\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7162 - accuracy: 0.3750 - val_loss: 1.2553 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7135 - accuracy: 0.3571 - val_loss: 1.2581 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7063 - accuracy: 0.3571 - val_loss: 1.2608 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7020 - accuracy: 0.3750 - val_loss: 1.2632 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6970 - accuracy: 0.3571 - val_loss: 1.2660 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6974 - accuracy: 0.3571 - val_loss: 1.2696 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6861 - accuracy: 0.3750 - val_loss: 1.2732 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6907 - accuracy: 0.3750 - val_loss: 1.2771 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6928 - accuracy: 0.3571 - val_loss: 1.2811 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6801 - accuracy: 0.3929 - val_loss: 1.2852 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6765 - accuracy: 0.3929 - val_loss: 1.2893 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.6816 - accuracy: 0.3929 - val_loss: 1.2930 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6712 - accuracy: 0.4107 - val_loss: 1.2965 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6613 - accuracy: 0.3571 - val_loss: 1.3001 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6656 - accuracy: 0.3571 - val_loss: 1.3041 - val_accuracy: 0.0714\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6603 - accuracy: 0.3929 - val_loss: 1.3080 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6576 - accuracy: 0.3750 - val_loss: 1.3119 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6586 - accuracy: 0.3929 - val_loss: 1.3153 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6500 - accuracy: 0.4286 - val_loss: 1.3180 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6451 - accuracy: 0.3929 - val_loss: 1.3217 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6462 - accuracy: 0.4107 - val_loss: 1.3250 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6364 - accuracy: 0.4464 - val_loss: 1.3289 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6423 - accuracy: 0.4286 - val_loss: 1.3330 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6319 - accuracy: 0.4286 - val_loss: 1.3373 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6281 - accuracy: 0.3929 - val_loss: 1.3411 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6246 - accuracy: 0.3571 - val_loss: 1.3464 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6270 - accuracy: 0.3750 - val_loss: 1.3518 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6244 - accuracy: 0.4107 - val_loss: 1.3566 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.6098 - accuracy: 0.4107 - val_loss: 1.3595 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6076 - accuracy: 0.4286 - val_loss: 1.3632 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6135 - accuracy: 0.4286 - val_loss: 1.3668 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6046 - accuracy: 0.4464 - val_loss: 1.3709 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6020 - accuracy: 0.4286 - val_loss: 1.3738 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.5929 - accuracy: 0.4643 - val_loss: 1.3775 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5807 - accuracy: 0.4464 - val_loss: 1.3824 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5841 - accuracy: 0.4286 - val_loss: 1.3866 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5846 - accuracy: 0.3750 - val_loss: 1.3914 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5886 - accuracy: 0.4286 - val_loss: 1.3950 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5781 - accuracy: 0.4464 - val_loss: 1.3994 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5796 - accuracy: 0.3929 - val_loss: 1.4051 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5645 - accuracy: 0.4107 - val_loss: 1.4101 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5682 - accuracy: 0.4107 - val_loss: 1.4151 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5633 - accuracy: 0.3929 - val_loss: 1.4191 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5692 - accuracy: 0.3750 - val_loss: 1.4212 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5586 - accuracy: 0.4107 - val_loss: 1.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5465 - accuracy: 0.3929 - val_loss: 1.4212 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5501 - accuracy: 0.3750 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5482 - accuracy: 0.3750 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5403 - accuracy: 0.3929 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5374 - accuracy: 0.4107 - val_loss: 1.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5307 - accuracy: 0.3929 - val_loss: 1.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5338 - accuracy: 0.4286 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5420 - accuracy: 0.3929 - val_loss: 1.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5299 - accuracy: 0.3929 - val_loss: 1.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5181 - accuracy: 0.3929 - val_loss: 1.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5415 - accuracy: 0.3929 - val_loss: 1.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5097 - accuracy: 0.4464 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4952 - accuracy: 0.4464 - val_loss: 1.4624 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4976 - accuracy: 0.4286 - val_loss: 1.4676 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5061 - accuracy: 0.4107 - val_loss: 1.4703 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4959 - accuracy: 0.4286 - val_loss: 1.4729 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4901 - accuracy: 0.4464 - val_loss: 1.4752 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4976 - accuracy: 0.4286 - val_loss: 1.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4868 - accuracy: 0.4464 - val_loss: 1.4791 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5021 - accuracy: 0.4286 - val_loss: 1.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4914 - accuracy: 0.4286 - val_loss: 1.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4810 - accuracy: 0.4821 - val_loss: 1.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4756 - accuracy: 0.4643 - val_loss: 1.4794 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4822 - accuracy: 0.4643 - val_loss: 1.4783 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4768 - accuracy: 0.4464 - val_loss: 1.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4756 - accuracy: 0.4464 - val_loss: 1.4832 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4675 - accuracy: 0.4821 - val_loss: 1.4845 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4619 - accuracy: 0.4464 - val_loss: 1.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4580 - accuracy: 0.4643 - val_loss: 1.4871 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4606 - accuracy: 0.4286 - val_loss: 1.4886 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4596 - accuracy: 0.4286 - val_loss: 1.4909 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4421 - accuracy: 0.4643 - val_loss: 1.4925 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4542 - accuracy: 0.4107 - val_loss: 1.4911 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.4554 - accuracy: 0.4286 - val_loss: 1.4869 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4320 - accuracy: 0.5000 - val_loss: 1.4854 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4216 - accuracy: 0.5000 - val_loss: 1.4841 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4365 - accuracy: 0.4464 - val_loss: 1.4814 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4402 - accuracy: 0.4643 - val_loss: 1.4797 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4330 - accuracy: 0.4464 - val_loss: 1.4804 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4291 - accuracy: 0.4464 - val_loss: 1.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4347 - accuracy: 0.4643 - val_loss: 1.4843 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4318 - accuracy: 0.5000 - val_loss: 1.4867 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4302 - accuracy: 0.5179 - val_loss: 1.4869 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4136 - accuracy: 0.5000 - val_loss: 1.4889 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4153 - accuracy: 0.4821 - val_loss: 1.4897 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4064 - accuracy: 0.4821 - val_loss: 1.4894 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4005 - accuracy: 0.4643 - val_loss: 1.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4267 - accuracy: 0.4286 - val_loss: 1.4851 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.4195 - accuracy: 0.4286 - val_loss: 1.4832 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3991 - accuracy: 0.4464 - val_loss: 1.4818 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3876 - accuracy: 0.5000 - val_loss: 1.4839 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4010 - accuracy: 0.4643 - val_loss: 1.4868 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3897 - accuracy: 0.5000 - val_loss: 1.4904 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3801 - accuracy: 0.5536 - val_loss: 1.4930 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3823 - accuracy: 0.6071 - val_loss: 1.4940 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3752 - accuracy: 0.5000 - val_loss: 1.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3739 - accuracy: 0.5000 - val_loss: 1.4860 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3865 - accuracy: 0.5536 - val_loss: 1.4815 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.3749 - accuracy: 0.5179 - val_loss: 1.4774 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3753 - accuracy: 0.5000 - val_loss: 1.4738 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3744 - accuracy: 0.5179 - val_loss: 1.4724 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3580 - accuracy: 0.5357 - val_loss: 1.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3730 - accuracy: 0.5179 - val_loss: 1.4715 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3521 - accuracy: 0.4821 - val_loss: 1.4748 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3493 - accuracy: 0.4643 - val_loss: 1.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3588 - accuracy: 0.5536 - val_loss: 1.4875 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3394 - accuracy: 0.5536 - val_loss: 1.4926 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3586 - accuracy: 0.4821 - val_loss: 1.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3327 - accuracy: 0.5179 - val_loss: 1.4925 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3418 - accuracy: 0.5000 - val_loss: 1.4896 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3275 - accuracy: 0.6071 - val_loss: 1.4879 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3387 - accuracy: 0.5536 - val_loss: 1.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3239 - accuracy: 0.5000 - val_loss: 1.4901 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3363 - accuracy: 0.4643 - val_loss: 1.4944 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3222 - accuracy: 0.5714 - val_loss: 1.4989 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3449 - accuracy: 0.5357 - val_loss: 1.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3340 - accuracy: 0.6071 - val_loss: 1.5058 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3267 - accuracy: 0.5179 - val_loss: 1.5067 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3169 - accuracy: 0.5893 - val_loss: 1.5064 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3202 - accuracy: 0.5714 - val_loss: 1.5028 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3159 - accuracy: 0.6071 - val_loss: 1.5025 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3116 - accuracy: 0.5714 - val_loss: 1.5019 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3140 - accuracy: 0.5714 - val_loss: 1.5032 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3115 - accuracy: 0.5714 - val_loss: 1.4984 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3086 - accuracy: 0.5536 - val_loss: 1.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2905 - accuracy: 0.5536 - val_loss: 1.4914 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3076 - accuracy: 0.5893 - val_loss: 1.4869 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3034 - accuracy: 0.5893 - val_loss: 1.4842 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3012 - accuracy: 0.5357 - val_loss: 1.4821 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2860 - accuracy: 0.6429 - val_loss: 1.4810 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3108 - accuracy: 0.5536 - val_loss: 1.4814 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3057 - accuracy: 0.5357 - val_loss: 1.4863 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2853 - accuracy: 0.5714 - val_loss: 1.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2815 - accuracy: 0.5893 - val_loss: 1.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2945 - accuracy: 0.5714 - val_loss: 1.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3011 - accuracy: 0.5714 - val_loss: 1.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2893 - accuracy: 0.5714 - val_loss: 1.4931 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2786 - accuracy: 0.5357 - val_loss: 1.4925 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2796 - accuracy: 0.6250 - val_loss: 1.4957 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2748 - accuracy: 0.5893 - val_loss: 1.4995 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2589 - accuracy: 0.6071 - val_loss: 1.5031 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2605 - accuracy: 0.6607 - val_loss: 1.5087 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5087 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=240, batch_size=400, Scores: [1.5086631774902344, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.5086631774902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9841 - accuracy: 0.1071 - val_loss: 1.0732 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9824 - accuracy: 0.1964 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9817 - accuracy: 0.1786 - val_loss: 1.0738 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9770 - accuracy: 0.1786 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9767 - accuracy: 0.2321 - val_loss: 1.0744 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9743 - accuracy: 0.2857 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9719 - accuracy: 0.2321 - val_loss: 1.0752 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9693 - accuracy: 0.2857 - val_loss: 1.0755 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9664 - accuracy: 0.2321 - val_loss: 1.0759 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9665 - accuracy: 0.1964 - val_loss: 1.0763 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9630 - accuracy: 0.2679 - val_loss: 1.0767 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.9628 - accuracy: 0.2500 - val_loss: 1.0771 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9605 - accuracy: 0.3214 - val_loss: 1.0775 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9580 - accuracy: 0.2679 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9563 - accuracy: 0.2857 - val_loss: 1.0783 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9530 - accuracy: 0.2679 - val_loss: 1.0787 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9513 - accuracy: 0.2679 - val_loss: 1.0791 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9483 - accuracy: 0.3036 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9455 - accuracy: 0.2679 - val_loss: 1.0800 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9445 - accuracy: 0.2679 - val_loss: 1.0804 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9423 - accuracy: 0.2679 - val_loss: 1.0809 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9408 - accuracy: 0.2857 - val_loss: 1.0813 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9372 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9340 - accuracy: 0.2857 - val_loss: 1.0823 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9323 - accuracy: 0.2679 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9281 - accuracy: 0.3036 - val_loss: 1.0833 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9283 - accuracy: 0.3393 - val_loss: 1.0838 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9245 - accuracy: 0.2857 - val_loss: 1.0844 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9205 - accuracy: 0.2679 - val_loss: 1.0850 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9170 - accuracy: 0.2500 - val_loss: 1.0856 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9145 - accuracy: 0.2857 - val_loss: 1.0863 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9098 - accuracy: 0.2679 - val_loss: 1.0870 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9074 - accuracy: 0.2500 - val_loss: 1.0878 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9067 - accuracy: 0.2857 - val_loss: 1.0885 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9013 - accuracy: 0.2679 - val_loss: 1.0894 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8964 - accuracy: 0.2321 - val_loss: 1.0903 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8942 - accuracy: 0.2500 - val_loss: 1.0913 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8910 - accuracy: 0.2500 - val_loss: 1.0924 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8834 - accuracy: 0.2500 - val_loss: 1.0935 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8809 - accuracy: 0.2321 - val_loss: 1.0946 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8803 - accuracy: 0.2500 - val_loss: 1.0959 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8788 - accuracy: 0.2500 - val_loss: 1.0971 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8752 - accuracy: 0.2500 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8679 - accuracy: 0.2679 - val_loss: 1.0999 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8660 - accuracy: 0.2143 - val_loss: 1.1013 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8619 - accuracy: 0.2500 - val_loss: 1.1026 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8522 - accuracy: 0.2321 - val_loss: 1.1040 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8545 - accuracy: 0.2500 - val_loss: 1.1053 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8453 - accuracy: 0.2143 - val_loss: 1.1067 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8510 - accuracy: 0.2500 - val_loss: 1.1081 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8430 - accuracy: 0.2500 - val_loss: 1.1097 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8397 - accuracy: 0.2500 - val_loss: 1.1112 - val_accuracy: 0.2143\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8397 - accuracy: 0.2679 - val_loss: 1.1129 - val_accuracy: 0.2143\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8304 - accuracy: 0.3393 - val_loss: 1.1147 - val_accuracy: 0.2143\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8329 - accuracy: 0.2321 - val_loss: 1.1167 - val_accuracy: 0.2143\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8301 - accuracy: 0.2857 - val_loss: 1.1188 - val_accuracy: 0.2143\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8289 - accuracy: 0.2679 - val_loss: 1.1212 - val_accuracy: 0.2143\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8191 - accuracy: 0.2679 - val_loss: 1.1237 - val_accuracy: 0.2143\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8153 - accuracy: 0.2679 - val_loss: 1.1263 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8158 - accuracy: 0.2857 - val_loss: 1.1291 - val_accuracy: 0.2143\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8189 - accuracy: 0.3214 - val_loss: 1.1321 - val_accuracy: 0.2143\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.8087 - accuracy: 0.2857 - val_loss: 1.1351 - val_accuracy: 0.2143\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8099 - accuracy: 0.3393 - val_loss: 1.1382 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8035 - accuracy: 0.3036 - val_loss: 1.1415 - val_accuracy: 0.2143\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7997 - accuracy: 0.3393 - val_loss: 1.1447 - val_accuracy: 0.2143\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7944 - accuracy: 0.3571 - val_loss: 1.1478 - val_accuracy: 0.2143\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7973 - accuracy: 0.3214 - val_loss: 1.1513 - val_accuracy: 0.2143\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7932 - accuracy: 0.3036 - val_loss: 1.1550 - val_accuracy: 0.2143\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7887 - accuracy: 0.2857 - val_loss: 1.1586 - val_accuracy: 0.2143\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7866 - accuracy: 0.3571 - val_loss: 1.1619 - val_accuracy: 0.2143\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7788 - accuracy: 0.3571 - val_loss: 1.1651 - val_accuracy: 0.2143\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7737 - accuracy: 0.3750 - val_loss: 1.1682 - val_accuracy: 0.2143\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7803 - accuracy: 0.3214 - val_loss: 1.1710 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7791 - accuracy: 0.3214 - val_loss: 1.1735 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7754 - accuracy: 0.3214 - val_loss: 1.1755 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7661 - accuracy: 0.2857 - val_loss: 1.1771 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7709 - accuracy: 0.3393 - val_loss: 1.1782 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7597 - accuracy: 0.2857 - val_loss: 1.1797 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7594 - accuracy: 0.3571 - val_loss: 1.1811 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7617 - accuracy: 0.3214 - val_loss: 1.1830 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7537 - accuracy: 0.3393 - val_loss: 1.1854 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7511 - accuracy: 0.3571 - val_loss: 1.1880 - val_accuracy: 0.1429\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7464 - accuracy: 0.3214 - val_loss: 1.1907 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7478 - accuracy: 0.3393 - val_loss: 1.1938 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7489 - accuracy: 0.3214 - val_loss: 1.1961 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7379 - accuracy: 0.3214 - val_loss: 1.1982 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7421 - accuracy: 0.3214 - val_loss: 1.2003 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7371 - accuracy: 0.2679 - val_loss: 1.2022 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7282 - accuracy: 0.3214 - val_loss: 1.2039 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7207 - accuracy: 0.3393 - val_loss: 1.2056 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7269 - accuracy: 0.3393 - val_loss: 1.2075 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7223 - accuracy: 0.3929 - val_loss: 1.2096 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7226 - accuracy: 0.3393 - val_loss: 1.2119 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7179 - accuracy: 0.3929 - val_loss: 1.2147 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7189 - accuracy: 0.3214 - val_loss: 1.2180 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7129 - accuracy: 0.3571 - val_loss: 1.2212 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7142 - accuracy: 0.3214 - val_loss: 1.2240 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7153 - accuracy: 0.3571 - val_loss: 1.2269 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7108 - accuracy: 0.3750 - val_loss: 1.2294 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7048 - accuracy: 0.3929 - val_loss: 1.2316 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7048 - accuracy: 0.3571 - val_loss: 1.2335 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7020 - accuracy: 0.3571 - val_loss: 1.2354 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6903 - accuracy: 0.3750 - val_loss: 1.2378 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6925 - accuracy: 0.3929 - val_loss: 1.2400 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6842 - accuracy: 0.3393 - val_loss: 1.2421 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6863 - accuracy: 0.3393 - val_loss: 1.2439 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6778 - accuracy: 0.3393 - val_loss: 1.2460 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6852 - accuracy: 0.3393 - val_loss: 1.2478 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6807 - accuracy: 0.3571 - val_loss: 1.2490 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6788 - accuracy: 0.4107 - val_loss: 1.2501 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6733 - accuracy: 0.3571 - val_loss: 1.2506 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6733 - accuracy: 0.3393 - val_loss: 1.2513 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6749 - accuracy: 0.3571 - val_loss: 1.2530 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6709 - accuracy: 0.3393 - val_loss: 1.2552 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6675 - accuracy: 0.3929 - val_loss: 1.2578 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.6610 - accuracy: 0.3929 - val_loss: 1.2604 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6718 - accuracy: 0.3929 - val_loss: 1.2628 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6553 - accuracy: 0.3571 - val_loss: 1.2657 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.6620 - accuracy: 0.3571 - val_loss: 1.2693 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6501 - accuracy: 0.4107 - val_loss: 1.2732 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.6516 - accuracy: 0.3571 - val_loss: 1.2770 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6461 - accuracy: 0.3750 - val_loss: 1.2785 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6421 - accuracy: 0.3571 - val_loss: 1.2787 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6467 - accuracy: 0.3571 - val_loss: 1.2779 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6346 - accuracy: 0.3929 - val_loss: 1.2776 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6304 - accuracy: 0.4286 - val_loss: 1.2784 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6319 - accuracy: 0.4286 - val_loss: 1.2798 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6287 - accuracy: 0.3750 - val_loss: 1.2820 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6232 - accuracy: 0.4107 - val_loss: 1.2848 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6199 - accuracy: 0.4286 - val_loss: 1.2886 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6128 - accuracy: 0.4107 - val_loss: 1.2931 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6138 - accuracy: 0.4286 - val_loss: 1.2988 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6113 - accuracy: 0.4286 - val_loss: 1.3044 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.6101 - accuracy: 0.4286 - val_loss: 1.3093 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5964 - accuracy: 0.4464 - val_loss: 1.3135 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5912 - accuracy: 0.4107 - val_loss: 1.3183 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5988 - accuracy: 0.4107 - val_loss: 1.3223 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5985 - accuracy: 0.4821 - val_loss: 1.3260 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5983 - accuracy: 0.4107 - val_loss: 1.3290 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5818 - accuracy: 0.4821 - val_loss: 1.3326 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5811 - accuracy: 0.4286 - val_loss: 1.3358 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.5789 - accuracy: 0.4643 - val_loss: 1.3399 - val_accuracy: 0.1429\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5682 - accuracy: 0.4107 - val_loss: 1.3449 - val_accuracy: 0.1429\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5723 - accuracy: 0.4464 - val_loss: 1.3498 - val_accuracy: 0.1429\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5637 - accuracy: 0.4464 - val_loss: 1.3549 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5620 - accuracy: 0.4464 - val_loss: 1.3607 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5604 - accuracy: 0.4464 - val_loss: 1.3672 - val_accuracy: 0.1429\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.5561 - accuracy: 0.4286 - val_loss: 1.3747 - val_accuracy: 0.1429\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5475 - accuracy: 0.4643 - val_loss: 1.3822 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.5631 - accuracy: 0.4286 - val_loss: 1.3875 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5395 - accuracy: 0.4464 - val_loss: 1.3918 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5434 - accuracy: 0.4107 - val_loss: 1.3959 - val_accuracy: 0.1429\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5442 - accuracy: 0.3929 - val_loss: 1.4006 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5436 - accuracy: 0.4464 - val_loss: 1.4048 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5369 - accuracy: 0.4821 - val_loss: 1.4082 - val_accuracy: 0.1429\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5242 - accuracy: 0.4286 - val_loss: 1.4117 - val_accuracy: 0.1429\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5246 - accuracy: 0.4286 - val_loss: 1.4150 - val_accuracy: 0.1429\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5276 - accuracy: 0.4643 - val_loss: 1.4185 - val_accuracy: 0.2143\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5229 - accuracy: 0.4464 - val_loss: 1.4245 - val_accuracy: 0.2143\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5182 - accuracy: 0.3929 - val_loss: 1.4289 - val_accuracy: 0.2143\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5070 - accuracy: 0.4821 - val_loss: 1.4334 - val_accuracy: 0.2143\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5102 - accuracy: 0.4107 - val_loss: 1.4375 - val_accuracy: 0.2143\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5040 - accuracy: 0.4464 - val_loss: 1.4427 - val_accuracy: 0.2143\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5058 - accuracy: 0.4107 - val_loss: 1.4456 - val_accuracy: 0.2143\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.5124 - accuracy: 0.3929 - val_loss: 1.4484 - val_accuracy: 0.2143\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4942 - accuracy: 0.4464 - val_loss: 1.4501 - val_accuracy: 0.2143\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5009 - accuracy: 0.4643 - val_loss: 1.4521 - val_accuracy: 0.2143\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5094 - accuracy: 0.4464 - val_loss: 1.4536 - val_accuracy: 0.2143\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4950 - accuracy: 0.4464 - val_loss: 1.4553 - val_accuracy: 0.2143\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4817 - accuracy: 0.4643 - val_loss: 1.4617 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4755 - accuracy: 0.3750 - val_loss: 1.4665 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4874 - accuracy: 0.4464 - val_loss: 1.4693 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4744 - accuracy: 0.4464 - val_loss: 1.4705 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4645 - accuracy: 0.4286 - val_loss: 1.4691 - val_accuracy: 0.1429\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4780 - accuracy: 0.4464 - val_loss: 1.4679 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4494 - accuracy: 0.4821 - val_loss: 1.4647 - val_accuracy: 0.2143\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4584 - accuracy: 0.4643 - val_loss: 1.4603 - val_accuracy: 0.2143\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4599 - accuracy: 0.4464 - val_loss: 1.4576 - val_accuracy: 0.2143\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4557 - accuracy: 0.4464 - val_loss: 1.4532 - val_accuracy: 0.2143\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4481 - accuracy: 0.4821 - val_loss: 1.4516 - val_accuracy: 0.2143\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4453 - accuracy: 0.4821 - val_loss: 1.4537 - val_accuracy: 0.2143\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4557 - accuracy: 0.4286 - val_loss: 1.4590 - val_accuracy: 0.2143\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4536 - accuracy: 0.4107 - val_loss: 1.4653 - val_accuracy: 0.2143\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4429 - accuracy: 0.5000 - val_loss: 1.4746 - val_accuracy: 0.2143\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4508 - accuracy: 0.4643 - val_loss: 1.4840 - val_accuracy: 0.2143\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4258 - accuracy: 0.5000 - val_loss: 1.4930 - val_accuracy: 0.2143\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4275 - accuracy: 0.4821 - val_loss: 1.4993 - val_accuracy: 0.2143\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4192 - accuracy: 0.5000 - val_loss: 1.5039 - val_accuracy: 0.2143\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4150 - accuracy: 0.5179 - val_loss: 1.5054 - val_accuracy: 0.2143\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4246 - accuracy: 0.3929 - val_loss: 1.5022 - val_accuracy: 0.2143\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4220 - accuracy: 0.4286 - val_loss: 1.4997 - val_accuracy: 0.2143\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4132 - accuracy: 0.4643 - val_loss: 1.4965 - val_accuracy: 0.2143\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4029 - accuracy: 0.4464 - val_loss: 1.4926 - val_accuracy: 0.2143\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4124 - accuracy: 0.4286 - val_loss: 1.4908 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4189 - accuracy: 0.4821 - val_loss: 1.4911 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4087 - accuracy: 0.5000 - val_loss: 1.4885 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4051 - accuracy: 0.5000 - val_loss: 1.4895 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4010 - accuracy: 0.4286 - val_loss: 1.4936 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3954 - accuracy: 0.5179 - val_loss: 1.4986 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3861 - accuracy: 0.4821 - val_loss: 1.5072 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3952 - accuracy: 0.5000 - val_loss: 1.5140 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3990 - accuracy: 0.4286 - val_loss: 1.5164 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3786 - accuracy: 0.4821 - val_loss: 1.5190 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3599 - accuracy: 0.5357 - val_loss: 1.5204 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3799 - accuracy: 0.5000 - val_loss: 1.5240 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3733 - accuracy: 0.4107 - val_loss: 1.5247 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3584 - accuracy: 0.4464 - val_loss: 1.5254 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3632 - accuracy: 0.4643 - val_loss: 1.5245 - val_accuracy: 0.1429\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3479 - accuracy: 0.5357 - val_loss: 1.5285 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3522 - accuracy: 0.5000 - val_loss: 1.5325 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3675 - accuracy: 0.5179 - val_loss: 1.5362 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3533 - accuracy: 0.4821 - val_loss: 1.5421 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3470 - accuracy: 0.5536 - val_loss: 1.5502 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3535 - accuracy: 0.4821 - val_loss: 1.5604 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3401 - accuracy: 0.5536 - val_loss: 1.5666 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3363 - accuracy: 0.5179 - val_loss: 1.5658 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3362 - accuracy: 0.5000 - val_loss: 1.5597 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3179 - accuracy: 0.5357 - val_loss: 1.5553 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3490 - accuracy: 0.5357 - val_loss: 1.5507 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3212 - accuracy: 0.5536 - val_loss: 1.5471 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3202 - accuracy: 0.5536 - val_loss: 1.5430 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3151 - accuracy: 0.5536 - val_loss: 1.5394 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3203 - accuracy: 0.6071 - val_loss: 1.5379 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3134 - accuracy: 0.5179 - val_loss: 1.5385 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3086 - accuracy: 0.5714 - val_loss: 1.5378 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3126 - accuracy: 0.5357 - val_loss: 1.5365 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3316 - accuracy: 0.5000 - val_loss: 1.5421 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2962 - accuracy: 0.5714 - val_loss: 1.5495 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2950 - accuracy: 0.5536 - val_loss: 1.5562 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 0.2887 - accuracy: 0.5357 - val_loss: 1.5635 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2958 - accuracy: 0.5714 - val_loss: 1.5683 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2850 - accuracy: 0.5714 - val_loss: 1.5692 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2908 - accuracy: 0.5536 - val_loss: 1.5661 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2884 - accuracy: 0.5893 - val_loss: 1.5565 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2850 - accuracy: 0.5536 - val_loss: 1.5505 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2595 - accuracy: 0.5536 - val_loss: 1.5496 - val_accuracy: 0.1429\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2811 - accuracy: 0.6071 - val_loss: 1.5507 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2655 - accuracy: 0.5714 - val_loss: 1.5534 - val_accuracy: 0.1429\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2827 - accuracy: 0.5357 - val_loss: 1.5575 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2685 - accuracy: 0.6250 - val_loss: 1.5625 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5625 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=120, wl= 7, epoch=240, batch_size=500, Scores: [1.5624533891677856, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.5624533891677856\n",
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9860 - accuracy: 0.0893 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9819 - accuracy: 0.0714 - val_loss: 1.0742 - val_accuracy: 0.0714\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.9782 - accuracy: 0.0893 - val_loss: 1.0749 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9733 - accuracy: 0.2143 - val_loss: 1.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9703 - accuracy: 0.1964 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9648 - accuracy: 0.2679 - val_loss: 1.0775 - val_accuracy: 0.0714\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9614 - accuracy: 0.2857 - val_loss: 1.0785 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9569 - accuracy: 0.2679 - val_loss: 1.0795 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9535 - accuracy: 0.2500 - val_loss: 1.0806 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9491 - accuracy: 0.2679 - val_loss: 1.0818 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9436 - accuracy: 0.3036 - val_loss: 1.0830 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9393 - accuracy: 0.2321 - val_loss: 1.0843 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9344 - accuracy: 0.3036 - val_loss: 1.0857 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9300 - accuracy: 0.2679 - val_loss: 1.0872 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9250 - accuracy: 0.2679 - val_loss: 1.0889 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.9193 - accuracy: 0.3214 - val_loss: 1.0907 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9144 - accuracy: 0.3393 - val_loss: 1.0926 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9079 - accuracy: 0.3036 - val_loss: 1.0948 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.9038 - accuracy: 0.2857 - val_loss: 1.0972 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8977 - accuracy: 0.3036 - val_loss: 1.0999 - val_accuracy: 0.2143\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.8860 - accuracy: 0.3214 - val_loss: 1.1030 - val_accuracy: 0.2143\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8847 - accuracy: 0.3214 - val_loss: 1.1064 - val_accuracy: 0.2143\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8804 - accuracy: 0.3214 - val_loss: 1.1101 - val_accuracy: 0.2143\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8717 - accuracy: 0.2857 - val_loss: 1.1142 - val_accuracy: 0.2143\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8652 - accuracy: 0.3214 - val_loss: 1.1187 - val_accuracy: 0.2143\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8606 - accuracy: 0.3036 - val_loss: 1.1234 - val_accuracy: 0.2143\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8535 - accuracy: 0.3214 - val_loss: 1.1286 - val_accuracy: 0.2143\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8523 - accuracy: 0.2679 - val_loss: 1.1338 - val_accuracy: 0.2143\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8424 - accuracy: 0.3214 - val_loss: 1.1391 - val_accuracy: 0.2143\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8395 - accuracy: 0.3214 - val_loss: 1.1446 - val_accuracy: 0.2143\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8332 - accuracy: 0.3393 - val_loss: 1.1501 - val_accuracy: 0.2143\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8273 - accuracy: 0.3393 - val_loss: 1.1558 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1558 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=32, batch_size=100, Scores: [1.1558091640472412, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.1558091640472412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9819 - accuracy: 0.1071 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9780 - accuracy: 0.1964 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9734 - accuracy: 0.2143 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9689 - accuracy: 0.3036 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9658 - accuracy: 0.2500 - val_loss: 1.0767 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.9603 - accuracy: 0.3393 - val_loss: 1.0776 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9560 - accuracy: 0.3036 - val_loss: 1.0785 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9517 - accuracy: 0.3036 - val_loss: 1.0796 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9464 - accuracy: 0.3036 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9419 - accuracy: 0.3036 - val_loss: 1.0820 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9368 - accuracy: 0.3393 - val_loss: 1.0833 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.9327 - accuracy: 0.3214 - val_loss: 1.0848 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.9264 - accuracy: 0.3036 - val_loss: 1.0864 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9219 - accuracy: 0.3036 - val_loss: 1.0881 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.9179 - accuracy: 0.3214 - val_loss: 1.0899 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9163 - accuracy: 0.2857 - val_loss: 1.0919 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9103 - accuracy: 0.3214 - val_loss: 1.0940 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9020 - accuracy: 0.3214 - val_loss: 1.0963 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8970 - accuracy: 0.3036 - val_loss: 1.0986 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8934 - accuracy: 0.3036 - val_loss: 1.1011 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8861 - accuracy: 0.3036 - val_loss: 1.1037 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8791 - accuracy: 0.3036 - val_loss: 1.1062 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8746 - accuracy: 0.3393 - val_loss: 1.1087 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8694 - accuracy: 0.2857 - val_loss: 1.1111 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8627 - accuracy: 0.3393 - val_loss: 1.1134 - val_accuracy: 0.1429\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8592 - accuracy: 0.2679 - val_loss: 1.1154 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8506 - accuracy: 0.3036 - val_loss: 1.1173 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8481 - accuracy: 0.3393 - val_loss: 1.1191 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8408 - accuracy: 0.3036 - val_loss: 1.1209 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8388 - accuracy: 0.3214 - val_loss: 1.1229 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8299 - accuracy: 0.3036 - val_loss: 1.1253 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8234 - accuracy: 0.3571 - val_loss: 1.1281 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1281 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=32, batch_size=300, Scores: [1.1280583143234253, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1280583143234253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9831 - accuracy: 0.0714 - val_loss: 1.0698 - val_accuracy: 0.1429\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9810 - accuracy: 0.0714 - val_loss: 1.0705 - val_accuracy: 0.1429\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9763 - accuracy: 0.1250 - val_loss: 1.0713 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9731 - accuracy: 0.2857 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9670 - accuracy: 0.2679 - val_loss: 1.0728 - val_accuracy: 0.0714\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9633 - accuracy: 0.2679 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9603 - accuracy: 0.1964 - val_loss: 1.0742 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9562 - accuracy: 0.3214 - val_loss: 1.0750 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9513 - accuracy: 0.3214 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9471 - accuracy: 0.2857 - val_loss: 1.0764 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9431 - accuracy: 0.2857 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9407 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9345 - accuracy: 0.3214 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9283 - accuracy: 0.3571 - val_loss: 1.0794 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9254 - accuracy: 0.3393 - val_loss: 1.0801 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9173 - accuracy: 0.3036 - val_loss: 1.0809 - val_accuracy: 0.0714\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9130 - accuracy: 0.3393 - val_loss: 1.0818 - val_accuracy: 0.0714\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9077 - accuracy: 0.3750 - val_loss: 1.0828 - val_accuracy: 0.0714\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9011 - accuracy: 0.3036 - val_loss: 1.0838 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8944 - accuracy: 0.3571 - val_loss: 1.0850 - val_accuracy: 0.0714\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8888 - accuracy: 0.3393 - val_loss: 1.0864 - val_accuracy: 0.0714\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8830 - accuracy: 0.3393 - val_loss: 1.0881 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8753 - accuracy: 0.3214 - val_loss: 1.0901 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8708 - accuracy: 0.3214 - val_loss: 1.0926 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8649 - accuracy: 0.3214 - val_loss: 1.0955 - val_accuracy: 0.2143\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8572 - accuracy: 0.3036 - val_loss: 1.0988 - val_accuracy: 0.2143\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8570 - accuracy: 0.2857 - val_loss: 1.1026 - val_accuracy: 0.2143\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8507 - accuracy: 0.3036 - val_loss: 1.1066 - val_accuracy: 0.2143\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8462 - accuracy: 0.3036 - val_loss: 1.1109 - val_accuracy: 0.2143\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8388 - accuracy: 0.3571 - val_loss: 1.1153 - val_accuracy: 0.2143\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8332 - accuracy: 0.3214 - val_loss: 1.1200 - val_accuracy: 0.2143\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8272 - accuracy: 0.2857 - val_loss: 1.1248 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1248 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=32, batch_size=400, Scores: [1.1247659921646118, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.1247659921646118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9842 - accuracy: 0.1429 - val_loss: 1.0726 - val_accuracy: 0.1429\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9793 - accuracy: 0.1964 - val_loss: 1.0728 - val_accuracy: 0.1429\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9752 - accuracy: 0.2857 - val_loss: 1.0731 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9735 - accuracy: 0.2143 - val_loss: 1.0734 - val_accuracy: 0.1429\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9683 - accuracy: 0.2679 - val_loss: 1.0738 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9638 - accuracy: 0.2500 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9597 - accuracy: 0.2500 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9540 - accuracy: 0.2679 - val_loss: 1.0752 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9525 - accuracy: 0.3036 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9479 - accuracy: 0.2857 - val_loss: 1.0764 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9436 - accuracy: 0.3036 - val_loss: 1.0772 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9398 - accuracy: 0.3393 - val_loss: 1.0780 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.9337 - accuracy: 0.3036 - val_loss: 1.0789 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.9295 - accuracy: 0.2857 - val_loss: 1.0799 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9245 - accuracy: 0.3036 - val_loss: 1.0810 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9199 - accuracy: 0.2857 - val_loss: 1.0823 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.9152 - accuracy: 0.3393 - val_loss: 1.0836 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9094 - accuracy: 0.3036 - val_loss: 1.0851 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9059 - accuracy: 0.3393 - val_loss: 1.0868 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8959 - accuracy: 0.3214 - val_loss: 1.0888 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8937 - accuracy: 0.3036 - val_loss: 1.0909 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8878 - accuracy: 0.3214 - val_loss: 1.0933 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8810 - accuracy: 0.3214 - val_loss: 1.0959 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8762 - accuracy: 0.3036 - val_loss: 1.0989 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8660 - accuracy: 0.3214 - val_loss: 1.1021 - val_accuracy: 0.1429\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8616 - accuracy: 0.3036 - val_loss: 1.1058 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8559 - accuracy: 0.3214 - val_loss: 1.1097 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8535 - accuracy: 0.3036 - val_loss: 1.1140 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8431 - accuracy: 0.3036 - val_loss: 1.1184 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8394 - accuracy: 0.3214 - val_loss: 1.1231 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8338 - accuracy: 0.2857 - val_loss: 1.1279 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8280 - accuracy: 0.3036 - val_loss: 1.1329 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1329 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=32, batch_size=500, Scores: [1.1329185962677002, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1329185962677002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9828 - accuracy: 0.1429 - val_loss: 1.0670 - val_accuracy: 0.1429\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9792 - accuracy: 0.2500 - val_loss: 1.0676 - val_accuracy: 0.2143\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9744 - accuracy: 0.3036 - val_loss: 1.0682 - val_accuracy: 0.1429\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9701 - accuracy: 0.3036 - val_loss: 1.0688 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9648 - accuracy: 0.3214 - val_loss: 1.0695 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9620 - accuracy: 0.2500 - val_loss: 1.0702 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9573 - accuracy: 0.3393 - val_loss: 1.0709 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.9522 - accuracy: 0.3036 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9481 - accuracy: 0.2857 - val_loss: 1.0724 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9438 - accuracy: 0.2857 - val_loss: 1.0733 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9387 - accuracy: 0.3214 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9327 - accuracy: 0.3036 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9265 - accuracy: 0.3036 - val_loss: 1.0761 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9235 - accuracy: 0.3036 - val_loss: 1.0772 - val_accuracy: 0.2143\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.9170 - accuracy: 0.3036 - val_loss: 1.0784 - val_accuracy: 0.2143\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9124 - accuracy: 0.3393 - val_loss: 1.0797 - val_accuracy: 0.2143\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9067 - accuracy: 0.3036 - val_loss: 1.0811 - val_accuracy: 0.2143\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9002 - accuracy: 0.3214 - val_loss: 1.0827 - val_accuracy: 0.2143\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8933 - accuracy: 0.3036 - val_loss: 1.0845 - val_accuracy: 0.2143\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8882 - accuracy: 0.2857 - val_loss: 1.0864 - val_accuracy: 0.2143\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8816 - accuracy: 0.3214 - val_loss: 1.0886 - val_accuracy: 0.2143\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8759 - accuracy: 0.2857 - val_loss: 1.0910 - val_accuracy: 0.2143\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8715 - accuracy: 0.3036 - val_loss: 1.0936 - val_accuracy: 0.2143\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8659 - accuracy: 0.2857 - val_loss: 1.0963 - val_accuracy: 0.2143\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8581 - accuracy: 0.3393 - val_loss: 1.0991 - val_accuracy: 0.2143\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8515 - accuracy: 0.3214 - val_loss: 1.1022 - val_accuracy: 0.2143\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8488 - accuracy: 0.2857 - val_loss: 1.1054 - val_accuracy: 0.2143\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8441 - accuracy: 0.3393 - val_loss: 1.1086 - val_accuracy: 0.2143\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.8369 - accuracy: 0.3214 - val_loss: 1.1121 - val_accuracy: 0.2143\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.8322 - accuracy: 0.3393 - val_loss: 1.1160 - val_accuracy: 0.2143\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8259 - accuracy: 0.3393 - val_loss: 1.1201 - val_accuracy: 0.2143\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8151 - accuracy: 0.3214 - val_loss: 1.1246 - val_accuracy: 0.2143\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8111 - accuracy: 0.3571 - val_loss: 1.1297 - val_accuracy: 0.2143\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8044 - accuracy: 0.3036 - val_loss: 1.1353 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8002 - accuracy: 0.2857 - val_loss: 1.1414 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7971 - accuracy: 0.3393 - val_loss: 1.1480 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7932 - accuracy: 0.3214 - val_loss: 1.1549 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7899 - accuracy: 0.2857 - val_loss: 1.1620 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7810 - accuracy: 0.3036 - val_loss: 1.1692 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7765 - accuracy: 0.3214 - val_loss: 1.1767 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7751 - accuracy: 0.3036 - val_loss: 1.1845 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7650 - accuracy: 0.3571 - val_loss: 1.1923 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7613 - accuracy: 0.3571 - val_loss: 1.2002 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7594 - accuracy: 0.3393 - val_loss: 1.2082 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7515 - accuracy: 0.3571 - val_loss: 1.2161 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7476 - accuracy: 0.3214 - val_loss: 1.2237 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7444 - accuracy: 0.3929 - val_loss: 1.2302 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7388 - accuracy: 0.3571 - val_loss: 1.2355 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7381 - accuracy: 0.3571 - val_loss: 1.2398 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7298 - accuracy: 0.3750 - val_loss: 1.2431 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7273 - accuracy: 0.3571 - val_loss: 1.2452 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7199 - accuracy: 0.3571 - val_loss: 1.2464 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7214 - accuracy: 0.3393 - val_loss: 1.2470 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7190 - accuracy: 0.3571 - val_loss: 1.2481 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7071 - accuracy: 0.3214 - val_loss: 1.2493 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6997 - accuracy: 0.3393 - val_loss: 1.2511 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6954 - accuracy: 0.3571 - val_loss: 1.2532 - val_accuracy: 0.0714\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6944 - accuracy: 0.3393 - val_loss: 1.2560 - val_accuracy: 0.0714\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6892 - accuracy: 0.3393 - val_loss: 1.2592 - val_accuracy: 0.0714\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6847 - accuracy: 0.3393 - val_loss: 1.2627 - val_accuracy: 0.0714\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6875 - accuracy: 0.3929 - val_loss: 1.2677 - val_accuracy: 0.0714\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6790 - accuracy: 0.3571 - val_loss: 1.2728 - val_accuracy: 0.0714\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6780 - accuracy: 0.3571 - val_loss: 1.2791 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6666 - accuracy: 0.3571 - val_loss: 1.2860 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2860 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=64, batch_size=100, Scores: [1.2859705686569214, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2859705686569214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9846 - accuracy: 0.1429 - val_loss: 1.0698 - val_accuracy: 0.0714\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9812 - accuracy: 0.1607 - val_loss: 1.0701 - val_accuracy: 0.1429\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9763 - accuracy: 0.2857 - val_loss: 1.0706 - val_accuracy: 0.1429\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9719 - accuracy: 0.3214 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9685 - accuracy: 0.3214 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9657 - accuracy: 0.3393 - val_loss: 1.0722 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9604 - accuracy: 0.3393 - val_loss: 1.0728 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9588 - accuracy: 0.3571 - val_loss: 1.0734 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9530 - accuracy: 0.3393 - val_loss: 1.0741 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9475 - accuracy: 0.3393 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.9444 - accuracy: 0.3393 - val_loss: 1.0754 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9406 - accuracy: 0.3214 - val_loss: 1.0761 - val_accuracy: 0.2143\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9335 - accuracy: 0.3571 - val_loss: 1.0769 - val_accuracy: 0.2143\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9297 - accuracy: 0.3214 - val_loss: 1.0776 - val_accuracy: 0.2143\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9251 - accuracy: 0.3036 - val_loss: 1.0785 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9217 - accuracy: 0.3214 - val_loss: 1.0793 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9142 - accuracy: 0.3036 - val_loss: 1.0803 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9095 - accuracy: 0.3036 - val_loss: 1.0814 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9027 - accuracy: 0.3036 - val_loss: 1.0827 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8978 - accuracy: 0.3036 - val_loss: 1.0841 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8938 - accuracy: 0.2857 - val_loss: 1.0859 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8846 - accuracy: 0.3036 - val_loss: 1.0879 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.8813 - accuracy: 0.3393 - val_loss: 1.0902 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8723 - accuracy: 0.2857 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8660 - accuracy: 0.3036 - val_loss: 1.0961 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8608 - accuracy: 0.3036 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8536 - accuracy: 0.2679 - val_loss: 1.1040 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8488 - accuracy: 0.3036 - val_loss: 1.1088 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8422 - accuracy: 0.2857 - val_loss: 1.1142 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.8343 - accuracy: 0.2857 - val_loss: 1.1202 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8322 - accuracy: 0.2857 - val_loss: 1.1267 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8249 - accuracy: 0.3036 - val_loss: 1.1337 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8231 - accuracy: 0.3036 - val_loss: 1.1412 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8185 - accuracy: 0.3036 - val_loss: 1.1490 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8113 - accuracy: 0.2857 - val_loss: 1.1573 - val_accuracy: 0.0714\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8080 - accuracy: 0.2857 - val_loss: 1.1658 - val_accuracy: 0.0714\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7998 - accuracy: 0.3036 - val_loss: 1.1745 - val_accuracy: 0.0714\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7954 - accuracy: 0.3214 - val_loss: 1.1833 - val_accuracy: 0.0714\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7905 - accuracy: 0.3214 - val_loss: 1.1921 - val_accuracy: 0.0714\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7853 - accuracy: 0.3036 - val_loss: 1.2005 - val_accuracy: 0.0714\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7778 - accuracy: 0.3393 - val_loss: 1.2088 - val_accuracy: 0.0714\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7752 - accuracy: 0.3036 - val_loss: 1.2167 - val_accuracy: 0.0714\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7726 - accuracy: 0.2679 - val_loss: 1.2241 - val_accuracy: 0.0714\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7657 - accuracy: 0.3036 - val_loss: 1.2310 - val_accuracy: 0.0714\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7574 - accuracy: 0.3036 - val_loss: 1.2373 - val_accuracy: 0.0714\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7542 - accuracy: 0.2679 - val_loss: 1.2431 - val_accuracy: 0.0714\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7523 - accuracy: 0.2857 - val_loss: 1.2484 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7416 - accuracy: 0.3036 - val_loss: 1.2532 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7447 - accuracy: 0.3393 - val_loss: 1.2567 - val_accuracy: 0.1429\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7359 - accuracy: 0.3036 - val_loss: 1.2596 - val_accuracy: 0.1429\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7334 - accuracy: 0.2857 - val_loss: 1.2620 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7322 - accuracy: 0.3393 - val_loss: 1.2639 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7293 - accuracy: 0.3571 - val_loss: 1.2649 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7201 - accuracy: 0.3571 - val_loss: 1.2655 - val_accuracy: 0.1429\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7190 - accuracy: 0.3571 - val_loss: 1.2659 - val_accuracy: 0.1429\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7169 - accuracy: 0.3750 - val_loss: 1.2661 - val_accuracy: 0.1429\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.7158 - accuracy: 0.3571 - val_loss: 1.2657 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7079 - accuracy: 0.3571 - val_loss: 1.2649 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7040 - accuracy: 0.3214 - val_loss: 1.2647 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7011 - accuracy: 0.3393 - val_loss: 1.2649 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6965 - accuracy: 0.3393 - val_loss: 1.2658 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6930 - accuracy: 0.3750 - val_loss: 1.2678 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6888 - accuracy: 0.3571 - val_loss: 1.2706 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6859 - accuracy: 0.3750 - val_loss: 1.2740 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2740 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=64, batch_size=300, Scores: [1.2739652395248413, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2739652395248413\n",
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9856 - accuracy: 0.0536 - val_loss: 1.0736 - val_accuracy: 0.2143\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9810 - accuracy: 0.1429 - val_loss: 1.0735 - val_accuracy: 0.1429\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9768 - accuracy: 0.2679 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9722 - accuracy: 0.2500 - val_loss: 1.0736 - val_accuracy: 0.0714\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9682 - accuracy: 0.2143 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9630 - accuracy: 0.2679 - val_loss: 1.0739 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9604 - accuracy: 0.3036 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9553 - accuracy: 0.2321 - val_loss: 1.0743 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9498 - accuracy: 0.3571 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9477 - accuracy: 0.3214 - val_loss: 1.0749 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9420 - accuracy: 0.3393 - val_loss: 1.0753 - val_accuracy: 0.0714\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9377 - accuracy: 0.3571 - val_loss: 1.0758 - val_accuracy: 0.0714\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9341 - accuracy: 0.3036 - val_loss: 1.0763 - val_accuracy: 0.0714\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9275 - accuracy: 0.3036 - val_loss: 1.0770 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9203 - accuracy: 0.3571 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9187 - accuracy: 0.3214 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9136 - accuracy: 0.3571 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9071 - accuracy: 0.3571 - val_loss: 1.0809 - val_accuracy: 0.0714\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9026 - accuracy: 0.3393 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8974 - accuracy: 0.3214 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8902 - accuracy: 0.3393 - val_loss: 1.0861 - val_accuracy: 0.0714\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8824 - accuracy: 0.3571 - val_loss: 1.0884 - val_accuracy: 0.0714\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8809 - accuracy: 0.3214 - val_loss: 1.0911 - val_accuracy: 0.0714\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8744 - accuracy: 0.3214 - val_loss: 1.0942 - val_accuracy: 0.0714\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8699 - accuracy: 0.3036 - val_loss: 1.0976 - val_accuracy: 0.0714\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8646 - accuracy: 0.3036 - val_loss: 1.1015 - val_accuracy: 0.0714\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8599 - accuracy: 0.3036 - val_loss: 1.1055 - val_accuracy: 0.0714\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8522 - accuracy: 0.2857 - val_loss: 1.1098 - val_accuracy: 0.0714\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8470 - accuracy: 0.3036 - val_loss: 1.1142 - val_accuracy: 0.0714\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8387 - accuracy: 0.3393 - val_loss: 1.1189 - val_accuracy: 0.0714\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8386 - accuracy: 0.3036 - val_loss: 1.1237 - val_accuracy: 0.0714\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8311 - accuracy: 0.3214 - val_loss: 1.1286 - val_accuracy: 0.0714\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8238 - accuracy: 0.3393 - val_loss: 1.1337 - val_accuracy: 0.0714\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8199 - accuracy: 0.3393 - val_loss: 1.1390 - val_accuracy: 0.0714\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8116 - accuracy: 0.3750 - val_loss: 1.1443 - val_accuracy: 0.0714\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8078 - accuracy: 0.3571 - val_loss: 1.1499 - val_accuracy: 0.0714\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7992 - accuracy: 0.4107 - val_loss: 1.1557 - val_accuracy: 0.0714\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7918 - accuracy: 0.3750 - val_loss: 1.1618 - val_accuracy: 0.0714\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7882 - accuracy: 0.3929 - val_loss: 1.1682 - val_accuracy: 0.0714\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7839 - accuracy: 0.4286 - val_loss: 1.1751 - val_accuracy: 0.0714\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7764 - accuracy: 0.3750 - val_loss: 1.1824 - val_accuracy: 0.0714\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7710 - accuracy: 0.3929 - val_loss: 1.1900 - val_accuracy: 0.0714\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7653 - accuracy: 0.3571 - val_loss: 1.1979 - val_accuracy: 0.0714\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7651 - accuracy: 0.3750 - val_loss: 1.2062 - val_accuracy: 0.0714\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7568 - accuracy: 0.3393 - val_loss: 1.2147 - val_accuracy: 0.0714\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7490 - accuracy: 0.3393 - val_loss: 1.2231 - val_accuracy: 0.0714\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7436 - accuracy: 0.3750 - val_loss: 1.2311 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7429 - accuracy: 0.3214 - val_loss: 1.2382 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7336 - accuracy: 0.3571 - val_loss: 1.2444 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7349 - accuracy: 0.3214 - val_loss: 1.2501 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7365 - accuracy: 0.3393 - val_loss: 1.2551 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7275 - accuracy: 0.3393 - val_loss: 1.2592 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7176 - accuracy: 0.3036 - val_loss: 1.2629 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7121 - accuracy: 0.3214 - val_loss: 1.2656 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7072 - accuracy: 0.3750 - val_loss: 1.2679 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7053 - accuracy: 0.3393 - val_loss: 1.2703 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7017 - accuracy: 0.3036 - val_loss: 1.2722 - val_accuracy: 0.0714\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6997 - accuracy: 0.3393 - val_loss: 1.2729 - val_accuracy: 0.0714\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6944 - accuracy: 0.2857 - val_loss: 1.2739 - val_accuracy: 0.0714\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6839 - accuracy: 0.3750 - val_loss: 1.2750 - val_accuracy: 0.0714\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6829 - accuracy: 0.3571 - val_loss: 1.2764 - val_accuracy: 0.0714\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6791 - accuracy: 0.3214 - val_loss: 1.2782 - val_accuracy: 0.0714\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6744 - accuracy: 0.3036 - val_loss: 1.2795 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6656 - accuracy: 0.3214 - val_loss: 1.2818 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2818 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=64, batch_size=400, Scores: [1.2818317413330078, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2818317413330078\n",
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9837 - accuracy: 0.1429 - val_loss: 1.0704 - val_accuracy: 0.0714\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9796 - accuracy: 0.2143 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9759 - accuracy: 0.2500 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9718 - accuracy: 0.2321 - val_loss: 1.0722 - val_accuracy: 0.0714\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9699 - accuracy: 0.2321 - val_loss: 1.0728 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9641 - accuracy: 0.3750 - val_loss: 1.0736 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9606 - accuracy: 0.3393 - val_loss: 1.0743 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9575 - accuracy: 0.3393 - val_loss: 1.0751 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9531 - accuracy: 0.3214 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9489 - accuracy: 0.3571 - val_loss: 1.0767 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9434 - accuracy: 0.3393 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9422 - accuracy: 0.3214 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9358 - accuracy: 0.3214 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9312 - accuracy: 0.3571 - val_loss: 1.0808 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9277 - accuracy: 0.3571 - val_loss: 1.0821 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9217 - accuracy: 0.3750 - val_loss: 1.0835 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9177 - accuracy: 0.3393 - val_loss: 1.0851 - val_accuracy: 0.0714\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9114 - accuracy: 0.3571 - val_loss: 1.0868 - val_accuracy: 0.0714\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9059 - accuracy: 0.3571 - val_loss: 1.0887 - val_accuracy: 0.0714\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9013 - accuracy: 0.3214 - val_loss: 1.0908 - val_accuracy: 0.0714\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8956 - accuracy: 0.3393 - val_loss: 1.0932 - val_accuracy: 0.0714\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8924 - accuracy: 0.3750 - val_loss: 1.0958 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8847 - accuracy: 0.3571 - val_loss: 1.0988 - val_accuracy: 0.2143\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8797 - accuracy: 0.3929 - val_loss: 1.1021 - val_accuracy: 0.2143\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8726 - accuracy: 0.3571 - val_loss: 1.1059 - val_accuracy: 0.2143\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8667 - accuracy: 0.3571 - val_loss: 1.1101 - val_accuracy: 0.2143\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8608 - accuracy: 0.2679 - val_loss: 1.1146 - val_accuracy: 0.2143\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8543 - accuracy: 0.3393 - val_loss: 1.1196 - val_accuracy: 0.2143\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8475 - accuracy: 0.3214 - val_loss: 1.1251 - val_accuracy: 0.2143\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8397 - accuracy: 0.3214 - val_loss: 1.1311 - val_accuracy: 0.2143\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8331 - accuracy: 0.3214 - val_loss: 1.1375 - val_accuracy: 0.2143\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8296 - accuracy: 0.3214 - val_loss: 1.1445 - val_accuracy: 0.2143\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8212 - accuracy: 0.2857 - val_loss: 1.1521 - val_accuracy: 0.2143\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8171 - accuracy: 0.3036 - val_loss: 1.1601 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8086 - accuracy: 0.2857 - val_loss: 1.1686 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8026 - accuracy: 0.3393 - val_loss: 1.1775 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7996 - accuracy: 0.2679 - val_loss: 1.1867 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7929 - accuracy: 0.2857 - val_loss: 1.1957 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7837 - accuracy: 0.3036 - val_loss: 1.2046 - val_accuracy: 0.2143\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7800 - accuracy: 0.2679 - val_loss: 1.2130 - val_accuracy: 0.2143\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7810 - accuracy: 0.2679 - val_loss: 1.2209 - val_accuracy: 0.2143\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7665 - accuracy: 0.2679 - val_loss: 1.2284 - val_accuracy: 0.2143\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7689 - accuracy: 0.3036 - val_loss: 1.2355 - val_accuracy: 0.2143\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7609 - accuracy: 0.2500 - val_loss: 1.2419 - val_accuracy: 0.2143\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7573 - accuracy: 0.3036 - val_loss: 1.2475 - val_accuracy: 0.2143\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7566 - accuracy: 0.3036 - val_loss: 1.2522 - val_accuracy: 0.2143\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7524 - accuracy: 0.3036 - val_loss: 1.2564 - val_accuracy: 0.2143\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7456 - accuracy: 0.3214 - val_loss: 1.2601 - val_accuracy: 0.2143\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7433 - accuracy: 0.3393 - val_loss: 1.2630 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7350 - accuracy: 0.3036 - val_loss: 1.2657 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7345 - accuracy: 0.3571 - val_loss: 1.2683 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7239 - accuracy: 0.3214 - val_loss: 1.2711 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7242 - accuracy: 0.3393 - val_loss: 1.2739 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7162 - accuracy: 0.3393 - val_loss: 1.2769 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7142 - accuracy: 0.3214 - val_loss: 1.2800 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7101 - accuracy: 0.3571 - val_loss: 1.2835 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7031 - accuracy: 0.3393 - val_loss: 1.2875 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6996 - accuracy: 0.3750 - val_loss: 1.2920 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6933 - accuracy: 0.3393 - val_loss: 1.2966 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6905 - accuracy: 0.3393 - val_loss: 1.3023 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6857 - accuracy: 0.3750 - val_loss: 1.3085 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6842 - accuracy: 0.3750 - val_loss: 1.3155 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6861 - accuracy: 0.3750 - val_loss: 1.3234 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6782 - accuracy: 0.3571 - val_loss: 1.3315 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3315 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=64, batch_size=500, Scores: [1.3314895629882812, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.3314895629882812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9827 - accuracy: 0.0179 - val_loss: 1.0707 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9802 - accuracy: 0.1429 - val_loss: 1.0712 - val_accuracy: 0.2143\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9749 - accuracy: 0.1429 - val_loss: 1.0718 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9722 - accuracy: 0.2143 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9666 - accuracy: 0.2857 - val_loss: 1.0731 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9622 - accuracy: 0.2679 - val_loss: 1.0739 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9586 - accuracy: 0.3393 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9549 - accuracy: 0.2679 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9507 - accuracy: 0.3036 - val_loss: 1.0763 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9464 - accuracy: 0.3036 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9417 - accuracy: 0.3214 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9363 - accuracy: 0.3393 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9317 - accuracy: 0.3036 - val_loss: 1.0803 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9254 - accuracy: 0.3393 - val_loss: 1.0815 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9197 - accuracy: 0.3393 - val_loss: 1.0829 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9157 - accuracy: 0.3214 - val_loss: 1.0844 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9084 - accuracy: 0.3214 - val_loss: 1.0860 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9028 - accuracy: 0.3214 - val_loss: 1.0879 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8973 - accuracy: 0.3214 - val_loss: 1.0899 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8910 - accuracy: 0.3036 - val_loss: 1.0921 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8837 - accuracy: 0.3214 - val_loss: 1.0947 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8757 - accuracy: 0.2857 - val_loss: 1.0975 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8711 - accuracy: 0.3036 - val_loss: 1.1007 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8663 - accuracy: 0.3214 - val_loss: 1.1042 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8606 - accuracy: 0.3036 - val_loss: 1.1081 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8560 - accuracy: 0.2857 - val_loss: 1.1125 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8477 - accuracy: 0.3393 - val_loss: 1.1170 - val_accuracy: 0.0714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8414 - accuracy: 0.3214 - val_loss: 1.1220 - val_accuracy: 0.0714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8358 - accuracy: 0.3214 - val_loss: 1.1274 - val_accuracy: 0.0714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8298 - accuracy: 0.3036 - val_loss: 1.1333 - val_accuracy: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8247 - accuracy: 0.3036 - val_loss: 1.1396 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8201 - accuracy: 0.2857 - val_loss: 1.1462 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8111 - accuracy: 0.3214 - val_loss: 1.1535 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8082 - accuracy: 0.3214 - val_loss: 1.1611 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7989 - accuracy: 0.3214 - val_loss: 1.1689 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7943 - accuracy: 0.3036 - val_loss: 1.1768 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7930 - accuracy: 0.3036 - val_loss: 1.1848 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7879 - accuracy: 0.3036 - val_loss: 1.1926 - val_accuracy: 0.0714\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7814 - accuracy: 0.3393 - val_loss: 1.2001 - val_accuracy: 0.0714\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7777 - accuracy: 0.3393 - val_loss: 1.2074 - val_accuracy: 0.0714\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7736 - accuracy: 0.3393 - val_loss: 1.2144 - val_accuracy: 0.0714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7668 - accuracy: 0.3393 - val_loss: 1.2209 - val_accuracy: 0.0714\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7645 - accuracy: 0.3036 - val_loss: 1.2268 - val_accuracy: 0.0714\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7699 - accuracy: 0.3214 - val_loss: 1.2324 - val_accuracy: 0.0714\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7575 - accuracy: 0.3393 - val_loss: 1.2376 - val_accuracy: 0.0714\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7528 - accuracy: 0.3214 - val_loss: 1.2422 - val_accuracy: 0.0714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7528 - accuracy: 0.3571 - val_loss: 1.2462 - val_accuracy: 0.0714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7463 - accuracy: 0.3571 - val_loss: 1.2498 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7516 - accuracy: 0.3036 - val_loss: 1.2525 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7414 - accuracy: 0.3571 - val_loss: 1.2545 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7436 - accuracy: 0.3214 - val_loss: 1.2559 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7364 - accuracy: 0.3393 - val_loss: 1.2567 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7294 - accuracy: 0.3214 - val_loss: 1.2570 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7284 - accuracy: 0.3036 - val_loss: 1.2576 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7237 - accuracy: 0.3393 - val_loss: 1.2580 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.7146 - accuracy: 0.3214 - val_loss: 1.2590 - val_accuracy: 0.1429\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7144 - accuracy: 0.3393 - val_loss: 1.2598 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7110 - accuracy: 0.3571 - val_loss: 1.2603 - val_accuracy: 0.1429\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7060 - accuracy: 0.3571 - val_loss: 1.2611 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7029 - accuracy: 0.3750 - val_loss: 1.2625 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7047 - accuracy: 0.3036 - val_loss: 1.2642 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6952 - accuracy: 0.3214 - val_loss: 1.2667 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6965 - accuracy: 0.3393 - val_loss: 1.2695 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6857 - accuracy: 0.3750 - val_loss: 1.2722 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6902 - accuracy: 0.3750 - val_loss: 1.2750 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6776 - accuracy: 0.3214 - val_loss: 1.2781 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6753 - accuracy: 0.3929 - val_loss: 1.2815 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6753 - accuracy: 0.3750 - val_loss: 1.2850 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6625 - accuracy: 0.3750 - val_loss: 1.2885 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6596 - accuracy: 0.3750 - val_loss: 1.2912 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6589 - accuracy: 0.3750 - val_loss: 1.2935 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6458 - accuracy: 0.3929 - val_loss: 1.2954 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6559 - accuracy: 0.3750 - val_loss: 1.2971 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6419 - accuracy: 0.3929 - val_loss: 1.2989 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6397 - accuracy: 0.3929 - val_loss: 1.3004 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.6345 - accuracy: 0.4286 - val_loss: 1.3027 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6385 - accuracy: 0.4107 - val_loss: 1.3051 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6266 - accuracy: 0.4107 - val_loss: 1.3085 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6185 - accuracy: 0.4286 - val_loss: 1.3131 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6163 - accuracy: 0.4107 - val_loss: 1.3176 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6116 - accuracy: 0.3750 - val_loss: 1.3220 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6021 - accuracy: 0.3929 - val_loss: 1.3268 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5997 - accuracy: 0.3929 - val_loss: 1.3312 - val_accuracy: 0.2143\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6006 - accuracy: 0.3929 - val_loss: 1.3350 - val_accuracy: 0.2143\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5890 - accuracy: 0.4286 - val_loss: 1.3383 - val_accuracy: 0.2143\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5874 - accuracy: 0.4286 - val_loss: 1.3418 - val_accuracy: 0.2143\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5957 - accuracy: 0.3750 - val_loss: 1.3465 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5778 - accuracy: 0.4107 - val_loss: 1.3530 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5784 - accuracy: 0.4643 - val_loss: 1.3608 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5658 - accuracy: 0.4107 - val_loss: 1.3686 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5617 - accuracy: 0.4464 - val_loss: 1.3743 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5691 - accuracy: 0.3929 - val_loss: 1.3784 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5533 - accuracy: 0.4464 - val_loss: 1.3828 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5491 - accuracy: 0.4464 - val_loss: 1.3875 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5443 - accuracy: 0.4464 - val_loss: 1.3939 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5477 - accuracy: 0.3929 - val_loss: 1.3989 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5238 - accuracy: 0.4286 - val_loss: 1.4013 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5315 - accuracy: 0.4464 - val_loss: 1.4033 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5122 - accuracy: 0.4107 - val_loss: 1.4056 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5193 - accuracy: 0.4286 - val_loss: 1.4082 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4082 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=100, batch_size=100, Scores: [1.408193826675415, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.408193826675415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9845 - accuracy: 0.0893 - val_loss: 1.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9809 - accuracy: 0.1071 - val_loss: 1.0681 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9757 - accuracy: 0.1607 - val_loss: 1.0684 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9720 - accuracy: 0.2500 - val_loss: 1.0687 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9680 - accuracy: 0.3036 - val_loss: 1.0690 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9630 - accuracy: 0.3393 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9595 - accuracy: 0.2857 - val_loss: 1.0698 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9546 - accuracy: 0.3393 - val_loss: 1.0702 - val_accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9512 - accuracy: 0.3036 - val_loss: 1.0706 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9471 - accuracy: 0.2679 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9418 - accuracy: 0.2857 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9376 - accuracy: 0.3214 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9320 - accuracy: 0.2857 - val_loss: 1.0725 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9271 - accuracy: 0.2857 - val_loss: 1.0731 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9209 - accuracy: 0.3036 - val_loss: 1.0737 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9160 - accuracy: 0.2857 - val_loss: 1.0744 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9107 - accuracy: 0.2857 - val_loss: 1.0753 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9043 - accuracy: 0.2857 - val_loss: 1.0764 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8981 - accuracy: 0.2857 - val_loss: 1.0776 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8950 - accuracy: 0.2857 - val_loss: 1.0791 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8887 - accuracy: 0.2679 - val_loss: 1.0807 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8840 - accuracy: 0.2857 - val_loss: 1.0826 - val_accuracy: 0.2143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8756 - accuracy: 0.2857 - val_loss: 1.0848 - val_accuracy: 0.2143\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8689 - accuracy: 0.2857 - val_loss: 1.0873 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8664 - accuracy: 0.2857 - val_loss: 1.0901 - val_accuracy: 0.2143\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8578 - accuracy: 0.2679 - val_loss: 1.0933 - val_accuracy: 0.2143\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8566 - accuracy: 0.2679 - val_loss: 1.0968 - val_accuracy: 0.2143\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8461 - accuracy: 0.2857 - val_loss: 1.1006 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8418 - accuracy: 0.3036 - val_loss: 1.1049 - val_accuracy: 0.2143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8356 - accuracy: 0.2679 - val_loss: 1.1098 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8282 - accuracy: 0.2679 - val_loss: 1.1155 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8261 - accuracy: 0.2679 - val_loss: 1.1218 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8176 - accuracy: 0.2679 - val_loss: 1.1289 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8103 - accuracy: 0.2857 - val_loss: 1.1368 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.8059 - accuracy: 0.2857 - val_loss: 1.1451 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8003 - accuracy: 0.2679 - val_loss: 1.1538 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7960 - accuracy: 0.3036 - val_loss: 1.1626 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7932 - accuracy: 0.2857 - val_loss: 1.1715 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7890 - accuracy: 0.2500 - val_loss: 1.1803 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7854 - accuracy: 0.2857 - val_loss: 1.1891 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7766 - accuracy: 0.3214 - val_loss: 1.1977 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7731 - accuracy: 0.3214 - val_loss: 1.2060 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7680 - accuracy: 0.3214 - val_loss: 1.2136 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7643 - accuracy: 0.3214 - val_loss: 1.2207 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7669 - accuracy: 0.3393 - val_loss: 1.2267 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7509 - accuracy: 0.3214 - val_loss: 1.2320 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7536 - accuracy: 0.3393 - val_loss: 1.2360 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7475 - accuracy: 0.3214 - val_loss: 1.2387 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7524 - accuracy: 0.3571 - val_loss: 1.2399 - val_accuracy: 0.0714\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7438 - accuracy: 0.3571 - val_loss: 1.2399 - val_accuracy: 0.0714\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7394 - accuracy: 0.3393 - val_loss: 1.2392 - val_accuracy: 0.0714\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7353 - accuracy: 0.3571 - val_loss: 1.2384 - val_accuracy: 0.0714\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7305 - accuracy: 0.3929 - val_loss: 1.2375 - val_accuracy: 0.0714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7215 - accuracy: 0.3750 - val_loss: 1.2366 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7215 - accuracy: 0.3393 - val_loss: 1.2355 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7149 - accuracy: 0.3571 - val_loss: 1.2352 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7103 - accuracy: 0.3750 - val_loss: 1.2346 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7094 - accuracy: 0.3750 - val_loss: 1.2346 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7042 - accuracy: 0.3750 - val_loss: 1.2355 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7055 - accuracy: 0.3571 - val_loss: 1.2376 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6986 - accuracy: 0.3750 - val_loss: 1.2405 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7015 - accuracy: 0.3571 - val_loss: 1.2431 - val_accuracy: 0.0714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6886 - accuracy: 0.3571 - val_loss: 1.2459 - val_accuracy: 0.0714\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6849 - accuracy: 0.3929 - val_loss: 1.2498 - val_accuracy: 0.0714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6832 - accuracy: 0.3571 - val_loss: 1.2540 - val_accuracy: 0.0714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6796 - accuracy: 0.3929 - val_loss: 1.2587 - val_accuracy: 0.0714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6783 - accuracy: 0.3929 - val_loss: 1.2647 - val_accuracy: 0.0714\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6702 - accuracy: 0.4286 - val_loss: 1.2712 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6689 - accuracy: 0.3750 - val_loss: 1.2787 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6664 - accuracy: 0.3571 - val_loss: 1.2860 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6603 - accuracy: 0.4107 - val_loss: 1.2937 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6484 - accuracy: 0.3929 - val_loss: 1.3012 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6501 - accuracy: 0.3929 - val_loss: 1.3074 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.6500 - accuracy: 0.3929 - val_loss: 1.3119 - val_accuracy: 0.0714\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6450 - accuracy: 0.4107 - val_loss: 1.3164 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6362 - accuracy: 0.3929 - val_loss: 1.3214 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6322 - accuracy: 0.4107 - val_loss: 1.3249 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6203 - accuracy: 0.4107 - val_loss: 1.3288 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6254 - accuracy: 0.3929 - val_loss: 1.3339 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6228 - accuracy: 0.4107 - val_loss: 1.3398 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6113 - accuracy: 0.3750 - val_loss: 1.3451 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6005 - accuracy: 0.4107 - val_loss: 1.3529 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5958 - accuracy: 0.4107 - val_loss: 1.3628 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6000 - accuracy: 0.4286 - val_loss: 1.3725 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5969 - accuracy: 0.4107 - val_loss: 1.3814 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5882 - accuracy: 0.4286 - val_loss: 1.3878 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5790 - accuracy: 0.4286 - val_loss: 1.3931 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5879 - accuracy: 0.4286 - val_loss: 1.3951 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5739 - accuracy: 0.4286 - val_loss: 1.3971 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5749 - accuracy: 0.3750 - val_loss: 1.3994 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5747 - accuracy: 0.3750 - val_loss: 1.4028 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5613 - accuracy: 0.3929 - val_loss: 1.4077 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5567 - accuracy: 0.4464 - val_loss: 1.4133 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5539 - accuracy: 0.4286 - val_loss: 1.4202 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5468 - accuracy: 0.4107 - val_loss: 1.4271 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5400 - accuracy: 0.4107 - val_loss: 1.4339 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5256 - accuracy: 0.4286 - val_loss: 1.4410 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5356 - accuracy: 0.4643 - val_loss: 1.4459 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5295 - accuracy: 0.4286 - val_loss: 1.4507 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5193 - accuracy: 0.4107 - val_loss: 1.4529 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4529 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=100, batch_size=300, Scores: [1.4529016017913818, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.4529016017913818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9831 - accuracy: 0.1607 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9795 - accuracy: 0.1964 - val_loss: 1.0724 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9749 - accuracy: 0.2500 - val_loss: 1.0731 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9713 - accuracy: 0.3036 - val_loss: 1.0739 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9681 - accuracy: 0.3036 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.9645 - accuracy: 0.3036 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.9605 - accuracy: 0.2857 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9559 - accuracy: 0.2679 - val_loss: 1.0775 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9525 - accuracy: 0.2679 - val_loss: 1.0785 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9479 - accuracy: 0.2857 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9435 - accuracy: 0.3214 - val_loss: 1.0806 - val_accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9375 - accuracy: 0.3214 - val_loss: 1.0817 - val_accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9341 - accuracy: 0.3036 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9297 - accuracy: 0.2857 - val_loss: 1.0840 - val_accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9264 - accuracy: 0.2857 - val_loss: 1.0851 - val_accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9203 - accuracy: 0.3214 - val_loss: 1.0864 - val_accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9154 - accuracy: 0.3036 - val_loss: 1.0877 - val_accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9110 - accuracy: 0.2857 - val_loss: 1.0892 - val_accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9051 - accuracy: 0.3036 - val_loss: 1.0908 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9007 - accuracy: 0.3214 - val_loss: 1.0924 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8938 - accuracy: 0.2857 - val_loss: 1.0942 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8917 - accuracy: 0.3393 - val_loss: 1.0961 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8807 - accuracy: 0.3393 - val_loss: 1.0980 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8793 - accuracy: 0.3036 - val_loss: 1.1001 - val_accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8698 - accuracy: 0.3571 - val_loss: 1.1022 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8623 - accuracy: 0.3393 - val_loss: 1.1044 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8611 - accuracy: 0.3393 - val_loss: 1.1065 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8537 - accuracy: 0.3750 - val_loss: 1.1086 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8526 - accuracy: 0.3571 - val_loss: 1.1105 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8430 - accuracy: 0.3571 - val_loss: 1.1124 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8416 - accuracy: 0.3571 - val_loss: 1.1142 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8315 - accuracy: 0.3393 - val_loss: 1.1161 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8242 - accuracy: 0.3571 - val_loss: 1.1182 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8237 - accuracy: 0.3214 - val_loss: 1.1207 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8188 - accuracy: 0.3214 - val_loss: 1.1238 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8136 - accuracy: 0.3214 - val_loss: 1.1275 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8057 - accuracy: 0.3036 - val_loss: 1.1321 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7954 - accuracy: 0.3036 - val_loss: 1.1373 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7961 - accuracy: 0.3214 - val_loss: 1.1432 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7941 - accuracy: 0.3214 - val_loss: 1.1498 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.7812 - accuracy: 0.2679 - val_loss: 1.1570 - val_accuracy: 0.2143\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7783 - accuracy: 0.3036 - val_loss: 1.1648 - val_accuracy: 0.2143\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7721 - accuracy: 0.2857 - val_loss: 1.1730 - val_accuracy: 0.2143\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7749 - accuracy: 0.3214 - val_loss: 1.1814 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7667 - accuracy: 0.3036 - val_loss: 1.1904 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7616 - accuracy: 0.2857 - val_loss: 1.1997 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7543 - accuracy: 0.2679 - val_loss: 1.2092 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7510 - accuracy: 0.3393 - val_loss: 1.2186 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7438 - accuracy: 0.3393 - val_loss: 1.2276 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7478 - accuracy: 0.3750 - val_loss: 1.2360 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7432 - accuracy: 0.3750 - val_loss: 1.2437 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7339 - accuracy: 0.3393 - val_loss: 1.2501 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7307 - accuracy: 0.3571 - val_loss: 1.2550 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7260 - accuracy: 0.3393 - val_loss: 1.2586 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7254 - accuracy: 0.3214 - val_loss: 1.2608 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7188 - accuracy: 0.3750 - val_loss: 1.2616 - val_accuracy: 0.1429\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7115 - accuracy: 0.3571 - val_loss: 1.2621 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7113 - accuracy: 0.3393 - val_loss: 1.2626 - val_accuracy: 0.1429\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7071 - accuracy: 0.3929 - val_loss: 1.2627 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6977 - accuracy: 0.3750 - val_loss: 1.2630 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7027 - accuracy: 0.3750 - val_loss: 1.2636 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6862 - accuracy: 0.4464 - val_loss: 1.2646 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6801 - accuracy: 0.4107 - val_loss: 1.2654 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6784 - accuracy: 0.3750 - val_loss: 1.2660 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6771 - accuracy: 0.4286 - val_loss: 1.2668 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6711 - accuracy: 0.4286 - val_loss: 1.2689 - val_accuracy: 0.0714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6685 - accuracy: 0.4107 - val_loss: 1.2719 - val_accuracy: 0.0714\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6604 - accuracy: 0.4464 - val_loss: 1.2753 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6588 - accuracy: 0.4286 - val_loss: 1.2791 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6542 - accuracy: 0.4107 - val_loss: 1.2838 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6555 - accuracy: 0.4107 - val_loss: 1.2883 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6457 - accuracy: 0.3929 - val_loss: 1.2926 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6342 - accuracy: 0.4286 - val_loss: 1.2980 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6458 - accuracy: 0.4464 - val_loss: 1.3027 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.6335 - accuracy: 0.4107 - val_loss: 1.3065 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.6268 - accuracy: 0.3393 - val_loss: 1.3101 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.6203 - accuracy: 0.3929 - val_loss: 1.3147 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6212 - accuracy: 0.3750 - val_loss: 1.3211 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6122 - accuracy: 0.4107 - val_loss: 1.3289 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6080 - accuracy: 0.4286 - val_loss: 1.3364 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5997 - accuracy: 0.3750 - val_loss: 1.3456 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5969 - accuracy: 0.3571 - val_loss: 1.3535 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5797 - accuracy: 0.3750 - val_loss: 1.3599 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5867 - accuracy: 0.3750 - val_loss: 1.3676 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5817 - accuracy: 0.3929 - val_loss: 1.3764 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5744 - accuracy: 0.4107 - val_loss: 1.3852 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5672 - accuracy: 0.3750 - val_loss: 1.3933 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5657 - accuracy: 0.4286 - val_loss: 1.3994 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5588 - accuracy: 0.3393 - val_loss: 1.4030 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5592 - accuracy: 0.3750 - val_loss: 1.4102 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5416 - accuracy: 0.3750 - val_loss: 1.4179 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5433 - accuracy: 0.3929 - val_loss: 1.4227 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5313 - accuracy: 0.3750 - val_loss: 1.4285 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5210 - accuracy: 0.4107 - val_loss: 1.4347 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5186 - accuracy: 0.3750 - val_loss: 1.4401 - val_accuracy: 0.0714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5220 - accuracy: 0.3750 - val_loss: 1.4445 - val_accuracy: 0.0714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5043 - accuracy: 0.3571 - val_loss: 1.4450 - val_accuracy: 0.0714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5086 - accuracy: 0.4107 - val_loss: 1.4482 - val_accuracy: 0.0714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5016 - accuracy: 0.3750 - val_loss: 1.4569 - val_accuracy: 0.0714\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4998 - accuracy: 0.4107 - val_loss: 1.4648 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4648 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=100, batch_size=400, Scores: [1.464816689491272, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.464816689491272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9844 - accuracy: 0.1250 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9804 - accuracy: 0.0893 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9755 - accuracy: 0.1429 - val_loss: 1.0724 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9703 - accuracy: 0.1786 - val_loss: 1.0728 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9670 - accuracy: 0.3036 - val_loss: 1.0733 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9621 - accuracy: 0.2679 - val_loss: 1.0738 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9570 - accuracy: 0.2679 - val_loss: 1.0743 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9525 - accuracy: 0.2321 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9469 - accuracy: 0.2321 - val_loss: 1.0753 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9448 - accuracy: 0.2679 - val_loss: 1.0759 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.9388 - accuracy: 0.2321 - val_loss: 1.0765 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9327 - accuracy: 0.2857 - val_loss: 1.0770 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9284 - accuracy: 0.3036 - val_loss: 1.0776 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9244 - accuracy: 0.3036 - val_loss: 1.0782 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9177 - accuracy: 0.3214 - val_loss: 1.0789 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9110 - accuracy: 0.3036 - val_loss: 1.0797 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9076 - accuracy: 0.2857 - val_loss: 1.0807 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.8971 - accuracy: 0.3036 - val_loss: 1.0819 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8948 - accuracy: 0.2857 - val_loss: 1.0834 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8877 - accuracy: 0.3036 - val_loss: 1.0851 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8822 - accuracy: 0.2679 - val_loss: 1.0873 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8740 - accuracy: 0.2857 - val_loss: 1.0900 - val_accuracy: 0.2143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.8705 - accuracy: 0.2857 - val_loss: 1.0931 - val_accuracy: 0.2143\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8620 - accuracy: 0.2679 - val_loss: 1.0968 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8626 - accuracy: 0.2679 - val_loss: 1.1011 - val_accuracy: 0.2143\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8539 - accuracy: 0.3036 - val_loss: 1.1058 - val_accuracy: 0.2143\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8538 - accuracy: 0.3214 - val_loss: 1.1109 - val_accuracy: 0.2143\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8421 - accuracy: 0.3036 - val_loss: 1.1163 - val_accuracy: 0.2143\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8391 - accuracy: 0.2857 - val_loss: 1.1221 - val_accuracy: 0.2143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8356 - accuracy: 0.3036 - val_loss: 1.1283 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8288 - accuracy: 0.3036 - val_loss: 1.1349 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8260 - accuracy: 0.3214 - val_loss: 1.1418 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8202 - accuracy: 0.3214 - val_loss: 1.1491 - val_accuracy: 0.2143\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8099 - accuracy: 0.3214 - val_loss: 1.1569 - val_accuracy: 0.2143\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8065 - accuracy: 0.3393 - val_loss: 1.1651 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8055 - accuracy: 0.3393 - val_loss: 1.1737 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7943 - accuracy: 0.3750 - val_loss: 1.1823 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7948 - accuracy: 0.3214 - val_loss: 1.1912 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7910 - accuracy: 0.3571 - val_loss: 1.2000 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.7864 - accuracy: 0.3571 - val_loss: 1.2087 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7836 - accuracy: 0.3393 - val_loss: 1.2171 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7774 - accuracy: 0.3393 - val_loss: 1.2253 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7765 - accuracy: 0.3571 - val_loss: 1.2330 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.7738 - accuracy: 0.3214 - val_loss: 1.2399 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7704 - accuracy: 0.3214 - val_loss: 1.2461 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7607 - accuracy: 0.3750 - val_loss: 1.2512 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7627 - accuracy: 0.3571 - val_loss: 1.2553 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7579 - accuracy: 0.3214 - val_loss: 1.2581 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7546 - accuracy: 0.3750 - val_loss: 1.2597 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7475 - accuracy: 0.3571 - val_loss: 1.2604 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7459 - accuracy: 0.3214 - val_loss: 1.2601 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7393 - accuracy: 0.3571 - val_loss: 1.2597 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7392 - accuracy: 0.3750 - val_loss: 1.2589 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7318 - accuracy: 0.3393 - val_loss: 1.2581 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7286 - accuracy: 0.3571 - val_loss: 1.2572 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7216 - accuracy: 0.3571 - val_loss: 1.2564 - val_accuracy: 0.1429\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7191 - accuracy: 0.3571 - val_loss: 1.2560 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7172 - accuracy: 0.3571 - val_loss: 1.2563 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7153 - accuracy: 0.3929 - val_loss: 1.2571 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7125 - accuracy: 0.3571 - val_loss: 1.2586 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7087 - accuracy: 0.3571 - val_loss: 1.2603 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7042 - accuracy: 0.3571 - val_loss: 1.2622 - val_accuracy: 0.0714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7038 - accuracy: 0.3571 - val_loss: 1.2639 - val_accuracy: 0.0714\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6978 - accuracy: 0.3750 - val_loss: 1.2662 - val_accuracy: 0.0714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6921 - accuracy: 0.3750 - val_loss: 1.2700 - val_accuracy: 0.0714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6871 - accuracy: 0.3571 - val_loss: 1.2743 - val_accuracy: 0.0714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6826 - accuracy: 0.3571 - val_loss: 1.2797 - val_accuracy: 0.0714\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6811 - accuracy: 0.3571 - val_loss: 1.2855 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6777 - accuracy: 0.3571 - val_loss: 1.2923 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6703 - accuracy: 0.4286 - val_loss: 1.2994 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6641 - accuracy: 0.4107 - val_loss: 1.3075 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6583 - accuracy: 0.4464 - val_loss: 1.3160 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6583 - accuracy: 0.4643 - val_loss: 1.3247 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6563 - accuracy: 0.4821 - val_loss: 1.3318 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6452 - accuracy: 0.4821 - val_loss: 1.3388 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6341 - accuracy: 0.4286 - val_loss: 1.3460 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6375 - accuracy: 0.4464 - val_loss: 1.3518 - val_accuracy: 0.2143\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6340 - accuracy: 0.4464 - val_loss: 1.3574 - val_accuracy: 0.2143\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6198 - accuracy: 0.4643 - val_loss: 1.3652 - val_accuracy: 0.2143\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6256 - accuracy: 0.4464 - val_loss: 1.3743 - val_accuracy: 0.2143\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6070 - accuracy: 0.4107 - val_loss: 1.3838 - val_accuracy: 0.2143\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6042 - accuracy: 0.4643 - val_loss: 1.3947 - val_accuracy: 0.2143\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6085 - accuracy: 0.4821 - val_loss: 1.4055 - val_accuracy: 0.2143\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5905 - accuracy: 0.4643 - val_loss: 1.4152 - val_accuracy: 0.2143\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5873 - accuracy: 0.4464 - val_loss: 1.4236 - val_accuracy: 0.2143\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5863 - accuracy: 0.4643 - val_loss: 1.4318 - val_accuracy: 0.2143\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5808 - accuracy: 0.4464 - val_loss: 1.4391 - val_accuracy: 0.2143\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5811 - accuracy: 0.4464 - val_loss: 1.4446 - val_accuracy: 0.2143\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5787 - accuracy: 0.4107 - val_loss: 1.4490 - val_accuracy: 0.2143\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5669 - accuracy: 0.4464 - val_loss: 1.4530 - val_accuracy: 0.2143\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5528 - accuracy: 0.4286 - val_loss: 1.4564 - val_accuracy: 0.2143\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5666 - accuracy: 0.4286 - val_loss: 1.4603 - val_accuracy: 0.2143\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5492 - accuracy: 0.3929 - val_loss: 1.4631 - val_accuracy: 0.2143\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5439 - accuracy: 0.4107 - val_loss: 1.4697 - val_accuracy: 0.2143\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5426 - accuracy: 0.4286 - val_loss: 1.4758 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5337 - accuracy: 0.4286 - val_loss: 1.4819 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5326 - accuracy: 0.4464 - val_loss: 1.4873 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5174 - accuracy: 0.4464 - val_loss: 1.4928 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5228 - accuracy: 0.4643 - val_loss: 1.4998 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5037 - accuracy: 0.4107 - val_loss: 1.5061 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5061 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=100, batch_size=500, Scores: [1.5060577392578125, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.5060577392578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9818 - accuracy: 0.1607 - val_loss: 1.0737 - val_accuracy: 0.2143\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9794 - accuracy: 0.1250 - val_loss: 1.0739 - val_accuracy: 0.2143\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9737 - accuracy: 0.1429 - val_loss: 1.0741 - val_accuracy: 0.2143\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.9715 - accuracy: 0.2143 - val_loss: 1.0743 - val_accuracy: 0.2143\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9661 - accuracy: 0.2321 - val_loss: 1.0745 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9609 - accuracy: 0.3036 - val_loss: 1.0748 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9579 - accuracy: 0.3036 - val_loss: 1.0751 - val_accuracy: 0.2143\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9529 - accuracy: 0.3036 - val_loss: 1.0754 - val_accuracy: 0.2143\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9490 - accuracy: 0.2679 - val_loss: 1.0757 - val_accuracy: 0.2143\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9453 - accuracy: 0.3036 - val_loss: 1.0761 - val_accuracy: 0.2143\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9388 - accuracy: 0.3036 - val_loss: 1.0765 - val_accuracy: 0.2143\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9346 - accuracy: 0.3036 - val_loss: 1.0769 - val_accuracy: 0.2143\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9305 - accuracy: 0.2857 - val_loss: 1.0774 - val_accuracy: 0.2143\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9249 - accuracy: 0.3214 - val_loss: 1.0780 - val_accuracy: 0.2143\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9219 - accuracy: 0.3214 - val_loss: 1.0786 - val_accuracy: 0.2143\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9151 - accuracy: 0.2500 - val_loss: 1.0793 - val_accuracy: 0.2143\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9103 - accuracy: 0.3214 - val_loss: 1.0801 - val_accuracy: 0.2143\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9016 - accuracy: 0.3036 - val_loss: 1.0810 - val_accuracy: 0.2143\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8995 - accuracy: 0.2679 - val_loss: 1.0821 - val_accuracy: 0.2143\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8919 - accuracy: 0.2679 - val_loss: 1.0834 - val_accuracy: 0.2143\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.8859 - accuracy: 0.2857 - val_loss: 1.0850 - val_accuracy: 0.2143\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8809 - accuracy: 0.2679 - val_loss: 1.0869 - val_accuracy: 0.2143\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8772 - accuracy: 0.3036 - val_loss: 1.0889 - val_accuracy: 0.2143\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8713 - accuracy: 0.3214 - val_loss: 1.0914 - val_accuracy: 0.2143\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8659 - accuracy: 0.2679 - val_loss: 1.0941 - val_accuracy: 0.2143\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8614 - accuracy: 0.2857 - val_loss: 1.0973 - val_accuracy: 0.2857\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8543 - accuracy: 0.3571 - val_loss: 1.1008 - val_accuracy: 0.2857\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8510 - accuracy: 0.3393 - val_loss: 1.1047 - val_accuracy: 0.2857\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8445 - accuracy: 0.3571 - val_loss: 1.1090 - val_accuracy: 0.2857\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8379 - accuracy: 0.3393 - val_loss: 1.1136 - val_accuracy: 0.2857\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8306 - accuracy: 0.3571 - val_loss: 1.1186 - val_accuracy: 0.2857\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8273 - accuracy: 0.3750 - val_loss: 1.1238 - val_accuracy: 0.2857\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8240 - accuracy: 0.3393 - val_loss: 1.1292 - val_accuracy: 0.2857\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8200 - accuracy: 0.3393 - val_loss: 1.1349 - val_accuracy: 0.2857\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8149 - accuracy: 0.3393 - val_loss: 1.1409 - val_accuracy: 0.2857\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8128 - accuracy: 0.3393 - val_loss: 1.1472 - val_accuracy: 0.2857\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8020 - accuracy: 0.3571 - val_loss: 1.1535 - val_accuracy: 0.2857\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8062 - accuracy: 0.3571 - val_loss: 1.1601 - val_accuracy: 0.2143\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7993 - accuracy: 0.3393 - val_loss: 1.1667 - val_accuracy: 0.2143\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7850 - accuracy: 0.3929 - val_loss: 1.1736 - val_accuracy: 0.2143\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.7840 - accuracy: 0.3571 - val_loss: 1.1805 - val_accuracy: 0.2143\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.7777 - accuracy: 0.3750 - val_loss: 1.1871 - val_accuracy: 0.2143\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7720 - accuracy: 0.3214 - val_loss: 1.1935 - val_accuracy: 0.2143\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7708 - accuracy: 0.3571 - val_loss: 1.2001 - val_accuracy: 0.2143\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7658 - accuracy: 0.3750 - val_loss: 1.2066 - val_accuracy: 0.2143\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7629 - accuracy: 0.3750 - val_loss: 1.2127 - val_accuracy: 0.2143\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7609 - accuracy: 0.3571 - val_loss: 1.2184 - val_accuracy: 0.2143\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.7484 - accuracy: 0.3393 - val_loss: 1.2240 - val_accuracy: 0.2143\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7543 - accuracy: 0.3571 - val_loss: 1.2290 - val_accuracy: 0.2143\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7416 - accuracy: 0.3571 - val_loss: 1.2336 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7444 - accuracy: 0.3750 - val_loss: 1.2371 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7428 - accuracy: 0.4107 - val_loss: 1.2397 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7367 - accuracy: 0.3571 - val_loss: 1.2419 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7357 - accuracy: 0.4107 - val_loss: 1.2440 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7297 - accuracy: 0.3929 - val_loss: 1.2461 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7271 - accuracy: 0.3929 - val_loss: 1.2484 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7227 - accuracy: 0.3750 - val_loss: 1.2506 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7114 - accuracy: 0.3750 - val_loss: 1.2525 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7165 - accuracy: 0.3750 - val_loss: 1.2543 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7071 - accuracy: 0.3750 - val_loss: 1.2562 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7049 - accuracy: 0.3929 - val_loss: 1.2582 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6943 - accuracy: 0.3571 - val_loss: 1.2607 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6934 - accuracy: 0.3571 - val_loss: 1.2631 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6933 - accuracy: 0.3571 - val_loss: 1.2662 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6851 - accuracy: 0.3750 - val_loss: 1.2697 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6755 - accuracy: 0.3750 - val_loss: 1.2738 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6797 - accuracy: 0.3750 - val_loss: 1.2784 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6730 - accuracy: 0.3571 - val_loss: 1.2836 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6700 - accuracy: 0.3571 - val_loss: 1.2895 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6638 - accuracy: 0.3571 - val_loss: 1.2961 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6564 - accuracy: 0.3750 - val_loss: 1.3034 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6582 - accuracy: 0.3750 - val_loss: 1.3114 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6488 - accuracy: 0.3750 - val_loss: 1.3193 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6389 - accuracy: 0.3571 - val_loss: 1.3277 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6394 - accuracy: 0.3750 - val_loss: 1.3354 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6358 - accuracy: 0.3750 - val_loss: 1.3440 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6306 - accuracy: 0.3571 - val_loss: 1.3531 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6251 - accuracy: 0.4107 - val_loss: 1.3626 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6222 - accuracy: 0.3750 - val_loss: 1.3716 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6182 - accuracy: 0.3929 - val_loss: 1.3795 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6071 - accuracy: 0.4107 - val_loss: 1.3879 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6099 - accuracy: 0.3750 - val_loss: 1.3952 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5983 - accuracy: 0.4107 - val_loss: 1.4049 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6036 - accuracy: 0.4107 - val_loss: 1.4141 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5988 - accuracy: 0.3929 - val_loss: 1.4201 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5969 - accuracy: 0.3750 - val_loss: 1.4234 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.5815 - accuracy: 0.4464 - val_loss: 1.4261 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5860 - accuracy: 0.4286 - val_loss: 1.4299 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5815 - accuracy: 0.4464 - val_loss: 1.4333 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5784 - accuracy: 0.4286 - val_loss: 1.4386 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5655 - accuracy: 0.3750 - val_loss: 1.4421 - val_accuracy: 0.0714\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5677 - accuracy: 0.3929 - val_loss: 1.4443 - val_accuracy: 0.0714\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5684 - accuracy: 0.3929 - val_loss: 1.4448 - val_accuracy: 0.0714\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5579 - accuracy: 0.4107 - val_loss: 1.4452 - val_accuracy: 0.0714\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5401 - accuracy: 0.4107 - val_loss: 1.4457 - val_accuracy: 0.0714\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5364 - accuracy: 0.4464 - val_loss: 1.4478 - val_accuracy: 0.0714\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5366 - accuracy: 0.4286 - val_loss: 1.4509 - val_accuracy: 0.0714\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5294 - accuracy: 0.3750 - val_loss: 1.4573 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5330 - accuracy: 0.3750 - val_loss: 1.4657 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5263 - accuracy: 0.4464 - val_loss: 1.4723 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5182 - accuracy: 0.4107 - val_loss: 1.4766 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5203 - accuracy: 0.4286 - val_loss: 1.4781 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5095 - accuracy: 0.4286 - val_loss: 1.4783 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5016 - accuracy: 0.3750 - val_loss: 1.4747 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4987 - accuracy: 0.3929 - val_loss: 1.4713 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4939 - accuracy: 0.4107 - val_loss: 1.4684 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4912 - accuracy: 0.4107 - val_loss: 1.4714 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4755 - accuracy: 0.4464 - val_loss: 1.4787 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4731 - accuracy: 0.4464 - val_loss: 1.4845 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4711 - accuracy: 0.4821 - val_loss: 1.4918 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4633 - accuracy: 0.4286 - val_loss: 1.5011 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4657 - accuracy: 0.4107 - val_loss: 1.5136 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4611 - accuracy: 0.4107 - val_loss: 1.5214 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.4539 - accuracy: 0.3929 - val_loss: 1.5242 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4380 - accuracy: 0.4286 - val_loss: 1.5222 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4427 - accuracy: 0.3929 - val_loss: 1.5174 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4444 - accuracy: 0.4821 - val_loss: 1.5131 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4203 - accuracy: 0.4643 - val_loss: 1.5061 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4268 - accuracy: 0.4107 - val_loss: 1.5001 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4145 - accuracy: 0.4821 - val_loss: 1.5013 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3992 - accuracy: 0.4821 - val_loss: 1.5089 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4086 - accuracy: 0.4464 - val_loss: 1.5232 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3993 - accuracy: 0.4464 - val_loss: 1.5395 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3887 - accuracy: 0.4643 - val_loss: 1.5519 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3817 - accuracy: 0.4821 - val_loss: 1.5557 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3992 - accuracy: 0.5179 - val_loss: 1.5451 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3760 - accuracy: 0.5000 - val_loss: 1.5352 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3802 - accuracy: 0.4821 - val_loss: 1.5202 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5202 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=128, batch_size=100, Scores: [1.5202052593231201, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.5202052593231201\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9838 - accuracy: 0.0893 - val_loss: 1.0689 - val_accuracy: 0.2143\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9814 - accuracy: 0.1607 - val_loss: 1.0690 - val_accuracy: 0.1429\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9756 - accuracy: 0.1786 - val_loss: 1.0691 - val_accuracy: 0.1429\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.9725 - accuracy: 0.2857 - val_loss: 1.0692 - val_accuracy: 0.1429\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9686 - accuracy: 0.3036 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.9645 - accuracy: 0.3036 - val_loss: 1.0697 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9601 - accuracy: 0.2857 - val_loss: 1.0700 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9552 - accuracy: 0.3393 - val_loss: 1.0703 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9503 - accuracy: 0.3214 - val_loss: 1.0706 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9453 - accuracy: 0.3214 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9427 - accuracy: 0.3214 - val_loss: 1.0714 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9376 - accuracy: 0.3571 - val_loss: 1.0719 - val_accuracy: 0.1429\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.9324 - accuracy: 0.3214 - val_loss: 1.0725 - val_accuracy: 0.1429\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9272 - accuracy: 0.3214 - val_loss: 1.0730 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9227 - accuracy: 0.3214 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9148 - accuracy: 0.3214 - val_loss: 1.0745 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9106 - accuracy: 0.3214 - val_loss: 1.0754 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9042 - accuracy: 0.3393 - val_loss: 1.0764 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8980 - accuracy: 0.3571 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8922 - accuracy: 0.3393 - val_loss: 1.0791 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8833 - accuracy: 0.3393 - val_loss: 1.0808 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.8783 - accuracy: 0.3036 - val_loss: 1.0828 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8734 - accuracy: 0.3036 - val_loss: 1.0852 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8658 - accuracy: 0.3571 - val_loss: 1.0879 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8587 - accuracy: 0.3214 - val_loss: 1.0910 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8536 - accuracy: 0.3214 - val_loss: 1.0946 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8476 - accuracy: 0.3036 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8431 - accuracy: 0.3036 - val_loss: 1.1027 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8361 - accuracy: 0.3750 - val_loss: 1.1073 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8276 - accuracy: 0.3036 - val_loss: 1.1123 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.8240 - accuracy: 0.3214 - val_loss: 1.1178 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8172 - accuracy: 0.2679 - val_loss: 1.1238 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.8107 - accuracy: 0.2857 - val_loss: 1.1304 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8073 - accuracy: 0.2857 - val_loss: 1.1377 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8011 - accuracy: 0.3036 - val_loss: 1.1453 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7958 - accuracy: 0.2679 - val_loss: 1.1534 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7914 - accuracy: 0.3393 - val_loss: 1.1619 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7921 - accuracy: 0.3214 - val_loss: 1.1707 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7850 - accuracy: 0.3571 - val_loss: 1.1796 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7792 - accuracy: 0.3036 - val_loss: 1.1885 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7747 - accuracy: 0.3571 - val_loss: 1.1973 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7738 - accuracy: 0.3393 - val_loss: 1.2052 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7659 - accuracy: 0.3750 - val_loss: 1.2129 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7639 - accuracy: 0.3393 - val_loss: 1.2198 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7606 - accuracy: 0.3393 - val_loss: 1.2259 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7542 - accuracy: 0.3571 - val_loss: 1.2307 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7480 - accuracy: 0.3571 - val_loss: 1.2346 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7533 - accuracy: 0.3929 - val_loss: 1.2374 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7460 - accuracy: 0.3571 - val_loss: 1.2391 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7387 - accuracy: 0.3571 - val_loss: 1.2402 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7320 - accuracy: 0.3750 - val_loss: 1.2408 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7334 - accuracy: 0.3750 - val_loss: 1.2412 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7278 - accuracy: 0.3750 - val_loss: 1.2417 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7218 - accuracy: 0.3750 - val_loss: 1.2417 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7180 - accuracy: 0.3750 - val_loss: 1.2419 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7139 - accuracy: 0.3929 - val_loss: 1.2425 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7137 - accuracy: 0.3929 - val_loss: 1.2436 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7026 - accuracy: 0.3750 - val_loss: 1.2452 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7119 - accuracy: 0.3750 - val_loss: 1.2473 - val_accuracy: 0.0714\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7019 - accuracy: 0.3571 - val_loss: 1.2495 - val_accuracy: 0.0714\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6977 - accuracy: 0.3571 - val_loss: 1.2525 - val_accuracy: 0.0714\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6961 - accuracy: 0.3750 - val_loss: 1.2561 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6844 - accuracy: 0.3750 - val_loss: 1.2608 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6842 - accuracy: 0.3929 - val_loss: 1.2662 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6668 - accuracy: 0.3750 - val_loss: 1.2724 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6846 - accuracy: 0.3571 - val_loss: 1.2786 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6687 - accuracy: 0.3393 - val_loss: 1.2849 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6605 - accuracy: 0.3929 - val_loss: 1.2917 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6619 - accuracy: 0.3750 - val_loss: 1.2983 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6621 - accuracy: 0.4107 - val_loss: 1.3054 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6513 - accuracy: 0.3929 - val_loss: 1.3124 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6498 - accuracy: 0.3929 - val_loss: 1.3206 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6363 - accuracy: 0.3929 - val_loss: 1.3291 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6480 - accuracy: 0.4107 - val_loss: 1.3381 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6273 - accuracy: 0.3929 - val_loss: 1.3480 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6237 - accuracy: 0.4464 - val_loss: 1.3573 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6289 - accuracy: 0.4107 - val_loss: 1.3661 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6170 - accuracy: 0.4286 - val_loss: 1.3739 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6155 - accuracy: 0.3929 - val_loss: 1.3823 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6121 - accuracy: 0.3929 - val_loss: 1.3894 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6065 - accuracy: 0.4286 - val_loss: 1.3970 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6023 - accuracy: 0.3750 - val_loss: 1.4035 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5988 - accuracy: 0.4286 - val_loss: 1.4100 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5972 - accuracy: 0.4107 - val_loss: 1.4165 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5883 - accuracy: 0.4464 - val_loss: 1.4224 - val_accuracy: 0.0714\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5911 - accuracy: 0.3929 - val_loss: 1.4279 - val_accuracy: 0.0714\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5870 - accuracy: 0.4286 - val_loss: 1.4315 - val_accuracy: 0.0714\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5748 - accuracy: 0.4286 - val_loss: 1.4365 - val_accuracy: 0.0714\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5643 - accuracy: 0.4643 - val_loss: 1.4410 - val_accuracy: 0.0714\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5688 - accuracy: 0.4464 - val_loss: 1.4451 - val_accuracy: 0.0714\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5545 - accuracy: 0.4107 - val_loss: 1.4488 - val_accuracy: 0.0714\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5617 - accuracy: 0.4464 - val_loss: 1.4513 - val_accuracy: 0.0714\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5564 - accuracy: 0.4464 - val_loss: 1.4536 - val_accuracy: 0.0714\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5505 - accuracy: 0.4464 - val_loss: 1.4562 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5513 - accuracy: 0.4286 - val_loss: 1.4608 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5376 - accuracy: 0.4464 - val_loss: 1.4662 - val_accuracy: 0.0714\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5335 - accuracy: 0.4286 - val_loss: 1.4682 - val_accuracy: 0.0714\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5322 - accuracy: 0.4286 - val_loss: 1.4692 - val_accuracy: 0.0714\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5166 - accuracy: 0.4643 - val_loss: 1.4710 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5170 - accuracy: 0.4464 - val_loss: 1.4747 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5165 - accuracy: 0.4643 - val_loss: 1.4801 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5172 - accuracy: 0.4643 - val_loss: 1.4841 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5093 - accuracy: 0.4643 - val_loss: 1.4872 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.4981 - accuracy: 0.5000 - val_loss: 1.4889 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.4937 - accuracy: 0.4286 - val_loss: 1.4895 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4912 - accuracy: 0.4286 - val_loss: 1.4905 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4905 - accuracy: 0.4286 - val_loss: 1.4926 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4817 - accuracy: 0.4643 - val_loss: 1.4954 - val_accuracy: 0.1429\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4673 - accuracy: 0.4643 - val_loss: 1.4973 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4801 - accuracy: 0.4464 - val_loss: 1.4978 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4702 - accuracy: 0.5000 - val_loss: 1.5006 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4652 - accuracy: 0.4821 - val_loss: 1.5020 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4522 - accuracy: 0.4643 - val_loss: 1.4989 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4503 - accuracy: 0.4643 - val_loss: 1.4955 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4461 - accuracy: 0.4643 - val_loss: 1.4940 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4570 - accuracy: 0.5000 - val_loss: 1.4931 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.4412 - accuracy: 0.5000 - val_loss: 1.4923 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4332 - accuracy: 0.5357 - val_loss: 1.4936 - val_accuracy: 0.2143\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4257 - accuracy: 0.5179 - val_loss: 1.4929 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4368 - accuracy: 0.5000 - val_loss: 1.4923 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4090 - accuracy: 0.5000 - val_loss: 1.4882 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4104 - accuracy: 0.5179 - val_loss: 1.4829 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4159 - accuracy: 0.5179 - val_loss: 1.4776 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4060 - accuracy: 0.5000 - val_loss: 1.4769 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4045 - accuracy: 0.5179 - val_loss: 1.4816 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4044 - accuracy: 0.5357 - val_loss: 1.4811 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3951 - accuracy: 0.5536 - val_loss: 1.4797 - val_accuracy: 0.2143\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3849 - accuracy: 0.5893 - val_loss: 1.4805 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4805 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=128, batch_size=300, Scores: [1.4804843664169312, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.4804843664169312\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9835 - accuracy: 0.1964 - val_loss: 1.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9800 - accuracy: 0.2143 - val_loss: 1.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9764 - accuracy: 0.2500 - val_loss: 1.0702 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9729 - accuracy: 0.3036 - val_loss: 1.0706 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9676 - accuracy: 0.2857 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9645 - accuracy: 0.2857 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9604 - accuracy: 0.2857 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9560 - accuracy: 0.3214 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9520 - accuracy: 0.2321 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9470 - accuracy: 0.2321 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9437 - accuracy: 0.2321 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9380 - accuracy: 0.2500 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9337 - accuracy: 0.2679 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9312 - accuracy: 0.2321 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.9238 - accuracy: 0.2679 - val_loss: 1.0769 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9175 - accuracy: 0.2679 - val_loss: 1.0778 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9135 - accuracy: 0.2500 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9081 - accuracy: 0.2500 - val_loss: 1.0798 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9021 - accuracy: 0.2143 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8965 - accuracy: 0.2679 - val_loss: 1.0825 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8895 - accuracy: 0.2679 - val_loss: 1.0842 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.8848 - accuracy: 0.2321 - val_loss: 1.0861 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.8773 - accuracy: 0.2500 - val_loss: 1.0884 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.8713 - accuracy: 0.2143 - val_loss: 1.0910 - val_accuracy: 0.2143\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8635 - accuracy: 0.2679 - val_loss: 1.0940 - val_accuracy: 0.2143\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8591 - accuracy: 0.2679 - val_loss: 1.0974 - val_accuracy: 0.2143\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8509 - accuracy: 0.3036 - val_loss: 1.1014 - val_accuracy: 0.2143\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8450 - accuracy: 0.2679 - val_loss: 1.1058 - val_accuracy: 0.2143\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8395 - accuracy: 0.2857 - val_loss: 1.1107 - val_accuracy: 0.2857\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8353 - accuracy: 0.3214 - val_loss: 1.1159 - val_accuracy: 0.2857\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8349 - accuracy: 0.3036 - val_loss: 1.1214 - val_accuracy: 0.2857\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8287 - accuracy: 0.2857 - val_loss: 1.1271 - val_accuracy: 0.2143\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8194 - accuracy: 0.3036 - val_loss: 1.1329 - val_accuracy: 0.2143\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8153 - accuracy: 0.3214 - val_loss: 1.1389 - val_accuracy: 0.2143\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8113 - accuracy: 0.2857 - val_loss: 1.1451 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8040 - accuracy: 0.2857 - val_loss: 1.1516 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7963 - accuracy: 0.2857 - val_loss: 1.1584 - val_accuracy: 0.2143\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7903 - accuracy: 0.2679 - val_loss: 1.1653 - val_accuracy: 0.2143\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7881 - accuracy: 0.3214 - val_loss: 1.1726 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7828 - accuracy: 0.2857 - val_loss: 1.1800 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7802 - accuracy: 0.3036 - val_loss: 1.1876 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7721 - accuracy: 0.3036 - val_loss: 1.1952 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.7695 - accuracy: 0.2857 - val_loss: 1.2029 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7629 - accuracy: 0.3214 - val_loss: 1.2105 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7624 - accuracy: 0.3214 - val_loss: 1.2179 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7529 - accuracy: 0.3036 - val_loss: 1.2254 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7481 - accuracy: 0.3214 - val_loss: 1.2327 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7496 - accuracy: 0.3571 - val_loss: 1.2396 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7478 - accuracy: 0.3214 - val_loss: 1.2456 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7396 - accuracy: 0.3393 - val_loss: 1.2508 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7358 - accuracy: 0.3214 - val_loss: 1.2551 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7316 - accuracy: 0.3214 - val_loss: 1.2588 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7280 - accuracy: 0.3393 - val_loss: 1.2617 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7171 - accuracy: 0.3750 - val_loss: 1.2644 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7174 - accuracy: 0.3214 - val_loss: 1.2663 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7105 - accuracy: 0.3214 - val_loss: 1.2675 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.7091 - accuracy: 0.3214 - val_loss: 1.2682 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7072 - accuracy: 0.3571 - val_loss: 1.2692 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7070 - accuracy: 0.3929 - val_loss: 1.2703 - val_accuracy: 0.2143\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6921 - accuracy: 0.3571 - val_loss: 1.2722 - val_accuracy: 0.2143\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6922 - accuracy: 0.3929 - val_loss: 1.2750 - val_accuracy: 0.2143\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6916 - accuracy: 0.3750 - val_loss: 1.2784 - val_accuracy: 0.2143\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6794 - accuracy: 0.3929 - val_loss: 1.2819 - val_accuracy: 0.2143\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6833 - accuracy: 0.3393 - val_loss: 1.2863 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6717 - accuracy: 0.3571 - val_loss: 1.2911 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6653 - accuracy: 0.3750 - val_loss: 1.2955 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6652 - accuracy: 0.3393 - val_loss: 1.3000 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6631 - accuracy: 0.3571 - val_loss: 1.3054 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6622 - accuracy: 0.3750 - val_loss: 1.3108 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6483 - accuracy: 0.3929 - val_loss: 1.3171 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6456 - accuracy: 0.3571 - val_loss: 1.3247 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6488 - accuracy: 0.3571 - val_loss: 1.3312 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6425 - accuracy: 0.3571 - val_loss: 1.3386 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6355 - accuracy: 0.3214 - val_loss: 1.3460 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6313 - accuracy: 0.3750 - val_loss: 1.3541 - val_accuracy: 0.2143\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6349 - accuracy: 0.3929 - val_loss: 1.3631 - val_accuracy: 0.2143\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6183 - accuracy: 0.4464 - val_loss: 1.3732 - val_accuracy: 0.2143\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6214 - accuracy: 0.3750 - val_loss: 1.3809 - val_accuracy: 0.2143\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6135 - accuracy: 0.4286 - val_loss: 1.3878 - val_accuracy: 0.2143\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6184 - accuracy: 0.3750 - val_loss: 1.3937 - val_accuracy: 0.2143\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6054 - accuracy: 0.3571 - val_loss: 1.4001 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5971 - accuracy: 0.4107 - val_loss: 1.4072 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5893 - accuracy: 0.3929 - val_loss: 1.4149 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5849 - accuracy: 0.4286 - val_loss: 1.4225 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5851 - accuracy: 0.4286 - val_loss: 1.4302 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5768 - accuracy: 0.3929 - val_loss: 1.4372 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5802 - accuracy: 0.4107 - val_loss: 1.4416 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5517 - accuracy: 0.4464 - val_loss: 1.4457 - val_accuracy: 0.0714\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5654 - accuracy: 0.4286 - val_loss: 1.4494 - val_accuracy: 0.0714\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5640 - accuracy: 0.4286 - val_loss: 1.4547 - val_accuracy: 0.0714\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5606 - accuracy: 0.4464 - val_loss: 1.4601 - val_accuracy: 0.0714\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5577 - accuracy: 0.4107 - val_loss: 1.4641 - val_accuracy: 0.0714\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5469 - accuracy: 0.4286 - val_loss: 1.4673 - val_accuracy: 0.0714\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5374 - accuracy: 0.4107 - val_loss: 1.4707 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5312 - accuracy: 0.4464 - val_loss: 1.4725 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5275 - accuracy: 0.4107 - val_loss: 1.4745 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5227 - accuracy: 0.3929 - val_loss: 1.4772 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5192 - accuracy: 0.3929 - val_loss: 1.4817 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5174 - accuracy: 0.4107 - val_loss: 1.4849 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5107 - accuracy: 0.4107 - val_loss: 1.4875 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5121 - accuracy: 0.4464 - val_loss: 1.4895 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5093 - accuracy: 0.4464 - val_loss: 1.4922 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4935 - accuracy: 0.4643 - val_loss: 1.4941 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4990 - accuracy: 0.4286 - val_loss: 1.4952 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4784 - accuracy: 0.4464 - val_loss: 1.4937 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4795 - accuracy: 0.4643 - val_loss: 1.4934 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4682 - accuracy: 0.4464 - val_loss: 1.4942 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4706 - accuracy: 0.4464 - val_loss: 1.4946 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4745 - accuracy: 0.3929 - val_loss: 1.4937 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4627 - accuracy: 0.4464 - val_loss: 1.4948 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.4586 - accuracy: 0.4464 - val_loss: 1.4993 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4529 - accuracy: 0.4643 - val_loss: 1.5039 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4416 - accuracy: 0.4643 - val_loss: 1.5097 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4433 - accuracy: 0.4643 - val_loss: 1.5163 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4310 - accuracy: 0.4643 - val_loss: 1.5192 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4220 - accuracy: 0.4464 - val_loss: 1.5187 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4241 - accuracy: 0.4643 - val_loss: 1.5145 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3974 - accuracy: 0.4643 - val_loss: 1.5103 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3940 - accuracy: 0.4821 - val_loss: 1.5056 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4101 - accuracy: 0.4821 - val_loss: 1.5027 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4080 - accuracy: 0.5000 - val_loss: 1.5034 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4135 - accuracy: 0.4464 - val_loss: 1.5030 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3870 - accuracy: 0.4643 - val_loss: 1.5044 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3817 - accuracy: 0.5179 - val_loss: 1.5093 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3761 - accuracy: 0.4821 - val_loss: 1.5097 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.3748 - accuracy: 0.5714 - val_loss: 1.5045 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3548 - accuracy: 0.4643 - val_loss: 1.4991 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3741 - accuracy: 0.5357 - val_loss: 1.4988 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4988 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=128, batch_size=400, Scores: [1.498810887336731, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.498810887336731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9848 - accuracy: 0.1071 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9802 - accuracy: 0.2143 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9773 - accuracy: 0.2321 - val_loss: 1.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9734 - accuracy: 0.3393 - val_loss: 1.0711 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9685 - accuracy: 0.3393 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9643 - accuracy: 0.3214 - val_loss: 1.0713 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9600 - accuracy: 0.3036 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9564 - accuracy: 0.2857 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9522 - accuracy: 0.3214 - val_loss: 1.0717 - val_accuracy: 0.1429\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.9467 - accuracy: 0.2679 - val_loss: 1.0718 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.9431 - accuracy: 0.3214 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9380 - accuracy: 0.3214 - val_loss: 1.0721 - val_accuracy: 0.1429\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9320 - accuracy: 0.3036 - val_loss: 1.0722 - val_accuracy: 0.1429\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9283 - accuracy: 0.2857 - val_loss: 1.0723 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9248 - accuracy: 0.2857 - val_loss: 1.0724 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9189 - accuracy: 0.2500 - val_loss: 1.0726 - val_accuracy: 0.2143\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9113 - accuracy: 0.3393 - val_loss: 1.0728 - val_accuracy: 0.2143\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9048 - accuracy: 0.3036 - val_loss: 1.0731 - val_accuracy: 0.2143\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9003 - accuracy: 0.2857 - val_loss: 1.0735 - val_accuracy: 0.2143\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8972 - accuracy: 0.3214 - val_loss: 1.0741 - val_accuracy: 0.2143\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8895 - accuracy: 0.2679 - val_loss: 1.0748 - val_accuracy: 0.2143\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8842 - accuracy: 0.2500 - val_loss: 1.0757 - val_accuracy: 0.2143\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8743 - accuracy: 0.2321 - val_loss: 1.0769 - val_accuracy: 0.2143\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8710 - accuracy: 0.2500 - val_loss: 1.0785 - val_accuracy: 0.2143\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8623 - accuracy: 0.3036 - val_loss: 1.0804 - val_accuracy: 0.2143\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8602 - accuracy: 0.3214 - val_loss: 1.0827 - val_accuracy: 0.2143\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8540 - accuracy: 0.2679 - val_loss: 1.0855 - val_accuracy: 0.2143\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8461 - accuracy: 0.2679 - val_loss: 1.0888 - val_accuracy: 0.2143\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8412 - accuracy: 0.2679 - val_loss: 1.0927 - val_accuracy: 0.2143\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8373 - accuracy: 0.2679 - val_loss: 1.0969 - val_accuracy: 0.2143\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8324 - accuracy: 0.2857 - val_loss: 1.1018 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8297 - accuracy: 0.3214 - val_loss: 1.1072 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8200 - accuracy: 0.2857 - val_loss: 1.1131 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8153 - accuracy: 0.3036 - val_loss: 1.1195 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8095 - accuracy: 0.3393 - val_loss: 1.1264 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8081 - accuracy: 0.3036 - val_loss: 1.1336 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8005 - accuracy: 0.3571 - val_loss: 1.1411 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7934 - accuracy: 0.3036 - val_loss: 1.1488 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7937 - accuracy: 0.3214 - val_loss: 1.1565 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7859 - accuracy: 0.3214 - val_loss: 1.1641 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7817 - accuracy: 0.3393 - val_loss: 1.1718 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7739 - accuracy: 0.3393 - val_loss: 1.1794 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7727 - accuracy: 0.3393 - val_loss: 1.1867 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7635 - accuracy: 0.3393 - val_loss: 1.1934 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7615 - accuracy: 0.3393 - val_loss: 1.1994 - val_accuracy: 0.0714\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.7634 - accuracy: 0.3571 - val_loss: 1.2047 - val_accuracy: 0.0714\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7560 - accuracy: 0.3750 - val_loss: 1.2090 - val_accuracy: 0.0714\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7518 - accuracy: 0.3750 - val_loss: 1.2120 - val_accuracy: 0.0714\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7499 - accuracy: 0.3214 - val_loss: 1.2140 - val_accuracy: 0.0714\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7483 - accuracy: 0.3393 - val_loss: 1.2150 - val_accuracy: 0.0714\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7454 - accuracy: 0.3571 - val_loss: 1.2155 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7315 - accuracy: 0.3393 - val_loss: 1.2156 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7350 - accuracy: 0.3750 - val_loss: 1.2152 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7324 - accuracy: 0.3750 - val_loss: 1.2152 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7254 - accuracy: 0.3571 - val_loss: 1.2151 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7227 - accuracy: 0.3393 - val_loss: 1.2158 - val_accuracy: 0.0714\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7196 - accuracy: 0.3393 - val_loss: 1.2168 - val_accuracy: 0.0714\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7085 - accuracy: 0.4107 - val_loss: 1.2183 - val_accuracy: 0.0714\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7075 - accuracy: 0.4107 - val_loss: 1.2209 - val_accuracy: 0.0714\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7046 - accuracy: 0.3750 - val_loss: 1.2241 - val_accuracy: 0.0714\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6952 - accuracy: 0.4464 - val_loss: 1.2276 - val_accuracy: 0.0714\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6904 - accuracy: 0.3750 - val_loss: 1.2315 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6938 - accuracy: 0.4107 - val_loss: 1.2357 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6867 - accuracy: 0.4107 - val_loss: 1.2407 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6811 - accuracy: 0.4286 - val_loss: 1.2457 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6784 - accuracy: 0.3750 - val_loss: 1.2513 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6730 - accuracy: 0.3929 - val_loss: 1.2577 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6651 - accuracy: 0.4107 - val_loss: 1.2652 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6554 - accuracy: 0.3750 - val_loss: 1.2738 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6617 - accuracy: 0.3750 - val_loss: 1.2833 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6536 - accuracy: 0.3750 - val_loss: 1.2927 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6420 - accuracy: 0.4107 - val_loss: 1.3024 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6428 - accuracy: 0.4107 - val_loss: 1.3114 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6279 - accuracy: 0.3571 - val_loss: 1.3211 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6335 - accuracy: 0.3929 - val_loss: 1.3297 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6333 - accuracy: 0.4286 - val_loss: 1.3392 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6265 - accuracy: 0.4107 - val_loss: 1.3477 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6178 - accuracy: 0.3929 - val_loss: 1.3560 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6063 - accuracy: 0.3929 - val_loss: 1.3651 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6056 - accuracy: 0.3750 - val_loss: 1.3743 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5999 - accuracy: 0.3929 - val_loss: 1.3819 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5882 - accuracy: 0.4286 - val_loss: 1.3896 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6013 - accuracy: 0.4464 - val_loss: 1.3970 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.5925 - accuracy: 0.4107 - val_loss: 1.4027 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5875 - accuracy: 0.4286 - val_loss: 1.4062 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5760 - accuracy: 0.4464 - val_loss: 1.4078 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5844 - accuracy: 0.3929 - val_loss: 1.4088 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5672 - accuracy: 0.4107 - val_loss: 1.4104 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5741 - accuracy: 0.3929 - val_loss: 1.4117 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5618 - accuracy: 0.4464 - val_loss: 1.4131 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5520 - accuracy: 0.4107 - val_loss: 1.4158 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5527 - accuracy: 0.4286 - val_loss: 1.4195 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5447 - accuracy: 0.4464 - val_loss: 1.4236 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5389 - accuracy: 0.4643 - val_loss: 1.4256 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5349 - accuracy: 0.4286 - val_loss: 1.4291 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5274 - accuracy: 0.4643 - val_loss: 1.4321 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5251 - accuracy: 0.4286 - val_loss: 1.4364 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5108 - accuracy: 0.4286 - val_loss: 1.4379 - val_accuracy: 0.0714\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5162 - accuracy: 0.4286 - val_loss: 1.4389 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5025 - accuracy: 0.3929 - val_loss: 1.4450 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5125 - accuracy: 0.4286 - val_loss: 1.4481 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5090 - accuracy: 0.3929 - val_loss: 1.4541 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5032 - accuracy: 0.4286 - val_loss: 1.4563 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4930 - accuracy: 0.4286 - val_loss: 1.4564 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4836 - accuracy: 0.4286 - val_loss: 1.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4773 - accuracy: 0.4643 - val_loss: 1.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4738 - accuracy: 0.4464 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4563 - accuracy: 0.3929 - val_loss: 1.4596 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4610 - accuracy: 0.4464 - val_loss: 1.4578 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4524 - accuracy: 0.4464 - val_loss: 1.4586 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4532 - accuracy: 0.3929 - val_loss: 1.4606 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4425 - accuracy: 0.4643 - val_loss: 1.4649 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4460 - accuracy: 0.4107 - val_loss: 1.4725 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4362 - accuracy: 0.3929 - val_loss: 1.4807 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4324 - accuracy: 0.4464 - val_loss: 1.4859 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4196 - accuracy: 0.4643 - val_loss: 1.4812 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4122 - accuracy: 0.5000 - val_loss: 1.4729 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3964 - accuracy: 0.4821 - val_loss: 1.4701 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4140 - accuracy: 0.4464 - val_loss: 1.4668 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4000 - accuracy: 0.4464 - val_loss: 1.4674 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3896 - accuracy: 0.4821 - val_loss: 1.4696 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3962 - accuracy: 0.4464 - val_loss: 1.4798 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3954 - accuracy: 0.4643 - val_loss: 1.4894 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3799 - accuracy: 0.4286 - val_loss: 1.4917 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3727 - accuracy: 0.5179 - val_loss: 1.4891 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3628 - accuracy: 0.5536 - val_loss: 1.4860 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3546 - accuracy: 0.4821 - val_loss: 1.4847 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3644 - accuracy: 0.5179 - val_loss: 1.4940 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4940 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=128, batch_size=500, Scores: [1.4939559698104858, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.4939559698104858\n",
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9847 - accuracy: 0.1429 - val_loss: 1.0663 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.9791 - accuracy: 0.1607 - val_loss: 1.0670 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.9757 - accuracy: 0.1607 - val_loss: 1.0677 - val_accuracy: 0.1429\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9713 - accuracy: 0.2679 - val_loss: 1.0684 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9667 - accuracy: 0.2857 - val_loss: 1.0692 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9626 - accuracy: 0.2679 - val_loss: 1.0700 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9560 - accuracy: 0.2679 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9514 - accuracy: 0.3393 - val_loss: 1.0717 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9464 - accuracy: 0.3393 - val_loss: 1.0726 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.9450 - accuracy: 0.3036 - val_loss: 1.0735 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9366 - accuracy: 0.2857 - val_loss: 1.0745 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9336 - accuracy: 0.3036 - val_loss: 1.0756 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9273 - accuracy: 0.3214 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9218 - accuracy: 0.3214 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9164 - accuracy: 0.3214 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9107 - accuracy: 0.3214 - val_loss: 1.0812 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9058 - accuracy: 0.3214 - val_loss: 1.0829 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9006 - accuracy: 0.3571 - val_loss: 1.0849 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8922 - accuracy: 0.3393 - val_loss: 1.0872 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8862 - accuracy: 0.3036 - val_loss: 1.0897 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8808 - accuracy: 0.3214 - val_loss: 1.0924 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8764 - accuracy: 0.3214 - val_loss: 1.0953 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8705 - accuracy: 0.3393 - val_loss: 1.0983 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8689 - accuracy: 0.3214 - val_loss: 1.1012 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8595 - accuracy: 0.3393 - val_loss: 1.1042 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8519 - accuracy: 0.3214 - val_loss: 1.1070 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8494 - accuracy: 0.3214 - val_loss: 1.1094 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8471 - accuracy: 0.3393 - val_loss: 1.1117 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8384 - accuracy: 0.3393 - val_loss: 1.1138 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8313 - accuracy: 0.3036 - val_loss: 1.1161 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8231 - accuracy: 0.3571 - val_loss: 1.1187 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8213 - accuracy: 0.3393 - val_loss: 1.1218 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8180 - accuracy: 0.3214 - val_loss: 1.1255 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8094 - accuracy: 0.3750 - val_loss: 1.1302 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8054 - accuracy: 0.3214 - val_loss: 1.1358 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8015 - accuracy: 0.3393 - val_loss: 1.1422 - val_accuracy: 0.2143\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7936 - accuracy: 0.3214 - val_loss: 1.1494 - val_accuracy: 0.2143\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7913 - accuracy: 0.3214 - val_loss: 1.1573 - val_accuracy: 0.2143\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7884 - accuracy: 0.2679 - val_loss: 1.1658 - val_accuracy: 0.2143\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7811 - accuracy: 0.3393 - val_loss: 1.1745 - val_accuracy: 0.2143\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.7740 - accuracy: 0.3571 - val_loss: 1.1835 - val_accuracy: 0.2143\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7735 - accuracy: 0.3393 - val_loss: 1.1925 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7734 - accuracy: 0.3214 - val_loss: 1.2012 - val_accuracy: 0.2143\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7682 - accuracy: 0.3036 - val_loss: 1.2097 - val_accuracy: 0.2143\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7611 - accuracy: 0.3571 - val_loss: 1.2175 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7586 - accuracy: 0.3929 - val_loss: 1.2246 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7516 - accuracy: 0.3393 - val_loss: 1.2309 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7495 - accuracy: 0.3393 - val_loss: 1.2362 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7486 - accuracy: 0.3036 - val_loss: 1.2409 - val_accuracy: 0.2143\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7437 - accuracy: 0.3750 - val_loss: 1.2449 - val_accuracy: 0.2143\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7453 - accuracy: 0.3571 - val_loss: 1.2483 - val_accuracy: 0.2143\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7370 - accuracy: 0.3214 - val_loss: 1.2506 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7331 - accuracy: 0.3036 - val_loss: 1.2524 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7292 - accuracy: 0.3214 - val_loss: 1.2531 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7235 - accuracy: 0.3393 - val_loss: 1.2536 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7228 - accuracy: 0.3393 - val_loss: 1.2539 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7125 - accuracy: 0.3393 - val_loss: 1.2538 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7104 - accuracy: 0.3393 - val_loss: 1.2535 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7159 - accuracy: 0.3214 - val_loss: 1.2532 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7019 - accuracy: 0.3393 - val_loss: 1.2540 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7033 - accuracy: 0.3393 - val_loss: 1.2554 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6999 - accuracy: 0.3393 - val_loss: 1.2571 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6951 - accuracy: 0.3571 - val_loss: 1.2600 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6821 - accuracy: 0.3571 - val_loss: 1.2627 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6844 - accuracy: 0.3571 - val_loss: 1.2657 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6883 - accuracy: 0.3750 - val_loss: 1.2696 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6859 - accuracy: 0.3750 - val_loss: 1.2737 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6718 - accuracy: 0.3750 - val_loss: 1.2786 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6666 - accuracy: 0.4107 - val_loss: 1.2841 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6660 - accuracy: 0.4107 - val_loss: 1.2896 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6572 - accuracy: 0.3929 - val_loss: 1.2952 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6505 - accuracy: 0.3929 - val_loss: 1.3013 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6558 - accuracy: 0.3929 - val_loss: 1.3085 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6469 - accuracy: 0.3750 - val_loss: 1.3163 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.6461 - accuracy: 0.4286 - val_loss: 1.3244 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6308 - accuracy: 0.3929 - val_loss: 1.3326 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.6336 - accuracy: 0.3750 - val_loss: 1.3406 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6270 - accuracy: 0.4286 - val_loss: 1.3478 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6316 - accuracy: 0.3929 - val_loss: 1.3555 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6137 - accuracy: 0.4464 - val_loss: 1.3639 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6174 - accuracy: 0.4286 - val_loss: 1.3742 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6124 - accuracy: 0.3571 - val_loss: 1.3835 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5952 - accuracy: 0.3929 - val_loss: 1.3915 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5950 - accuracy: 0.3750 - val_loss: 1.3984 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5879 - accuracy: 0.4107 - val_loss: 1.4069 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5898 - accuracy: 0.4107 - val_loss: 1.4151 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5854 - accuracy: 0.3750 - val_loss: 1.4221 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5847 - accuracy: 0.3929 - val_loss: 1.4289 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5795 - accuracy: 0.4107 - val_loss: 1.4355 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5792 - accuracy: 0.4107 - val_loss: 1.4431 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5689 - accuracy: 0.3929 - val_loss: 1.4484 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5625 - accuracy: 0.4107 - val_loss: 1.4537 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5594 - accuracy: 0.4464 - val_loss: 1.4602 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5618 - accuracy: 0.3571 - val_loss: 1.4677 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5420 - accuracy: 0.3750 - val_loss: 1.4734 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5401 - accuracy: 0.3929 - val_loss: 1.4797 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5443 - accuracy: 0.3750 - val_loss: 1.4806 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5378 - accuracy: 0.4107 - val_loss: 1.4807 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5285 - accuracy: 0.3929 - val_loss: 1.4809 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5228 - accuracy: 0.4286 - val_loss: 1.4796 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5270 - accuracy: 0.4107 - val_loss: 1.4844 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5115 - accuracy: 0.4107 - val_loss: 1.4900 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4987 - accuracy: 0.4107 - val_loss: 1.4947 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4969 - accuracy: 0.4464 - val_loss: 1.4985 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4982 - accuracy: 0.4643 - val_loss: 1.5015 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5027 - accuracy: 0.4286 - val_loss: 1.5066 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4871 - accuracy: 0.4286 - val_loss: 1.5143 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4967 - accuracy: 0.3929 - val_loss: 1.5227 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4856 - accuracy: 0.4107 - val_loss: 1.5295 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4680 - accuracy: 0.4286 - val_loss: 1.5335 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4596 - accuracy: 0.4821 - val_loss: 1.5399 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4629 - accuracy: 0.4464 - val_loss: 1.5461 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4541 - accuracy: 0.4286 - val_loss: 1.5513 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4481 - accuracy: 0.4821 - val_loss: 1.5478 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4406 - accuracy: 0.4821 - val_loss: 1.5427 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4375 - accuracy: 0.4643 - val_loss: 1.5400 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4368 - accuracy: 0.4464 - val_loss: 1.5386 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4356 - accuracy: 0.4643 - val_loss: 1.5421 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4417 - accuracy: 0.4286 - val_loss: 1.5459 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4346 - accuracy: 0.4464 - val_loss: 1.5473 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4273 - accuracy: 0.4464 - val_loss: 1.5466 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4110 - accuracy: 0.4464 - val_loss: 1.5444 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4070 - accuracy: 0.3750 - val_loss: 1.5478 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.4009 - accuracy: 0.4643 - val_loss: 1.5534 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4021 - accuracy: 0.5000 - val_loss: 1.5529 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4049 - accuracy: 0.4821 - val_loss: 1.5505 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3933 - accuracy: 0.5179 - val_loss: 1.5469 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3983 - accuracy: 0.5179 - val_loss: 1.5365 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3891 - accuracy: 0.5357 - val_loss: 1.5235 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3722 - accuracy: 0.5000 - val_loss: 1.5144 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3777 - accuracy: 0.5000 - val_loss: 1.5144 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3757 - accuracy: 0.5000 - val_loss: 1.5180 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3714 - accuracy: 0.5536 - val_loss: 1.5212 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3580 - accuracy: 0.5536 - val_loss: 1.5229 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3556 - accuracy: 0.5357 - val_loss: 1.5231 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3541 - accuracy: 0.5357 - val_loss: 1.5196 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3627 - accuracy: 0.5714 - val_loss: 1.5178 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3526 - accuracy: 0.5357 - val_loss: 1.5220 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3430 - accuracy: 0.5893 - val_loss: 1.5357 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3359 - accuracy: 0.6071 - val_loss: 1.5508 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3369 - accuracy: 0.5536 - val_loss: 1.5672 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3412 - accuracy: 0.5357 - val_loss: 1.5742 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3410 - accuracy: 0.5357 - val_loss: 1.5711 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3283 - accuracy: 0.5893 - val_loss: 1.5565 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3274 - accuracy: 0.5714 - val_loss: 1.5438 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3142 - accuracy: 0.6071 - val_loss: 1.5392 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3069 - accuracy: 0.6071 - val_loss: 1.5392 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2997 - accuracy: 0.6429 - val_loss: 1.5403 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3175 - accuracy: 0.5893 - val_loss: 1.5390 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3088 - accuracy: 0.5893 - val_loss: 1.5370 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2896 - accuracy: 0.6250 - val_loss: 1.5273 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2973 - accuracy: 0.5893 - val_loss: 1.5180 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3071 - accuracy: 0.5179 - val_loss: 1.5133 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2833 - accuracy: 0.6250 - val_loss: 1.5134 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2723 - accuracy: 0.6429 - val_loss: 1.5157 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2786 - accuracy: 0.6607 - val_loss: 1.5212 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2758 - accuracy: 0.6071 - val_loss: 1.5301 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2869 - accuracy: 0.6786 - val_loss: 1.5385 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2747 - accuracy: 0.6607 - val_loss: 1.5406 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2675 - accuracy: 0.6250 - val_loss: 1.5429 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2598 - accuracy: 0.5536 - val_loss: 1.5412 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2623 - accuracy: 0.5714 - val_loss: 1.5456 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2642 - accuracy: 0.5893 - val_loss: 1.5486 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2625 - accuracy: 0.5179 - val_loss: 1.5501 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2400 - accuracy: 0.6250 - val_loss: 1.5496 - val_accuracy: 0.0714\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2489 - accuracy: 0.6786 - val_loss: 1.5479 - val_accuracy: 0.0714\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2375 - accuracy: 0.6429 - val_loss: 1.5452 - val_accuracy: 0.0714\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2403 - accuracy: 0.6607 - val_loss: 1.5410 - val_accuracy: 0.0714\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2387 - accuracy: 0.6607 - val_loss: 1.5426 - val_accuracy: 0.0714\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2453 - accuracy: 0.5714 - val_loss: 1.5498 - val_accuracy: 0.0714\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2248 - accuracy: 0.6071 - val_loss: 1.5611 - val_accuracy: 0.0714\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2185 - accuracy: 0.6071 - val_loss: 1.5713 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2245 - accuracy: 0.6071 - val_loss: 1.5875 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2299 - accuracy: 0.6607 - val_loss: 1.6036 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.2359 - accuracy: 0.6071 - val_loss: 1.6081 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2265 - accuracy: 0.6607 - val_loss: 1.6093 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2174 - accuracy: 0.5714 - val_loss: 1.6116 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2220 - accuracy: 0.6429 - val_loss: 1.6135 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2146 - accuracy: 0.6071 - val_loss: 1.6175 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2114 - accuracy: 0.6607 - val_loss: 1.6188 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2381 - accuracy: 0.6607 - val_loss: 1.6082 - val_accuracy: 0.0714\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2172 - accuracy: 0.6786 - val_loss: 1.6029 - val_accuracy: 0.0714\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2023 - accuracy: 0.6429 - val_loss: 1.6016 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1983 - accuracy: 0.6250 - val_loss: 1.5991 - val_accuracy: 0.0714\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1978 - accuracy: 0.6429 - val_loss: 1.5992 - val_accuracy: 0.0714\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2073 - accuracy: 0.5893 - val_loss: 1.5988 - val_accuracy: 0.0714\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1947 - accuracy: 0.6250 - val_loss: 1.6018 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2010 - accuracy: 0.6786 - val_loss: 1.6038 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2040 - accuracy: 0.6071 - val_loss: 1.6068 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1934 - accuracy: 0.6071 - val_loss: 1.6116 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1867 - accuracy: 0.6607 - val_loss: 1.6137 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1788 - accuracy: 0.6607 - val_loss: 1.6106 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1818 - accuracy: 0.6071 - val_loss: 1.6035 - val_accuracy: 0.0714\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1651 - accuracy: 0.7143 - val_loss: 1.6061 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1892 - accuracy: 0.6250 - val_loss: 1.6080 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1825 - accuracy: 0.6250 - val_loss: 1.6159 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1678 - accuracy: 0.6429 - val_loss: 1.6269 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1663 - accuracy: 0.6429 - val_loss: 1.6355 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1795 - accuracy: 0.5893 - val_loss: 1.6428 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1579 - accuracy: 0.6786 - val_loss: 1.6512 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1604 - accuracy: 0.6964 - val_loss: 1.6558 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1708 - accuracy: 0.6071 - val_loss: 1.6612 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1606 - accuracy: 0.6607 - val_loss: 1.6620 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1672 - accuracy: 0.6429 - val_loss: 1.6582 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1568 - accuracy: 0.6786 - val_loss: 1.6558 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1602 - accuracy: 0.5893 - val_loss: 1.6533 - val_accuracy: 0.0714\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1661 - accuracy: 0.6429 - val_loss: 1.6559 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1665 - accuracy: 0.6250 - val_loss: 1.6668 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1524 - accuracy: 0.6964 - val_loss: 1.6820 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1551 - accuracy: 0.6429 - val_loss: 1.7000 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1462 - accuracy: 0.5714 - val_loss: 1.7132 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1473 - accuracy: 0.6429 - val_loss: 1.7210 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1612 - accuracy: 0.6607 - val_loss: 1.7226 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1420 - accuracy: 0.6786 - val_loss: 1.7188 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1366 - accuracy: 0.6071 - val_loss: 1.7119 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1441 - accuracy: 0.7143 - val_loss: 1.6983 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1348 - accuracy: 0.6786 - val_loss: 1.6821 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1549 - accuracy: 0.6607 - val_loss: 1.6673 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1372 - accuracy: 0.7143 - val_loss: 1.6517 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1285 - accuracy: 0.6964 - val_loss: 1.6421 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1277 - accuracy: 0.6607 - val_loss: 1.6361 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1443 - accuracy: 0.6964 - val_loss: 1.6335 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1233 - accuracy: 0.6607 - val_loss: 1.6334 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1238 - accuracy: 0.6964 - val_loss: 1.6406 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1330 - accuracy: 0.7500 - val_loss: 1.6506 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1425 - accuracy: 0.6607 - val_loss: 1.6636 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1302 - accuracy: 0.6607 - val_loss: 1.6737 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1326 - accuracy: 0.6607 - val_loss: 1.6767 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1198 - accuracy: 0.7500 - val_loss: 1.6794 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1196 - accuracy: 0.7321 - val_loss: 1.6781 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1197 - accuracy: 0.7143 - val_loss: 1.6721 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1278 - accuracy: 0.6786 - val_loss: 1.6662 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1251 - accuracy: 0.6607 - val_loss: 1.6673 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1162 - accuracy: 0.7143 - val_loss: 1.6731 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1169 - accuracy: 0.6607 - val_loss: 1.6797 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1160 - accuracy: 0.6250 - val_loss: 1.6843 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1218 - accuracy: 0.7321 - val_loss: 1.6873 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.1108 - accuracy: 0.7679 - val_loss: 1.6829 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1184 - accuracy: 0.7500 - val_loss: 1.6759 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1127 - accuracy: 0.7321 - val_loss: 1.6775 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6775 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=240, batch_size=100, Scores: [1.6775001287460327, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.6775001287460327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9840 - accuracy: 0.1607 - val_loss: 1.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9796 - accuracy: 0.2143 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9759 - accuracy: 0.3036 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9716 - accuracy: 0.3571 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9666 - accuracy: 0.2857 - val_loss: 1.0713 - val_accuracy: 0.1429\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9644 - accuracy: 0.3214 - val_loss: 1.0714 - val_accuracy: 0.1429\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9591 - accuracy: 0.3571 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9563 - accuracy: 0.2857 - val_loss: 1.0718 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.9514 - accuracy: 0.3214 - val_loss: 1.0721 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9473 - accuracy: 0.3393 - val_loss: 1.0723 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9430 - accuracy: 0.3214 - val_loss: 1.0726 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9379 - accuracy: 0.3214 - val_loss: 1.0729 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9342 - accuracy: 0.3214 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9283 - accuracy: 0.3214 - val_loss: 1.0736 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9238 - accuracy: 0.3214 - val_loss: 1.0740 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9186 - accuracy: 0.3393 - val_loss: 1.0746 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9141 - accuracy: 0.3036 - val_loss: 1.0752 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9083 - accuracy: 0.3393 - val_loss: 1.0759 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.9023 - accuracy: 0.3393 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.8928 - accuracy: 0.3036 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.8892 - accuracy: 0.3214 - val_loss: 1.0791 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8836 - accuracy: 0.3214 - val_loss: 1.0806 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8750 - accuracy: 0.3393 - val_loss: 1.0825 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8728 - accuracy: 0.3036 - val_loss: 1.0847 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8656 - accuracy: 0.3214 - val_loss: 1.0874 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8583 - accuracy: 0.3214 - val_loss: 1.0905 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8543 - accuracy: 0.3571 - val_loss: 1.0941 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8483 - accuracy: 0.3036 - val_loss: 1.0979 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8454 - accuracy: 0.3571 - val_loss: 1.1021 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8371 - accuracy: 0.3214 - val_loss: 1.1067 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8336 - accuracy: 0.3750 - val_loss: 1.1115 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8277 - accuracy: 0.3393 - val_loss: 1.1167 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8209 - accuracy: 0.3929 - val_loss: 1.1221 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8155 - accuracy: 0.3571 - val_loss: 1.1280 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8095 - accuracy: 0.3393 - val_loss: 1.1341 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8031 - accuracy: 0.3571 - val_loss: 1.1407 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7945 - accuracy: 0.3571 - val_loss: 1.1476 - val_accuracy: 0.2143\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7893 - accuracy: 0.3571 - val_loss: 1.1550 - val_accuracy: 0.2143\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7896 - accuracy: 0.3571 - val_loss: 1.1629 - val_accuracy: 0.2143\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7872 - accuracy: 0.3214 - val_loss: 1.1709 - val_accuracy: 0.2143\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7772 - accuracy: 0.3571 - val_loss: 1.1790 - val_accuracy: 0.2143\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7766 - accuracy: 0.3214 - val_loss: 1.1873 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7669 - accuracy: 0.3393 - val_loss: 1.1955 - val_accuracy: 0.2143\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7664 - accuracy: 0.3036 - val_loss: 1.2034 - val_accuracy: 0.2143\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7585 - accuracy: 0.3571 - val_loss: 1.2108 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7596 - accuracy: 0.3571 - val_loss: 1.2175 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7566 - accuracy: 0.3214 - val_loss: 1.2237 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7546 - accuracy: 0.3571 - val_loss: 1.2294 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7484 - accuracy: 0.3571 - val_loss: 1.2341 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7429 - accuracy: 0.3214 - val_loss: 1.2380 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7434 - accuracy: 0.3214 - val_loss: 1.2408 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7386 - accuracy: 0.3214 - val_loss: 1.2426 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7299 - accuracy: 0.3393 - val_loss: 1.2436 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7328 - accuracy: 0.3393 - val_loss: 1.2441 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7243 - accuracy: 0.3214 - val_loss: 1.2440 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7198 - accuracy: 0.3393 - val_loss: 1.2438 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7155 - accuracy: 0.3750 - val_loss: 1.2437 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7118 - accuracy: 0.3393 - val_loss: 1.2438 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7051 - accuracy: 0.3750 - val_loss: 1.2443 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7068 - accuracy: 0.3571 - val_loss: 1.2451 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6975 - accuracy: 0.3750 - val_loss: 1.2461 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6953 - accuracy: 0.3750 - val_loss: 1.2474 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6926 - accuracy: 0.3571 - val_loss: 1.2494 - val_accuracy: 0.1429\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6878 - accuracy: 0.3393 - val_loss: 1.2522 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6824 - accuracy: 0.3571 - val_loss: 1.2553 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6820 - accuracy: 0.3393 - val_loss: 1.2591 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6802 - accuracy: 0.3393 - val_loss: 1.2640 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6682 - accuracy: 0.3750 - val_loss: 1.2695 - val_accuracy: 0.0714\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6690 - accuracy: 0.3750 - val_loss: 1.2750 - val_accuracy: 0.0714\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6598 - accuracy: 0.3571 - val_loss: 1.2810 - val_accuracy: 0.0714\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6629 - accuracy: 0.3571 - val_loss: 1.2868 - val_accuracy: 0.0714\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6534 - accuracy: 0.3929 - val_loss: 1.2929 - val_accuracy: 0.0714\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6476 - accuracy: 0.3929 - val_loss: 1.2989 - val_accuracy: 0.0714\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6436 - accuracy: 0.3750 - val_loss: 1.3044 - val_accuracy: 0.0714\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6364 - accuracy: 0.3929 - val_loss: 1.3105 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6319 - accuracy: 0.4286 - val_loss: 1.3173 - val_accuracy: 0.0714\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6350 - accuracy: 0.3571 - val_loss: 1.3229 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6307 - accuracy: 0.4107 - val_loss: 1.3275 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6232 - accuracy: 0.4286 - val_loss: 1.3321 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6137 - accuracy: 0.3750 - val_loss: 1.3380 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6124 - accuracy: 0.4464 - val_loss: 1.3444 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6126 - accuracy: 0.4464 - val_loss: 1.3517 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6014 - accuracy: 0.4107 - val_loss: 1.3594 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5989 - accuracy: 0.4464 - val_loss: 1.3674 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5942 - accuracy: 0.4107 - val_loss: 1.3755 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5936 - accuracy: 0.4464 - val_loss: 1.3832 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5834 - accuracy: 0.4286 - val_loss: 1.3904 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5768 - accuracy: 0.4286 - val_loss: 1.3979 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5728 - accuracy: 0.4643 - val_loss: 1.4070 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5709 - accuracy: 0.4464 - val_loss: 1.4155 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5572 - accuracy: 0.4464 - val_loss: 1.4244 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5622 - accuracy: 0.4464 - val_loss: 1.4334 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5579 - accuracy: 0.4464 - val_loss: 1.4425 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5451 - accuracy: 0.4107 - val_loss: 1.4507 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5386 - accuracy: 0.4286 - val_loss: 1.4569 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5451 - accuracy: 0.4107 - val_loss: 1.4633 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5385 - accuracy: 0.4464 - val_loss: 1.4690 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5259 - accuracy: 0.4464 - val_loss: 1.4728 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5245 - accuracy: 0.4286 - val_loss: 1.4744 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5147 - accuracy: 0.4107 - val_loss: 1.4741 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5117 - accuracy: 0.3929 - val_loss: 1.4737 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.4992 - accuracy: 0.4286 - val_loss: 1.4753 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5037 - accuracy: 0.4464 - val_loss: 1.4776 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.5021 - accuracy: 0.4107 - val_loss: 1.4824 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.4860 - accuracy: 0.4643 - val_loss: 1.4873 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4871 - accuracy: 0.4286 - val_loss: 1.4898 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.4758 - accuracy: 0.4821 - val_loss: 1.4956 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.4748 - accuracy: 0.4464 - val_loss: 1.4982 - val_accuracy: 0.0714\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4673 - accuracy: 0.4643 - val_loss: 1.5025 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4645 - accuracy: 0.4821 - val_loss: 1.5042 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4635 - accuracy: 0.4464 - val_loss: 1.5032 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4486 - accuracy: 0.4286 - val_loss: 1.5035 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4504 - accuracy: 0.4643 - val_loss: 1.5050 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.4454 - accuracy: 0.4107 - val_loss: 1.5072 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.4325 - accuracy: 0.4286 - val_loss: 1.5051 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.4192 - accuracy: 0.5000 - val_loss: 1.5023 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.4242 - accuracy: 0.4643 - val_loss: 1.4938 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4203 - accuracy: 0.4643 - val_loss: 1.4871 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4202 - accuracy: 0.4464 - val_loss: 1.4868 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4172 - accuracy: 0.4643 - val_loss: 1.4882 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4123 - accuracy: 0.4107 - val_loss: 1.4922 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3979 - accuracy: 0.5357 - val_loss: 1.4945 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3864 - accuracy: 0.5179 - val_loss: 1.4971 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3930 - accuracy: 0.5000 - val_loss: 1.5001 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3800 - accuracy: 0.4643 - val_loss: 1.4940 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3741 - accuracy: 0.5000 - val_loss: 1.4864 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3718 - accuracy: 0.4643 - val_loss: 1.4819 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3631 - accuracy: 0.5000 - val_loss: 1.4808 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3733 - accuracy: 0.5179 - val_loss: 1.4857 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3673 - accuracy: 0.5179 - val_loss: 1.4969 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3591 - accuracy: 0.5179 - val_loss: 1.5098 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3477 - accuracy: 0.4643 - val_loss: 1.5182 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3377 - accuracy: 0.5000 - val_loss: 1.5139 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3446 - accuracy: 0.5179 - val_loss: 1.5094 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3437 - accuracy: 0.4821 - val_loss: 1.5002 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3380 - accuracy: 0.5000 - val_loss: 1.4870 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3307 - accuracy: 0.5000 - val_loss: 1.4765 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3181 - accuracy: 0.5179 - val_loss: 1.4765 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3285 - accuracy: 0.5893 - val_loss: 1.4846 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3208 - accuracy: 0.5357 - val_loss: 1.4968 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3077 - accuracy: 0.4821 - val_loss: 1.5021 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3039 - accuracy: 0.5179 - val_loss: 1.4975 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2909 - accuracy: 0.5536 - val_loss: 1.4941 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2971 - accuracy: 0.5000 - val_loss: 1.4919 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3030 - accuracy: 0.4643 - val_loss: 1.4870 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2888 - accuracy: 0.5357 - val_loss: 1.4835 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2899 - accuracy: 0.5000 - val_loss: 1.4810 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2829 - accuracy: 0.5357 - val_loss: 1.4784 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2884 - accuracy: 0.5000 - val_loss: 1.4769 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2865 - accuracy: 0.5179 - val_loss: 1.4720 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2837 - accuracy: 0.5179 - val_loss: 1.4754 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.2648 - accuracy: 0.5714 - val_loss: 1.4911 - val_accuracy: 0.1429\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2628 - accuracy: 0.5357 - val_loss: 1.5092 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2586 - accuracy: 0.5536 - val_loss: 1.5302 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2613 - accuracy: 0.4821 - val_loss: 1.5409 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2612 - accuracy: 0.5000 - val_loss: 1.5378 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2473 - accuracy: 0.6250 - val_loss: 1.5275 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2420 - accuracy: 0.5536 - val_loss: 1.5131 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2450 - accuracy: 0.5714 - val_loss: 1.5042 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2450 - accuracy: 0.5536 - val_loss: 1.5097 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2398 - accuracy: 0.5536 - val_loss: 1.5264 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2319 - accuracy: 0.6071 - val_loss: 1.5357 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2273 - accuracy: 0.5714 - val_loss: 1.5366 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2210 - accuracy: 0.5357 - val_loss: 1.5335 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2296 - accuracy: 0.5536 - val_loss: 1.5261 - val_accuracy: 0.0714\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2245 - accuracy: 0.5893 - val_loss: 1.5227 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2172 - accuracy: 0.6250 - val_loss: 1.5242 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2149 - accuracy: 0.6071 - val_loss: 1.5273 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2060 - accuracy: 0.6071 - val_loss: 1.5306 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1951 - accuracy: 0.5536 - val_loss: 1.5318 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2201 - accuracy: 0.5893 - val_loss: 1.5355 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1977 - accuracy: 0.5536 - val_loss: 1.5416 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1990 - accuracy: 0.6071 - val_loss: 1.5453 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2033 - accuracy: 0.6071 - val_loss: 1.5472 - val_accuracy: 0.1429\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2055 - accuracy: 0.5357 - val_loss: 1.5477 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1992 - accuracy: 0.6071 - val_loss: 1.5478 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1964 - accuracy: 0.6429 - val_loss: 1.5426 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2018 - accuracy: 0.5714 - val_loss: 1.5358 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1803 - accuracy: 0.6071 - val_loss: 1.5290 - val_accuracy: 0.1429\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1956 - accuracy: 0.6250 - val_loss: 1.5294 - val_accuracy: 0.1429\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1826 - accuracy: 0.6071 - val_loss: 1.5298 - val_accuracy: 0.2143\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2011 - accuracy: 0.5357 - val_loss: 1.5302 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1890 - accuracy: 0.6071 - val_loss: 1.5370 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1748 - accuracy: 0.5893 - val_loss: 1.5533 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1749 - accuracy: 0.6429 - val_loss: 1.5697 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1849 - accuracy: 0.6071 - val_loss: 1.5774 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1800 - accuracy: 0.5893 - val_loss: 1.5813 - val_accuracy: 0.2143\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1814 - accuracy: 0.5714 - val_loss: 1.5799 - val_accuracy: 0.2143\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1701 - accuracy: 0.6250 - val_loss: 1.5813 - val_accuracy: 0.2143\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1720 - accuracy: 0.6250 - val_loss: 1.5797 - val_accuracy: 0.2143\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1686 - accuracy: 0.6071 - val_loss: 1.5788 - val_accuracy: 0.2143\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1640 - accuracy: 0.5893 - val_loss: 1.5820 - val_accuracy: 0.2143\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1702 - accuracy: 0.6607 - val_loss: 1.5857 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1684 - accuracy: 0.6250 - val_loss: 1.5844 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1602 - accuracy: 0.6607 - val_loss: 1.5839 - val_accuracy: 0.2143\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1586 - accuracy: 0.6429 - val_loss: 1.5846 - val_accuracy: 0.2143\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1521 - accuracy: 0.6964 - val_loss: 1.5946 - val_accuracy: 0.2143\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1572 - accuracy: 0.6429 - val_loss: 1.6088 - val_accuracy: 0.2143\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1530 - accuracy: 0.7143 - val_loss: 1.6255 - val_accuracy: 0.2143\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1538 - accuracy: 0.6071 - val_loss: 1.6355 - val_accuracy: 0.2143\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1497 - accuracy: 0.6607 - val_loss: 1.6392 - val_accuracy: 0.2143\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1455 - accuracy: 0.6250 - val_loss: 1.6372 - val_accuracy: 0.2143\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1392 - accuracy: 0.6607 - val_loss: 1.6321 - val_accuracy: 0.2143\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1498 - accuracy: 0.6964 - val_loss: 1.6248 - val_accuracy: 0.2143\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1433 - accuracy: 0.6429 - val_loss: 1.6240 - val_accuracy: 0.2143\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1417 - accuracy: 0.6250 - val_loss: 1.6193 - val_accuracy: 0.2143\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1392 - accuracy: 0.6250 - val_loss: 1.6200 - val_accuracy: 0.2143\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1362 - accuracy: 0.7143 - val_loss: 1.6206 - val_accuracy: 0.2143\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1414 - accuracy: 0.6607 - val_loss: 1.6226 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1464 - accuracy: 0.5714 - val_loss: 1.6297 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1385 - accuracy: 0.6429 - val_loss: 1.6338 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1338 - accuracy: 0.6964 - val_loss: 1.6354 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1331 - accuracy: 0.6964 - val_loss: 1.6336 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1221 - accuracy: 0.6429 - val_loss: 1.6320 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1406 - accuracy: 0.6250 - val_loss: 1.6286 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1357 - accuracy: 0.6607 - val_loss: 1.6297 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1299 - accuracy: 0.6607 - val_loss: 1.6373 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1393 - accuracy: 0.6071 - val_loss: 1.6419 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1240 - accuracy: 0.6429 - val_loss: 1.6467 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1163 - accuracy: 0.6429 - val_loss: 1.6526 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1357 - accuracy: 0.6786 - val_loss: 1.6537 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1301 - accuracy: 0.7143 - val_loss: 1.6496 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1180 - accuracy: 0.6964 - val_loss: 1.6419 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1287 - accuracy: 0.6429 - val_loss: 1.6288 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1191 - accuracy: 0.6964 - val_loss: 1.6217 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.1199 - accuracy: 0.7857 - val_loss: 1.6157 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1204 - accuracy: 0.6429 - val_loss: 1.6147 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1189 - accuracy: 0.6786 - val_loss: 1.6199 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1152 - accuracy: 0.7321 - val_loss: 1.6256 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1168 - accuracy: 0.6607 - val_loss: 1.6337 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1227 - accuracy: 0.6964 - val_loss: 1.6371 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1221 - accuracy: 0.6429 - val_loss: 1.6367 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1126 - accuracy: 0.6786 - val_loss: 1.6351 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1155 - accuracy: 0.6964 - val_loss: 1.6365 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1193 - accuracy: 0.6607 - val_loss: 1.6417 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1105 - accuracy: 0.7143 - val_loss: 1.6522 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1178 - accuracy: 0.6250 - val_loss: 1.6624 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1010 - accuracy: 0.6964 - val_loss: 1.6687 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1085 - accuracy: 0.6964 - val_loss: 1.6698 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1206 - accuracy: 0.7679 - val_loss: 1.6741 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6741 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=240, batch_size=300, Scores: [1.674112319946289, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.674112319946289\n",
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9816 - accuracy: 0.1250 - val_loss: 1.0712 - val_accuracy: 0.2143\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9776 - accuracy: 0.1786 - val_loss: 1.0722 - val_accuracy: 0.1429\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9733 - accuracy: 0.2857 - val_loss: 1.0731 - val_accuracy: 0.1429\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9689 - accuracy: 0.2857 - val_loss: 1.0741 - val_accuracy: 0.2143\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9640 - accuracy: 0.3036 - val_loss: 1.0752 - val_accuracy: 0.2143\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9598 - accuracy: 0.2679 - val_loss: 1.0762 - val_accuracy: 0.2143\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9560 - accuracy: 0.2679 - val_loss: 1.0773 - val_accuracy: 0.2143\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9506 - accuracy: 0.3036 - val_loss: 1.0786 - val_accuracy: 0.2143\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9469 - accuracy: 0.3571 - val_loss: 1.0798 - val_accuracy: 0.2143\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9410 - accuracy: 0.3393 - val_loss: 1.0811 - val_accuracy: 0.2143\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9374 - accuracy: 0.3750 - val_loss: 1.0825 - val_accuracy: 0.2143\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9315 - accuracy: 0.3214 - val_loss: 1.0839 - val_accuracy: 0.2143\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9263 - accuracy: 0.2857 - val_loss: 1.0855 - val_accuracy: 0.2143\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.9209 - accuracy: 0.3214 - val_loss: 1.0871 - val_accuracy: 0.2143\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9174 - accuracy: 0.3393 - val_loss: 1.0888 - val_accuracy: 0.2143\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9090 - accuracy: 0.3214 - val_loss: 1.0906 - val_accuracy: 0.2143\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9061 - accuracy: 0.3393 - val_loss: 1.0925 - val_accuracy: 0.2143\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8987 - accuracy: 0.3571 - val_loss: 1.0945 - val_accuracy: 0.2143\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8949 - accuracy: 0.3571 - val_loss: 1.0966 - val_accuracy: 0.2143\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8860 - accuracy: 0.3393 - val_loss: 1.0988 - val_accuracy: 0.2143\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8840 - accuracy: 0.3214 - val_loss: 1.1011 - val_accuracy: 0.2143\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8769 - accuracy: 0.3214 - val_loss: 1.1033 - val_accuracy: 0.2143\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8716 - accuracy: 0.3393 - val_loss: 1.1055 - val_accuracy: 0.2143\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8644 - accuracy: 0.3393 - val_loss: 1.1075 - val_accuracy: 0.2143\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8589 - accuracy: 0.3571 - val_loss: 1.1093 - val_accuracy: 0.2143\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8535 - accuracy: 0.3214 - val_loss: 1.1109 - val_accuracy: 0.2143\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.8445 - accuracy: 0.2679 - val_loss: 1.1123 - val_accuracy: 0.2143\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8446 - accuracy: 0.3036 - val_loss: 1.1135 - val_accuracy: 0.2143\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8373 - accuracy: 0.3214 - val_loss: 1.1146 - val_accuracy: 0.2143\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8254 - accuracy: 0.3393 - val_loss: 1.1159 - val_accuracy: 0.2143\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8231 - accuracy: 0.3571 - val_loss: 1.1174 - val_accuracy: 0.2143\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8162 - accuracy: 0.3393 - val_loss: 1.1194 - val_accuracy: 0.2143\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.8121 - accuracy: 0.3036 - val_loss: 1.1221 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8072 - accuracy: 0.2857 - val_loss: 1.1256 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7960 - accuracy: 0.3214 - val_loss: 1.1301 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7902 - accuracy: 0.3036 - val_loss: 1.1355 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7856 - accuracy: 0.3393 - val_loss: 1.1416 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7796 - accuracy: 0.2857 - val_loss: 1.1484 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7768 - accuracy: 0.3036 - val_loss: 1.1559 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7757 - accuracy: 0.3036 - val_loss: 1.1639 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7680 - accuracy: 0.2857 - val_loss: 1.1726 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7629 - accuracy: 0.3036 - val_loss: 1.1815 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7589 - accuracy: 0.3571 - val_loss: 1.1906 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7531 - accuracy: 0.3393 - val_loss: 1.1996 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7497 - accuracy: 0.3393 - val_loss: 1.2081 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7482 - accuracy: 0.3571 - val_loss: 1.2154 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7437 - accuracy: 0.3571 - val_loss: 1.2217 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7409 - accuracy: 0.3393 - val_loss: 1.2271 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7439 - accuracy: 0.3393 - val_loss: 1.2313 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7349 - accuracy: 0.3214 - val_loss: 1.2348 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7276 - accuracy: 0.3571 - val_loss: 1.2367 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7247 - accuracy: 0.3571 - val_loss: 1.2380 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7217 - accuracy: 0.3571 - val_loss: 1.2387 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7193 - accuracy: 0.3393 - val_loss: 1.2391 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7163 - accuracy: 0.3750 - val_loss: 1.2398 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7099 - accuracy: 0.3214 - val_loss: 1.2411 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7062 - accuracy: 0.3571 - val_loss: 1.2425 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7029 - accuracy: 0.3571 - val_loss: 1.2446 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7001 - accuracy: 0.3393 - val_loss: 1.2472 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6989 - accuracy: 0.3571 - val_loss: 1.2516 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6980 - accuracy: 0.3750 - val_loss: 1.2565 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6820 - accuracy: 0.3214 - val_loss: 1.2606 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6831 - accuracy: 0.3571 - val_loss: 1.2664 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6734 - accuracy: 0.3929 - val_loss: 1.2721 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6757 - accuracy: 0.3929 - val_loss: 1.2774 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6684 - accuracy: 0.3750 - val_loss: 1.2827 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6659 - accuracy: 0.3571 - val_loss: 1.2870 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6545 - accuracy: 0.3393 - val_loss: 1.2919 - val_accuracy: 0.0714\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6593 - accuracy: 0.3214 - val_loss: 1.2973 - val_accuracy: 0.0714\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6534 - accuracy: 0.3750 - val_loss: 1.3037 - val_accuracy: 0.0714\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6529 - accuracy: 0.3393 - val_loss: 1.3102 - val_accuracy: 0.0714\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6456 - accuracy: 0.3929 - val_loss: 1.3147 - val_accuracy: 0.0714\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6431 - accuracy: 0.3750 - val_loss: 1.3204 - val_accuracy: 0.0714\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6427 - accuracy: 0.3393 - val_loss: 1.3252 - val_accuracy: 0.0714\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6285 - accuracy: 0.3571 - val_loss: 1.3302 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6257 - accuracy: 0.3393 - val_loss: 1.3362 - val_accuracy: 0.0714\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6283 - accuracy: 0.3750 - val_loss: 1.3419 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6261 - accuracy: 0.3571 - val_loss: 1.3470 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6108 - accuracy: 0.3393 - val_loss: 1.3511 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6092 - accuracy: 0.3571 - val_loss: 1.3563 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6122 - accuracy: 0.3571 - val_loss: 1.3612 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6096 - accuracy: 0.3214 - val_loss: 1.3664 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6007 - accuracy: 0.3393 - val_loss: 1.3734 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6010 - accuracy: 0.3036 - val_loss: 1.3792 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5897 - accuracy: 0.3393 - val_loss: 1.3873 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5864 - accuracy: 0.3214 - val_loss: 1.3950 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5915 - accuracy: 0.3036 - val_loss: 1.4008 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5753 - accuracy: 0.2857 - val_loss: 1.4055 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5878 - accuracy: 0.3036 - val_loss: 1.4071 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5715 - accuracy: 0.3571 - val_loss: 1.4072 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5688 - accuracy: 0.3929 - val_loss: 1.4094 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5548 - accuracy: 0.3571 - val_loss: 1.4119 - val_accuracy: 0.0714\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5518 - accuracy: 0.3571 - val_loss: 1.4181 - val_accuracy: 0.0714\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5490 - accuracy: 0.3214 - val_loss: 1.4254 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5500 - accuracy: 0.3393 - val_loss: 1.4271 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5476 - accuracy: 0.4107 - val_loss: 1.4286 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5474 - accuracy: 0.3929 - val_loss: 1.4306 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5390 - accuracy: 0.3929 - val_loss: 1.4358 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.5259 - accuracy: 0.3929 - val_loss: 1.4425 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 0.5237 - accuracy: 0.3929 - val_loss: 1.4470 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5213 - accuracy: 0.3750 - val_loss: 1.4494 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5102 - accuracy: 0.3750 - val_loss: 1.4506 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5057 - accuracy: 0.3929 - val_loss: 1.4480 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5032 - accuracy: 0.3750 - val_loss: 1.4469 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.4922 - accuracy: 0.4107 - val_loss: 1.4488 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4952 - accuracy: 0.4643 - val_loss: 1.4517 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4999 - accuracy: 0.3750 - val_loss: 1.4553 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4817 - accuracy: 0.4107 - val_loss: 1.4649 - val_accuracy: 0.0714\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4845 - accuracy: 0.3571 - val_loss: 1.4724 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4758 - accuracy: 0.3750 - val_loss: 1.4718 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4671 - accuracy: 0.4464 - val_loss: 1.4623 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4685 - accuracy: 0.3929 - val_loss: 1.4567 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4704 - accuracy: 0.4286 - val_loss: 1.4570 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4533 - accuracy: 0.4286 - val_loss: 1.4647 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4469 - accuracy: 0.4286 - val_loss: 1.4741 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4423 - accuracy: 0.3929 - val_loss: 1.4823 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4378 - accuracy: 0.4286 - val_loss: 1.4876 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4412 - accuracy: 0.4107 - val_loss: 1.4884 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4272 - accuracy: 0.4643 - val_loss: 1.4893 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4253 - accuracy: 0.4464 - val_loss: 1.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4147 - accuracy: 0.4286 - val_loss: 1.4796 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4079 - accuracy: 0.4643 - val_loss: 1.4726 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4142 - accuracy: 0.3929 - val_loss: 1.4728 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4131 - accuracy: 0.4821 - val_loss: 1.4691 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3965 - accuracy: 0.4464 - val_loss: 1.4676 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3957 - accuracy: 0.4464 - val_loss: 1.4679 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3946 - accuracy: 0.4821 - val_loss: 1.4720 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3662 - accuracy: 0.5179 - val_loss: 1.4811 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3661 - accuracy: 0.5179 - val_loss: 1.4960 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3711 - accuracy: 0.4821 - val_loss: 1.5005 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3698 - accuracy: 0.5357 - val_loss: 1.5048 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3558 - accuracy: 0.5714 - val_loss: 1.5011 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3643 - accuracy: 0.4821 - val_loss: 1.5068 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3483 - accuracy: 0.5357 - val_loss: 1.5170 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3502 - accuracy: 0.5357 - val_loss: 1.5294 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3718 - accuracy: 0.5536 - val_loss: 1.5107 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3435 - accuracy: 0.5536 - val_loss: 1.4933 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3492 - accuracy: 0.4643 - val_loss: 1.5019 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3344 - accuracy: 0.5000 - val_loss: 1.5100 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3539 - accuracy: 0.5000 - val_loss: 1.5219 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3405 - accuracy: 0.4286 - val_loss: 1.5359 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3227 - accuracy: 0.5714 - val_loss: 1.5406 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3269 - accuracy: 0.5000 - val_loss: 1.5319 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3215 - accuracy: 0.5179 - val_loss: 1.5104 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3198 - accuracy: 0.5179 - val_loss: 1.4909 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3047 - accuracy: 0.5357 - val_loss: 1.4847 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3108 - accuracy: 0.5000 - val_loss: 1.4903 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3050 - accuracy: 0.5893 - val_loss: 1.4977 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3173 - accuracy: 0.5357 - val_loss: 1.5127 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2954 - accuracy: 0.5179 - val_loss: 1.5386 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2976 - accuracy: 0.5536 - val_loss: 1.5622 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2951 - accuracy: 0.5536 - val_loss: 1.5748 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2984 - accuracy: 0.5714 - val_loss: 1.5746 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2742 - accuracy: 0.5357 - val_loss: 1.5668 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2833 - accuracy: 0.5536 - val_loss: 1.5588 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2644 - accuracy: 0.5714 - val_loss: 1.5538 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2746 - accuracy: 0.5893 - val_loss: 1.5505 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2642 - accuracy: 0.5536 - val_loss: 1.5498 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2641 - accuracy: 0.5179 - val_loss: 1.5564 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2623 - accuracy: 0.5893 - val_loss: 1.5656 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2587 - accuracy: 0.5714 - val_loss: 1.5703 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2575 - accuracy: 0.5893 - val_loss: 1.5699 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2411 - accuracy: 0.6071 - val_loss: 1.5699 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2315 - accuracy: 0.5714 - val_loss: 1.5691 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2357 - accuracy: 0.6071 - val_loss: 1.5723 - val_accuracy: 0.0714\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.2510 - accuracy: 0.6071 - val_loss: 1.5841 - val_accuracy: 0.0714\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2460 - accuracy: 0.5536 - val_loss: 1.5973 - val_accuracy: 0.0714\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2352 - accuracy: 0.6250 - val_loss: 1.6210 - val_accuracy: 0.0714\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2319 - accuracy: 0.5714 - val_loss: 1.6366 - val_accuracy: 0.0714\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2362 - accuracy: 0.6429 - val_loss: 1.6380 - val_accuracy: 0.0714\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2396 - accuracy: 0.6607 - val_loss: 1.6335 - val_accuracy: 0.0714\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2242 - accuracy: 0.6786 - val_loss: 1.6202 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2264 - accuracy: 0.6429 - val_loss: 1.6099 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2187 - accuracy: 0.6071 - val_loss: 1.6024 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2274 - accuracy: 0.6071 - val_loss: 1.5943 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2188 - accuracy: 0.6250 - val_loss: 1.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2214 - accuracy: 0.5714 - val_loss: 1.5925 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2058 - accuracy: 0.6607 - val_loss: 1.5991 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2071 - accuracy: 0.6250 - val_loss: 1.6063 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2108 - accuracy: 0.6607 - val_loss: 1.6129 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2030 - accuracy: 0.5536 - val_loss: 1.6348 - val_accuracy: 0.0714\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1934 - accuracy: 0.6071 - val_loss: 1.6641 - val_accuracy: 0.0714\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2054 - accuracy: 0.6250 - val_loss: 1.6937 - val_accuracy: 0.0714\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2002 - accuracy: 0.6429 - val_loss: 1.7066 - val_accuracy: 0.0714\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1955 - accuracy: 0.6607 - val_loss: 1.7119 - val_accuracy: 0.0714\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1960 - accuracy: 0.6429 - val_loss: 1.7051 - val_accuracy: 0.0714\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1868 - accuracy: 0.6607 - val_loss: 1.6920 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1813 - accuracy: 0.6964 - val_loss: 1.6825 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1823 - accuracy: 0.5893 - val_loss: 1.6817 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1822 - accuracy: 0.6786 - val_loss: 1.6883 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1824 - accuracy: 0.6429 - val_loss: 1.7009 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1868 - accuracy: 0.6250 - val_loss: 1.7239 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1826 - accuracy: 0.5714 - val_loss: 1.7393 - val_accuracy: 0.0714\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1741 - accuracy: 0.6071 - val_loss: 1.7530 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1810 - accuracy: 0.6071 - val_loss: 1.7475 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1801 - accuracy: 0.6071 - val_loss: 1.7392 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1742 - accuracy: 0.6786 - val_loss: 1.7227 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1639 - accuracy: 0.6250 - val_loss: 1.7130 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1615 - accuracy: 0.6429 - val_loss: 1.7167 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1652 - accuracy: 0.6786 - val_loss: 1.7382 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1660 - accuracy: 0.7143 - val_loss: 1.7562 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1688 - accuracy: 0.6964 - val_loss: 1.7743 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1617 - accuracy: 0.6429 - val_loss: 1.7925 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1532 - accuracy: 0.7321 - val_loss: 1.8036 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1618 - accuracy: 0.6964 - val_loss: 1.8083 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1544 - accuracy: 0.6786 - val_loss: 1.8018 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1562 - accuracy: 0.6429 - val_loss: 1.7921 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1592 - accuracy: 0.6250 - val_loss: 1.7831 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1515 - accuracy: 0.6250 - val_loss: 1.7805 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1501 - accuracy: 0.6786 - val_loss: 1.7845 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1404 - accuracy: 0.6964 - val_loss: 1.7981 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1517 - accuracy: 0.6607 - val_loss: 1.8113 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1466 - accuracy: 0.6607 - val_loss: 1.8270 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1516 - accuracy: 0.6786 - val_loss: 1.8429 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1413 - accuracy: 0.6786 - val_loss: 1.8563 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1323 - accuracy: 0.6607 - val_loss: 1.8539 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1423 - accuracy: 0.6429 - val_loss: 1.8488 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1433 - accuracy: 0.6250 - val_loss: 1.8365 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1362 - accuracy: 0.6786 - val_loss: 1.8194 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1330 - accuracy: 0.6964 - val_loss: 1.8027 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1313 - accuracy: 0.6786 - val_loss: 1.7880 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1313 - accuracy: 0.6964 - val_loss: 1.7785 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1333 - accuracy: 0.5893 - val_loss: 1.7790 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1324 - accuracy: 0.5893 - val_loss: 1.7802 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1374 - accuracy: 0.6786 - val_loss: 1.7927 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1194 - accuracy: 0.6964 - val_loss: 1.8055 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1294 - accuracy: 0.6429 - val_loss: 1.8186 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1215 - accuracy: 0.6964 - val_loss: 1.8287 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1285 - accuracy: 0.7679 - val_loss: 1.8323 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1241 - accuracy: 0.6250 - val_loss: 1.8361 - val_accuracy: 0.0714\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1327 - accuracy: 0.7143 - val_loss: 1.8447 - val_accuracy: 0.0714\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1333 - accuracy: 0.7143 - val_loss: 1.8455 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1158 - accuracy: 0.6964 - val_loss: 1.8401 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1217 - accuracy: 0.7500 - val_loss: 1.8327 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1329 - accuracy: 0.6786 - val_loss: 1.8351 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1201 - accuracy: 0.6429 - val_loss: 1.8383 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1188 - accuracy: 0.6964 - val_loss: 1.8414 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1275 - accuracy: 0.6429 - val_loss: 1.8632 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1173 - accuracy: 0.6250 - val_loss: 1.8814 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1191 - accuracy: 0.6071 - val_loss: 1.8838 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.8838 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=240, batch_size=400, Scores: [1.8837850093841553, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.8837850093841553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9826 - accuracy: 0.1607 - val_loss: 1.0683 - val_accuracy: 0.3571\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9781 - accuracy: 0.3214 - val_loss: 1.0688 - val_accuracy: 0.4286\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9742 - accuracy: 0.3393 - val_loss: 1.0693 - val_accuracy: 0.2857\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9707 - accuracy: 0.3036 - val_loss: 1.0698 - val_accuracy: 0.2857\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9668 - accuracy: 0.2679 - val_loss: 1.0704 - val_accuracy: 0.2857\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9611 - accuracy: 0.2857 - val_loss: 1.0710 - val_accuracy: 0.2857\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9573 - accuracy: 0.3036 - val_loss: 1.0717 - val_accuracy: 0.2857\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9536 - accuracy: 0.2857 - val_loss: 1.0724 - val_accuracy: 0.2857\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9503 - accuracy: 0.2857 - val_loss: 1.0732 - val_accuracy: 0.2857\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9459 - accuracy: 0.3036 - val_loss: 1.0740 - val_accuracy: 0.2857\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.9397 - accuracy: 0.3214 - val_loss: 1.0749 - val_accuracy: 0.2857\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9352 - accuracy: 0.3214 - val_loss: 1.0758 - val_accuracy: 0.2857\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.9303 - accuracy: 0.2857 - val_loss: 1.0768 - val_accuracy: 0.2857\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9240 - accuracy: 0.2679 - val_loss: 1.0778 - val_accuracy: 0.2857\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9213 - accuracy: 0.2857 - val_loss: 1.0791 - val_accuracy: 0.2857\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9148 - accuracy: 0.3214 - val_loss: 1.0804 - val_accuracy: 0.2857\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9091 - accuracy: 0.2679 - val_loss: 1.0819 - val_accuracy: 0.2857\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9032 - accuracy: 0.3036 - val_loss: 1.0837 - val_accuracy: 0.2857\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.8965 - accuracy: 0.3036 - val_loss: 1.0856 - val_accuracy: 0.2857\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8908 - accuracy: 0.2857 - val_loss: 1.0879 - val_accuracy: 0.2857\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8839 - accuracy: 0.3036 - val_loss: 1.0907 - val_accuracy: 0.2857\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8776 - accuracy: 0.2500 - val_loss: 1.0938 - val_accuracy: 0.2857\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8738 - accuracy: 0.2857 - val_loss: 1.0974 - val_accuracy: 0.2857\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8676 - accuracy: 0.2857 - val_loss: 1.1014 - val_accuracy: 0.2857\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8603 - accuracy: 0.2679 - val_loss: 1.1060 - val_accuracy: 0.2857\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8527 - accuracy: 0.2679 - val_loss: 1.1111 - val_accuracy: 0.2857\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8504 - accuracy: 0.2679 - val_loss: 1.1168 - val_accuracy: 0.2857\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8440 - accuracy: 0.2679 - val_loss: 1.1230 - val_accuracy: 0.2857\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8400 - accuracy: 0.2500 - val_loss: 1.1297 - val_accuracy: 0.2857\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8315 - accuracy: 0.2857 - val_loss: 1.1367 - val_accuracy: 0.2857\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8298 - accuracy: 0.2857 - val_loss: 1.1437 - val_accuracy: 0.2857\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8226 - accuracy: 0.2500 - val_loss: 1.1510 - val_accuracy: 0.2857\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8146 - accuracy: 0.2679 - val_loss: 1.1582 - val_accuracy: 0.2857\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8145 - accuracy: 0.2857 - val_loss: 1.1654 - val_accuracy: 0.2857\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8033 - accuracy: 0.2500 - val_loss: 1.1723 - val_accuracy: 0.2857\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7991 - accuracy: 0.3036 - val_loss: 1.1790 - val_accuracy: 0.2857\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7915 - accuracy: 0.2500 - val_loss: 1.1852 - val_accuracy: 0.2857\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7876 - accuracy: 0.2679 - val_loss: 1.1910 - val_accuracy: 0.2857\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7892 - accuracy: 0.2857 - val_loss: 1.1962 - val_accuracy: 0.2857\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7825 - accuracy: 0.2857 - val_loss: 1.2008 - val_accuracy: 0.2857\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7752 - accuracy: 0.3036 - val_loss: 1.2052 - val_accuracy: 0.2857\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.7684 - accuracy: 0.3036 - val_loss: 1.2093 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.7631 - accuracy: 0.3036 - val_loss: 1.2133 - val_accuracy: 0.2143\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7612 - accuracy: 0.2857 - val_loss: 1.2166 - val_accuracy: 0.2143\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7564 - accuracy: 0.3393 - val_loss: 1.2201 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7565 - accuracy: 0.3214 - val_loss: 1.2233 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7474 - accuracy: 0.3393 - val_loss: 1.2264 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7435 - accuracy: 0.3393 - val_loss: 1.2296 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7410 - accuracy: 0.3214 - val_loss: 1.2326 - val_accuracy: 0.2143\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7378 - accuracy: 0.3571 - val_loss: 1.2355 - val_accuracy: 0.2143\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7326 - accuracy: 0.3214 - val_loss: 1.2377 - val_accuracy: 0.2143\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7271 - accuracy: 0.3393 - val_loss: 1.2392 - val_accuracy: 0.2143\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7206 - accuracy: 0.3750 - val_loss: 1.2401 - val_accuracy: 0.2143\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7177 - accuracy: 0.3571 - val_loss: 1.2414 - val_accuracy: 0.0714\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7190 - accuracy: 0.3750 - val_loss: 1.2420 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7117 - accuracy: 0.3393 - val_loss: 1.2419 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7062 - accuracy: 0.4464 - val_loss: 1.2425 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7006 - accuracy: 0.3929 - val_loss: 1.2435 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6982 - accuracy: 0.4107 - val_loss: 1.2450 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6960 - accuracy: 0.4107 - val_loss: 1.2464 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6982 - accuracy: 0.3929 - val_loss: 1.2477 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6840 - accuracy: 0.4107 - val_loss: 1.2491 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6803 - accuracy: 0.4286 - val_loss: 1.2508 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6717 - accuracy: 0.4107 - val_loss: 1.2528 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6804 - accuracy: 0.4286 - val_loss: 1.2549 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6697 - accuracy: 0.3750 - val_loss: 1.2573 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6627 - accuracy: 0.4286 - val_loss: 1.2615 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6655 - accuracy: 0.4107 - val_loss: 1.2656 - val_accuracy: 0.0714\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6550 - accuracy: 0.4643 - val_loss: 1.2700 - val_accuracy: 0.0714\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6492 - accuracy: 0.3929 - val_loss: 1.2740 - val_accuracy: 0.0714\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6459 - accuracy: 0.4464 - val_loss: 1.2787 - val_accuracy: 0.0714\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6442 - accuracy: 0.4107 - val_loss: 1.2861 - val_accuracy: 0.0714\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6424 - accuracy: 0.4643 - val_loss: 1.2928 - val_accuracy: 0.0714\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6331 - accuracy: 0.4286 - val_loss: 1.2955 - val_accuracy: 0.0714\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6363 - accuracy: 0.4107 - val_loss: 1.2956 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6315 - accuracy: 0.3929 - val_loss: 1.2928 - val_accuracy: 0.0714\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6244 - accuracy: 0.4286 - val_loss: 1.2949 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6164 - accuracy: 0.4286 - val_loss: 1.2982 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6142 - accuracy: 0.4107 - val_loss: 1.3022 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6069 - accuracy: 0.4286 - val_loss: 1.3083 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6096 - accuracy: 0.3929 - val_loss: 1.3171 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6060 - accuracy: 0.4107 - val_loss: 1.3255 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6082 - accuracy: 0.4464 - val_loss: 1.3299 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.5924 - accuracy: 0.4464 - val_loss: 1.3326 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5954 - accuracy: 0.4286 - val_loss: 1.3316 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5930 - accuracy: 0.3750 - val_loss: 1.3300 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5692 - accuracy: 0.4107 - val_loss: 1.3303 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5771 - accuracy: 0.4107 - val_loss: 1.3331 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5687 - accuracy: 0.3929 - val_loss: 1.3399 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5637 - accuracy: 0.4107 - val_loss: 1.3487 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5750 - accuracy: 0.3929 - val_loss: 1.3568 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5498 - accuracy: 0.4464 - val_loss: 1.3640 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5493 - accuracy: 0.4286 - val_loss: 1.3707 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5508 - accuracy: 0.4107 - val_loss: 1.3747 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5473 - accuracy: 0.4107 - val_loss: 1.3732 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5455 - accuracy: 0.3929 - val_loss: 1.3735 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5340 - accuracy: 0.4286 - val_loss: 1.3748 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5233 - accuracy: 0.4464 - val_loss: 1.3772 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5231 - accuracy: 0.4464 - val_loss: 1.3825 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5134 - accuracy: 0.4286 - val_loss: 1.3902 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5142 - accuracy: 0.4643 - val_loss: 1.3952 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5058 - accuracy: 0.4286 - val_loss: 1.3964 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5020 - accuracy: 0.4286 - val_loss: 1.3969 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4878 - accuracy: 0.4107 - val_loss: 1.4011 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4893 - accuracy: 0.4286 - val_loss: 1.4044 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4961 - accuracy: 0.4643 - val_loss: 1.4104 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4804 - accuracy: 0.4286 - val_loss: 1.4172 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4915 - accuracy: 0.4464 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4692 - accuracy: 0.4286 - val_loss: 1.4291 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4720 - accuracy: 0.4286 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4624 - accuracy: 0.3750 - val_loss: 1.4277 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4630 - accuracy: 0.4286 - val_loss: 1.4271 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.4432 - accuracy: 0.4643 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4541 - accuracy: 0.4464 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4525 - accuracy: 0.4464 - val_loss: 1.4277 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4450 - accuracy: 0.5179 - val_loss: 1.4266 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4510 - accuracy: 0.4107 - val_loss: 1.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4401 - accuracy: 0.4821 - val_loss: 1.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4323 - accuracy: 0.4107 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4231 - accuracy: 0.4286 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4063 - accuracy: 0.4464 - val_loss: 1.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4067 - accuracy: 0.4821 - val_loss: 1.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4147 - accuracy: 0.4821 - val_loss: 1.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4054 - accuracy: 0.4286 - val_loss: 1.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4000 - accuracy: 0.3929 - val_loss: 1.4343 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3897 - accuracy: 0.5179 - val_loss: 1.4385 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4015 - accuracy: 0.4464 - val_loss: 1.4366 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4024 - accuracy: 0.5179 - val_loss: 1.4289 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.3980 - accuracy: 0.5000 - val_loss: 1.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3973 - accuracy: 0.4643 - val_loss: 1.4265 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3874 - accuracy: 0.5357 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3604 - accuracy: 0.4643 - val_loss: 1.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3739 - accuracy: 0.5179 - val_loss: 1.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3709 - accuracy: 0.4464 - val_loss: 1.4161 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3734 - accuracy: 0.4464 - val_loss: 1.4054 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3558 - accuracy: 0.5000 - val_loss: 1.3990 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3454 - accuracy: 0.5536 - val_loss: 1.4035 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3513 - accuracy: 0.5000 - val_loss: 1.4122 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3432 - accuracy: 0.4643 - val_loss: 1.4258 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3450 - accuracy: 0.5000 - val_loss: 1.4408 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3377 - accuracy: 0.5179 - val_loss: 1.4497 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3301 - accuracy: 0.5000 - val_loss: 1.4496 - val_accuracy: 0.1429\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3324 - accuracy: 0.5536 - val_loss: 1.4362 - val_accuracy: 0.1429\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3351 - accuracy: 0.5000 - val_loss: 1.4261 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3318 - accuracy: 0.4643 - val_loss: 1.4165 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3311 - accuracy: 0.5179 - val_loss: 1.4057 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3165 - accuracy: 0.5893 - val_loss: 1.3993 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3169 - accuracy: 0.4821 - val_loss: 1.3962 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3063 - accuracy: 0.5357 - val_loss: 1.3979 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3156 - accuracy: 0.4286 - val_loss: 1.4054 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3010 - accuracy: 0.5179 - val_loss: 1.4094 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3087 - accuracy: 0.5179 - val_loss: 1.4110 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2877 - accuracy: 0.5357 - val_loss: 1.4109 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2858 - accuracy: 0.5893 - val_loss: 1.4070 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2970 - accuracy: 0.5357 - val_loss: 1.4057 - val_accuracy: 0.1429\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2824 - accuracy: 0.5714 - val_loss: 1.4059 - val_accuracy: 0.1429\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2862 - accuracy: 0.4821 - val_loss: 1.4101 - val_accuracy: 0.2143\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2761 - accuracy: 0.5714 - val_loss: 1.4169 - val_accuracy: 0.1429\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2831 - accuracy: 0.4821 - val_loss: 1.4162 - val_accuracy: 0.1429\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2770 - accuracy: 0.5179 - val_loss: 1.4141 - val_accuracy: 0.0714\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2753 - accuracy: 0.5536 - val_loss: 1.4135 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2708 - accuracy: 0.5179 - val_loss: 1.4134 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2720 - accuracy: 0.4643 - val_loss: 1.4178 - val_accuracy: 0.2143\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2685 - accuracy: 0.5714 - val_loss: 1.4118 - val_accuracy: 0.1429\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2590 - accuracy: 0.5179 - val_loss: 1.4054 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2525 - accuracy: 0.5000 - val_loss: 1.3984 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2621 - accuracy: 0.5714 - val_loss: 1.3947 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2517 - accuracy: 0.6250 - val_loss: 1.4015 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2530 - accuracy: 0.5536 - val_loss: 1.4032 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2473 - accuracy: 0.5357 - val_loss: 1.4034 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2502 - accuracy: 0.5179 - val_loss: 1.4032 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2478 - accuracy: 0.5893 - val_loss: 1.4052 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2314 - accuracy: 0.6250 - val_loss: 1.4142 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2337 - accuracy: 0.6250 - val_loss: 1.4260 - val_accuracy: 0.2143\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2435 - accuracy: 0.5893 - val_loss: 1.4219 - val_accuracy: 0.2143\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2325 - accuracy: 0.6071 - val_loss: 1.4202 - val_accuracy: 0.2143\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2307 - accuracy: 0.6071 - val_loss: 1.4228 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2358 - accuracy: 0.5357 - val_loss: 1.4298 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2203 - accuracy: 0.5714 - val_loss: 1.4329 - val_accuracy: 0.1429\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2153 - accuracy: 0.5893 - val_loss: 1.4345 - val_accuracy: 0.1429\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2253 - accuracy: 0.6607 - val_loss: 1.4360 - val_accuracy: 0.1429\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2181 - accuracy: 0.5893 - val_loss: 1.4463 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2071 - accuracy: 0.5714 - val_loss: 1.4596 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2216 - accuracy: 0.5714 - val_loss: 1.4570 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2158 - accuracy: 0.6071 - val_loss: 1.4443 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2097 - accuracy: 0.6250 - val_loss: 1.4317 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2048 - accuracy: 0.5893 - val_loss: 1.4230 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2068 - accuracy: 0.5357 - val_loss: 1.4113 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1970 - accuracy: 0.5893 - val_loss: 1.3950 - val_accuracy: 0.1429\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.2011 - accuracy: 0.6071 - val_loss: 1.3843 - val_accuracy: 0.1429\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1989 - accuracy: 0.6607 - val_loss: 1.3809 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2087 - accuracy: 0.5893 - val_loss: 1.3956 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1829 - accuracy: 0.6071 - val_loss: 1.4185 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1818 - accuracy: 0.5893 - val_loss: 1.4460 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1882 - accuracy: 0.5536 - val_loss: 1.4720 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1918 - accuracy: 0.6071 - val_loss: 1.4823 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1861 - accuracy: 0.6429 - val_loss: 1.4797 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1847 - accuracy: 0.6071 - val_loss: 1.4669 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1774 - accuracy: 0.6071 - val_loss: 1.4520 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1732 - accuracy: 0.5893 - val_loss: 1.4497 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1858 - accuracy: 0.5893 - val_loss: 1.4543 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1732 - accuracy: 0.5179 - val_loss: 1.4619 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1763 - accuracy: 0.6607 - val_loss: 1.4642 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1644 - accuracy: 0.6607 - val_loss: 1.4696 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1686 - accuracy: 0.6429 - val_loss: 1.4742 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1567 - accuracy: 0.6250 - val_loss: 1.4767 - val_accuracy: 0.0714\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1627 - accuracy: 0.6250 - val_loss: 1.4767 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1572 - accuracy: 0.5893 - val_loss: 1.4791 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1649 - accuracy: 0.5714 - val_loss: 1.4843 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1605 - accuracy: 0.6250 - val_loss: 1.4945 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1598 - accuracy: 0.5893 - val_loss: 1.4988 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1483 - accuracy: 0.6607 - val_loss: 1.5007 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1521 - accuracy: 0.6071 - val_loss: 1.5013 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1656 - accuracy: 0.6429 - val_loss: 1.5037 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1532 - accuracy: 0.6964 - val_loss: 1.5073 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1488 - accuracy: 0.6607 - val_loss: 1.5114 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1585 - accuracy: 0.6607 - val_loss: 1.5137 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1527 - accuracy: 0.6250 - val_loss: 1.5109 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1481 - accuracy: 0.6786 - val_loss: 1.5057 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1412 - accuracy: 0.6786 - val_loss: 1.5042 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1441 - accuracy: 0.6786 - val_loss: 1.5054 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1413 - accuracy: 0.6607 - val_loss: 1.5133 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1325 - accuracy: 0.6429 - val_loss: 1.5221 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1374 - accuracy: 0.6607 - val_loss: 1.5341 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1375 - accuracy: 0.6607 - val_loss: 1.5441 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1389 - accuracy: 0.6429 - val_loss: 1.5543 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1352 - accuracy: 0.7143 - val_loss: 1.5640 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1408 - accuracy: 0.6964 - val_loss: 1.5652 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1231 - accuracy: 0.7143 - val_loss: 1.5629 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1225 - accuracy: 0.7143 - val_loss: 1.5627 - val_accuracy: 0.0714\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1408 - accuracy: 0.6429 - val_loss: 1.5558 - val_accuracy: 0.0714\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1280 - accuracy: 0.6429 - val_loss: 1.5488 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1277 - accuracy: 0.7321 - val_loss: 1.5427 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1348 - accuracy: 0.6607 - val_loss: 1.5412 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1359 - accuracy: 0.7321 - val_loss: 1.5486 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1260 - accuracy: 0.6964 - val_loss: 1.5642 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1276 - accuracy: 0.6786 - val_loss: 1.5747 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1210 - accuracy: 0.7500 - val_loss: 1.5829 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1194 - accuracy: 0.6964 - val_loss: 1.5852 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.1200 - accuracy: 0.7500 - val_loss: 1.5817 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.5817 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.4, lstm_units=240, wl= 7, epoch=240, batch_size=500, Scores: [1.5816651582717896, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.5816651582717896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9845 - accuracy: 0.1786 - val_loss: 1.0685 - val_accuracy: 0.2143\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9827 - accuracy: 0.1429 - val_loss: 1.0691 - val_accuracy: 0.2143\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9793 - accuracy: 0.1250 - val_loss: 1.0697 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9787 - accuracy: 0.1964 - val_loss: 1.0703 - val_accuracy: 0.0714\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9767 - accuracy: 0.2143 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9762 - accuracy: 0.2143 - val_loss: 1.0714 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9745 - accuracy: 0.2321 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9721 - accuracy: 0.2500 - val_loss: 1.0726 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9680 - accuracy: 0.3214 - val_loss: 1.0733 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9680 - accuracy: 0.2500 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9667 - accuracy: 0.3036 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9630 - accuracy: 0.3214 - val_loss: 1.0752 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.9624 - accuracy: 0.3214 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9618 - accuracy: 0.3214 - val_loss: 1.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9587 - accuracy: 0.3571 - val_loss: 1.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9579 - accuracy: 0.3214 - val_loss: 1.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9533 - accuracy: 0.3214 - val_loss: 1.0784 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9522 - accuracy: 0.3929 - val_loss: 1.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9483 - accuracy: 0.4286 - val_loss: 1.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9474 - accuracy: 0.3214 - val_loss: 1.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9441 - accuracy: 0.3571 - val_loss: 1.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9449 - accuracy: 0.3393 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9430 - accuracy: 0.3393 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9386 - accuracy: 0.3571 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9364 - accuracy: 0.3393 - val_loss: 1.0838 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9336 - accuracy: 0.3571 - val_loss: 1.0845 - val_accuracy: 0.0714\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9318 - accuracy: 0.3750 - val_loss: 1.0852 - val_accuracy: 0.0714\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9314 - accuracy: 0.3393 - val_loss: 1.0860 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9262 - accuracy: 0.3393 - val_loss: 1.0867 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9252 - accuracy: 0.3393 - val_loss: 1.0874 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9225 - accuracy: 0.3214 - val_loss: 1.0882 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9178 - accuracy: 0.4286 - val_loss: 1.0890 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0890 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=32, batch_size=100, Scores: [1.0890041589736938, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.0890041589736938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9838 - accuracy: 0.1250 - val_loss: 1.0731 - val_accuracy: 0.3571\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9813 - accuracy: 0.0893 - val_loss: 1.0737 - val_accuracy: 0.2857\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9833 - accuracy: 0.1071 - val_loss: 1.0743 - val_accuracy: 0.2143\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9769 - accuracy: 0.1964 - val_loss: 1.0749 - val_accuracy: 0.0714\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9753 - accuracy: 0.1429 - val_loss: 1.0756 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9763 - accuracy: 0.1964 - val_loss: 1.0763 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9760 - accuracy: 0.1964 - val_loss: 1.0769 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9714 - accuracy: 0.2500 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9719 - accuracy: 0.2143 - val_loss: 1.0783 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9663 - accuracy: 0.2500 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9661 - accuracy: 0.2143 - val_loss: 1.0797 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9636 - accuracy: 0.2679 - val_loss: 1.0804 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9627 - accuracy: 0.3036 - val_loss: 1.0811 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9599 - accuracy: 0.2679 - val_loss: 1.0818 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9595 - accuracy: 0.3036 - val_loss: 1.0825 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9546 - accuracy: 0.3214 - val_loss: 1.0832 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9541 - accuracy: 0.2679 - val_loss: 1.0839 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9526 - accuracy: 0.3214 - val_loss: 1.0846 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9486 - accuracy: 0.3036 - val_loss: 1.0853 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9515 - accuracy: 0.2679 - val_loss: 1.0860 - val_accuracy: 0.0714\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9467 - accuracy: 0.3571 - val_loss: 1.0867 - val_accuracy: 0.0714\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9482 - accuracy: 0.2857 - val_loss: 1.0875 - val_accuracy: 0.0714\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9441 - accuracy: 0.2679 - val_loss: 1.0882 - val_accuracy: 0.0714\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9374 - accuracy: 0.2857 - val_loss: 1.0890 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9379 - accuracy: 0.3036 - val_loss: 1.0898 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9318 - accuracy: 0.3571 - val_loss: 1.0905 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9329 - accuracy: 0.3571 - val_loss: 1.0913 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9278 - accuracy: 0.3393 - val_loss: 1.0922 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9264 - accuracy: 0.3571 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9246 - accuracy: 0.3214 - val_loss: 1.0938 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9202 - accuracy: 0.3214 - val_loss: 1.0947 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9188 - accuracy: 0.3214 - val_loss: 1.0956 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0956 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=32, batch_size=300, Scores: [1.0955935716629028, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.0955935716629028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9843 - accuracy: 0.0893 - val_loss: 1.0716 - val_accuracy: 0.2143\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9803 - accuracy: 0.0714 - val_loss: 1.0722 - val_accuracy: 0.2143\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 1s 769ms/step - loss: 0.9797 - accuracy: 0.1786 - val_loss: 1.0729 - val_accuracy: 0.2143\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9772 - accuracy: 0.2321 - val_loss: 1.0736 - val_accuracy: 0.2143\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9757 - accuracy: 0.0893 - val_loss: 1.0742 - val_accuracy: 0.2143\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9723 - accuracy: 0.2321 - val_loss: 1.0749 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9709 - accuracy: 0.2143 - val_loss: 1.0757 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9694 - accuracy: 0.2857 - val_loss: 1.0764 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9686 - accuracy: 0.2321 - val_loss: 1.0772 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9646 - accuracy: 0.2321 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9623 - accuracy: 0.3393 - val_loss: 1.0787 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9608 - accuracy: 0.3214 - val_loss: 1.0795 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9583 - accuracy: 0.3393 - val_loss: 1.0803 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9606 - accuracy: 0.3750 - val_loss: 1.0811 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9571 - accuracy: 0.2857 - val_loss: 1.0819 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9547 - accuracy: 0.3036 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9526 - accuracy: 0.3571 - val_loss: 1.0836 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9508 - accuracy: 0.3393 - val_loss: 1.0845 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9455 - accuracy: 0.2857 - val_loss: 1.0854 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9436 - accuracy: 0.3214 - val_loss: 1.0862 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9434 - accuracy: 0.3036 - val_loss: 1.0871 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9424 - accuracy: 0.3214 - val_loss: 1.0881 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9390 - accuracy: 0.3036 - val_loss: 1.0890 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9387 - accuracy: 0.3750 - val_loss: 1.0899 - val_accuracy: 0.1429\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9355 - accuracy: 0.3393 - val_loss: 1.0908 - val_accuracy: 0.1429\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9307 - accuracy: 0.3036 - val_loss: 1.0918 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9307 - accuracy: 0.3571 - val_loss: 1.0928 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9307 - accuracy: 0.3036 - val_loss: 1.0938 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9282 - accuracy: 0.3750 - val_loss: 1.0948 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9250 - accuracy: 0.3571 - val_loss: 1.0959 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9176 - accuracy: 0.3214 - val_loss: 1.0969 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9181 - accuracy: 0.3393 - val_loss: 1.0980 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0980 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=32, batch_size=400, Scores: [1.0979758501052856, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.0979758501052856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9826 - accuracy: 0.2321 - val_loss: 1.0659 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9848 - accuracy: 0.1071 - val_loss: 1.0662 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9818 - accuracy: 0.3214 - val_loss: 1.0665 - val_accuracy: 0.0714\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9787 - accuracy: 0.2143 - val_loss: 1.0668 - val_accuracy: 0.0714\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9765 - accuracy: 0.1786 - val_loss: 1.0671 - val_accuracy: 0.0714\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9752 - accuracy: 0.1964 - val_loss: 1.0674 - val_accuracy: 0.0714\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9738 - accuracy: 0.2679 - val_loss: 1.0678 - val_accuracy: 0.0714\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9721 - accuracy: 0.1964 - val_loss: 1.0681 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9703 - accuracy: 0.2679 - val_loss: 1.0684 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9695 - accuracy: 0.1071 - val_loss: 1.0687 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9672 - accuracy: 0.2857 - val_loss: 1.0690 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9645 - accuracy: 0.2500 - val_loss: 1.0693 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9647 - accuracy: 0.3036 - val_loss: 1.0696 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9620 - accuracy: 0.2321 - val_loss: 1.0700 - val_accuracy: 0.0714\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9591 - accuracy: 0.3036 - val_loss: 1.0703 - val_accuracy: 0.0714\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9584 - accuracy: 0.3036 - val_loss: 1.0706 - val_accuracy: 0.0714\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9588 - accuracy: 0.3036 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9563 - accuracy: 0.2857 - val_loss: 1.0713 - val_accuracy: 0.0714\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9528 - accuracy: 0.2500 - val_loss: 1.0717 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9507 - accuracy: 0.3214 - val_loss: 1.0720 - val_accuracy: 0.0714\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9462 - accuracy: 0.3036 - val_loss: 1.0723 - val_accuracy: 0.0714\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9460 - accuracy: 0.2679 - val_loss: 1.0727 - val_accuracy: 0.0714\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9439 - accuracy: 0.3036 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9429 - accuracy: 0.2857 - val_loss: 1.0733 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9392 - accuracy: 0.2321 - val_loss: 1.0736 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9347 - accuracy: 0.3393 - val_loss: 1.0739 - val_accuracy: 0.0714\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9384 - accuracy: 0.3214 - val_loss: 1.0742 - val_accuracy: 0.0714\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9330 - accuracy: 0.2857 - val_loss: 1.0745 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9293 - accuracy: 0.2857 - val_loss: 1.0747 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9286 - accuracy: 0.2500 - val_loss: 1.0750 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9232 - accuracy: 0.3036 - val_loss: 1.0753 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9201 - accuracy: 0.2857 - val_loss: 1.0755 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0755 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=32, batch_size=500, Scores: [1.0755298137664795, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.0755298137664795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9820 - accuracy: 0.0893 - val_loss: 1.0692 - val_accuracy: 0.0714\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9810 - accuracy: 0.0893 - val_loss: 1.0698 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9788 - accuracy: 0.1429 - val_loss: 1.0703 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9796 - accuracy: 0.1429 - val_loss: 1.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9766 - accuracy: 0.1964 - val_loss: 1.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9746 - accuracy: 0.1786 - val_loss: 1.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9718 - accuracy: 0.1429 - val_loss: 1.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9710 - accuracy: 0.1786 - val_loss: 1.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9694 - accuracy: 0.2143 - val_loss: 1.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9684 - accuracy: 0.1786 - val_loss: 1.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9644 - accuracy: 0.1964 - val_loss: 1.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9622 - accuracy: 0.2143 - val_loss: 1.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9630 - accuracy: 0.2500 - val_loss: 1.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9608 - accuracy: 0.1964 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9604 - accuracy: 0.1786 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9577 - accuracy: 0.1964 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9523 - accuracy: 0.2857 - val_loss: 1.0791 - val_accuracy: 0.0714\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9502 - accuracy: 0.2857 - val_loss: 1.0798 - val_accuracy: 0.0714\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9517 - accuracy: 0.2857 - val_loss: 1.0804 - val_accuracy: 0.0714\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9469 - accuracy: 0.2500 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9485 - accuracy: 0.2679 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9427 - accuracy: 0.2500 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9415 - accuracy: 0.2500 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9420 - accuracy: 0.2679 - val_loss: 1.0837 - val_accuracy: 0.0714\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9375 - accuracy: 0.2679 - val_loss: 1.0844 - val_accuracy: 0.0714\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9357 - accuracy: 0.2857 - val_loss: 1.0850 - val_accuracy: 0.0714\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9342 - accuracy: 0.3036 - val_loss: 1.0856 - val_accuracy: 0.0714\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9285 - accuracy: 0.3036 - val_loss: 1.0863 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9292 - accuracy: 0.2321 - val_loss: 1.0869 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9265 - accuracy: 0.2679 - val_loss: 1.0876 - val_accuracy: 0.1429\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9213 - accuracy: 0.3036 - val_loss: 1.0882 - val_accuracy: 0.1429\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9180 - accuracy: 0.2500 - val_loss: 1.0889 - val_accuracy: 0.1429\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9202 - accuracy: 0.2500 - val_loss: 1.0895 - val_accuracy: 0.1429\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9149 - accuracy: 0.3214 - val_loss: 1.0902 - val_accuracy: 0.1429\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9120 - accuracy: 0.3036 - val_loss: 1.0909 - val_accuracy: 0.1429\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9045 - accuracy: 0.3214 - val_loss: 1.0915 - val_accuracy: 0.1429\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9104 - accuracy: 0.3036 - val_loss: 1.0923 - val_accuracy: 0.1429\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9029 - accuracy: 0.2679 - val_loss: 1.0931 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8993 - accuracy: 0.2857 - val_loss: 1.0938 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8943 - accuracy: 0.2500 - val_loss: 1.0947 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8956 - accuracy: 0.3214 - val_loss: 1.0956 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8917 - accuracy: 0.2857 - val_loss: 1.0966 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8915 - accuracy: 0.2679 - val_loss: 1.0977 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8818 - accuracy: 0.2679 - val_loss: 1.0988 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8847 - accuracy: 0.2500 - val_loss: 1.0999 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8831 - accuracy: 0.3214 - val_loss: 1.1012 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8766 - accuracy: 0.2679 - val_loss: 1.1025 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8766 - accuracy: 0.3036 - val_loss: 1.1039 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8711 - accuracy: 0.2857 - val_loss: 1.1053 - val_accuracy: 0.1429\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.8657 - accuracy: 0.2679 - val_loss: 1.1068 - val_accuracy: 0.1429\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8646 - accuracy: 0.2679 - val_loss: 1.1084 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8613 - accuracy: 0.2857 - val_loss: 1.1101 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8540 - accuracy: 0.3036 - val_loss: 1.1119 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8551 - accuracy: 0.2679 - val_loss: 1.1137 - val_accuracy: 0.1429\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8446 - accuracy: 0.2857 - val_loss: 1.1156 - val_accuracy: 0.1429\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8523 - accuracy: 0.3214 - val_loss: 1.1175 - val_accuracy: 0.1429\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8468 - accuracy: 0.2679 - val_loss: 1.1195 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8469 - accuracy: 0.2679 - val_loss: 1.1215 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8358 - accuracy: 0.3036 - val_loss: 1.1237 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8376 - accuracy: 0.2857 - val_loss: 1.1259 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8311 - accuracy: 0.3036 - val_loss: 1.1279 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.8278 - accuracy: 0.3036 - val_loss: 1.1301 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8254 - accuracy: 0.3036 - val_loss: 1.1322 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8252 - accuracy: 0.2857 - val_loss: 1.1343 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1343 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=64, batch_size=100, Scores: [1.1343437433242798, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.1343437433242798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9830 - accuracy: 0.1607 - val_loss: 1.0702 - val_accuracy: 0.0714\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9810 - accuracy: 0.2321 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9821 - accuracy: 0.1250 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9812 - accuracy: 0.1250 - val_loss: 1.0722 - val_accuracy: 0.0714\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9747 - accuracy: 0.2143 - val_loss: 1.0729 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9722 - accuracy: 0.2500 - val_loss: 1.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9736 - accuracy: 0.2143 - val_loss: 1.0743 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9715 - accuracy: 0.3036 - val_loss: 1.0750 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9685 - accuracy: 0.2500 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9651 - accuracy: 0.2143 - val_loss: 1.0764 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9653 - accuracy: 0.2143 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9609 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9608 - accuracy: 0.3571 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9610 - accuracy: 0.2143 - val_loss: 1.0795 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9586 - accuracy: 0.2857 - val_loss: 1.0802 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9533 - accuracy: 0.2679 - val_loss: 1.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9531 - accuracy: 0.2857 - val_loss: 1.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9519 - accuracy: 0.3214 - val_loss: 1.0827 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9517 - accuracy: 0.2679 - val_loss: 1.0835 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9488 - accuracy: 0.3036 - val_loss: 1.0844 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9473 - accuracy: 0.3036 - val_loss: 1.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9459 - accuracy: 0.2857 - val_loss: 1.0862 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.9439 - accuracy: 0.2857 - val_loss: 1.0871 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9427 - accuracy: 0.2857 - val_loss: 1.0880 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9342 - accuracy: 0.2500 - val_loss: 1.0890 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9371 - accuracy: 0.3571 - val_loss: 1.0900 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9357 - accuracy: 0.3036 - val_loss: 1.0910 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9324 - accuracy: 0.3393 - val_loss: 1.0920 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9334 - accuracy: 0.2500 - val_loss: 1.0930 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9236 - accuracy: 0.2857 - val_loss: 1.0941 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9236 - accuracy: 0.3214 - val_loss: 1.0952 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9200 - accuracy: 0.3571 - val_loss: 1.0963 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9175 - accuracy: 0.3214 - val_loss: 1.0975 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9176 - accuracy: 0.3750 - val_loss: 1.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9122 - accuracy: 0.3036 - val_loss: 1.0999 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9110 - accuracy: 0.3571 - val_loss: 1.1012 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9112 - accuracy: 0.3571 - val_loss: 1.1025 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9043 - accuracy: 0.3929 - val_loss: 1.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8984 - accuracy: 0.3036 - val_loss: 1.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9011 - accuracy: 0.2857 - val_loss: 1.1066 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8962 - accuracy: 0.3571 - val_loss: 1.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8980 - accuracy: 0.3929 - val_loss: 1.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8838 - accuracy: 0.3571 - val_loss: 1.1113 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8888 - accuracy: 0.2857 - val_loss: 1.1130 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8825 - accuracy: 0.3036 - val_loss: 1.1148 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8684 - accuracy: 0.3036 - val_loss: 1.1166 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8718 - accuracy: 0.3214 - val_loss: 1.1186 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8721 - accuracy: 0.3571 - val_loss: 1.1207 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8639 - accuracy: 0.3750 - val_loss: 1.1230 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8633 - accuracy: 0.3214 - val_loss: 1.1254 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8644 - accuracy: 0.3214 - val_loss: 1.1279 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8580 - accuracy: 0.3571 - val_loss: 1.1305 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8488 - accuracy: 0.3571 - val_loss: 1.1333 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8428 - accuracy: 0.3393 - val_loss: 1.1362 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8396 - accuracy: 0.3214 - val_loss: 1.1390 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8450 - accuracy: 0.3393 - val_loss: 1.1420 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8373 - accuracy: 0.3214 - val_loss: 1.1449 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8270 - accuracy: 0.3393 - val_loss: 1.1479 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8305 - accuracy: 0.3036 - val_loss: 1.1511 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8188 - accuracy: 0.3571 - val_loss: 1.1540 - val_accuracy: 0.1429\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8297 - accuracy: 0.3393 - val_loss: 1.1568 - val_accuracy: 0.1429\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8152 - accuracy: 0.3214 - val_loss: 1.1595 - val_accuracy: 0.1429\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8288 - accuracy: 0.3571 - val_loss: 1.1622 - val_accuracy: 0.1429\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8158 - accuracy: 0.3571 - val_loss: 1.1649 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1649 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=64, batch_size=300, Scores: [1.1649237871170044, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1649237871170044\n",
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9811 - accuracy: 0.1429 - val_loss: 1.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.9799 - accuracy: 0.1429 - val_loss: 1.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9773 - accuracy: 0.2143 - val_loss: 1.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9747 - accuracy: 0.1429 - val_loss: 1.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9743 - accuracy: 0.2500 - val_loss: 1.0743 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9725 - accuracy: 0.1964 - val_loss: 1.0752 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9692 - accuracy: 0.2500 - val_loss: 1.0761 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9702 - accuracy: 0.1964 - val_loss: 1.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9675 - accuracy: 0.2500 - val_loss: 1.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9674 - accuracy: 0.2321 - val_loss: 1.0788 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9651 - accuracy: 0.3571 - val_loss: 1.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9610 - accuracy: 0.2321 - val_loss: 1.0806 - val_accuracy: 0.0714\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9596 - accuracy: 0.3036 - val_loss: 1.0815 - val_accuracy: 0.0714\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9594 - accuracy: 0.2500 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.9576 - accuracy: 0.3393 - val_loss: 1.0834 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9548 - accuracy: 0.2500 - val_loss: 1.0843 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9518 - accuracy: 0.2321 - val_loss: 1.0853 - val_accuracy: 0.0714\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9489 - accuracy: 0.2857 - val_loss: 1.0863 - val_accuracy: 0.0714\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9506 - accuracy: 0.2679 - val_loss: 1.0873 - val_accuracy: 0.0714\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9464 - accuracy: 0.2679 - val_loss: 1.0883 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9468 - accuracy: 0.3036 - val_loss: 1.0894 - val_accuracy: 0.0714\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9448 - accuracy: 0.3214 - val_loss: 1.0905 - val_accuracy: 0.0714\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9429 - accuracy: 0.3036 - val_loss: 1.0916 - val_accuracy: 0.0714\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9385 - accuracy: 0.2857 - val_loss: 1.0927 - val_accuracy: 0.0714\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9406 - accuracy: 0.3214 - val_loss: 1.0938 - val_accuracy: 0.0714\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9366 - accuracy: 0.3036 - val_loss: 1.0950 - val_accuracy: 0.0714\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9325 - accuracy: 0.3036 - val_loss: 1.0962 - val_accuracy: 0.0714\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9307 - accuracy: 0.3571 - val_loss: 1.0975 - val_accuracy: 0.0714\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9297 - accuracy: 0.3036 - val_loss: 1.0987 - val_accuracy: 0.0714\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9258 - accuracy: 0.3214 - val_loss: 1.1000 - val_accuracy: 0.0714\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9224 - accuracy: 0.4107 - val_loss: 1.1012 - val_accuracy: 0.0714\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9268 - accuracy: 0.3214 - val_loss: 1.1025 - val_accuracy: 0.0714\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9196 - accuracy: 0.3393 - val_loss: 1.1038 - val_accuracy: 0.0714\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9172 - accuracy: 0.3036 - val_loss: 1.1050 - val_accuracy: 0.0714\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9141 - accuracy: 0.3036 - val_loss: 1.1064 - val_accuracy: 0.0714\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9106 - accuracy: 0.3750 - val_loss: 1.1078 - val_accuracy: 0.0714\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9064 - accuracy: 0.2500 - val_loss: 1.1092 - val_accuracy: 0.0714\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9070 - accuracy: 0.3214 - val_loss: 1.1107 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9012 - accuracy: 0.3393 - val_loss: 1.1122 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9065 - accuracy: 0.3393 - val_loss: 1.1137 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9007 - accuracy: 0.3214 - val_loss: 1.1153 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8976 - accuracy: 0.3214 - val_loss: 1.1169 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8894 - accuracy: 0.3036 - val_loss: 1.1185 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8926 - accuracy: 0.3571 - val_loss: 1.1202 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8843 - accuracy: 0.3571 - val_loss: 1.1218 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8847 - accuracy: 0.3571 - val_loss: 1.1235 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8807 - accuracy: 0.3393 - val_loss: 1.1252 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8738 - accuracy: 0.3393 - val_loss: 1.1269 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8697 - accuracy: 0.3393 - val_loss: 1.1287 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8650 - accuracy: 0.3393 - val_loss: 1.1306 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8634 - accuracy: 0.3393 - val_loss: 1.1325 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8657 - accuracy: 0.3036 - val_loss: 1.1344 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8555 - accuracy: 0.3393 - val_loss: 1.1363 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8617 - accuracy: 0.3214 - val_loss: 1.1383 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8560 - accuracy: 0.3393 - val_loss: 1.1403 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8491 - accuracy: 0.3036 - val_loss: 1.1425 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8447 - accuracy: 0.2857 - val_loss: 1.1445 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8350 - accuracy: 0.3214 - val_loss: 1.1465 - val_accuracy: 0.2143\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8392 - accuracy: 0.3393 - val_loss: 1.1484 - val_accuracy: 0.2143\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8326 - accuracy: 0.3036 - val_loss: 1.1504 - val_accuracy: 0.2143\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8253 - accuracy: 0.3571 - val_loss: 1.1523 - val_accuracy: 0.2143\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8253 - accuracy: 0.3571 - val_loss: 1.1542 - val_accuracy: 0.2143\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8224 - accuracy: 0.3393 - val_loss: 1.1562 - val_accuracy: 0.2143\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8123 - accuracy: 0.3214 - val_loss: 1.1582 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.1582 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=64, batch_size=400, Scores: [1.1581653356552124, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.1581653356552124\n",
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9889 - accuracy: 0.1250 - val_loss: 1.0766 - val_accuracy: 0.1429\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9851 - accuracy: 0.1250 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9822 - accuracy: 0.1786 - val_loss: 1.0776 - val_accuracy: 0.1429\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9827 - accuracy: 0.1429 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9778 - accuracy: 0.2321 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9775 - accuracy: 0.2321 - val_loss: 1.0791 - val_accuracy: 0.0714\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9756 - accuracy: 0.2321 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9734 - accuracy: 0.2321 - val_loss: 1.0802 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9703 - accuracy: 0.1786 - val_loss: 1.0807 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9701 - accuracy: 0.2857 - val_loss: 1.0813 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9694 - accuracy: 0.1607 - val_loss: 1.0819 - val_accuracy: 0.0714\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9649 - accuracy: 0.2500 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9654 - accuracy: 0.2500 - val_loss: 1.0830 - val_accuracy: 0.0714\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.9646 - accuracy: 0.2321 - val_loss: 1.0835 - val_accuracy: 0.0714\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9601 - accuracy: 0.1964 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9599 - accuracy: 0.2500 - val_loss: 1.0846 - val_accuracy: 0.0714\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9581 - accuracy: 0.2143 - val_loss: 1.0851 - val_accuracy: 0.0714\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9559 - accuracy: 0.2321 - val_loss: 1.0856 - val_accuracy: 0.0714\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9539 - accuracy: 0.3214 - val_loss: 1.0861 - val_accuracy: 0.0714\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9520 - accuracy: 0.2857 - val_loss: 1.0865 - val_accuracy: 0.0714\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9477 - accuracy: 0.2857 - val_loss: 1.0870 - val_accuracy: 0.0714\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9495 - accuracy: 0.2500 - val_loss: 1.0875 - val_accuracy: 0.0714\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9467 - accuracy: 0.3036 - val_loss: 1.0880 - val_accuracy: 0.0714\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9425 - accuracy: 0.3036 - val_loss: 1.0885 - val_accuracy: 0.0714\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9423 - accuracy: 0.3036 - val_loss: 1.0890 - val_accuracy: 0.0714\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9413 - accuracy: 0.2857 - val_loss: 1.0895 - val_accuracy: 0.0714\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9378 - accuracy: 0.2857 - val_loss: 1.0900 - val_accuracy: 0.0714\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9330 - accuracy: 0.2679 - val_loss: 1.0905 - val_accuracy: 0.0714\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9328 - accuracy: 0.3571 - val_loss: 1.0910 - val_accuracy: 0.0714\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9321 - accuracy: 0.3571 - val_loss: 1.0914 - val_accuracy: 0.0714\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9280 - accuracy: 0.3393 - val_loss: 1.0919 - val_accuracy: 0.0714\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9251 - accuracy: 0.3571 - val_loss: 1.0924 - val_accuracy: 0.0714\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9227 - accuracy: 0.3750 - val_loss: 1.0928 - val_accuracy: 0.0714\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9162 - accuracy: 0.3750 - val_loss: 1.0933 - val_accuracy: 0.0714\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9164 - accuracy: 0.3750 - val_loss: 1.0937 - val_accuracy: 0.0714\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9149 - accuracy: 0.3214 - val_loss: 1.0942 - val_accuracy: 0.0714\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9136 - accuracy: 0.3750 - val_loss: 1.0948 - val_accuracy: 0.0714\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9105 - accuracy: 0.3571 - val_loss: 1.0953 - val_accuracy: 0.0714\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9043 - accuracy: 0.3393 - val_loss: 1.0959 - val_accuracy: 0.0714\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9022 - accuracy: 0.3750 - val_loss: 1.0965 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8912 - accuracy: 0.3750 - val_loss: 1.0972 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8927 - accuracy: 0.3393 - val_loss: 1.0979 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8914 - accuracy: 0.4107 - val_loss: 1.0987 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8857 - accuracy: 0.3750 - val_loss: 1.0996 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8863 - accuracy: 0.4286 - val_loss: 1.1005 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8803 - accuracy: 0.3393 - val_loss: 1.1016 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8799 - accuracy: 0.3036 - val_loss: 1.1027 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.8746 - accuracy: 0.3036 - val_loss: 1.1039 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8727 - accuracy: 0.2857 - val_loss: 1.1052 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8633 - accuracy: 0.3571 - val_loss: 1.1065 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8642 - accuracy: 0.3214 - val_loss: 1.1078 - val_accuracy: 0.2143\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8629 - accuracy: 0.3393 - val_loss: 1.1092 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8541 - accuracy: 0.3214 - val_loss: 1.1106 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8593 - accuracy: 0.3036 - val_loss: 1.1119 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8527 - accuracy: 0.3929 - val_loss: 1.1132 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8508 - accuracy: 0.3571 - val_loss: 1.1146 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8443 - accuracy: 0.3036 - val_loss: 1.1159 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8494 - accuracy: 0.3393 - val_loss: 1.1171 - val_accuracy: 0.2143\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8415 - accuracy: 0.3036 - val_loss: 1.1184 - val_accuracy: 0.2143\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8435 - accuracy: 0.2857 - val_loss: 1.1196 - val_accuracy: 0.2143\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8403 - accuracy: 0.3214 - val_loss: 1.1208 - val_accuracy: 0.2143\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8372 - accuracy: 0.3036 - val_loss: 1.1219 - val_accuracy: 0.2143\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8241 - accuracy: 0.3214 - val_loss: 1.1230 - val_accuracy: 0.2143\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8282 - accuracy: 0.3750 - val_loss: 1.1241 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1241 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=64, batch_size=500, Scores: [1.124104619026184, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.124104619026184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9846 - accuracy: 0.0714 - val_loss: 1.0660 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9847 - accuracy: 0.1429 - val_loss: 1.0667 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9823 - accuracy: 0.0893 - val_loss: 1.0674 - val_accuracy: 0.2143\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9800 - accuracy: 0.1250 - val_loss: 1.0681 - val_accuracy: 0.2143\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9794 - accuracy: 0.1964 - val_loss: 1.0688 - val_accuracy: 0.2143\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9744 - accuracy: 0.2143 - val_loss: 1.0695 - val_accuracy: 0.2143\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9738 - accuracy: 0.1607 - val_loss: 1.0702 - val_accuracy: 0.2143\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9735 - accuracy: 0.1964 - val_loss: 1.0710 - val_accuracy: 0.2143\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9698 - accuracy: 0.1964 - val_loss: 1.0717 - val_accuracy: 0.2143\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9681 - accuracy: 0.1964 - val_loss: 1.0724 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9685 - accuracy: 0.2321 - val_loss: 1.0732 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9672 - accuracy: 0.2143 - val_loss: 1.0740 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9631 - accuracy: 0.2679 - val_loss: 1.0747 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9621 - accuracy: 0.1786 - val_loss: 1.0755 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9605 - accuracy: 0.1964 - val_loss: 1.0763 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9577 - accuracy: 0.2500 - val_loss: 1.0772 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9555 - accuracy: 0.2857 - val_loss: 1.0780 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9562 - accuracy: 0.2321 - val_loss: 1.0788 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9549 - accuracy: 0.3036 - val_loss: 1.0797 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9500 - accuracy: 0.3214 - val_loss: 1.0805 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9485 - accuracy: 0.2500 - val_loss: 1.0814 - val_accuracy: 0.2857\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9497 - accuracy: 0.2143 - val_loss: 1.0823 - val_accuracy: 0.2857\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9433 - accuracy: 0.2500 - val_loss: 1.0832 - val_accuracy: 0.2857\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9455 - accuracy: 0.2321 - val_loss: 1.0841 - val_accuracy: 0.2857\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9422 - accuracy: 0.2321 - val_loss: 1.0851 - val_accuracy: 0.2857\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9391 - accuracy: 0.2143 - val_loss: 1.0860 - val_accuracy: 0.2857\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9387 - accuracy: 0.2500 - val_loss: 1.0870 - val_accuracy: 0.2857\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9335 - accuracy: 0.2500 - val_loss: 1.0881 - val_accuracy: 0.2857\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9339 - accuracy: 0.2500 - val_loss: 1.0891 - val_accuracy: 0.2857\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9351 - accuracy: 0.1964 - val_loss: 1.0902 - val_accuracy: 0.2857\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9296 - accuracy: 0.1786 - val_loss: 1.0912 - val_accuracy: 0.2857\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9273 - accuracy: 0.2500 - val_loss: 1.0922 - val_accuracy: 0.2857\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9234 - accuracy: 0.2500 - val_loss: 1.0933 - val_accuracy: 0.2857\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9254 - accuracy: 0.2679 - val_loss: 1.0943 - val_accuracy: 0.2857\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9225 - accuracy: 0.1964 - val_loss: 1.0954 - val_accuracy: 0.2857\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9140 - accuracy: 0.2500 - val_loss: 1.0964 - val_accuracy: 0.2857\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9164 - accuracy: 0.2500 - val_loss: 1.0976 - val_accuracy: 0.2857\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9118 - accuracy: 0.2500 - val_loss: 1.0987 - val_accuracy: 0.2857\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9060 - accuracy: 0.2857 - val_loss: 1.0997 - val_accuracy: 0.2857\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9045 - accuracy: 0.3214 - val_loss: 1.1008 - val_accuracy: 0.2857\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8998 - accuracy: 0.2857 - val_loss: 1.1019 - val_accuracy: 0.2857\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8987 - accuracy: 0.2500 - val_loss: 1.1029 - val_accuracy: 0.2857\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8961 - accuracy: 0.2857 - val_loss: 1.1039 - val_accuracy: 0.2857\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8952 - accuracy: 0.2857 - val_loss: 1.1049 - val_accuracy: 0.2143\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8890 - accuracy: 0.2857 - val_loss: 1.1059 - val_accuracy: 0.2143\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8872 - accuracy: 0.3036 - val_loss: 1.1069 - val_accuracy: 0.2143\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8883 - accuracy: 0.3036 - val_loss: 1.1080 - val_accuracy: 0.2857\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8822 - accuracy: 0.3036 - val_loss: 1.1091 - val_accuracy: 0.2857\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8769 - accuracy: 0.3214 - val_loss: 1.1101 - val_accuracy: 0.2857\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8765 - accuracy: 0.3393 - val_loss: 1.1111 - val_accuracy: 0.2857\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8736 - accuracy: 0.3036 - val_loss: 1.1121 - val_accuracy: 0.2857\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8629 - accuracy: 0.2857 - val_loss: 1.1132 - val_accuracy: 0.2857\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.8659 - accuracy: 0.3036 - val_loss: 1.1142 - val_accuracy: 0.2857\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8544 - accuracy: 0.2857 - val_loss: 1.1151 - val_accuracy: 0.2857\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8593 - accuracy: 0.3036 - val_loss: 1.1159 - val_accuracy: 0.2857\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8525 - accuracy: 0.3036 - val_loss: 1.1168 - val_accuracy: 0.2857\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8495 - accuracy: 0.2679 - val_loss: 1.1175 - val_accuracy: 0.2857\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8402 - accuracy: 0.3214 - val_loss: 1.1182 - val_accuracy: 0.2857\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8413 - accuracy: 0.3214 - val_loss: 1.1190 - val_accuracy: 0.2857\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8420 - accuracy: 0.2500 - val_loss: 1.1197 - val_accuracy: 0.2857\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8423 - accuracy: 0.3036 - val_loss: 1.1205 - val_accuracy: 0.2857\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8319 - accuracy: 0.2679 - val_loss: 1.1214 - val_accuracy: 0.2857\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8317 - accuracy: 0.3214 - val_loss: 1.1223 - val_accuracy: 0.2857\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8219 - accuracy: 0.3214 - val_loss: 1.1233 - val_accuracy: 0.2857\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8261 - accuracy: 0.2857 - val_loss: 1.1241 - val_accuracy: 0.2857\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8207 - accuracy: 0.3214 - val_loss: 1.1250 - val_accuracy: 0.2857\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8136 - accuracy: 0.2679 - val_loss: 1.1257 - val_accuracy: 0.2857\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8184 - accuracy: 0.2857 - val_loss: 1.1266 - val_accuracy: 0.2857\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8105 - accuracy: 0.3214 - val_loss: 1.1277 - val_accuracy: 0.2857\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8042 - accuracy: 0.3214 - val_loss: 1.1290 - val_accuracy: 0.2857\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8048 - accuracy: 0.3214 - val_loss: 1.1305 - val_accuracy: 0.2857\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7920 - accuracy: 0.2857 - val_loss: 1.1325 - val_accuracy: 0.2857\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7988 - accuracy: 0.3036 - val_loss: 1.1348 - val_accuracy: 0.2143\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7911 - accuracy: 0.3393 - val_loss: 1.1377 - val_accuracy: 0.2143\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7969 - accuracy: 0.3214 - val_loss: 1.1410 - val_accuracy: 0.2143\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7856 - accuracy: 0.3214 - val_loss: 1.1447 - val_accuracy: 0.2143\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7840 - accuracy: 0.3393 - val_loss: 1.1482 - val_accuracy: 0.2143\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7842 - accuracy: 0.3393 - val_loss: 1.1520 - val_accuracy: 0.2143\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7792 - accuracy: 0.3393 - val_loss: 1.1561 - val_accuracy: 0.2143\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7771 - accuracy: 0.3750 - val_loss: 1.1604 - val_accuracy: 0.2143\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7815 - accuracy: 0.3393 - val_loss: 1.1648 - val_accuracy: 0.2143\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7684 - accuracy: 0.3393 - val_loss: 1.1691 - val_accuracy: 0.2143\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7680 - accuracy: 0.3393 - val_loss: 1.1734 - val_accuracy: 0.2143\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7700 - accuracy: 0.3750 - val_loss: 1.1773 - val_accuracy: 0.2143\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7682 - accuracy: 0.3571 - val_loss: 1.1813 - val_accuracy: 0.2143\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7690 - accuracy: 0.3929 - val_loss: 1.1852 - val_accuracy: 0.2143\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7560 - accuracy: 0.3571 - val_loss: 1.1891 - val_accuracy: 0.2143\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7587 - accuracy: 0.3214 - val_loss: 1.1924 - val_accuracy: 0.2143\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7690 - accuracy: 0.3393 - val_loss: 1.1954 - val_accuracy: 0.2143\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7605 - accuracy: 0.3393 - val_loss: 1.1980 - val_accuracy: 0.2143\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7537 - accuracy: 0.3750 - val_loss: 1.2006 - val_accuracy: 0.2143\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7624 - accuracy: 0.3393 - val_loss: 1.2029 - val_accuracy: 0.2143\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7568 - accuracy: 0.3214 - val_loss: 1.2051 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7530 - accuracy: 0.3393 - val_loss: 1.2073 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7514 - accuracy: 0.3571 - val_loss: 1.2086 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7452 - accuracy: 0.3393 - val_loss: 1.2099 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7429 - accuracy: 0.3571 - val_loss: 1.2113 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7558 - accuracy: 0.3750 - val_loss: 1.2124 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7460 - accuracy: 0.2857 - val_loss: 1.2137 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7360 - accuracy: 0.3571 - val_loss: 1.2154 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2154 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=100, batch_size=100, Scores: [1.2154195308685303, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.2154195308685303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9832 - accuracy: 0.2321 - val_loss: 1.0732 - val_accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.9819 - accuracy: 0.1786 - val_loss: 1.0738 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9785 - accuracy: 0.3214 - val_loss: 1.0743 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9773 - accuracy: 0.1786 - val_loss: 1.0749 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9746 - accuracy: 0.2143 - val_loss: 1.0755 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9754 - accuracy: 0.3036 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9698 - accuracy: 0.3393 - val_loss: 1.0767 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9682 - accuracy: 0.2679 - val_loss: 1.0773 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9662 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9625 - accuracy: 0.3571 - val_loss: 1.0785 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9617 - accuracy: 0.2321 - val_loss: 1.0791 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9610 - accuracy: 0.2857 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9603 - accuracy: 0.2500 - val_loss: 1.0804 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9565 - accuracy: 0.2679 - val_loss: 1.0810 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.9555 - accuracy: 0.2857 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9513 - accuracy: 0.2857 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9535 - accuracy: 0.2857 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9478 - accuracy: 0.3036 - val_loss: 1.0838 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9472 - accuracy: 0.3036 - val_loss: 1.0845 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.9460 - accuracy: 0.3036 - val_loss: 1.0851 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9440 - accuracy: 0.2500 - val_loss: 1.0859 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9403 - accuracy: 0.2679 - val_loss: 1.0866 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9399 - accuracy: 0.3036 - val_loss: 1.0874 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9375 - accuracy: 0.3214 - val_loss: 1.0882 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9387 - accuracy: 0.2857 - val_loss: 1.0889 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9327 - accuracy: 0.2857 - val_loss: 1.0897 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9291 - accuracy: 0.2857 - val_loss: 1.0905 - val_accuracy: 0.0714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9308 - accuracy: 0.2857 - val_loss: 1.0913 - val_accuracy: 0.0714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9218 - accuracy: 0.3393 - val_loss: 1.0921 - val_accuracy: 0.0714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9241 - accuracy: 0.2857 - val_loss: 1.0930 - val_accuracy: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9187 - accuracy: 0.2857 - val_loss: 1.0939 - val_accuracy: 0.0714\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9114 - accuracy: 0.2679 - val_loss: 1.0948 - val_accuracy: 0.0714\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9118 - accuracy: 0.3214 - val_loss: 1.0958 - val_accuracy: 0.0714\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9061 - accuracy: 0.3393 - val_loss: 1.0968 - val_accuracy: 0.0714\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9032 - accuracy: 0.3036 - val_loss: 1.0979 - val_accuracy: 0.0714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9023 - accuracy: 0.3214 - val_loss: 1.0991 - val_accuracy: 0.0714\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9045 - accuracy: 0.3750 - val_loss: 1.1003 - val_accuracy: 0.0714\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8955 - accuracy: 0.3393 - val_loss: 1.1015 - val_accuracy: 0.0714\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8992 - accuracy: 0.3393 - val_loss: 1.1029 - val_accuracy: 0.0714\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8905 - accuracy: 0.3393 - val_loss: 1.1043 - val_accuracy: 0.0714\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8903 - accuracy: 0.3214 - val_loss: 1.1057 - val_accuracy: 0.0714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8896 - accuracy: 0.3750 - val_loss: 1.1071 - val_accuracy: 0.0714\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8887 - accuracy: 0.3571 - val_loss: 1.1087 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8800 - accuracy: 0.3393 - val_loss: 1.1102 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8768 - accuracy: 0.3929 - val_loss: 1.1118 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8741 - accuracy: 0.3750 - val_loss: 1.1134 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8711 - accuracy: 0.3393 - val_loss: 1.1150 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8701 - accuracy: 0.3571 - val_loss: 1.1164 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8640 - accuracy: 0.3571 - val_loss: 1.1178 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8597 - accuracy: 0.3393 - val_loss: 1.1191 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8648 - accuracy: 0.3571 - val_loss: 1.1205 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8565 - accuracy: 0.3393 - val_loss: 1.1218 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8570 - accuracy: 0.3393 - val_loss: 1.1231 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8482 - accuracy: 0.3571 - val_loss: 1.1243 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8441 - accuracy: 0.3750 - val_loss: 1.1252 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8512 - accuracy: 0.3571 - val_loss: 1.1259 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8490 - accuracy: 0.3571 - val_loss: 1.1266 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8390 - accuracy: 0.3393 - val_loss: 1.1271 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8298 - accuracy: 0.3571 - val_loss: 1.1277 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8347 - accuracy: 0.3214 - val_loss: 1.1284 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8267 - accuracy: 0.3393 - val_loss: 1.1292 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8258 - accuracy: 0.3393 - val_loss: 1.1302 - val_accuracy: 0.0714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8254 - accuracy: 0.3036 - val_loss: 1.1314 - val_accuracy: 0.0714\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8213 - accuracy: 0.3571 - val_loss: 1.1329 - val_accuracy: 0.0714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8163 - accuracy: 0.3214 - val_loss: 1.1346 - val_accuracy: 0.0714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8043 - accuracy: 0.3571 - val_loss: 1.1366 - val_accuracy: 0.0714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8117 - accuracy: 0.3393 - val_loss: 1.1387 - val_accuracy: 0.0714\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7971 - accuracy: 0.3214 - val_loss: 1.1411 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8074 - accuracy: 0.3393 - val_loss: 1.1436 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8054 - accuracy: 0.3393 - val_loss: 1.1463 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7943 - accuracy: 0.3571 - val_loss: 1.1490 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8032 - accuracy: 0.3214 - val_loss: 1.1521 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8055 - accuracy: 0.3036 - val_loss: 1.1555 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7950 - accuracy: 0.3571 - val_loss: 1.1589 - val_accuracy: 0.0714\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7852 - accuracy: 0.3393 - val_loss: 1.1624 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7830 - accuracy: 0.3393 - val_loss: 1.1661 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7821 - accuracy: 0.3036 - val_loss: 1.1696 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7753 - accuracy: 0.3214 - val_loss: 1.1731 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7818 - accuracy: 0.3036 - val_loss: 1.1765 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7738 - accuracy: 0.3214 - val_loss: 1.1798 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7674 - accuracy: 0.3214 - val_loss: 1.1835 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7781 - accuracy: 0.3393 - val_loss: 1.1872 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7664 - accuracy: 0.3393 - val_loss: 1.1907 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7736 - accuracy: 0.3393 - val_loss: 1.1942 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7665 - accuracy: 0.3393 - val_loss: 1.1977 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7669 - accuracy: 0.3571 - val_loss: 1.2010 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7515 - accuracy: 0.3214 - val_loss: 1.2046 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7602 - accuracy: 0.3393 - val_loss: 1.2083 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7655 - accuracy: 0.3036 - val_loss: 1.2116 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7694 - accuracy: 0.3036 - val_loss: 1.2145 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7589 - accuracy: 0.3036 - val_loss: 1.2171 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7481 - accuracy: 0.3393 - val_loss: 1.2193 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7466 - accuracy: 0.3214 - val_loss: 1.2212 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7514 - accuracy: 0.3393 - val_loss: 1.2233 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7473 - accuracy: 0.3750 - val_loss: 1.2252 - val_accuracy: 0.0714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7346 - accuracy: 0.3571 - val_loss: 1.2277 - val_accuracy: 0.0714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7375 - accuracy: 0.3393 - val_loss: 1.2301 - val_accuracy: 0.0714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7464 - accuracy: 0.3750 - val_loss: 1.2323 - val_accuracy: 0.0714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7360 - accuracy: 0.3750 - val_loss: 1.2347 - val_accuracy: 0.0714\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7382 - accuracy: 0.3571 - val_loss: 1.2369 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2369 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=100, batch_size=300, Scores: [1.2369157075881958, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2369157075881958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9892 - accuracy: 0.0893 - val_loss: 1.0727 - val_accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9852 - accuracy: 0.1071 - val_loss: 1.0730 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9825 - accuracy: 0.1429 - val_loss: 1.0733 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9792 - accuracy: 0.1607 - val_loss: 1.0736 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9788 - accuracy: 0.1250 - val_loss: 1.0740 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9784 - accuracy: 0.1786 - val_loss: 1.0744 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9785 - accuracy: 0.1071 - val_loss: 1.0747 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9754 - accuracy: 0.1071 - val_loss: 1.0751 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9725 - accuracy: 0.1786 - val_loss: 1.0755 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9716 - accuracy: 0.1607 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9682 - accuracy: 0.2143 - val_loss: 1.0764 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9675 - accuracy: 0.2321 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9658 - accuracy: 0.2500 - val_loss: 1.0773 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9661 - accuracy: 0.2500 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9623 - accuracy: 0.3214 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9619 - accuracy: 0.2679 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9605 - accuracy: 0.2143 - val_loss: 1.0791 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9560 - accuracy: 0.2321 - val_loss: 1.0796 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9545 - accuracy: 0.2857 - val_loss: 1.0801 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9551 - accuracy: 0.2500 - val_loss: 1.0806 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9530 - accuracy: 0.2500 - val_loss: 1.0812 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9497 - accuracy: 0.3393 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9482 - accuracy: 0.1786 - val_loss: 1.0823 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9460 - accuracy: 0.2679 - val_loss: 1.0829 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9421 - accuracy: 0.2500 - val_loss: 1.0835 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9429 - accuracy: 0.3214 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9408 - accuracy: 0.2679 - val_loss: 1.0846 - val_accuracy: 0.0714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9373 - accuracy: 0.3393 - val_loss: 1.0852 - val_accuracy: 0.0714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9361 - accuracy: 0.2500 - val_loss: 1.0858 - val_accuracy: 0.0714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9378 - accuracy: 0.2857 - val_loss: 1.0864 - val_accuracy: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9322 - accuracy: 0.2679 - val_loss: 1.0869 - val_accuracy: 0.0714\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9311 - accuracy: 0.2857 - val_loss: 1.0875 - val_accuracy: 0.0714\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9273 - accuracy: 0.2857 - val_loss: 1.0880 - val_accuracy: 0.0714\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9246 - accuracy: 0.2857 - val_loss: 1.0885 - val_accuracy: 0.0714\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9222 - accuracy: 0.2679 - val_loss: 1.0891 - val_accuracy: 0.0714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9243 - accuracy: 0.2679 - val_loss: 1.0896 - val_accuracy: 0.0714\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9197 - accuracy: 0.2500 - val_loss: 1.0902 - val_accuracy: 0.0714\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9128 - accuracy: 0.3036 - val_loss: 1.0907 - val_accuracy: 0.0714\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9106 - accuracy: 0.2857 - val_loss: 1.0912 - val_accuracy: 0.0714\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9116 - accuracy: 0.2857 - val_loss: 1.0917 - val_accuracy: 0.0714\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9082 - accuracy: 0.2857 - val_loss: 1.0922 - val_accuracy: 0.0714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9007 - accuracy: 0.3214 - val_loss: 1.0928 - val_accuracy: 0.0714\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9019 - accuracy: 0.2679 - val_loss: 1.0934 - val_accuracy: 0.0714\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8977 - accuracy: 0.3036 - val_loss: 1.0940 - val_accuracy: 0.0714\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8919 - accuracy: 0.3036 - val_loss: 1.0946 - val_accuracy: 0.0714\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8894 - accuracy: 0.3393 - val_loss: 1.0952 - val_accuracy: 0.0714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8905 - accuracy: 0.3214 - val_loss: 1.0959 - val_accuracy: 0.0714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8909 - accuracy: 0.3036 - val_loss: 1.0966 - val_accuracy: 0.0714\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8791 - accuracy: 0.3750 - val_loss: 1.0973 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8758 - accuracy: 0.3214 - val_loss: 1.0982 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8694 - accuracy: 0.3214 - val_loss: 1.0991 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8625 - accuracy: 0.3393 - val_loss: 1.1001 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.8710 - accuracy: 0.3929 - val_loss: 1.1012 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8678 - accuracy: 0.3393 - val_loss: 1.1024 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8608 - accuracy: 0.3036 - val_loss: 1.1038 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8523 - accuracy: 0.3214 - val_loss: 1.1053 - val_accuracy: 0.1429\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8499 - accuracy: 0.3571 - val_loss: 1.1070 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8481 - accuracy: 0.3393 - val_loss: 1.1088 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8466 - accuracy: 0.3750 - val_loss: 1.1107 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8389 - accuracy: 0.3571 - val_loss: 1.1127 - val_accuracy: 0.2143\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8333 - accuracy: 0.3750 - val_loss: 1.1149 - val_accuracy: 0.2143\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.8420 - accuracy: 0.3393 - val_loss: 1.1173 - val_accuracy: 0.2143\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8207 - accuracy: 0.3214 - val_loss: 1.1198 - val_accuracy: 0.2143\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8230 - accuracy: 0.3036 - val_loss: 1.1224 - val_accuracy: 0.2143\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8205 - accuracy: 0.3750 - val_loss: 1.1251 - val_accuracy: 0.2143\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8227 - accuracy: 0.3393 - val_loss: 1.1279 - val_accuracy: 0.2143\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8215 - accuracy: 0.3036 - val_loss: 1.1309 - val_accuracy: 0.2143\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8123 - accuracy: 0.4286 - val_loss: 1.1339 - val_accuracy: 0.2143\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8109 - accuracy: 0.3571 - val_loss: 1.1372 - val_accuracy: 0.2143\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8023 - accuracy: 0.2857 - val_loss: 1.1404 - val_accuracy: 0.2143\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7960 - accuracy: 0.3393 - val_loss: 1.1437 - val_accuracy: 0.2143\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8005 - accuracy: 0.3214 - val_loss: 1.1472 - val_accuracy: 0.2143\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8040 - accuracy: 0.4107 - val_loss: 1.1508 - val_accuracy: 0.2143\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7946 - accuracy: 0.3571 - val_loss: 1.1543 - val_accuracy: 0.2143\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7928 - accuracy: 0.3393 - val_loss: 1.1577 - val_accuracy: 0.2143\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7886 - accuracy: 0.2857 - val_loss: 1.1612 - val_accuracy: 0.2143\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7891 - accuracy: 0.3214 - val_loss: 1.1647 - val_accuracy: 0.2143\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7706 - accuracy: 0.3571 - val_loss: 1.1684 - val_accuracy: 0.2143\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7847 - accuracy: 0.3571 - val_loss: 1.1720 - val_accuracy: 0.2143\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7773 - accuracy: 0.3750 - val_loss: 1.1756 - val_accuracy: 0.2143\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7765 - accuracy: 0.3393 - val_loss: 1.1790 - val_accuracy: 0.2143\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7714 - accuracy: 0.3571 - val_loss: 1.1824 - val_accuracy: 0.2143\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7703 - accuracy: 0.3393 - val_loss: 1.1855 - val_accuracy: 0.2143\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7737 - accuracy: 0.3571 - val_loss: 1.1889 - val_accuracy: 0.2143\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7508 - accuracy: 0.3214 - val_loss: 1.1924 - val_accuracy: 0.2143\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7510 - accuracy: 0.3214 - val_loss: 1.1960 - val_accuracy: 0.2143\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7576 - accuracy: 0.3393 - val_loss: 1.1995 - val_accuracy: 0.2143\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7599 - accuracy: 0.3036 - val_loss: 1.2031 - val_accuracy: 0.2143\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7633 - accuracy: 0.3036 - val_loss: 1.2064 - val_accuracy: 0.2143\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7440 - accuracy: 0.3393 - val_loss: 1.2097 - val_accuracy: 0.2143\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7455 - accuracy: 0.3571 - val_loss: 1.2122 - val_accuracy: 0.2143\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7482 - accuracy: 0.3750 - val_loss: 1.2146 - val_accuracy: 0.2143\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7428 - accuracy: 0.3393 - val_loss: 1.2167 - val_accuracy: 0.2143\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.7482 - accuracy: 0.3929 - val_loss: 1.2185 - val_accuracy: 0.2143\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7446 - accuracy: 0.3571 - val_loss: 1.2202 - val_accuracy: 0.2143\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7479 - accuracy: 0.3214 - val_loss: 1.2219 - val_accuracy: 0.2143\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7308 - accuracy: 0.3571 - val_loss: 1.2232 - val_accuracy: 0.2143\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7398 - accuracy: 0.3571 - val_loss: 1.2240 - val_accuracy: 0.2143\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7288 - accuracy: 0.3214 - val_loss: 1.2250 - val_accuracy: 0.2143\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7325 - accuracy: 0.3036 - val_loss: 1.2258 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2258 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=100, batch_size=400, Scores: [1.2258151769638062, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2258151769638062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9852 - accuracy: 0.1071 - val_loss: 1.0697 - val_accuracy: 0.2143\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9834 - accuracy: 0.0893 - val_loss: 1.0699 - val_accuracy: 0.2143\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9815 - accuracy: 0.1429 - val_loss: 1.0702 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9813 - accuracy: 0.1607 - val_loss: 1.0705 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9767 - accuracy: 0.1429 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9761 - accuracy: 0.1964 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9711 - accuracy: 0.2321 - val_loss: 1.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9722 - accuracy: 0.2143 - val_loss: 1.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9709 - accuracy: 0.1786 - val_loss: 1.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9689 - accuracy: 0.2679 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9664 - accuracy: 0.2321 - val_loss: 1.0729 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.9632 - accuracy: 0.2679 - val_loss: 1.0733 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9617 - accuracy: 0.2143 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9586 - accuracy: 0.2679 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9591 - accuracy: 0.3036 - val_loss: 1.0744 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9558 - accuracy: 0.2500 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9543 - accuracy: 0.1964 - val_loss: 1.0751 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9531 - accuracy: 0.2321 - val_loss: 1.0755 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9502 - accuracy: 0.3036 - val_loss: 1.0758 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9480 - accuracy: 0.2857 - val_loss: 1.0761 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9461 - accuracy: 0.2679 - val_loss: 1.0764 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9427 - accuracy: 0.3393 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9398 - accuracy: 0.2857 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9392 - accuracy: 0.3393 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9356 - accuracy: 0.3571 - val_loss: 1.0773 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9339 - accuracy: 0.2500 - val_loss: 1.0775 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9305 - accuracy: 0.3036 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9318 - accuracy: 0.3571 - val_loss: 1.0778 - val_accuracy: 0.0714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9283 - accuracy: 0.3214 - val_loss: 1.0779 - val_accuracy: 0.0714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9253 - accuracy: 0.3393 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9212 - accuracy: 0.3036 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9184 - accuracy: 0.3036 - val_loss: 1.0783 - val_accuracy: 0.0714\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.9178 - accuracy: 0.3214 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9163 - accuracy: 0.3036 - val_loss: 1.0785 - val_accuracy: 0.0714\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9097 - accuracy: 0.3750 - val_loss: 1.0786 - val_accuracy: 0.0714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9110 - accuracy: 0.3036 - val_loss: 1.0788 - val_accuracy: 0.0714\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9083 - accuracy: 0.2857 - val_loss: 1.0789 - val_accuracy: 0.0714\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9052 - accuracy: 0.2857 - val_loss: 1.0791 - val_accuracy: 0.0714\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8946 - accuracy: 0.3214 - val_loss: 1.0794 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8976 - accuracy: 0.2679 - val_loss: 1.0797 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8899 - accuracy: 0.3214 - val_loss: 1.0800 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8924 - accuracy: 0.2679 - val_loss: 1.0805 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8876 - accuracy: 0.3393 - val_loss: 1.0810 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8844 - accuracy: 0.3036 - val_loss: 1.0816 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8812 - accuracy: 0.2857 - val_loss: 1.0824 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8783 - accuracy: 0.2679 - val_loss: 1.0834 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8701 - accuracy: 0.3393 - val_loss: 1.0844 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8753 - accuracy: 0.3036 - val_loss: 1.0855 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8706 - accuracy: 0.2857 - val_loss: 1.0867 - val_accuracy: 0.2143\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8669 - accuracy: 0.3036 - val_loss: 1.0881 - val_accuracy: 0.2143\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8706 - accuracy: 0.3571 - val_loss: 1.0896 - val_accuracy: 0.2143\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8598 - accuracy: 0.3214 - val_loss: 1.0913 - val_accuracy: 0.2143\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8615 - accuracy: 0.3036 - val_loss: 1.0931 - val_accuracy: 0.2143\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8551 - accuracy: 0.3036 - val_loss: 1.0951 - val_accuracy: 0.2143\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8571 - accuracy: 0.3393 - val_loss: 1.0972 - val_accuracy: 0.2143\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8570 - accuracy: 0.3036 - val_loss: 1.0994 - val_accuracy: 0.2143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8452 - accuracy: 0.3393 - val_loss: 1.1017 - val_accuracy: 0.2143\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.8465 - accuracy: 0.2857 - val_loss: 1.1040 - val_accuracy: 0.2143\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8485 - accuracy: 0.3214 - val_loss: 1.1065 - val_accuracy: 0.2143\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8416 - accuracy: 0.3214 - val_loss: 1.1090 - val_accuracy: 0.2143\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8378 - accuracy: 0.3214 - val_loss: 1.1117 - val_accuracy: 0.2143\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8285 - accuracy: 0.3036 - val_loss: 1.1143 - val_accuracy: 0.2143\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.8353 - accuracy: 0.3571 - val_loss: 1.1171 - val_accuracy: 0.2143\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8320 - accuracy: 0.3393 - val_loss: 1.1199 - val_accuracy: 0.2143\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8306 - accuracy: 0.3750 - val_loss: 1.1229 - val_accuracy: 0.2143\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8298 - accuracy: 0.2857 - val_loss: 1.1259 - val_accuracy: 0.2143\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8230 - accuracy: 0.3214 - val_loss: 1.1289 - val_accuracy: 0.2143\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8167 - accuracy: 0.3214 - val_loss: 1.1319 - val_accuracy: 0.2143\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8097 - accuracy: 0.3214 - val_loss: 1.1348 - val_accuracy: 0.2143\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8120 - accuracy: 0.3214 - val_loss: 1.1377 - val_accuracy: 0.2143\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8104 - accuracy: 0.2857 - val_loss: 1.1405 - val_accuracy: 0.2143\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8136 - accuracy: 0.3036 - val_loss: 1.1434 - val_accuracy: 0.2143\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8042 - accuracy: 0.3214 - val_loss: 1.1464 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.8105 - accuracy: 0.2857 - val_loss: 1.1494 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7955 - accuracy: 0.3750 - val_loss: 1.1523 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7981 - accuracy: 0.3214 - val_loss: 1.1551 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7928 - accuracy: 0.3036 - val_loss: 1.1580 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7895 - accuracy: 0.3750 - val_loss: 1.1610 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7869 - accuracy: 0.2857 - val_loss: 1.1639 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7824 - accuracy: 0.3571 - val_loss: 1.1669 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7837 - accuracy: 0.3214 - val_loss: 1.1700 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7768 - accuracy: 0.2857 - val_loss: 1.1731 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7875 - accuracy: 0.2679 - val_loss: 1.1759 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7734 - accuracy: 0.3214 - val_loss: 1.1789 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7793 - accuracy: 0.3036 - val_loss: 1.1818 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7706 - accuracy: 0.2857 - val_loss: 1.1845 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7739 - accuracy: 0.3036 - val_loss: 1.1872 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7613 - accuracy: 0.3393 - val_loss: 1.1895 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7569 - accuracy: 0.3571 - val_loss: 1.1917 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7588 - accuracy: 0.3214 - val_loss: 1.1938 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7607 - accuracy: 0.3571 - val_loss: 1.1961 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7633 - accuracy: 0.3214 - val_loss: 1.1984 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7499 - accuracy: 0.3036 - val_loss: 1.2007 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7569 - accuracy: 0.2857 - val_loss: 1.2028 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7515 - accuracy: 0.3036 - val_loss: 1.2048 - val_accuracy: 0.0714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7497 - accuracy: 0.3393 - val_loss: 1.2069 - val_accuracy: 0.0714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7633 - accuracy: 0.3571 - val_loss: 1.2094 - val_accuracy: 0.0714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7536 - accuracy: 0.3214 - val_loss: 1.2115 - val_accuracy: 0.0714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7405 - accuracy: 0.3393 - val_loss: 1.2140 - val_accuracy: 0.0714\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7366 - accuracy: 0.3393 - val_loss: 1.2168 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2168 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=100, batch_size=500, Scores: [1.2167757749557495, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2167757749557495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9814 - accuracy: 0.1250 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9834 - accuracy: 0.2143 - val_loss: 1.0718 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9785 - accuracy: 0.1786 - val_loss: 1.0722 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9804 - accuracy: 0.1250 - val_loss: 1.0725 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9753 - accuracy: 0.1786 - val_loss: 1.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9739 - accuracy: 0.1429 - val_loss: 1.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9719 - accuracy: 0.1964 - val_loss: 1.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9714 - accuracy: 0.3214 - val_loss: 1.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9699 - accuracy: 0.2679 - val_loss: 1.0746 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9664 - accuracy: 0.2321 - val_loss: 1.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9649 - accuracy: 0.2143 - val_loss: 1.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.9676 - accuracy: 0.1964 - val_loss: 1.0760 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9615 - accuracy: 0.2500 - val_loss: 1.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9606 - accuracy: 0.2500 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9605 - accuracy: 0.2857 - val_loss: 1.0776 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9578 - accuracy: 0.2143 - val_loss: 1.0780 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9565 - accuracy: 0.2500 - val_loss: 1.0785 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9549 - accuracy: 0.2500 - val_loss: 1.0790 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.9495 - accuracy: 0.2857 - val_loss: 1.0795 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9521 - accuracy: 0.3393 - val_loss: 1.0800 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9449 - accuracy: 0.2679 - val_loss: 1.0805 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9436 - accuracy: 0.3036 - val_loss: 1.0810 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9461 - accuracy: 0.2500 - val_loss: 1.0815 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9401 - accuracy: 0.2143 - val_loss: 1.0820 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9381 - accuracy: 0.3036 - val_loss: 1.0824 - val_accuracy: 0.0714\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9420 - accuracy: 0.2857 - val_loss: 1.0829 - val_accuracy: 0.0714\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9315 - accuracy: 0.2679 - val_loss: 1.0834 - val_accuracy: 0.0714\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9329 - accuracy: 0.2500 - val_loss: 1.0839 - val_accuracy: 0.0714\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9295 - accuracy: 0.2500 - val_loss: 1.0844 - val_accuracy: 0.0714\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9280 - accuracy: 0.2321 - val_loss: 1.0848 - val_accuracy: 0.0714\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9267 - accuracy: 0.3214 - val_loss: 1.0853 - val_accuracy: 0.0714\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9241 - accuracy: 0.2679 - val_loss: 1.0859 - val_accuracy: 0.0714\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9216 - accuracy: 0.2679 - val_loss: 1.0864 - val_accuracy: 0.0714\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9194 - accuracy: 0.2500 - val_loss: 1.0870 - val_accuracy: 0.0714\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9157 - accuracy: 0.2321 - val_loss: 1.0876 - val_accuracy: 0.0714\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9121 - accuracy: 0.2679 - val_loss: 1.0882 - val_accuracy: 0.0714\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9058 - accuracy: 0.2143 - val_loss: 1.0888 - val_accuracy: 0.0714\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9040 - accuracy: 0.2679 - val_loss: 1.0894 - val_accuracy: 0.0714\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8992 - accuracy: 0.2679 - val_loss: 1.0901 - val_accuracy: 0.0714\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9036 - accuracy: 0.2679 - val_loss: 1.0909 - val_accuracy: 0.0714\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8972 - accuracy: 0.2321 - val_loss: 1.0917 - val_accuracy: 0.0714\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8962 - accuracy: 0.2857 - val_loss: 1.0925 - val_accuracy: 0.0714\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8921 - accuracy: 0.2857 - val_loss: 1.0935 - val_accuracy: 0.0714\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8912 - accuracy: 0.2679 - val_loss: 1.0946 - val_accuracy: 0.0714\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.8810 - accuracy: 0.2857 - val_loss: 1.0958 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8834 - accuracy: 0.2679 - val_loss: 1.0970 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8756 - accuracy: 0.2679 - val_loss: 1.0983 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8755 - accuracy: 0.3393 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8667 - accuracy: 0.3214 - val_loss: 1.1014 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8718 - accuracy: 0.2321 - val_loss: 1.1031 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8620 - accuracy: 0.2857 - val_loss: 1.1047 - val_accuracy: 0.2143\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8628 - accuracy: 0.2679 - val_loss: 1.1065 - val_accuracy: 0.2143\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8571 - accuracy: 0.3036 - val_loss: 1.1082 - val_accuracy: 0.2143\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8575 - accuracy: 0.3036 - val_loss: 1.1101 - val_accuracy: 0.2143\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8566 - accuracy: 0.3036 - val_loss: 1.1120 - val_accuracy: 0.2143\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8461 - accuracy: 0.2857 - val_loss: 1.1140 - val_accuracy: 0.2143\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8413 - accuracy: 0.2857 - val_loss: 1.1161 - val_accuracy: 0.2143\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8396 - accuracy: 0.3036 - val_loss: 1.1182 - val_accuracy: 0.2143\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8440 - accuracy: 0.2857 - val_loss: 1.1202 - val_accuracy: 0.2143\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8368 - accuracy: 0.3036 - val_loss: 1.1223 - val_accuracy: 0.2143\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8313 - accuracy: 0.2857 - val_loss: 1.1245 - val_accuracy: 0.2143\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8364 - accuracy: 0.3214 - val_loss: 1.1267 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8220 - accuracy: 0.2500 - val_loss: 1.1289 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8186 - accuracy: 0.3036 - val_loss: 1.1310 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8217 - accuracy: 0.2857 - val_loss: 1.1332 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8182 - accuracy: 0.3036 - val_loss: 1.1353 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8196 - accuracy: 0.2679 - val_loss: 1.1375 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8005 - accuracy: 0.3036 - val_loss: 1.1399 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8138 - accuracy: 0.3214 - val_loss: 1.1424 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8094 - accuracy: 0.3036 - val_loss: 1.1447 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8008 - accuracy: 0.3036 - val_loss: 1.1471 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7997 - accuracy: 0.2679 - val_loss: 1.1497 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7987 - accuracy: 0.3036 - val_loss: 1.1523 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7951 - accuracy: 0.3036 - val_loss: 1.1550 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7883 - accuracy: 0.3036 - val_loss: 1.1579 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7867 - accuracy: 0.2679 - val_loss: 1.1610 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7984 - accuracy: 0.2857 - val_loss: 1.1644 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7856 - accuracy: 0.2679 - val_loss: 1.1680 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7804 - accuracy: 0.3214 - val_loss: 1.1717 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7726 - accuracy: 0.3214 - val_loss: 1.1752 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7704 - accuracy: 0.2679 - val_loss: 1.1785 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7738 - accuracy: 0.2679 - val_loss: 1.1818 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7780 - accuracy: 0.3036 - val_loss: 1.1852 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7683 - accuracy: 0.3036 - val_loss: 1.1886 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7742 - accuracy: 0.3036 - val_loss: 1.1921 - val_accuracy: 0.2143\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7668 - accuracy: 0.2857 - val_loss: 1.1953 - val_accuracy: 0.2143\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.7599 - accuracy: 0.3036 - val_loss: 1.1978 - val_accuracy: 0.2143\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7502 - accuracy: 0.3393 - val_loss: 1.2001 - val_accuracy: 0.2143\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7642 - accuracy: 0.2857 - val_loss: 1.2019 - val_accuracy: 0.2143\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7509 - accuracy: 0.3214 - val_loss: 1.2041 - val_accuracy: 0.2143\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7587 - accuracy: 0.2857 - val_loss: 1.2059 - val_accuracy: 0.2143\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7519 - accuracy: 0.2500 - val_loss: 1.2072 - val_accuracy: 0.2143\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7354 - accuracy: 0.2857 - val_loss: 1.2083 - val_accuracy: 0.2143\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7465 - accuracy: 0.3036 - val_loss: 1.2097 - val_accuracy: 0.2143\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7419 - accuracy: 0.3393 - val_loss: 1.2107 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7376 - accuracy: 0.3393 - val_loss: 1.2114 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.7381 - accuracy: 0.3214 - val_loss: 1.2119 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7233 - accuracy: 0.3393 - val_loss: 1.2123 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7258 - accuracy: 0.3393 - val_loss: 1.2122 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7329 - accuracy: 0.3393 - val_loss: 1.2125 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7309 - accuracy: 0.3214 - val_loss: 1.2125 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7215 - accuracy: 0.3393 - val_loss: 1.2129 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7181 - accuracy: 0.3571 - val_loss: 1.2129 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7139 - accuracy: 0.3214 - val_loss: 1.2131 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7226 - accuracy: 0.2857 - val_loss: 1.2137 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7115 - accuracy: 0.3393 - val_loss: 1.2139 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7238 - accuracy: 0.3393 - val_loss: 1.2134 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.7261 - accuracy: 0.3750 - val_loss: 1.2131 - val_accuracy: 0.1429\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7116 - accuracy: 0.3571 - val_loss: 1.2130 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7083 - accuracy: 0.3750 - val_loss: 1.2133 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6934 - accuracy: 0.3750 - val_loss: 1.2139 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7106 - accuracy: 0.3393 - val_loss: 1.2153 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7149 - accuracy: 0.3214 - val_loss: 1.2163 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7131 - accuracy: 0.3214 - val_loss: 1.2174 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6877 - accuracy: 0.3750 - val_loss: 1.2185 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6921 - accuracy: 0.3393 - val_loss: 1.2198 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7004 - accuracy: 0.3750 - val_loss: 1.2213 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6926 - accuracy: 0.3393 - val_loss: 1.2217 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7053 - accuracy: 0.3571 - val_loss: 1.2221 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6855 - accuracy: 0.3393 - val_loss: 1.2219 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6828 - accuracy: 0.3750 - val_loss: 1.2219 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6749 - accuracy: 0.3393 - val_loss: 1.2226 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7018 - accuracy: 0.3393 - val_loss: 1.2232 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6841 - accuracy: 0.3393 - val_loss: 1.2247 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6910 - accuracy: 0.3036 - val_loss: 1.2265 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6675 - accuracy: 0.3571 - val_loss: 1.2283 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6798 - accuracy: 0.3214 - val_loss: 1.2302 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6814 - accuracy: 0.3393 - val_loss: 1.2333 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2333 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=128, batch_size=100, Scores: [1.2332956790924072, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2332956790924072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9841 - accuracy: 0.0714 - val_loss: 1.0683 - val_accuracy: 0.0714\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.9839 - accuracy: 0.0714 - val_loss: 1.0687 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9823 - accuracy: 0.0179 - val_loss: 1.0691 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9763 - accuracy: 0.1071 - val_loss: 1.0695 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9753 - accuracy: 0.1250 - val_loss: 1.0699 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.9746 - accuracy: 0.1786 - val_loss: 1.0703 - val_accuracy: 0.1429\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9703 - accuracy: 0.1607 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9710 - accuracy: 0.2143 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9685 - accuracy: 0.1071 - val_loss: 1.0714 - val_accuracy: 0.2143\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9682 - accuracy: 0.1786 - val_loss: 1.0718 - val_accuracy: 0.2143\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9617 - accuracy: 0.1429 - val_loss: 1.0722 - val_accuracy: 0.2143\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9657 - accuracy: 0.2857 - val_loss: 1.0725 - val_accuracy: 0.2143\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9622 - accuracy: 0.2500 - val_loss: 1.0729 - val_accuracy: 0.2143\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9584 - accuracy: 0.2143 - val_loss: 1.0733 - val_accuracy: 0.2143\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9582 - accuracy: 0.3036 - val_loss: 1.0736 - val_accuracy: 0.2143\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9561 - accuracy: 0.2679 - val_loss: 1.0739 - val_accuracy: 0.2143\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9534 - accuracy: 0.2143 - val_loss: 1.0742 - val_accuracy: 0.2143\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9509 - accuracy: 0.3214 - val_loss: 1.0746 - val_accuracy: 0.2143\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9515 - accuracy: 0.2500 - val_loss: 1.0749 - val_accuracy: 0.2143\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9464 - accuracy: 0.2679 - val_loss: 1.0752 - val_accuracy: 0.2143\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9475 - accuracy: 0.2679 - val_loss: 1.0755 - val_accuracy: 0.2143\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9437 - accuracy: 0.3036 - val_loss: 1.0758 - val_accuracy: 0.2143\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9412 - accuracy: 0.3036 - val_loss: 1.0762 - val_accuracy: 0.2143\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9385 - accuracy: 0.2500 - val_loss: 1.0765 - val_accuracy: 0.2143\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9358 - accuracy: 0.3393 - val_loss: 1.0768 - val_accuracy: 0.2143\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9349 - accuracy: 0.2321 - val_loss: 1.0772 - val_accuracy: 0.2143\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9299 - accuracy: 0.3214 - val_loss: 1.0776 - val_accuracy: 0.2143\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9311 - accuracy: 0.2857 - val_loss: 1.0779 - val_accuracy: 0.2143\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9268 - accuracy: 0.2679 - val_loss: 1.0783 - val_accuracy: 0.2143\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9257 - accuracy: 0.3036 - val_loss: 1.0787 - val_accuracy: 0.2143\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9225 - accuracy: 0.3214 - val_loss: 1.0791 - val_accuracy: 0.2143\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9236 - accuracy: 0.3036 - val_loss: 1.0796 - val_accuracy: 0.2143\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9173 - accuracy: 0.3036 - val_loss: 1.0800 - val_accuracy: 0.2143\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9175 - accuracy: 0.3036 - val_loss: 1.0805 - val_accuracy: 0.2143\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9063 - accuracy: 0.3214 - val_loss: 1.0810 - val_accuracy: 0.2143\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9054 - accuracy: 0.2857 - val_loss: 1.0815 - val_accuracy: 0.2143\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9024 - accuracy: 0.3393 - val_loss: 1.0820 - val_accuracy: 0.2143\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8935 - accuracy: 0.3036 - val_loss: 1.0826 - val_accuracy: 0.2143\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8906 - accuracy: 0.2857 - val_loss: 1.0832 - val_accuracy: 0.2143\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8908 - accuracy: 0.3214 - val_loss: 1.0838 - val_accuracy: 0.2143\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8897 - accuracy: 0.3036 - val_loss: 1.0845 - val_accuracy: 0.2143\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8881 - accuracy: 0.3750 - val_loss: 1.0853 - val_accuracy: 0.2143\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8859 - accuracy: 0.2679 - val_loss: 1.0862 - val_accuracy: 0.2143\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8808 - accuracy: 0.2857 - val_loss: 1.0872 - val_accuracy: 0.2143\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8741 - accuracy: 0.3214 - val_loss: 1.0883 - val_accuracy: 0.2143\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8760 - accuracy: 0.3214 - val_loss: 1.0895 - val_accuracy: 0.2143\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8704 - accuracy: 0.3571 - val_loss: 1.0909 - val_accuracy: 0.2143\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8668 - accuracy: 0.3036 - val_loss: 1.0923 - val_accuracy: 0.2143\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8606 - accuracy: 0.3036 - val_loss: 1.0938 - val_accuracy: 0.2143\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8641 - accuracy: 0.3036 - val_loss: 1.0955 - val_accuracy: 0.2143\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8569 - accuracy: 0.3036 - val_loss: 1.0973 - val_accuracy: 0.2143\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8437 - accuracy: 0.2857 - val_loss: 1.0993 - val_accuracy: 0.2143\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8516 - accuracy: 0.3036 - val_loss: 1.1014 - val_accuracy: 0.2143\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8527 - accuracy: 0.2679 - val_loss: 1.1036 - val_accuracy: 0.2143\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8409 - accuracy: 0.3214 - val_loss: 1.1060 - val_accuracy: 0.2143\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8488 - accuracy: 0.2857 - val_loss: 1.1084 - val_accuracy: 0.2143\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8308 - accuracy: 0.3036 - val_loss: 1.1109 - val_accuracy: 0.2143\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8347 - accuracy: 0.3214 - val_loss: 1.1136 - val_accuracy: 0.2143\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8350 - accuracy: 0.3393 - val_loss: 1.1164 - val_accuracy: 0.2143\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8281 - accuracy: 0.2857 - val_loss: 1.1192 - val_accuracy: 0.2143\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8232 - accuracy: 0.3214 - val_loss: 1.1222 - val_accuracy: 0.2143\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8200 - accuracy: 0.2857 - val_loss: 1.1253 - val_accuracy: 0.2143\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8257 - accuracy: 0.3393 - val_loss: 1.1286 - val_accuracy: 0.2143\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8131 - accuracy: 0.3036 - val_loss: 1.1320 - val_accuracy: 0.2143\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8140 - accuracy: 0.3214 - val_loss: 1.1354 - val_accuracy: 0.2143\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8089 - accuracy: 0.3214 - val_loss: 1.1389 - val_accuracy: 0.2143\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8056 - accuracy: 0.2857 - val_loss: 1.1426 - val_accuracy: 0.2143\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8017 - accuracy: 0.3393 - val_loss: 1.1465 - val_accuracy: 0.2143\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8048 - accuracy: 0.3214 - val_loss: 1.1504 - val_accuracy: 0.2143\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7964 - accuracy: 0.2857 - val_loss: 1.1545 - val_accuracy: 0.2143\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8018 - accuracy: 0.3214 - val_loss: 1.1585 - val_accuracy: 0.2143\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7878 - accuracy: 0.3036 - val_loss: 1.1628 - val_accuracy: 0.2143\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7908 - accuracy: 0.3036 - val_loss: 1.1670 - val_accuracy: 0.2143\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7880 - accuracy: 0.3036 - val_loss: 1.1711 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7900 - accuracy: 0.2857 - val_loss: 1.1750 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7800 - accuracy: 0.3036 - val_loss: 1.1790 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7859 - accuracy: 0.3393 - val_loss: 1.1828 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7784 - accuracy: 0.3393 - val_loss: 1.1861 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7813 - accuracy: 0.3036 - val_loss: 1.1893 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7758 - accuracy: 0.3214 - val_loss: 1.1925 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7857 - accuracy: 0.2857 - val_loss: 1.1954 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7741 - accuracy: 0.3214 - val_loss: 1.1981 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7751 - accuracy: 0.3571 - val_loss: 1.2009 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7629 - accuracy: 0.2857 - val_loss: 1.2035 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7613 - accuracy: 0.3393 - val_loss: 1.2061 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7634 - accuracy: 0.3393 - val_loss: 1.2083 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7622 - accuracy: 0.3571 - val_loss: 1.2105 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7585 - accuracy: 0.3393 - val_loss: 1.2126 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7627 - accuracy: 0.3214 - val_loss: 1.2145 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7606 - accuracy: 0.3036 - val_loss: 1.2162 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7609 - accuracy: 0.3214 - val_loss: 1.2178 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7483 - accuracy: 0.3750 - val_loss: 1.2193 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7478 - accuracy: 0.3571 - val_loss: 1.2202 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7404 - accuracy: 0.3571 - val_loss: 1.2214 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7400 - accuracy: 0.3750 - val_loss: 1.2222 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.7446 - accuracy: 0.3393 - val_loss: 1.2228 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7546 - accuracy: 0.3393 - val_loss: 1.2228 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7314 - accuracy: 0.3036 - val_loss: 1.2229 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7409 - accuracy: 0.3571 - val_loss: 1.2233 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7355 - accuracy: 0.3571 - val_loss: 1.2237 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7450 - accuracy: 0.3571 - val_loss: 1.2247 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7341 - accuracy: 0.4107 - val_loss: 1.2258 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7315 - accuracy: 0.3214 - val_loss: 1.2265 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7278 - accuracy: 0.3393 - val_loss: 1.2274 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7191 - accuracy: 0.3571 - val_loss: 1.2283 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7340 - accuracy: 0.3036 - val_loss: 1.2292 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7257 - accuracy: 0.3571 - val_loss: 1.2304 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7227 - accuracy: 0.3214 - val_loss: 1.2319 - val_accuracy: 0.1429\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7149 - accuracy: 0.3393 - val_loss: 1.2330 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7302 - accuracy: 0.3929 - val_loss: 1.2344 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7159 - accuracy: 0.3214 - val_loss: 1.2356 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7216 - accuracy: 0.3750 - val_loss: 1.2366 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7014 - accuracy: 0.3036 - val_loss: 1.2380 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7127 - accuracy: 0.3036 - val_loss: 1.2389 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7019 - accuracy: 0.3571 - val_loss: 1.2400 - val_accuracy: 0.1429\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7082 - accuracy: 0.3571 - val_loss: 1.2415 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7064 - accuracy: 0.3214 - val_loss: 1.2426 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7025 - accuracy: 0.3571 - val_loss: 1.2433 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6916 - accuracy: 0.3571 - val_loss: 1.2443 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6920 - accuracy: 0.3393 - val_loss: 1.2458 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6966 - accuracy: 0.3214 - val_loss: 1.2472 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6847 - accuracy: 0.3393 - val_loss: 1.2487 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6905 - accuracy: 0.3750 - val_loss: 1.2498 - val_accuracy: 0.1429\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6818 - accuracy: 0.3929 - val_loss: 1.2511 - val_accuracy: 0.1429\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6744 - accuracy: 0.3571 - val_loss: 1.2529 - val_accuracy: 0.1429\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6869 - accuracy: 0.3393 - val_loss: 1.2550 - val_accuracy: 0.1429\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6908 - accuracy: 0.3214 - val_loss: 1.2565 - val_accuracy: 0.1429\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6742 - accuracy: 0.3393 - val_loss: 1.2581 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2581 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=128, batch_size=300, Scores: [1.2581253051757812, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.2581253051757812\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9797 - accuracy: 0.1250 - val_loss: 1.0707 - val_accuracy: 0.0714\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.9815 - accuracy: 0.1429 - val_loss: 1.0706 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9788 - accuracy: 0.1429 - val_loss: 1.0707 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9770 - accuracy: 0.2143 - val_loss: 1.0707 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9765 - accuracy: 0.1964 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9742 - accuracy: 0.2500 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9722 - accuracy: 0.2679 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9708 - accuracy: 0.2321 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9655 - accuracy: 0.2321 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9674 - accuracy: 0.2143 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9631 - accuracy: 0.2143 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9627 - accuracy: 0.2679 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.9574 - accuracy: 0.2857 - val_loss: 1.0710 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9594 - accuracy: 0.3571 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9582 - accuracy: 0.2857 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9572 - accuracy: 0.3214 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9525 - accuracy: 0.2500 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9475 - accuracy: 0.3214 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9492 - accuracy: 0.2857 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9438 - accuracy: 0.3214 - val_loss: 1.0712 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9482 - accuracy: 0.2857 - val_loss: 1.0712 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9449 - accuracy: 0.3571 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9394 - accuracy: 0.3393 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9391 - accuracy: 0.2679 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9351 - accuracy: 0.3393 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9341 - accuracy: 0.3036 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9293 - accuracy: 0.3393 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9290 - accuracy: 0.3036 - val_loss: 1.0709 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9242 - accuracy: 0.3393 - val_loss: 1.0709 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9298 - accuracy: 0.3214 - val_loss: 1.0709 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9220 - accuracy: 0.3571 - val_loss: 1.0708 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9170 - accuracy: 0.3393 - val_loss: 1.0708 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9180 - accuracy: 0.3036 - val_loss: 1.0708 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9117 - accuracy: 0.2857 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9096 - accuracy: 0.3036 - val_loss: 1.0707 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9087 - accuracy: 0.3036 - val_loss: 1.0708 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9066 - accuracy: 0.2679 - val_loss: 1.0708 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8993 - accuracy: 0.3036 - val_loss: 1.0709 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8980 - accuracy: 0.3036 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8979 - accuracy: 0.3393 - val_loss: 1.0713 - val_accuracy: 0.2143\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8927 - accuracy: 0.3036 - val_loss: 1.0717 - val_accuracy: 0.2143\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8894 - accuracy: 0.2500 - val_loss: 1.0721 - val_accuracy: 0.2143\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8887 - accuracy: 0.2679 - val_loss: 1.0727 - val_accuracy: 0.2143\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8894 - accuracy: 0.2679 - val_loss: 1.0733 - val_accuracy: 0.2143\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8791 - accuracy: 0.3036 - val_loss: 1.0742 - val_accuracy: 0.2143\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8846 - accuracy: 0.2679 - val_loss: 1.0751 - val_accuracy: 0.2143\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8753 - accuracy: 0.2857 - val_loss: 1.0762 - val_accuracy: 0.2143\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8737 - accuracy: 0.3214 - val_loss: 1.0774 - val_accuracy: 0.2143\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8710 - accuracy: 0.2679 - val_loss: 1.0787 - val_accuracy: 0.2143\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8652 - accuracy: 0.3393 - val_loss: 1.0803 - val_accuracy: 0.2143\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8670 - accuracy: 0.3393 - val_loss: 1.0820 - val_accuracy: 0.2143\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.8620 - accuracy: 0.2857 - val_loss: 1.0839 - val_accuracy: 0.2143\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8578 - accuracy: 0.3036 - val_loss: 1.0860 - val_accuracy: 0.2143\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8621 - accuracy: 0.3214 - val_loss: 1.0881 - val_accuracy: 0.2143\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8467 - accuracy: 0.3571 - val_loss: 1.0903 - val_accuracy: 0.2143\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8485 - accuracy: 0.3929 - val_loss: 1.0926 - val_accuracy: 0.2143\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8485 - accuracy: 0.3036 - val_loss: 1.0950 - val_accuracy: 0.2143\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8442 - accuracy: 0.2857 - val_loss: 1.0974 - val_accuracy: 0.2143\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8466 - accuracy: 0.3393 - val_loss: 1.0999 - val_accuracy: 0.2143\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8420 - accuracy: 0.3214 - val_loss: 1.1024 - val_accuracy: 0.2143\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8406 - accuracy: 0.3393 - val_loss: 1.1051 - val_accuracy: 0.2143\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8320 - accuracy: 0.2857 - val_loss: 1.1079 - val_accuracy: 0.2143\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8334 - accuracy: 0.2679 - val_loss: 1.1108 - val_accuracy: 0.2143\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8293 - accuracy: 0.3571 - val_loss: 1.1138 - val_accuracy: 0.2143\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8303 - accuracy: 0.3571 - val_loss: 1.1167 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8189 - accuracy: 0.4107 - val_loss: 1.1198 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8268 - accuracy: 0.3036 - val_loss: 1.1229 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8208 - accuracy: 0.2679 - val_loss: 1.1260 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8170 - accuracy: 0.3036 - val_loss: 1.1290 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8081 - accuracy: 0.3214 - val_loss: 1.1320 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8109 - accuracy: 0.3214 - val_loss: 1.1351 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8094 - accuracy: 0.3214 - val_loss: 1.1381 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8009 - accuracy: 0.3750 - val_loss: 1.1410 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7994 - accuracy: 0.3214 - val_loss: 1.1441 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.8039 - accuracy: 0.3036 - val_loss: 1.1473 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7985 - accuracy: 0.2857 - val_loss: 1.1508 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8013 - accuracy: 0.3393 - val_loss: 1.1543 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7997 - accuracy: 0.3393 - val_loss: 1.1578 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7920 - accuracy: 0.3393 - val_loss: 1.1611 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7872 - accuracy: 0.3393 - val_loss: 1.1647 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7745 - accuracy: 0.2857 - val_loss: 1.1681 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7739 - accuracy: 0.3750 - val_loss: 1.1715 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7871 - accuracy: 0.3393 - val_loss: 1.1748 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7746 - accuracy: 0.3214 - val_loss: 1.1781 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7760 - accuracy: 0.3393 - val_loss: 1.1809 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7772 - accuracy: 0.3571 - val_loss: 1.1830 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7751 - accuracy: 0.2679 - val_loss: 1.1849 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7699 - accuracy: 0.3393 - val_loss: 1.1867 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7675 - accuracy: 0.3571 - val_loss: 1.1884 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7758 - accuracy: 0.3571 - val_loss: 1.1898 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7587 - accuracy: 0.3393 - val_loss: 1.1912 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7656 - accuracy: 0.3214 - val_loss: 1.1929 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7564 - accuracy: 0.2857 - val_loss: 1.1948 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7623 - accuracy: 0.3036 - val_loss: 1.1966 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7502 - accuracy: 0.2679 - val_loss: 1.1982 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7466 - accuracy: 0.3571 - val_loss: 1.1997 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7495 - accuracy: 0.3393 - val_loss: 1.2012 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7572 - accuracy: 0.2857 - val_loss: 1.2027 - val_accuracy: 0.2143\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7539 - accuracy: 0.3393 - val_loss: 1.2042 - val_accuracy: 0.2143\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7385 - accuracy: 0.3393 - val_loss: 1.2050 - val_accuracy: 0.2143\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7447 - accuracy: 0.3393 - val_loss: 1.2057 - val_accuracy: 0.2143\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7539 - accuracy: 0.3750 - val_loss: 1.2063 - val_accuracy: 0.2143\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7297 - accuracy: 0.3214 - val_loss: 1.2069 - val_accuracy: 0.2143\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7437 - accuracy: 0.3036 - val_loss: 1.2078 - val_accuracy: 0.2143\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7218 - accuracy: 0.3036 - val_loss: 1.2083 - val_accuracy: 0.2143\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7324 - accuracy: 0.3214 - val_loss: 1.2089 - val_accuracy: 0.2143\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7255 - accuracy: 0.3036 - val_loss: 1.2090 - val_accuracy: 0.2143\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7280 - accuracy: 0.3393 - val_loss: 1.2093 - val_accuracy: 0.2143\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7249 - accuracy: 0.3750 - val_loss: 1.2093 - val_accuracy: 0.2143\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7366 - accuracy: 0.2857 - val_loss: 1.2100 - val_accuracy: 0.2143\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7337 - accuracy: 0.3750 - val_loss: 1.2109 - val_accuracy: 0.2143\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7219 - accuracy: 0.3393 - val_loss: 1.2125 - val_accuracy: 0.2143\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7027 - accuracy: 0.4107 - val_loss: 1.2139 - val_accuracy: 0.2143\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7094 - accuracy: 0.3393 - val_loss: 1.2153 - val_accuracy: 0.2143\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7071 - accuracy: 0.3571 - val_loss: 1.2163 - val_accuracy: 0.2143\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.7052 - accuracy: 0.3214 - val_loss: 1.2170 - val_accuracy: 0.2143\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7033 - accuracy: 0.3393 - val_loss: 1.2183 - val_accuracy: 0.2143\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7137 - accuracy: 0.3214 - val_loss: 1.2196 - val_accuracy: 0.2143\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7021 - accuracy: 0.3214 - val_loss: 1.2216 - val_accuracy: 0.2143\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7192 - accuracy: 0.3750 - val_loss: 1.2233 - val_accuracy: 0.2143\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6945 - accuracy: 0.3571 - val_loss: 1.2250 - val_accuracy: 0.2143\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6973 - accuracy: 0.3036 - val_loss: 1.2273 - val_accuracy: 0.2143\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6943 - accuracy: 0.3571 - val_loss: 1.2296 - val_accuracy: 0.2143\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7032 - accuracy: 0.3036 - val_loss: 1.2306 - val_accuracy: 0.2143\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6842 - accuracy: 0.3571 - val_loss: 1.2314 - val_accuracy: 0.2143\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7063 - accuracy: 0.2679 - val_loss: 1.2324 - val_accuracy: 0.2143\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6964 - accuracy: 0.3393 - val_loss: 1.2331 - val_accuracy: 0.2143\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6892 - accuracy: 0.3750 - val_loss: 1.2339 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2339 - accuracy: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=128, batch_size=400, Scores: [1.2338541746139526, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.2338541746139526\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9833 - accuracy: 0.1071 - val_loss: 1.0660 - val_accuracy: 0.2143\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9804 - accuracy: 0.1250 - val_loss: 1.0667 - val_accuracy: 0.2143\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9794 - accuracy: 0.1250 - val_loss: 1.0675 - val_accuracy: 0.2143\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9775 - accuracy: 0.2143 - val_loss: 1.0683 - val_accuracy: 0.2143\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9776 - accuracy: 0.2500 - val_loss: 1.0690 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9741 - accuracy: 0.1250 - val_loss: 1.0698 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9725 - accuracy: 0.1607 - val_loss: 1.0705 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9721 - accuracy: 0.2321 - val_loss: 1.0713 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.9680 - accuracy: 0.1964 - val_loss: 1.0721 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9703 - accuracy: 0.2679 - val_loss: 1.0729 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9650 - accuracy: 0.2679 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9624 - accuracy: 0.2857 - val_loss: 1.0745 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9638 - accuracy: 0.1786 - val_loss: 1.0752 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9597 - accuracy: 0.2500 - val_loss: 1.0760 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9584 - accuracy: 0.2679 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9570 - accuracy: 0.2500 - val_loss: 1.0775 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9507 - accuracy: 0.2679 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9505 - accuracy: 0.2679 - val_loss: 1.0790 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9502 - accuracy: 0.2679 - val_loss: 1.0797 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9498 - accuracy: 0.2857 - val_loss: 1.0805 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9470 - accuracy: 0.2321 - val_loss: 1.0813 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9422 - accuracy: 0.2857 - val_loss: 1.0821 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9430 - accuracy: 0.2500 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9403 - accuracy: 0.2857 - val_loss: 1.0835 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9393 - accuracy: 0.2143 - val_loss: 1.0843 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9332 - accuracy: 0.2857 - val_loss: 1.0850 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9354 - accuracy: 0.2143 - val_loss: 1.0857 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9328 - accuracy: 0.2679 - val_loss: 1.0864 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9276 - accuracy: 0.2857 - val_loss: 1.0872 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9286 - accuracy: 0.2679 - val_loss: 1.0879 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9257 - accuracy: 0.2857 - val_loss: 1.0886 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9237 - accuracy: 0.2857 - val_loss: 1.0893 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9219 - accuracy: 0.2679 - val_loss: 1.0901 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9160 - accuracy: 0.2679 - val_loss: 1.0909 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.9167 - accuracy: 0.2679 - val_loss: 1.0916 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9106 - accuracy: 0.3036 - val_loss: 1.0924 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9033 - accuracy: 0.2143 - val_loss: 1.0933 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9024 - accuracy: 0.3214 - val_loss: 1.0942 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9021 - accuracy: 0.2679 - val_loss: 1.0951 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9039 - accuracy: 0.2500 - val_loss: 1.0962 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8939 - accuracy: 0.2679 - val_loss: 1.0972 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8904 - accuracy: 0.3036 - val_loss: 1.0984 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8949 - accuracy: 0.3036 - val_loss: 1.0995 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8888 - accuracy: 0.2679 - val_loss: 1.1007 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8855 - accuracy: 0.2857 - val_loss: 1.1019 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8790 - accuracy: 0.2679 - val_loss: 1.1032 - val_accuracy: 0.2143\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8854 - accuracy: 0.2679 - val_loss: 1.1046 - val_accuracy: 0.2143\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8749 - accuracy: 0.2500 - val_loss: 1.1060 - val_accuracy: 0.2143\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8738 - accuracy: 0.2500 - val_loss: 1.1073 - val_accuracy: 0.2143\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8699 - accuracy: 0.2857 - val_loss: 1.1086 - val_accuracy: 0.2143\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8648 - accuracy: 0.2679 - val_loss: 1.1100 - val_accuracy: 0.2143\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8684 - accuracy: 0.2679 - val_loss: 1.1113 - val_accuracy: 0.2143\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8606 - accuracy: 0.2679 - val_loss: 1.1127 - val_accuracy: 0.2143\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8622 - accuracy: 0.3036 - val_loss: 1.1141 - val_accuracy: 0.2143\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8637 - accuracy: 0.3036 - val_loss: 1.1153 - val_accuracy: 0.2143\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8593 - accuracy: 0.2679 - val_loss: 1.1165 - val_accuracy: 0.2143\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.8479 - accuracy: 0.2857 - val_loss: 1.1178 - val_accuracy: 0.2143\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8551 - accuracy: 0.2857 - val_loss: 1.1192 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8437 - accuracy: 0.2857 - val_loss: 1.1208 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8335 - accuracy: 0.3036 - val_loss: 1.1223 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8414 - accuracy: 0.2857 - val_loss: 1.1239 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8371 - accuracy: 0.3036 - val_loss: 1.1255 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8359 - accuracy: 0.3036 - val_loss: 1.1272 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8320 - accuracy: 0.3214 - val_loss: 1.1290 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8287 - accuracy: 0.3036 - val_loss: 1.1309 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8192 - accuracy: 0.2857 - val_loss: 1.1328 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8186 - accuracy: 0.3214 - val_loss: 1.1349 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8276 - accuracy: 0.3036 - val_loss: 1.1369 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.8196 - accuracy: 0.3214 - val_loss: 1.1391 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8137 - accuracy: 0.3750 - val_loss: 1.1415 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8115 - accuracy: 0.2857 - val_loss: 1.1439 - val_accuracy: 0.0714\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8115 - accuracy: 0.2857 - val_loss: 1.1464 - val_accuracy: 0.0714\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8075 - accuracy: 0.2857 - val_loss: 1.1490 - val_accuracy: 0.0714\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8039 - accuracy: 0.2679 - val_loss: 1.1516 - val_accuracy: 0.0714\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8041 - accuracy: 0.3036 - val_loss: 1.1545 - val_accuracy: 0.0714\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8119 - accuracy: 0.2679 - val_loss: 1.1575 - val_accuracy: 0.0714\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8021 - accuracy: 0.3036 - val_loss: 1.1606 - val_accuracy: 0.0714\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7976 - accuracy: 0.3036 - val_loss: 1.1639 - val_accuracy: 0.0714\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7967 - accuracy: 0.3036 - val_loss: 1.1674 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7879 - accuracy: 0.3214 - val_loss: 1.1711 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7885 - accuracy: 0.3036 - val_loss: 1.1747 - val_accuracy: 0.0714\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7784 - accuracy: 0.3214 - val_loss: 1.1783 - val_accuracy: 0.0714\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7964 - accuracy: 0.2679 - val_loss: 1.1817 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7798 - accuracy: 0.3393 - val_loss: 1.1849 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7776 - accuracy: 0.3036 - val_loss: 1.1877 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7756 - accuracy: 0.3036 - val_loss: 1.1902 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7721 - accuracy: 0.3214 - val_loss: 1.1926 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7758 - accuracy: 0.2500 - val_loss: 1.1948 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7681 - accuracy: 0.3214 - val_loss: 1.1967 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7598 - accuracy: 0.3393 - val_loss: 1.1984 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7696 - accuracy: 0.3214 - val_loss: 1.2000 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7690 - accuracy: 0.3929 - val_loss: 1.2018 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7701 - accuracy: 0.3571 - val_loss: 1.2038 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7594 - accuracy: 0.2857 - val_loss: 1.2062 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7655 - accuracy: 0.3571 - val_loss: 1.2082 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7449 - accuracy: 0.2679 - val_loss: 1.2102 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7573 - accuracy: 0.2857 - val_loss: 1.2127 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7453 - accuracy: 0.3214 - val_loss: 1.2154 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7441 - accuracy: 0.3571 - val_loss: 1.2187 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7507 - accuracy: 0.3571 - val_loss: 1.2222 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7488 - accuracy: 0.3393 - val_loss: 1.2262 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7348 - accuracy: 0.3214 - val_loss: 1.2300 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7308 - accuracy: 0.3393 - val_loss: 1.2336 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7309 - accuracy: 0.3571 - val_loss: 1.2369 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7207 - accuracy: 0.3750 - val_loss: 1.2400 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7299 - accuracy: 0.3571 - val_loss: 1.2429 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7203 - accuracy: 0.3214 - val_loss: 1.2457 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7227 - accuracy: 0.3214 - val_loss: 1.2484 - val_accuracy: 0.1429\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7224 - accuracy: 0.3393 - val_loss: 1.2509 - val_accuracy: 0.1429\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7155 - accuracy: 0.4107 - val_loss: 1.2531 - val_accuracy: 0.1429\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7228 - accuracy: 0.4464 - val_loss: 1.2558 - val_accuracy: 0.1429\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.7177 - accuracy: 0.3929 - val_loss: 1.2587 - val_accuracy: 0.1429\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7117 - accuracy: 0.3393 - val_loss: 1.2609 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7231 - accuracy: 0.3036 - val_loss: 1.2634 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7131 - accuracy: 0.3214 - val_loss: 1.2658 - val_accuracy: 0.1429\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7103 - accuracy: 0.3214 - val_loss: 1.2674 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7066 - accuracy: 0.3214 - val_loss: 1.2688 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7086 - accuracy: 0.3571 - val_loss: 1.2707 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7112 - accuracy: 0.3393 - val_loss: 1.2728 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7010 - accuracy: 0.3214 - val_loss: 1.2751 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7035 - accuracy: 0.3393 - val_loss: 1.2771 - val_accuracy: 0.1429\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.7070 - accuracy: 0.3393 - val_loss: 1.2794 - val_accuracy: 0.1429\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7048 - accuracy: 0.3214 - val_loss: 1.2813 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6808 - accuracy: 0.3571 - val_loss: 1.2836 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6914 - accuracy: 0.3393 - val_loss: 1.2858 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6864 - accuracy: 0.3750 - val_loss: 1.2881 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6783 - accuracy: 0.3929 - val_loss: 1.2897 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6813 - accuracy: 0.3750 - val_loss: 1.2915 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2915 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=128, batch_size=500, Scores: [1.2915303707122803, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2915303707122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9837 - accuracy: 0.1071 - val_loss: 1.0738 - val_accuracy: 0.1429\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9832 - accuracy: 0.0536 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9821 - accuracy: 0.1250 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9779 - accuracy: 0.1429 - val_loss: 1.0752 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9772 - accuracy: 0.1786 - val_loss: 1.0757 - val_accuracy: 0.2143\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9771 - accuracy: 0.2143 - val_loss: 1.0762 - val_accuracy: 0.2143\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9760 - accuracy: 0.2143 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9755 - accuracy: 0.1429 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9700 - accuracy: 0.2500 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9702 - accuracy: 0.2321 - val_loss: 1.0784 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 0.9689 - accuracy: 0.2143 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9673 - accuracy: 0.2857 - val_loss: 1.0796 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9675 - accuracy: 0.2857 - val_loss: 1.0802 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9637 - accuracy: 0.2321 - val_loss: 1.0808 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9629 - accuracy: 0.3571 - val_loss: 1.0813 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9584 - accuracy: 0.2679 - val_loss: 1.0819 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.9577 - accuracy: 0.3214 - val_loss: 1.0825 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9566 - accuracy: 0.2500 - val_loss: 1.0831 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9550 - accuracy: 0.3571 - val_loss: 1.0837 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9537 - accuracy: 0.2321 - val_loss: 1.0844 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9467 - accuracy: 0.2321 - val_loss: 1.0850 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9500 - accuracy: 0.2679 - val_loss: 1.0856 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9483 - accuracy: 0.3036 - val_loss: 1.0863 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9460 - accuracy: 0.2500 - val_loss: 1.0869 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9426 - accuracy: 0.2679 - val_loss: 1.0876 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9399 - accuracy: 0.2679 - val_loss: 1.0883 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9384 - accuracy: 0.3036 - val_loss: 1.0891 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9363 - accuracy: 0.2857 - val_loss: 1.0898 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.9340 - accuracy: 0.2679 - val_loss: 1.0906 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9301 - accuracy: 0.2679 - val_loss: 1.0914 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9288 - accuracy: 0.3036 - val_loss: 1.0922 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9271 - accuracy: 0.3393 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.9256 - accuracy: 0.3036 - val_loss: 1.0938 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9230 - accuracy: 0.2679 - val_loss: 1.0946 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9224 - accuracy: 0.2857 - val_loss: 1.0955 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9171 - accuracy: 0.2857 - val_loss: 1.0965 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9114 - accuracy: 0.3036 - val_loss: 1.0974 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9088 - accuracy: 0.2500 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9096 - accuracy: 0.2857 - val_loss: 1.0995 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9094 - accuracy: 0.3036 - val_loss: 1.1006 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9078 - accuracy: 0.3214 - val_loss: 1.1017 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9039 - accuracy: 0.3036 - val_loss: 1.1029 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8935 - accuracy: 0.3036 - val_loss: 1.1041 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8903 - accuracy: 0.3036 - val_loss: 1.1053 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8909 - accuracy: 0.2679 - val_loss: 1.1066 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8885 - accuracy: 0.2857 - val_loss: 1.1080 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8867 - accuracy: 0.3214 - val_loss: 1.1093 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8851 - accuracy: 0.2679 - val_loss: 1.1107 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8828 - accuracy: 0.3393 - val_loss: 1.1120 - val_accuracy: 0.2143\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8754 - accuracy: 0.3036 - val_loss: 1.1134 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8755 - accuracy: 0.3036 - val_loss: 1.1147 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.8660 - accuracy: 0.3214 - val_loss: 1.1161 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8611 - accuracy: 0.2857 - val_loss: 1.1175 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8598 - accuracy: 0.2857 - val_loss: 1.1188 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8593 - accuracy: 0.2321 - val_loss: 1.1201 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8582 - accuracy: 0.3393 - val_loss: 1.1215 - val_accuracy: 0.2143\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8508 - accuracy: 0.3393 - val_loss: 1.1229 - val_accuracy: 0.2143\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8514 - accuracy: 0.3214 - val_loss: 1.1243 - val_accuracy: 0.2143\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8484 - accuracy: 0.3393 - val_loss: 1.1257 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8482 - accuracy: 0.2679 - val_loss: 1.1272 - val_accuracy: 0.2143\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8446 - accuracy: 0.3214 - val_loss: 1.1287 - val_accuracy: 0.2143\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8391 - accuracy: 0.3393 - val_loss: 1.1302 - val_accuracy: 0.2143\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8338 - accuracy: 0.3214 - val_loss: 1.1317 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8387 - accuracy: 0.2500 - val_loss: 1.1332 - val_accuracy: 0.2143\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8314 - accuracy: 0.3393 - val_loss: 1.1347 - val_accuracy: 0.2143\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8238 - accuracy: 0.3214 - val_loss: 1.1362 - val_accuracy: 0.2143\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8288 - accuracy: 0.3214 - val_loss: 1.1377 - val_accuracy: 0.2143\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8150 - accuracy: 0.2679 - val_loss: 1.1393 - val_accuracy: 0.2143\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8148 - accuracy: 0.3036 - val_loss: 1.1409 - val_accuracy: 0.2143\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8139 - accuracy: 0.3214 - val_loss: 1.1427 - val_accuracy: 0.2143\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.8092 - accuracy: 0.3036 - val_loss: 1.1447 - val_accuracy: 0.2143\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8076 - accuracy: 0.3393 - val_loss: 1.1469 - val_accuracy: 0.2143\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8033 - accuracy: 0.3214 - val_loss: 1.1491 - val_accuracy: 0.2143\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7986 - accuracy: 0.3214 - val_loss: 1.1513 - val_accuracy: 0.2143\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7971 - accuracy: 0.2857 - val_loss: 1.1536 - val_accuracy: 0.2143\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7981 - accuracy: 0.3036 - val_loss: 1.1559 - val_accuracy: 0.2143\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7959 - accuracy: 0.3393 - val_loss: 1.1584 - val_accuracy: 0.2143\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7940 - accuracy: 0.3393 - val_loss: 1.1611 - val_accuracy: 0.2143\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7812 - accuracy: 0.3571 - val_loss: 1.1639 - val_accuracy: 0.2143\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7852 - accuracy: 0.3393 - val_loss: 1.1667 - val_accuracy: 0.2143\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7755 - accuracy: 0.3214 - val_loss: 1.1696 - val_accuracy: 0.2143\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7831 - accuracy: 0.3393 - val_loss: 1.1725 - val_accuracy: 0.2143\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7817 - accuracy: 0.2857 - val_loss: 1.1752 - val_accuracy: 0.2143\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7769 - accuracy: 0.3750 - val_loss: 1.1778 - val_accuracy: 0.2143\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7694 - accuracy: 0.3571 - val_loss: 1.1805 - val_accuracy: 0.2143\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7681 - accuracy: 0.3750 - val_loss: 1.1833 - val_accuracy: 0.2143\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7718 - accuracy: 0.3393 - val_loss: 1.1859 - val_accuracy: 0.2143\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7623 - accuracy: 0.3214 - val_loss: 1.1884 - val_accuracy: 0.2143\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7624 - accuracy: 0.3214 - val_loss: 1.1909 - val_accuracy: 0.2143\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7566 - accuracy: 0.3214 - val_loss: 1.1935 - val_accuracy: 0.2143\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7637 - accuracy: 0.2857 - val_loss: 1.1960 - val_accuracy: 0.2143\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7406 - accuracy: 0.3571 - val_loss: 1.1986 - val_accuracy: 0.2143\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7562 - accuracy: 0.3750 - val_loss: 1.2007 - val_accuracy: 0.2143\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7540 - accuracy: 0.3214 - val_loss: 1.2023 - val_accuracy: 0.2143\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7439 - accuracy: 0.3393 - val_loss: 1.2041 - val_accuracy: 0.2143\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.7397 - accuracy: 0.3214 - val_loss: 1.2061 - val_accuracy: 0.2143\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7327 - accuracy: 0.3750 - val_loss: 1.2083 - val_accuracy: 0.2143\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7432 - accuracy: 0.3750 - val_loss: 1.2106 - val_accuracy: 0.2143\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7289 - accuracy: 0.3750 - val_loss: 1.2127 - val_accuracy: 0.2143\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7221 - accuracy: 0.3750 - val_loss: 1.2150 - val_accuracy: 0.2143\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7282 - accuracy: 0.3393 - val_loss: 1.2170 - val_accuracy: 0.2143\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7317 - accuracy: 0.3214 - val_loss: 1.2192 - val_accuracy: 0.2143\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7297 - accuracy: 0.3571 - val_loss: 1.2212 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7343 - accuracy: 0.3214 - val_loss: 1.2238 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7225 - accuracy: 0.4107 - val_loss: 1.2265 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7108 - accuracy: 0.2857 - val_loss: 1.2290 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7188 - accuracy: 0.3571 - val_loss: 1.2311 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7137 - accuracy: 0.4107 - val_loss: 1.2327 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7193 - accuracy: 0.3571 - val_loss: 1.2337 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7024 - accuracy: 0.3393 - val_loss: 1.2345 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7113 - accuracy: 0.3571 - val_loss: 1.2351 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7044 - accuracy: 0.4107 - val_loss: 1.2352 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7106 - accuracy: 0.3571 - val_loss: 1.2351 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6972 - accuracy: 0.3929 - val_loss: 1.2356 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7078 - accuracy: 0.3571 - val_loss: 1.2364 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6795 - accuracy: 0.3750 - val_loss: 1.2369 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7062 - accuracy: 0.3929 - val_loss: 1.2376 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6915 - accuracy: 0.4107 - val_loss: 1.2384 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6860 - accuracy: 0.3393 - val_loss: 1.2395 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6943 - accuracy: 0.3750 - val_loss: 1.2404 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6828 - accuracy: 0.3393 - val_loss: 1.2416 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6710 - accuracy: 0.3929 - val_loss: 1.2430 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6698 - accuracy: 0.3750 - val_loss: 1.2447 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6763 - accuracy: 0.3571 - val_loss: 1.2468 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6743 - accuracy: 0.4464 - val_loss: 1.2493 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6758 - accuracy: 0.3393 - val_loss: 1.2519 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6847 - accuracy: 0.3750 - val_loss: 1.2544 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6760 - accuracy: 0.3571 - val_loss: 1.2571 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6635 - accuracy: 0.3929 - val_loss: 1.2601 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6638 - accuracy: 0.4107 - val_loss: 1.2634 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6609 - accuracy: 0.3929 - val_loss: 1.2665 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6686 - accuracy: 0.4464 - val_loss: 1.2690 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6665 - accuracy: 0.3929 - val_loss: 1.2713 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6592 - accuracy: 0.3214 - val_loss: 1.2737 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6633 - accuracy: 0.4107 - val_loss: 1.2762 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6456 - accuracy: 0.4107 - val_loss: 1.2793 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6540 - accuracy: 0.3393 - val_loss: 1.2825 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6392 - accuracy: 0.4107 - val_loss: 1.2858 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6433 - accuracy: 0.4464 - val_loss: 1.2891 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6696 - accuracy: 0.3929 - val_loss: 1.2918 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6380 - accuracy: 0.4464 - val_loss: 1.2943 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6334 - accuracy: 0.4286 - val_loss: 1.2973 - val_accuracy: 0.1429\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6435 - accuracy: 0.4464 - val_loss: 1.2996 - val_accuracy: 0.1429\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6311 - accuracy: 0.4286 - val_loss: 1.3016 - val_accuracy: 0.1429\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6304 - accuracy: 0.3929 - val_loss: 1.3034 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6267 - accuracy: 0.3571 - val_loss: 1.3053 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6340 - accuracy: 0.4286 - val_loss: 1.3083 - val_accuracy: 0.1429\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6393 - accuracy: 0.3929 - val_loss: 1.3104 - val_accuracy: 0.1429\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6149 - accuracy: 0.3750 - val_loss: 1.3136 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6232 - accuracy: 0.3750 - val_loss: 1.3166 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6246 - accuracy: 0.3571 - val_loss: 1.3196 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6209 - accuracy: 0.4286 - val_loss: 1.3226 - val_accuracy: 0.1429\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6202 - accuracy: 0.4464 - val_loss: 1.3251 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6076 - accuracy: 0.3929 - val_loss: 1.3273 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6110 - accuracy: 0.3571 - val_loss: 1.3293 - val_accuracy: 0.1429\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6083 - accuracy: 0.4464 - val_loss: 1.3319 - val_accuracy: 0.1429\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6161 - accuracy: 0.3929 - val_loss: 1.3346 - val_accuracy: 0.1429\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5939 - accuracy: 0.4286 - val_loss: 1.3381 - val_accuracy: 0.1429\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5878 - accuracy: 0.3929 - val_loss: 1.3413 - val_accuracy: 0.1429\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5938 - accuracy: 0.4286 - val_loss: 1.3450 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5832 - accuracy: 0.4464 - val_loss: 1.3483 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5911 - accuracy: 0.4286 - val_loss: 1.3523 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5909 - accuracy: 0.4107 - val_loss: 1.3557 - val_accuracy: 0.1429\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5854 - accuracy: 0.4107 - val_loss: 1.3592 - val_accuracy: 0.1429\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5870 - accuracy: 0.4821 - val_loss: 1.3626 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5842 - accuracy: 0.4821 - val_loss: 1.3655 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5715 - accuracy: 0.4107 - val_loss: 1.3680 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5829 - accuracy: 0.3929 - val_loss: 1.3698 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5916 - accuracy: 0.3929 - val_loss: 1.3717 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5746 - accuracy: 0.4821 - val_loss: 1.3736 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5681 - accuracy: 0.4643 - val_loss: 1.3731 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5714 - accuracy: 0.4643 - val_loss: 1.3733 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5666 - accuracy: 0.4643 - val_loss: 1.3734 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.5848 - accuracy: 0.3750 - val_loss: 1.3731 - val_accuracy: 0.1429\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5744 - accuracy: 0.4464 - val_loss: 1.3739 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5524 - accuracy: 0.3750 - val_loss: 1.3754 - val_accuracy: 0.2143\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5514 - accuracy: 0.4464 - val_loss: 1.3777 - val_accuracy: 0.2143\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5529 - accuracy: 0.4464 - val_loss: 1.3793 - val_accuracy: 0.2143\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5373 - accuracy: 0.4107 - val_loss: 1.3818 - val_accuracy: 0.2143\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5529 - accuracy: 0.4107 - val_loss: 1.3849 - val_accuracy: 0.2143\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.5522 - accuracy: 0.4643 - val_loss: 1.3870 - val_accuracy: 0.2143\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5475 - accuracy: 0.4821 - val_loss: 1.3893 - val_accuracy: 0.2143\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.5438 - accuracy: 0.3929 - val_loss: 1.3916 - val_accuracy: 0.2143\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.5490 - accuracy: 0.4107 - val_loss: 1.3925 - val_accuracy: 0.2143\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5486 - accuracy: 0.3571 - val_loss: 1.3933 - val_accuracy: 0.2143\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5379 - accuracy: 0.3929 - val_loss: 1.3939 - val_accuracy: 0.2143\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5305 - accuracy: 0.4286 - val_loss: 1.3947 - val_accuracy: 0.2143\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5210 - accuracy: 0.4464 - val_loss: 1.3946 - val_accuracy: 0.2143\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5075 - accuracy: 0.4286 - val_loss: 1.3953 - val_accuracy: 0.2143\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5211 - accuracy: 0.4464 - val_loss: 1.3952 - val_accuracy: 0.2143\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5293 - accuracy: 0.5000 - val_loss: 1.3957 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.5178 - accuracy: 0.4286 - val_loss: 1.3960 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5089 - accuracy: 0.4821 - val_loss: 1.3982 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5116 - accuracy: 0.4107 - val_loss: 1.3995 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5030 - accuracy: 0.4464 - val_loss: 1.4022 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5059 - accuracy: 0.4464 - val_loss: 1.4050 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5114 - accuracy: 0.4286 - val_loss: 1.4078 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4937 - accuracy: 0.4643 - val_loss: 1.4115 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4780 - accuracy: 0.5357 - val_loss: 1.4160 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4762 - accuracy: 0.5357 - val_loss: 1.4199 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5101 - accuracy: 0.3929 - val_loss: 1.4223 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4858 - accuracy: 0.4107 - val_loss: 1.4250 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4948 - accuracy: 0.4464 - val_loss: 1.4277 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4854 - accuracy: 0.4821 - val_loss: 1.4297 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4840 - accuracy: 0.4643 - val_loss: 1.4302 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4678 - accuracy: 0.4464 - val_loss: 1.4308 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4817 - accuracy: 0.4464 - val_loss: 1.4320 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4578 - accuracy: 0.4107 - val_loss: 1.4331 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4644 - accuracy: 0.5000 - val_loss: 1.4340 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4529 - accuracy: 0.4286 - val_loss: 1.4356 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4831 - accuracy: 0.4464 - val_loss: 1.4374 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4579 - accuracy: 0.5000 - val_loss: 1.4393 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4683 - accuracy: 0.4643 - val_loss: 1.4418 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4574 - accuracy: 0.4643 - val_loss: 1.4450 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4490 - accuracy: 0.5179 - val_loss: 1.4478 - val_accuracy: 0.2143\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4438 - accuracy: 0.4464 - val_loss: 1.4490 - val_accuracy: 0.2143\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4783 - accuracy: 0.5000 - val_loss: 1.4489 - val_accuracy: 0.2143\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4656 - accuracy: 0.4821 - val_loss: 1.4495 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4317 - accuracy: 0.4464 - val_loss: 1.4501 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4425 - accuracy: 0.4821 - val_loss: 1.4509 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4408 - accuracy: 0.4464 - val_loss: 1.4528 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4317 - accuracy: 0.4286 - val_loss: 1.4543 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4351 - accuracy: 0.5000 - val_loss: 1.4557 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4525 - accuracy: 0.5179 - val_loss: 1.4570 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4101 - accuracy: 0.5000 - val_loss: 1.4590 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4242 - accuracy: 0.5000 - val_loss: 1.4613 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4372 - accuracy: 0.4821 - val_loss: 1.4627 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4202 - accuracy: 0.4821 - val_loss: 1.4660 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4350 - accuracy: 0.5357 - val_loss: 1.4695 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4198 - accuracy: 0.5714 - val_loss: 1.4712 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4359 - accuracy: 0.4286 - val_loss: 1.4728 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4499 - accuracy: 0.4821 - val_loss: 1.4718 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4115 - accuracy: 0.5357 - val_loss: 1.4696 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.4014 - accuracy: 0.5536 - val_loss: 1.4670 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4204 - accuracy: 0.5000 - val_loss: 1.4653 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4184 - accuracy: 0.5714 - val_loss: 1.4606 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4149 - accuracy: 0.4107 - val_loss: 1.4578 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4377 - accuracy: 0.5000 - val_loss: 1.4572 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4108 - accuracy: 0.5893 - val_loss: 1.4579 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4130 - accuracy: 0.5357 - val_loss: 1.4590 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4590 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=240, batch_size=100, Scores: [1.4590140581130981, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.4590140581130981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9796 - accuracy: 0.2857 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9795 - accuracy: 0.1429 - val_loss: 1.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9763 - accuracy: 0.1607 - val_loss: 1.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.9754 - accuracy: 0.3036 - val_loss: 1.0725 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.9722 - accuracy: 0.2321 - val_loss: 1.0728 - val_accuracy: 0.1429\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9731 - accuracy: 0.2143 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9695 - accuracy: 0.1964 - val_loss: 1.0736 - val_accuracy: 0.2143\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9672 - accuracy: 0.2321 - val_loss: 1.0740 - val_accuracy: 0.2143\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9655 - accuracy: 0.3214 - val_loss: 1.0744 - val_accuracy: 0.2857\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.9636 - accuracy: 0.2857 - val_loss: 1.0747 - val_accuracy: 0.2857\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9621 - accuracy: 0.2679 - val_loss: 1.0751 - val_accuracy: 0.2857\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9587 - accuracy: 0.1964 - val_loss: 1.0755 - val_accuracy: 0.2143\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9593 - accuracy: 0.2500 - val_loss: 1.0759 - val_accuracy: 0.2143\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9562 - accuracy: 0.3214 - val_loss: 1.0764 - val_accuracy: 0.2143\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9541 - accuracy: 0.2679 - val_loss: 1.0768 - val_accuracy: 0.2143\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9534 - accuracy: 0.2679 - val_loss: 1.0772 - val_accuracy: 0.2143\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9477 - accuracy: 0.2500 - val_loss: 1.0777 - val_accuracy: 0.2143\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9487 - accuracy: 0.2500 - val_loss: 1.0781 - val_accuracy: 0.2143\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9444 - accuracy: 0.3036 - val_loss: 1.0785 - val_accuracy: 0.2143\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9437 - accuracy: 0.2500 - val_loss: 1.0790 - val_accuracy: 0.2143\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9418 - accuracy: 0.2679 - val_loss: 1.0794 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.9364 - accuracy: 0.2500 - val_loss: 1.0799 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9335 - accuracy: 0.3036 - val_loss: 1.0803 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9354 - accuracy: 0.2321 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9300 - accuracy: 0.3214 - val_loss: 1.0812 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9286 - accuracy: 0.3036 - val_loss: 1.0817 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9301 - accuracy: 0.2857 - val_loss: 1.0822 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9249 - accuracy: 0.3750 - val_loss: 1.0827 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9209 - accuracy: 0.3571 - val_loss: 1.0833 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9206 - accuracy: 0.3036 - val_loss: 1.0839 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9122 - accuracy: 0.4107 - val_loss: 1.0845 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9159 - accuracy: 0.3214 - val_loss: 1.0851 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9098 - accuracy: 0.3571 - val_loss: 1.0858 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9045 - accuracy: 0.3393 - val_loss: 1.0865 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9077 - accuracy: 0.3036 - val_loss: 1.0873 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8993 - accuracy: 0.3393 - val_loss: 1.0881 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9067 - accuracy: 0.3214 - val_loss: 1.0888 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8988 - accuracy: 0.3393 - val_loss: 1.0897 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8942 - accuracy: 0.2857 - val_loss: 1.0906 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8926 - accuracy: 0.3393 - val_loss: 1.0916 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8886 - accuracy: 0.3214 - val_loss: 1.0927 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8797 - accuracy: 0.3214 - val_loss: 1.0938 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8793 - accuracy: 0.2857 - val_loss: 1.0949 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8821 - accuracy: 0.3571 - val_loss: 1.0961 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8683 - accuracy: 0.2679 - val_loss: 1.0973 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8670 - accuracy: 0.3036 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8683 - accuracy: 0.3214 - val_loss: 1.0998 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8590 - accuracy: 0.2857 - val_loss: 1.1010 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8611 - accuracy: 0.3214 - val_loss: 1.1023 - val_accuracy: 0.2143\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8669 - accuracy: 0.3214 - val_loss: 1.1036 - val_accuracy: 0.2143\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8530 - accuracy: 0.3393 - val_loss: 1.1050 - val_accuracy: 0.2143\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.8551 - accuracy: 0.3036 - val_loss: 1.1065 - val_accuracy: 0.2143\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8503 - accuracy: 0.3214 - val_loss: 1.1080 - val_accuracy: 0.2143\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8484 - accuracy: 0.3036 - val_loss: 1.1095 - val_accuracy: 0.2143\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8404 - accuracy: 0.3036 - val_loss: 1.1111 - val_accuracy: 0.2857\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8445 - accuracy: 0.3036 - val_loss: 1.1128 - val_accuracy: 0.2143\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.8376 - accuracy: 0.2679 - val_loss: 1.1144 - val_accuracy: 0.2143\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8360 - accuracy: 0.3393 - val_loss: 1.1162 - val_accuracy: 0.2143\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8358 - accuracy: 0.3036 - val_loss: 1.1179 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8362 - accuracy: 0.2679 - val_loss: 1.1198 - val_accuracy: 0.2143\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.8253 - accuracy: 0.2857 - val_loss: 1.1217 - val_accuracy: 0.2143\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8181 - accuracy: 0.3036 - val_loss: 1.1239 - val_accuracy: 0.2143\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8269 - accuracy: 0.3214 - val_loss: 1.1262 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8221 - accuracy: 0.2857 - val_loss: 1.1287 - val_accuracy: 0.2143\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8125 - accuracy: 0.3036 - val_loss: 1.1312 - val_accuracy: 0.2143\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8168 - accuracy: 0.3214 - val_loss: 1.1339 - val_accuracy: 0.2143\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8085 - accuracy: 0.3036 - val_loss: 1.1366 - val_accuracy: 0.2143\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8024 - accuracy: 0.3214 - val_loss: 1.1394 - val_accuracy: 0.2143\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8033 - accuracy: 0.2857 - val_loss: 1.1421 - val_accuracy: 0.2143\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7995 - accuracy: 0.3036 - val_loss: 1.1450 - val_accuracy: 0.2143\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7978 - accuracy: 0.3214 - val_loss: 1.1481 - val_accuracy: 0.2143\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7986 - accuracy: 0.2857 - val_loss: 1.1512 - val_accuracy: 0.2143\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8049 - accuracy: 0.2321 - val_loss: 1.1543 - val_accuracy: 0.2143\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7947 - accuracy: 0.2857 - val_loss: 1.1572 - val_accuracy: 0.2143\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7970 - accuracy: 0.3214 - val_loss: 1.1601 - val_accuracy: 0.2143\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7798 - accuracy: 0.3036 - val_loss: 1.1632 - val_accuracy: 0.2143\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7831 - accuracy: 0.3036 - val_loss: 1.1661 - val_accuracy: 0.2143\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7830 - accuracy: 0.3214 - val_loss: 1.1687 - val_accuracy: 0.2143\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7787 - accuracy: 0.3571 - val_loss: 1.1713 - val_accuracy: 0.2143\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7779 - accuracy: 0.3393 - val_loss: 1.1735 - val_accuracy: 0.2143\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7773 - accuracy: 0.3036 - val_loss: 1.1754 - val_accuracy: 0.2143\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7687 - accuracy: 0.3750 - val_loss: 1.1773 - val_accuracy: 0.2143\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7687 - accuracy: 0.3036 - val_loss: 1.1791 - val_accuracy: 0.2143\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.7728 - accuracy: 0.3393 - val_loss: 1.1811 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7650 - accuracy: 0.3393 - val_loss: 1.1830 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7643 - accuracy: 0.3036 - val_loss: 1.1851 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7575 - accuracy: 0.3571 - val_loss: 1.1874 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7478 - accuracy: 0.3571 - val_loss: 1.1895 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7472 - accuracy: 0.3571 - val_loss: 1.1911 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7467 - accuracy: 0.3393 - val_loss: 1.1926 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7471 - accuracy: 0.2857 - val_loss: 1.1939 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7625 - accuracy: 0.3214 - val_loss: 1.1952 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7392 - accuracy: 0.3036 - val_loss: 1.1964 - val_accuracy: 0.0714\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7454 - accuracy: 0.3393 - val_loss: 1.1982 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7498 - accuracy: 0.3214 - val_loss: 1.1994 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7414 - accuracy: 0.3571 - val_loss: 1.2009 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7369 - accuracy: 0.3214 - val_loss: 1.2016 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.7401 - accuracy: 0.3036 - val_loss: 1.2012 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7396 - accuracy: 0.3214 - val_loss: 1.2010 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7319 - accuracy: 0.3571 - val_loss: 1.2008 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7423 - accuracy: 0.3571 - val_loss: 1.2007 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7324 - accuracy: 0.3214 - val_loss: 1.2011 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7315 - accuracy: 0.3571 - val_loss: 1.2012 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7265 - accuracy: 0.2857 - val_loss: 1.2012 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7329 - accuracy: 0.3036 - val_loss: 1.2010 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7271 - accuracy: 0.3036 - val_loss: 1.2011 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7183 - accuracy: 0.3214 - val_loss: 1.2004 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7177 - accuracy: 0.3393 - val_loss: 1.1999 - val_accuracy: 0.0714\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7222 - accuracy: 0.3571 - val_loss: 1.1999 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7231 - accuracy: 0.3571 - val_loss: 1.2003 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7139 - accuracy: 0.3571 - val_loss: 1.2013 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.7145 - accuracy: 0.3571 - val_loss: 1.2028 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7132 - accuracy: 0.3929 - val_loss: 1.2045 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7151 - accuracy: 0.3571 - val_loss: 1.2053 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7036 - accuracy: 0.3571 - val_loss: 1.2065 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6966 - accuracy: 0.3750 - val_loss: 1.2087 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7010 - accuracy: 0.3929 - val_loss: 1.2115 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7113 - accuracy: 0.3750 - val_loss: 1.2141 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.7160 - accuracy: 0.3571 - val_loss: 1.2166 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6983 - accuracy: 0.3929 - val_loss: 1.2187 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6926 - accuracy: 0.3393 - val_loss: 1.2204 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6924 - accuracy: 0.3750 - val_loss: 1.2217 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6927 - accuracy: 0.3571 - val_loss: 1.2234 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6926 - accuracy: 0.3750 - val_loss: 1.2249 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6920 - accuracy: 0.3750 - val_loss: 1.2253 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6989 - accuracy: 0.3750 - val_loss: 1.2261 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6936 - accuracy: 0.3750 - val_loss: 1.2263 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6666 - accuracy: 0.3393 - val_loss: 1.2266 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6841 - accuracy: 0.4107 - val_loss: 1.2270 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6898 - accuracy: 0.3929 - val_loss: 1.2287 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6723 - accuracy: 0.3929 - val_loss: 1.2303 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6814 - accuracy: 0.3571 - val_loss: 1.2319 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6668 - accuracy: 0.3929 - val_loss: 1.2339 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6663 - accuracy: 0.4107 - val_loss: 1.2357 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6695 - accuracy: 0.4107 - val_loss: 1.2373 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6543 - accuracy: 0.4107 - val_loss: 1.2394 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6588 - accuracy: 0.4286 - val_loss: 1.2418 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6557 - accuracy: 0.4107 - val_loss: 1.2431 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6762 - accuracy: 0.3929 - val_loss: 1.2450 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6547 - accuracy: 0.3929 - val_loss: 1.2463 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6507 - accuracy: 0.4107 - val_loss: 1.2476 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6607 - accuracy: 0.3750 - val_loss: 1.2498 - val_accuracy: 0.1429\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6439 - accuracy: 0.3929 - val_loss: 1.2512 - val_accuracy: 0.1429\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6479 - accuracy: 0.4464 - val_loss: 1.2532 - val_accuracy: 0.1429\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6394 - accuracy: 0.4107 - val_loss: 1.2561 - val_accuracy: 0.1429\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6253 - accuracy: 0.4286 - val_loss: 1.2587 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6281 - accuracy: 0.3750 - val_loss: 1.2615 - val_accuracy: 0.1429\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6256 - accuracy: 0.4286 - val_loss: 1.2644 - val_accuracy: 0.1429\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6174 - accuracy: 0.4107 - val_loss: 1.2683 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6361 - accuracy: 0.4107 - val_loss: 1.2726 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6210 - accuracy: 0.4286 - val_loss: 1.2774 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6125 - accuracy: 0.4464 - val_loss: 1.2810 - val_accuracy: 0.1429\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6267 - accuracy: 0.4107 - val_loss: 1.2833 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6226 - accuracy: 0.3929 - val_loss: 1.2855 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6364 - accuracy: 0.4286 - val_loss: 1.2860 - val_accuracy: 0.1429\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6102 - accuracy: 0.4286 - val_loss: 1.2870 - val_accuracy: 0.1429\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.6060 - accuracy: 0.4286 - val_loss: 1.2885 - val_accuracy: 0.1429\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6003 - accuracy: 0.4107 - val_loss: 1.2907 - val_accuracy: 0.1429\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6028 - accuracy: 0.3929 - val_loss: 1.2947 - val_accuracy: 0.1429\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6306 - accuracy: 0.3929 - val_loss: 1.2999 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6021 - accuracy: 0.4107 - val_loss: 1.3058 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6004 - accuracy: 0.4107 - val_loss: 1.3122 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5800 - accuracy: 0.4464 - val_loss: 1.3196 - val_accuracy: 0.1429\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6126 - accuracy: 0.4107 - val_loss: 1.3264 - val_accuracy: 0.1429\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.5928 - accuracy: 0.3929 - val_loss: 1.3320 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6127 - accuracy: 0.4643 - val_loss: 1.3366 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5879 - accuracy: 0.4464 - val_loss: 1.3400 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5771 - accuracy: 0.4464 - val_loss: 1.3432 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5581 - accuracy: 0.4464 - val_loss: 1.3462 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5846 - accuracy: 0.4286 - val_loss: 1.3488 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5532 - accuracy: 0.4464 - val_loss: 1.3506 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5727 - accuracy: 0.4464 - val_loss: 1.3518 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5796 - accuracy: 0.4643 - val_loss: 1.3537 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5540 - accuracy: 0.4643 - val_loss: 1.3558 - val_accuracy: 0.1429\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5343 - accuracy: 0.4286 - val_loss: 1.3590 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5680 - accuracy: 0.4286 - val_loss: 1.3626 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5503 - accuracy: 0.3929 - val_loss: 1.3663 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5589 - accuracy: 0.4821 - val_loss: 1.3704 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5794 - accuracy: 0.4107 - val_loss: 1.3742 - val_accuracy: 0.1429\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 0.5579 - accuracy: 0.3750 - val_loss: 1.3774 - val_accuracy: 0.1429\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5539 - accuracy: 0.4286 - val_loss: 1.3811 - val_accuracy: 0.1429\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5484 - accuracy: 0.4286 - val_loss: 1.3856 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5421 - accuracy: 0.4643 - val_loss: 1.3900 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5461 - accuracy: 0.4464 - val_loss: 1.3941 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5426 - accuracy: 0.4643 - val_loss: 1.3968 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.5338 - accuracy: 0.4643 - val_loss: 1.3986 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5357 - accuracy: 0.4286 - val_loss: 1.3996 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5361 - accuracy: 0.4464 - val_loss: 1.4001 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.5270 - accuracy: 0.4464 - val_loss: 1.4009 - val_accuracy: 0.1429\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5250 - accuracy: 0.4464 - val_loss: 1.4017 - val_accuracy: 0.1429\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5383 - accuracy: 0.5000 - val_loss: 1.4023 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4925 - accuracy: 0.5179 - val_loss: 1.4025 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5234 - accuracy: 0.4464 - val_loss: 1.4036 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5264 - accuracy: 0.3929 - val_loss: 1.4053 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5160 - accuracy: 0.4643 - val_loss: 1.4073 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5126 - accuracy: 0.5179 - val_loss: 1.4094 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4948 - accuracy: 0.4286 - val_loss: 1.4132 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5043 - accuracy: 0.4107 - val_loss: 1.4178 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4907 - accuracy: 0.4464 - val_loss: 1.4243 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4946 - accuracy: 0.4464 - val_loss: 1.4316 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4882 - accuracy: 0.4643 - val_loss: 1.4373 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5076 - accuracy: 0.4286 - val_loss: 1.4417 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4970 - accuracy: 0.4464 - val_loss: 1.4433 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.5001 - accuracy: 0.4821 - val_loss: 1.4444 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4884 - accuracy: 0.4464 - val_loss: 1.4454 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5133 - accuracy: 0.3750 - val_loss: 1.4460 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4698 - accuracy: 0.4821 - val_loss: 1.4458 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4963 - accuracy: 0.4464 - val_loss: 1.4485 - val_accuracy: 0.1429\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4541 - accuracy: 0.4464 - val_loss: 1.4526 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4675 - accuracy: 0.4286 - val_loss: 1.4558 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4489 - accuracy: 0.5000 - val_loss: 1.4580 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4577 - accuracy: 0.4464 - val_loss: 1.4597 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4579 - accuracy: 0.5000 - val_loss: 1.4621 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4743 - accuracy: 0.4821 - val_loss: 1.4632 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4687 - accuracy: 0.4464 - val_loss: 1.4646 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4816 - accuracy: 0.3929 - val_loss: 1.4640 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4472 - accuracy: 0.4821 - val_loss: 1.4621 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4561 - accuracy: 0.4286 - val_loss: 1.4615 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4312 - accuracy: 0.4643 - val_loss: 1.4609 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4405 - accuracy: 0.4821 - val_loss: 1.4630 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4402 - accuracy: 0.4643 - val_loss: 1.4632 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4501 - accuracy: 0.4643 - val_loss: 1.4637 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4609 - accuracy: 0.4286 - val_loss: 1.4621 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4560 - accuracy: 0.4643 - val_loss: 1.4611 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4288 - accuracy: 0.5000 - val_loss: 1.4593 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4208 - accuracy: 0.5000 - val_loss: 1.4600 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4304 - accuracy: 0.5179 - val_loss: 1.4615 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.4317 - accuracy: 0.4821 - val_loss: 1.4625 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4100 - accuracy: 0.5357 - val_loss: 1.4632 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4339 - accuracy: 0.4821 - val_loss: 1.4639 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.4215 - accuracy: 0.4464 - val_loss: 1.4661 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4182 - accuracy: 0.5357 - val_loss: 1.4701 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4279 - accuracy: 0.5179 - val_loss: 1.4737 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4038 - accuracy: 0.5357 - val_loss: 1.4750 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4061 - accuracy: 0.5357 - val_loss: 1.4727 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3976 - accuracy: 0.5179 - val_loss: 1.4730 - val_accuracy: 0.1429\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4320 - accuracy: 0.4286 - val_loss: 1.4716 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3866 - accuracy: 0.5357 - val_loss: 1.4701 - val_accuracy: 0.1429\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4101 - accuracy: 0.5000 - val_loss: 1.4692 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4057 - accuracy: 0.4643 - val_loss: 1.4675 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4675 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=240, batch_size=300, Scores: [1.4674712419509888, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.4674712419509888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9805 - accuracy: 0.1071 - val_loss: 1.0661 - val_accuracy: 0.1429\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9788 - accuracy: 0.2143 - val_loss: 1.0666 - val_accuracy: 0.2143\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9781 - accuracy: 0.1429 - val_loss: 1.0671 - val_accuracy: 0.2143\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.9745 - accuracy: 0.3036 - val_loss: 1.0676 - val_accuracy: 0.2143\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9741 - accuracy: 0.3571 - val_loss: 1.0681 - val_accuracy: 0.2143\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9730 - accuracy: 0.2321 - val_loss: 1.0687 - val_accuracy: 0.2143\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.9714 - accuracy: 0.2143 - val_loss: 1.0693 - val_accuracy: 0.2143\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9682 - accuracy: 0.3036 - val_loss: 1.0699 - val_accuracy: 0.2143\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.9688 - accuracy: 0.2679 - val_loss: 1.0705 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9658 - accuracy: 0.2857 - val_loss: 1.0711 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9612 - accuracy: 0.2500 - val_loss: 1.0717 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9608 - accuracy: 0.2857 - val_loss: 1.0723 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9617 - accuracy: 0.3393 - val_loss: 1.0729 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9568 - accuracy: 0.3571 - val_loss: 1.0735 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9558 - accuracy: 0.3393 - val_loss: 1.0741 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9549 - accuracy: 0.2857 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.9510 - accuracy: 0.3214 - val_loss: 1.0753 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9528 - accuracy: 0.2679 - val_loss: 1.0760 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9451 - accuracy: 0.3214 - val_loss: 1.0766 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9491 - accuracy: 0.3214 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9430 - accuracy: 0.3393 - val_loss: 1.0780 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9404 - accuracy: 0.3750 - val_loss: 1.0787 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9377 - accuracy: 0.3214 - val_loss: 1.0793 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9378 - accuracy: 0.3929 - val_loss: 1.0800 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9352 - accuracy: 0.3214 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9311 - accuracy: 0.3929 - val_loss: 1.0813 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9308 - accuracy: 0.3214 - val_loss: 1.0820 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9259 - accuracy: 0.3393 - val_loss: 1.0827 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9241 - accuracy: 0.2857 - val_loss: 1.0833 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9218 - accuracy: 0.3214 - val_loss: 1.0839 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9228 - accuracy: 0.3393 - val_loss: 1.0846 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.9202 - accuracy: 0.3214 - val_loss: 1.0853 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9121 - accuracy: 0.3393 - val_loss: 1.0859 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9114 - accuracy: 0.3393 - val_loss: 1.0867 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.9098 - accuracy: 0.3571 - val_loss: 1.0874 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.9056 - accuracy: 0.3036 - val_loss: 1.0882 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9005 - accuracy: 0.3393 - val_loss: 1.0891 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9008 - accuracy: 0.3393 - val_loss: 1.0900 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9011 - accuracy: 0.3393 - val_loss: 1.0909 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8941 - accuracy: 0.3929 - val_loss: 1.0919 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8878 - accuracy: 0.3393 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8902 - accuracy: 0.3393 - val_loss: 1.0942 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8868 - accuracy: 0.3750 - val_loss: 1.0955 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8844 - accuracy: 0.3214 - val_loss: 1.0970 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.8796 - accuracy: 0.2857 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8791 - accuracy: 0.3750 - val_loss: 1.1002 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8713 - accuracy: 0.3750 - val_loss: 1.1020 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8668 - accuracy: 0.3393 - val_loss: 1.1040 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8643 - accuracy: 0.3214 - val_loss: 1.1062 - val_accuracy: 0.2143\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8628 - accuracy: 0.3036 - val_loss: 1.1085 - val_accuracy: 0.2143\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8553 - accuracy: 0.2857 - val_loss: 1.1108 - val_accuracy: 0.2143\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8523 - accuracy: 0.3571 - val_loss: 1.1134 - val_accuracy: 0.2143\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8481 - accuracy: 0.3750 - val_loss: 1.1161 - val_accuracy: 0.2143\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8466 - accuracy: 0.3214 - val_loss: 1.1189 - val_accuracy: 0.2143\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8482 - accuracy: 0.3393 - val_loss: 1.1218 - val_accuracy: 0.2143\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.8501 - accuracy: 0.3036 - val_loss: 1.1248 - val_accuracy: 0.2143\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8425 - accuracy: 0.3214 - val_loss: 1.1280 - val_accuracy: 0.2143\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8367 - accuracy: 0.3571 - val_loss: 1.1313 - val_accuracy: 0.2143\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8295 - accuracy: 0.3214 - val_loss: 1.1347 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8431 - accuracy: 0.3214 - val_loss: 1.1381 - val_accuracy: 0.2143\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8286 - accuracy: 0.3036 - val_loss: 1.1415 - val_accuracy: 0.2143\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8284 - accuracy: 0.3214 - val_loss: 1.1449 - val_accuracy: 0.2143\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8210 - accuracy: 0.3214 - val_loss: 1.1483 - val_accuracy: 0.2143\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8239 - accuracy: 0.2857 - val_loss: 1.1518 - val_accuracy: 0.2143\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.8190 - accuracy: 0.3214 - val_loss: 1.1553 - val_accuracy: 0.2143\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8217 - accuracy: 0.3393 - val_loss: 1.1586 - val_accuracy: 0.2143\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8176 - accuracy: 0.3571 - val_loss: 1.1620 - val_accuracy: 0.2143\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8083 - accuracy: 0.3214 - val_loss: 1.1653 - val_accuracy: 0.2143\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8130 - accuracy: 0.3036 - val_loss: 1.1684 - val_accuracy: 0.2143\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8079 - accuracy: 0.2857 - val_loss: 1.1714 - val_accuracy: 0.2143\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.8035 - accuracy: 0.3393 - val_loss: 1.1745 - val_accuracy: 0.2143\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8019 - accuracy: 0.2857 - val_loss: 1.1776 - val_accuracy: 0.2143\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8005 - accuracy: 0.3393 - val_loss: 1.1806 - val_accuracy: 0.2143\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8002 - accuracy: 0.3036 - val_loss: 1.1835 - val_accuracy: 0.2143\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7942 - accuracy: 0.3214 - val_loss: 1.1867 - val_accuracy: 0.2143\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7979 - accuracy: 0.3571 - val_loss: 1.1897 - val_accuracy: 0.2143\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7945 - accuracy: 0.3214 - val_loss: 1.1926 - val_accuracy: 0.2143\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7874 - accuracy: 0.3393 - val_loss: 1.1954 - val_accuracy: 0.2143\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7860 - accuracy: 0.3393 - val_loss: 1.1982 - val_accuracy: 0.2143\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7827 - accuracy: 0.3036 - val_loss: 1.2009 - val_accuracy: 0.2143\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7811 - accuracy: 0.3393 - val_loss: 1.2035 - val_accuracy: 0.2143\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7896 - accuracy: 0.3214 - val_loss: 1.2060 - val_accuracy: 0.2143\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7745 - accuracy: 0.2857 - val_loss: 1.2084 - val_accuracy: 0.2143\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7742 - accuracy: 0.2857 - val_loss: 1.2110 - val_accuracy: 0.2143\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7819 - accuracy: 0.3214 - val_loss: 1.2135 - val_accuracy: 0.2143\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7808 - accuracy: 0.3036 - val_loss: 1.2158 - val_accuracy: 0.2143\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7736 - accuracy: 0.3750 - val_loss: 1.2178 - val_accuracy: 0.2143\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7653 - accuracy: 0.3571 - val_loss: 1.2196 - val_accuracy: 0.2143\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.7692 - accuracy: 0.3750 - val_loss: 1.2212 - val_accuracy: 0.2143\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7641 - accuracy: 0.3214 - val_loss: 1.2223 - val_accuracy: 0.2143\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7619 - accuracy: 0.3214 - val_loss: 1.2236 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7549 - accuracy: 0.3571 - val_loss: 1.2251 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7509 - accuracy: 0.4107 - val_loss: 1.2264 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7591 - accuracy: 0.3571 - val_loss: 1.2279 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7505 - accuracy: 0.3214 - val_loss: 1.2294 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7571 - accuracy: 0.3036 - val_loss: 1.2306 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7464 - accuracy: 0.3571 - val_loss: 1.2320 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7421 - accuracy: 0.3571 - val_loss: 1.2336 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7452 - accuracy: 0.3571 - val_loss: 1.2353 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7379 - accuracy: 0.3393 - val_loss: 1.2372 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7375 - accuracy: 0.3750 - val_loss: 1.2395 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7440 - accuracy: 0.3929 - val_loss: 1.2416 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7314 - accuracy: 0.3571 - val_loss: 1.2438 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7253 - accuracy: 0.3929 - val_loss: 1.2462 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.7240 - accuracy: 0.3750 - val_loss: 1.2481 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.7216 - accuracy: 0.3571 - val_loss: 1.2497 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7204 - accuracy: 0.3929 - val_loss: 1.2510 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7258 - accuracy: 0.3750 - val_loss: 1.2521 - val_accuracy: 0.0714\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7247 - accuracy: 0.3571 - val_loss: 1.2528 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7117 - accuracy: 0.3929 - val_loss: 1.2539 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7113 - accuracy: 0.3750 - val_loss: 1.2546 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7093 - accuracy: 0.3571 - val_loss: 1.2558 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7172 - accuracy: 0.4107 - val_loss: 1.2574 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6946 - accuracy: 0.3750 - val_loss: 1.2594 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7161 - accuracy: 0.3750 - val_loss: 1.2620 - val_accuracy: 0.0714\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7018 - accuracy: 0.3571 - val_loss: 1.2649 - val_accuracy: 0.0714\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7055 - accuracy: 0.3929 - val_loss: 1.2683 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7022 - accuracy: 0.3393 - val_loss: 1.2713 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6928 - accuracy: 0.3571 - val_loss: 1.2744 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6937 - accuracy: 0.3750 - val_loss: 1.2774 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7081 - accuracy: 0.3393 - val_loss: 1.2810 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6842 - accuracy: 0.3571 - val_loss: 1.2839 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6866 - accuracy: 0.3571 - val_loss: 1.2868 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6855 - accuracy: 0.3929 - val_loss: 1.2895 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6762 - accuracy: 0.3393 - val_loss: 1.2921 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6788 - accuracy: 0.3750 - val_loss: 1.2949 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6886 - accuracy: 0.3750 - val_loss: 1.2976 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6836 - accuracy: 0.3929 - val_loss: 1.3002 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6674 - accuracy: 0.3750 - val_loss: 1.3032 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6738 - accuracy: 0.3929 - val_loss: 1.3063 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6734 - accuracy: 0.3750 - val_loss: 1.3091 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6653 - accuracy: 0.4107 - val_loss: 1.3119 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6637 - accuracy: 0.4464 - val_loss: 1.3152 - val_accuracy: 0.0714\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6497 - accuracy: 0.4643 - val_loss: 1.3188 - val_accuracy: 0.0714\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6553 - accuracy: 0.3750 - val_loss: 1.3225 - val_accuracy: 0.0714\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6558 - accuracy: 0.4286 - val_loss: 1.3268 - val_accuracy: 0.0714\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6579 - accuracy: 0.4643 - val_loss: 1.3305 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6449 - accuracy: 0.4464 - val_loss: 1.3350 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6490 - accuracy: 0.3571 - val_loss: 1.3393 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6517 - accuracy: 0.3929 - val_loss: 1.3432 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6391 - accuracy: 0.4107 - val_loss: 1.3475 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6361 - accuracy: 0.3929 - val_loss: 1.3517 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6436 - accuracy: 0.4107 - val_loss: 1.3556 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6380 - accuracy: 0.4107 - val_loss: 1.3597 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6349 - accuracy: 0.4464 - val_loss: 1.3643 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6341 - accuracy: 0.4464 - val_loss: 1.3684 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6243 - accuracy: 0.4286 - val_loss: 1.3721 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6260 - accuracy: 0.3929 - val_loss: 1.3757 - val_accuracy: 0.1429\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6417 - accuracy: 0.4107 - val_loss: 1.3787 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6153 - accuracy: 0.3571 - val_loss: 1.3823 - val_accuracy: 0.1429\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6256 - accuracy: 0.3929 - val_loss: 1.3852 - val_accuracy: 0.1429\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6223 - accuracy: 0.4821 - val_loss: 1.3882 - val_accuracy: 0.1429\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.6175 - accuracy: 0.4107 - val_loss: 1.3906 - val_accuracy: 0.1429\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6098 - accuracy: 0.4464 - val_loss: 1.3932 - val_accuracy: 0.1429\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5801 - accuracy: 0.4821 - val_loss: 1.3964 - val_accuracy: 0.1429\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6098 - accuracy: 0.4464 - val_loss: 1.3992 - val_accuracy: 0.1429\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6058 - accuracy: 0.4821 - val_loss: 1.4019 - val_accuracy: 0.1429\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5935 - accuracy: 0.3750 - val_loss: 1.4041 - val_accuracy: 0.1429\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5866 - accuracy: 0.3750 - val_loss: 1.4069 - val_accuracy: 0.1429\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6029 - accuracy: 0.5000 - val_loss: 1.4101 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.5896 - accuracy: 0.4286 - val_loss: 1.4137 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5910 - accuracy: 0.4107 - val_loss: 1.4179 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5882 - accuracy: 0.4464 - val_loss: 1.4227 - val_accuracy: 0.1429\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5945 - accuracy: 0.3571 - val_loss: 1.4278 - val_accuracy: 0.1429\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5632 - accuracy: 0.3929 - val_loss: 1.4318 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5937 - accuracy: 0.4286 - val_loss: 1.4361 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5635 - accuracy: 0.4107 - val_loss: 1.4398 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5711 - accuracy: 0.3750 - val_loss: 1.4431 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5721 - accuracy: 0.3929 - val_loss: 1.4454 - val_accuracy: 0.0714\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5849 - accuracy: 0.3929 - val_loss: 1.4483 - val_accuracy: 0.0714\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5786 - accuracy: 0.4286 - val_loss: 1.4503 - val_accuracy: 0.0714\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5783 - accuracy: 0.4107 - val_loss: 1.4533 - val_accuracy: 0.0714\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5605 - accuracy: 0.4107 - val_loss: 1.4562 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.5729 - accuracy: 0.3929 - val_loss: 1.4579 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.5699 - accuracy: 0.3929 - val_loss: 1.4583 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5803 - accuracy: 0.4107 - val_loss: 1.4590 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5769 - accuracy: 0.3393 - val_loss: 1.4598 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5558 - accuracy: 0.4464 - val_loss: 1.4609 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5492 - accuracy: 0.4286 - val_loss: 1.4622 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.5577 - accuracy: 0.4286 - val_loss: 1.4638 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5592 - accuracy: 0.4643 - val_loss: 1.4651 - val_accuracy: 0.1429\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5527 - accuracy: 0.4821 - val_loss: 1.4673 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5362 - accuracy: 0.3929 - val_loss: 1.4713 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5517 - accuracy: 0.3929 - val_loss: 1.4759 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5495 - accuracy: 0.3750 - val_loss: 1.4797 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5446 - accuracy: 0.4107 - val_loss: 1.4837 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5204 - accuracy: 0.4107 - val_loss: 1.4863 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5607 - accuracy: 0.3393 - val_loss: 1.4893 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.5383 - accuracy: 0.4107 - val_loss: 1.4908 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5497 - accuracy: 0.3571 - val_loss: 1.4925 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5365 - accuracy: 0.4107 - val_loss: 1.4929 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.5362 - accuracy: 0.4107 - val_loss: 1.4925 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5443 - accuracy: 0.4643 - val_loss: 1.4931 - val_accuracy: 0.0714\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5383 - accuracy: 0.4286 - val_loss: 1.4918 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5109 - accuracy: 0.4107 - val_loss: 1.4899 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5425 - accuracy: 0.4464 - val_loss: 1.4886 - val_accuracy: 0.0714\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.5122 - accuracy: 0.4286 - val_loss: 1.4869 - val_accuracy: 0.0714\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5265 - accuracy: 0.4107 - val_loss: 1.4854 - val_accuracy: 0.0714\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.5134 - accuracy: 0.4286 - val_loss: 1.4846 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5284 - accuracy: 0.3571 - val_loss: 1.4840 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5180 - accuracy: 0.4286 - val_loss: 1.4843 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5225 - accuracy: 0.4643 - val_loss: 1.4855 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5130 - accuracy: 0.4286 - val_loss: 1.4877 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5265 - accuracy: 0.3929 - val_loss: 1.4890 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5091 - accuracy: 0.4821 - val_loss: 1.4906 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5286 - accuracy: 0.4107 - val_loss: 1.4916 - val_accuracy: 0.0714\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5105 - accuracy: 0.5000 - val_loss: 1.4917 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4888 - accuracy: 0.4107 - val_loss: 1.4912 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5118 - accuracy: 0.3929 - val_loss: 1.4906 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5170 - accuracy: 0.4643 - val_loss: 1.4909 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5120 - accuracy: 0.4107 - val_loss: 1.4911 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4894 - accuracy: 0.4643 - val_loss: 1.4905 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4924 - accuracy: 0.4821 - val_loss: 1.4909 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4815 - accuracy: 0.4464 - val_loss: 1.4917 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4680 - accuracy: 0.4821 - val_loss: 1.4948 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4994 - accuracy: 0.4286 - val_loss: 1.4978 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5009 - accuracy: 0.4107 - val_loss: 1.5017 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4825 - accuracy: 0.4821 - val_loss: 1.5054 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4950 - accuracy: 0.4286 - val_loss: 1.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4980 - accuracy: 0.3929 - val_loss: 1.5088 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4819 - accuracy: 0.3393 - val_loss: 1.5097 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4627 - accuracy: 0.4286 - val_loss: 1.5093 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4539 - accuracy: 0.4286 - val_loss: 1.5082 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4617 - accuracy: 0.4643 - val_loss: 1.5065 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4650 - accuracy: 0.4107 - val_loss: 1.5050 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4838 - accuracy: 0.4464 - val_loss: 1.5044 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4487 - accuracy: 0.4464 - val_loss: 1.5019 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4664 - accuracy: 0.4643 - val_loss: 1.4981 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4489 - accuracy: 0.4286 - val_loss: 1.4946 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4502 - accuracy: 0.4821 - val_loss: 1.4942 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4588 - accuracy: 0.4643 - val_loss: 1.4956 - val_accuracy: 0.0714\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4587 - accuracy: 0.4286 - val_loss: 1.4971 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4468 - accuracy: 0.4464 - val_loss: 1.4988 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4429 - accuracy: 0.4464 - val_loss: 1.5019 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4666 - accuracy: 0.4107 - val_loss: 1.5035 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4483 - accuracy: 0.4821 - val_loss: 1.5055 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4319 - accuracy: 0.4643 - val_loss: 1.5070 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4482 - accuracy: 0.4821 - val_loss: 1.5085 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4181 - accuracy: 0.4464 - val_loss: 1.5102 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4532 - accuracy: 0.4286 - val_loss: 1.5065 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5065 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=240, batch_size=400, Scores: [1.506515622138977, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.506515622138977\n",
      "Epoch 1/240\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9833 - accuracy: 0.1429 - val_loss: 1.0687 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9823 - accuracy: 0.1786 - val_loss: 1.0692 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.9784 - accuracy: 0.2143 - val_loss: 1.0697 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9757 - accuracy: 0.2857 - val_loss: 1.0703 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9743 - accuracy: 0.1786 - val_loss: 1.0709 - val_accuracy: 0.1429\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9772 - accuracy: 0.1786 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9741 - accuracy: 0.2679 - val_loss: 1.0721 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9705 - accuracy: 0.2679 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 0.9656 - accuracy: 0.3036 - val_loss: 1.0733 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9682 - accuracy: 0.2143 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.9645 - accuracy: 0.1607 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9606 - accuracy: 0.3214 - val_loss: 1.0752 - val_accuracy: 0.0714\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9596 - accuracy: 0.3036 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9560 - accuracy: 0.3393 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9571 - accuracy: 0.2321 - val_loss: 1.0773 - val_accuracy: 0.0714\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9550 - accuracy: 0.2857 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9537 - accuracy: 0.3393 - val_loss: 1.0788 - val_accuracy: 0.0714\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9504 - accuracy: 0.2857 - val_loss: 1.0796 - val_accuracy: 0.0714\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.9462 - accuracy: 0.3214 - val_loss: 1.0803 - val_accuracy: 0.0714\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9479 - accuracy: 0.3214 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9440 - accuracy: 0.2679 - val_loss: 1.0819 - val_accuracy: 0.0714\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9421 - accuracy: 0.3393 - val_loss: 1.0828 - val_accuracy: 0.0714\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9420 - accuracy: 0.3393 - val_loss: 1.0837 - val_accuracy: 0.0714\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9389 - accuracy: 0.2679 - val_loss: 1.0846 - val_accuracy: 0.0714\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.9346 - accuracy: 0.2679 - val_loss: 1.0855 - val_accuracy: 0.0714\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9339 - accuracy: 0.2857 - val_loss: 1.0864 - val_accuracy: 0.0714\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9279 - accuracy: 0.3393 - val_loss: 1.0874 - val_accuracy: 0.0714\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.9297 - accuracy: 0.2857 - val_loss: 1.0883 - val_accuracy: 0.0714\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9235 - accuracy: 0.3393 - val_loss: 1.0893 - val_accuracy: 0.0714\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9171 - accuracy: 0.3571 - val_loss: 1.0904 - val_accuracy: 0.0714\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9197 - accuracy: 0.2857 - val_loss: 1.0915 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9213 - accuracy: 0.3571 - val_loss: 1.0926 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9164 - accuracy: 0.3393 - val_loss: 1.0938 - val_accuracy: 0.0714\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9159 - accuracy: 0.2857 - val_loss: 1.0950 - val_accuracy: 0.0714\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9115 - accuracy: 0.3036 - val_loss: 1.0963 - val_accuracy: 0.0714\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9080 - accuracy: 0.3036 - val_loss: 1.0976 - val_accuracy: 0.0714\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9029 - accuracy: 0.3036 - val_loss: 1.0990 - val_accuracy: 0.0714\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8954 - accuracy: 0.3571 - val_loss: 1.1003 - val_accuracy: 0.0714\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8988 - accuracy: 0.3393 - val_loss: 1.1018 - val_accuracy: 0.0714\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.8950 - accuracy: 0.3393 - val_loss: 1.1033 - val_accuracy: 0.0714\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8859 - accuracy: 0.3036 - val_loss: 1.1048 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8853 - accuracy: 0.3214 - val_loss: 1.1065 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8868 - accuracy: 0.3750 - val_loss: 1.1082 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8840 - accuracy: 0.3929 - val_loss: 1.1099 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8778 - accuracy: 0.3214 - val_loss: 1.1117 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.8743 - accuracy: 0.3214 - val_loss: 1.1135 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8733 - accuracy: 0.3393 - val_loss: 1.1153 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8670 - accuracy: 0.3393 - val_loss: 1.1172 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8656 - accuracy: 0.3214 - val_loss: 1.1190 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8581 - accuracy: 0.3571 - val_loss: 1.1209 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8536 - accuracy: 0.3214 - val_loss: 1.1227 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8629 - accuracy: 0.3214 - val_loss: 1.1247 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8468 - accuracy: 0.2857 - val_loss: 1.1266 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8482 - accuracy: 0.3571 - val_loss: 1.1286 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.8380 - accuracy: 0.3214 - val_loss: 1.1305 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8409 - accuracy: 0.2857 - val_loss: 1.1324 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8427 - accuracy: 0.3750 - val_loss: 1.1343 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.8269 - accuracy: 0.3036 - val_loss: 1.1363 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8293 - accuracy: 0.3393 - val_loss: 1.1382 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8293 - accuracy: 0.3036 - val_loss: 1.1401 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8248 - accuracy: 0.3036 - val_loss: 1.1419 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.8197 - accuracy: 0.3214 - val_loss: 1.1439 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8150 - accuracy: 0.3214 - val_loss: 1.1461 - val_accuracy: 0.1429\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8151 - accuracy: 0.3036 - val_loss: 1.1484 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8141 - accuracy: 0.3214 - val_loss: 1.1506 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8083 - accuracy: 0.3393 - val_loss: 1.1531 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7984 - accuracy: 0.2857 - val_loss: 1.1558 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8056 - accuracy: 0.3393 - val_loss: 1.1586 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8006 - accuracy: 0.3214 - val_loss: 1.1615 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7991 - accuracy: 0.2679 - val_loss: 1.1645 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7967 - accuracy: 0.3214 - val_loss: 1.1675 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7897 - accuracy: 0.3036 - val_loss: 1.1706 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7889 - accuracy: 0.3214 - val_loss: 1.1738 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7844 - accuracy: 0.3393 - val_loss: 1.1768 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7869 - accuracy: 0.2857 - val_loss: 1.1798 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7811 - accuracy: 0.3571 - val_loss: 1.1830 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7879 - accuracy: 0.3214 - val_loss: 1.1861 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7701 - accuracy: 0.3571 - val_loss: 1.1892 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.7775 - accuracy: 0.3571 - val_loss: 1.1923 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7777 - accuracy: 0.3571 - val_loss: 1.1952 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7751 - accuracy: 0.3571 - val_loss: 1.1982 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7683 - accuracy: 0.3750 - val_loss: 1.2012 - val_accuracy: 0.1429\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7718 - accuracy: 0.3571 - val_loss: 1.2040 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7660 - accuracy: 0.3036 - val_loss: 1.2068 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7672 - accuracy: 0.3393 - val_loss: 1.2097 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7648 - accuracy: 0.3393 - val_loss: 1.2123 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7645 - accuracy: 0.3214 - val_loss: 1.2150 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7628 - accuracy: 0.3571 - val_loss: 1.2176 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7593 - accuracy: 0.3393 - val_loss: 1.2201 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.7641 - accuracy: 0.3571 - val_loss: 1.2220 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7545 - accuracy: 0.3036 - val_loss: 1.2239 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7450 - accuracy: 0.3571 - val_loss: 1.2255 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7585 - accuracy: 0.3214 - val_loss: 1.2269 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.7404 - accuracy: 0.3750 - val_loss: 1.2279 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7474 - accuracy: 0.3214 - val_loss: 1.2291 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7362 - accuracy: 0.3393 - val_loss: 1.2301 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7332 - accuracy: 0.3929 - val_loss: 1.2309 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7399 - accuracy: 0.3036 - val_loss: 1.2318 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7387 - accuracy: 0.3393 - val_loss: 1.2327 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7308 - accuracy: 0.3571 - val_loss: 1.2335 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7281 - accuracy: 0.3571 - val_loss: 1.2343 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7310 - accuracy: 0.3750 - val_loss: 1.2351 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7325 - accuracy: 0.3929 - val_loss: 1.2362 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7271 - accuracy: 0.3393 - val_loss: 1.2375 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7190 - accuracy: 0.3750 - val_loss: 1.2388 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7140 - accuracy: 0.3929 - val_loss: 1.2404 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7343 - accuracy: 0.3393 - val_loss: 1.2421 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7217 - accuracy: 0.3036 - val_loss: 1.2439 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.7125 - accuracy: 0.3214 - val_loss: 1.2456 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7243 - accuracy: 0.3750 - val_loss: 1.2475 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7075 - accuracy: 0.3571 - val_loss: 1.2495 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.7166 - accuracy: 0.3036 - val_loss: 1.2513 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7087 - accuracy: 0.4107 - val_loss: 1.2531 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6960 - accuracy: 0.3929 - val_loss: 1.2546 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.7077 - accuracy: 0.3036 - val_loss: 1.2562 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6937 - accuracy: 0.3214 - val_loss: 1.2577 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6944 - accuracy: 0.3571 - val_loss: 1.2594 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6977 - accuracy: 0.3393 - val_loss: 1.2612 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.6877 - accuracy: 0.3393 - val_loss: 1.2637 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7032 - accuracy: 0.3393 - val_loss: 1.2662 - val_accuracy: 0.1429\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6862 - accuracy: 0.3571 - val_loss: 1.2689 - val_accuracy: 0.1429\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6809 - accuracy: 0.3571 - val_loss: 1.2719 - val_accuracy: 0.1429\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6996 - accuracy: 0.3214 - val_loss: 1.2747 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6888 - accuracy: 0.3571 - val_loss: 1.2775 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6833 - accuracy: 0.3393 - val_loss: 1.2803 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6831 - accuracy: 0.3750 - val_loss: 1.2836 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6870 - accuracy: 0.3393 - val_loss: 1.2874 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6828 - accuracy: 0.3214 - val_loss: 1.2909 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6760 - accuracy: 0.3750 - val_loss: 1.2951 - val_accuracy: 0.1429\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6648 - accuracy: 0.3750 - val_loss: 1.2984 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.6660 - accuracy: 0.4107 - val_loss: 1.3019 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6629 - accuracy: 0.2857 - val_loss: 1.3058 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6674 - accuracy: 0.3036 - val_loss: 1.3095 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6499 - accuracy: 0.3393 - val_loss: 1.3132 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6428 - accuracy: 0.3929 - val_loss: 1.3166 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6616 - accuracy: 0.3571 - val_loss: 1.3199 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6625 - accuracy: 0.3036 - val_loss: 1.3237 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6482 - accuracy: 0.3929 - val_loss: 1.3271 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6553 - accuracy: 0.3750 - val_loss: 1.3308 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6540 - accuracy: 0.3750 - val_loss: 1.3348 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6471 - accuracy: 0.3750 - val_loss: 1.3383 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.6424 - accuracy: 0.3929 - val_loss: 1.3415 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6517 - accuracy: 0.3393 - val_loss: 1.3449 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6286 - accuracy: 0.3393 - val_loss: 1.3482 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6293 - accuracy: 0.3036 - val_loss: 1.3513 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6206 - accuracy: 0.4107 - val_loss: 1.3546 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6455 - accuracy: 0.4107 - val_loss: 1.3574 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6347 - accuracy: 0.4107 - val_loss: 1.3594 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6354 - accuracy: 0.3929 - val_loss: 1.3616 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6148 - accuracy: 0.4286 - val_loss: 1.3642 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6247 - accuracy: 0.3929 - val_loss: 1.3676 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6393 - accuracy: 0.4286 - val_loss: 1.3708 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6150 - accuracy: 0.4821 - val_loss: 1.3740 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6124 - accuracy: 0.3929 - val_loss: 1.3780 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6083 - accuracy: 0.4286 - val_loss: 1.3821 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6177 - accuracy: 0.3750 - val_loss: 1.3863 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6071 - accuracy: 0.3571 - val_loss: 1.3910 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6116 - accuracy: 0.3750 - val_loss: 1.3949 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5945 - accuracy: 0.4286 - val_loss: 1.3987 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5889 - accuracy: 0.4107 - val_loss: 1.4024 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5992 - accuracy: 0.3929 - val_loss: 1.4049 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5987 - accuracy: 0.4643 - val_loss: 1.4071 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5925 - accuracy: 0.3929 - val_loss: 1.4091 - val_accuracy: 0.1429\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5830 - accuracy: 0.3393 - val_loss: 1.4118 - val_accuracy: 0.1429\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6077 - accuracy: 0.3929 - val_loss: 1.4144 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6023 - accuracy: 0.4286 - val_loss: 1.4170 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5861 - accuracy: 0.4286 - val_loss: 1.4194 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5854 - accuracy: 0.4107 - val_loss: 1.4212 - val_accuracy: 0.1429\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5805 - accuracy: 0.4107 - val_loss: 1.4222 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5845 - accuracy: 0.3929 - val_loss: 1.4241 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6082 - accuracy: 0.3929 - val_loss: 1.4253 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5697 - accuracy: 0.3750 - val_loss: 1.4266 - val_accuracy: 0.1429\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5667 - accuracy: 0.4107 - val_loss: 1.4279 - val_accuracy: 0.1429\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5773 - accuracy: 0.4286 - val_loss: 1.4296 - val_accuracy: 0.1429\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5693 - accuracy: 0.3929 - val_loss: 1.4308 - val_accuracy: 0.1429\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5606 - accuracy: 0.4464 - val_loss: 1.4332 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5590 - accuracy: 0.3750 - val_loss: 1.4362 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5721 - accuracy: 0.4107 - val_loss: 1.4399 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.5516 - accuracy: 0.4286 - val_loss: 1.4434 - val_accuracy: 0.1429\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5542 - accuracy: 0.4643 - val_loss: 1.4465 - val_accuracy: 0.1429\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5517 - accuracy: 0.3571 - val_loss: 1.4497 - val_accuracy: 0.1429\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.5490 - accuracy: 0.4107 - val_loss: 1.4531 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5341 - accuracy: 0.4464 - val_loss: 1.4574 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5576 - accuracy: 0.4464 - val_loss: 1.4618 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5677 - accuracy: 0.3571 - val_loss: 1.4650 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5416 - accuracy: 0.3929 - val_loss: 1.4678 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5361 - accuracy: 0.4286 - val_loss: 1.4699 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5524 - accuracy: 0.4107 - val_loss: 1.4719 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5379 - accuracy: 0.3929 - val_loss: 1.4740 - val_accuracy: 0.1429\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5352 - accuracy: 0.4107 - val_loss: 1.4757 - val_accuracy: 0.1429\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5290 - accuracy: 0.3571 - val_loss: 1.4764 - val_accuracy: 0.1429\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5366 - accuracy: 0.3929 - val_loss: 1.4762 - val_accuracy: 0.1429\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5290 - accuracy: 0.4107 - val_loss: 1.4754 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.5298 - accuracy: 0.4107 - val_loss: 1.4755 - val_accuracy: 0.1429\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5154 - accuracy: 0.4107 - val_loss: 1.4751 - val_accuracy: 0.1429\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5407 - accuracy: 0.4464 - val_loss: 1.4745 - val_accuracy: 0.1429\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5181 - accuracy: 0.4464 - val_loss: 1.4744 - val_accuracy: 0.1429\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5059 - accuracy: 0.4464 - val_loss: 1.4744 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5054 - accuracy: 0.4464 - val_loss: 1.4752 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5093 - accuracy: 0.3929 - val_loss: 1.4752 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4968 - accuracy: 0.4286 - val_loss: 1.4764 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4899 - accuracy: 0.4107 - val_loss: 1.4783 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5121 - accuracy: 0.4286 - val_loss: 1.4815 - val_accuracy: 0.1429\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4886 - accuracy: 0.4821 - val_loss: 1.4851 - val_accuracy: 0.1429\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4774 - accuracy: 0.3929 - val_loss: 1.4888 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4827 - accuracy: 0.4286 - val_loss: 1.4921 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4960 - accuracy: 0.4107 - val_loss: 1.4961 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4719 - accuracy: 0.3929 - val_loss: 1.5018 - val_accuracy: 0.1429\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4759 - accuracy: 0.4464 - val_loss: 1.5081 - val_accuracy: 0.1429\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4745 - accuracy: 0.4464 - val_loss: 1.5135 - val_accuracy: 0.1429\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4763 - accuracy: 0.4286 - val_loss: 1.5171 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4724 - accuracy: 0.4464 - val_loss: 1.5184 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4661 - accuracy: 0.4464 - val_loss: 1.5203 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4487 - accuracy: 0.4464 - val_loss: 1.5213 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4777 - accuracy: 0.4464 - val_loss: 1.5227 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4616 - accuracy: 0.4286 - val_loss: 1.5235 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4615 - accuracy: 0.4464 - val_loss: 1.5237 - val_accuracy: 0.1429\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4404 - accuracy: 0.4464 - val_loss: 1.5236 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4545 - accuracy: 0.4286 - val_loss: 1.5237 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4585 - accuracy: 0.4821 - val_loss: 1.5235 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.4638 - accuracy: 0.3929 - val_loss: 1.5232 - val_accuracy: 0.1429\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4380 - accuracy: 0.4643 - val_loss: 1.5235 - val_accuracy: 0.1429\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4475 - accuracy: 0.4464 - val_loss: 1.5243 - val_accuracy: 0.1429\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4380 - accuracy: 0.4643 - val_loss: 1.5242 - val_accuracy: 0.1429\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4585 - accuracy: 0.4286 - val_loss: 1.5241 - val_accuracy: 0.1429\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4129 - accuracy: 0.4643 - val_loss: 1.5250 - val_accuracy: 0.1429\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4240 - accuracy: 0.4107 - val_loss: 1.5263 - val_accuracy: 0.1429\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4131 - accuracy: 0.4643 - val_loss: 1.5270 - val_accuracy: 0.1429\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4326 - accuracy: 0.4821 - val_loss: 1.5279 - val_accuracy: 0.1429\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4267 - accuracy: 0.4821 - val_loss: 1.5290 - val_accuracy: 0.1429\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4122 - accuracy: 0.4643 - val_loss: 1.5306 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4140 - accuracy: 0.4107 - val_loss: 1.5326 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4050 - accuracy: 0.4286 - val_loss: 1.5368 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3905 - accuracy: 0.4821 - val_loss: 1.5407 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4212 - accuracy: 0.4821 - val_loss: 1.5443 - val_accuracy: 0.1429\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4216 - accuracy: 0.4643 - val_loss: 1.5486 - val_accuracy: 0.1429\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3809 - accuracy: 0.4643 - val_loss: 1.5531 - val_accuracy: 0.1429\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4196 - accuracy: 0.4643 - val_loss: 1.5601 - val_accuracy: 0.1429\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4042 - accuracy: 0.4821 - val_loss: 1.5673 - val_accuracy: 0.1429\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4124 - accuracy: 0.4464 - val_loss: 1.5697 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5697 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=120, wl= 7, epoch=240, batch_size=500, Scores: [1.5697296857833862, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.5697296857833862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9857 - accuracy: 0.0714 - val_loss: 1.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9805 - accuracy: 0.1786 - val_loss: 1.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9791 - accuracy: 0.2321 - val_loss: 1.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9726 - accuracy: 0.2857 - val_loss: 1.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9694 - accuracy: 0.2143 - val_loss: 1.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9673 - accuracy: 0.2321 - val_loss: 1.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9629 - accuracy: 0.3393 - val_loss: 1.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9608 - accuracy: 0.3036 - val_loss: 1.0733 - val_accuracy: 0.0714\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.9541 - accuracy: 0.3214 - val_loss: 1.0739 - val_accuracy: 0.0714\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.9489 - accuracy: 0.3214 - val_loss: 1.0746 - val_accuracy: 0.0714\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9493 - accuracy: 0.3750 - val_loss: 1.0752 - val_accuracy: 0.0714\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.9426 - accuracy: 0.3393 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9397 - accuracy: 0.3929 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9350 - accuracy: 0.3393 - val_loss: 1.0774 - val_accuracy: 0.0714\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9301 - accuracy: 0.3571 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9248 - accuracy: 0.3929 - val_loss: 1.0790 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9190 - accuracy: 0.3393 - val_loss: 1.0798 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.9127 - accuracy: 0.3393 - val_loss: 1.0807 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.9122 - accuracy: 0.3393 - val_loss: 1.0817 - val_accuracy: 0.0714\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9055 - accuracy: 0.3929 - val_loss: 1.0827 - val_accuracy: 0.0714\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8981 - accuracy: 0.3393 - val_loss: 1.0838 - val_accuracy: 0.0714\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8957 - accuracy: 0.3036 - val_loss: 1.0852 - val_accuracy: 0.0714\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8886 - accuracy: 0.3393 - val_loss: 1.0868 - val_accuracy: 0.0714\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8801 - accuracy: 0.3214 - val_loss: 1.0886 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8809 - accuracy: 0.3036 - val_loss: 1.0907 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8727 - accuracy: 0.3750 - val_loss: 1.0931 - val_accuracy: 0.0714\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8653 - accuracy: 0.3036 - val_loss: 1.0957 - val_accuracy: 0.0714\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8646 - accuracy: 0.3393 - val_loss: 1.0987 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8561 - accuracy: 0.3214 - val_loss: 1.1021 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8562 - accuracy: 0.3214 - val_loss: 1.1060 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8469 - accuracy: 0.3036 - val_loss: 1.1101 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8415 - accuracy: 0.2857 - val_loss: 1.1146 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1146 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=32, batch_size=100, Scores: [1.114614486694336, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.114614486694336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9848 - accuracy: 0.1607 - val_loss: 1.0699 - val_accuracy: 0.0714\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9798 - accuracy: 0.2500 - val_loss: 1.0707 - val_accuracy: 0.0714\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9776 - accuracy: 0.2500 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9719 - accuracy: 0.2857 - val_loss: 1.0724 - val_accuracy: 0.1429\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9695 - accuracy: 0.3036 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9647 - accuracy: 0.3571 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9594 - accuracy: 0.3214 - val_loss: 1.0751 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9564 - accuracy: 0.3036 - val_loss: 1.0761 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9515 - accuracy: 0.3393 - val_loss: 1.0771 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9497 - accuracy: 0.2500 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9450 - accuracy: 0.3036 - val_loss: 1.0792 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9398 - accuracy: 0.3929 - val_loss: 1.0804 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9389 - accuracy: 0.3571 - val_loss: 1.0816 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9304 - accuracy: 0.3750 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9274 - accuracy: 0.3571 - val_loss: 1.0842 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9226 - accuracy: 0.3214 - val_loss: 1.0857 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.9202 - accuracy: 0.3214 - val_loss: 1.0874 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9188 - accuracy: 0.3571 - val_loss: 1.0892 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9065 - accuracy: 0.4107 - val_loss: 1.0913 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9063 - accuracy: 0.3036 - val_loss: 1.0935 - val_accuracy: 0.1429\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8971 - accuracy: 0.3036 - val_loss: 1.0959 - val_accuracy: 0.1429\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.8885 - accuracy: 0.3393 - val_loss: 1.0986 - val_accuracy: 0.1429\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8914 - accuracy: 0.3571 - val_loss: 1.1016 - val_accuracy: 0.1429\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8832 - accuracy: 0.2857 - val_loss: 1.1048 - val_accuracy: 0.0714\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8769 - accuracy: 0.3214 - val_loss: 1.1082 - val_accuracy: 0.0714\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8741 - accuracy: 0.3393 - val_loss: 1.1117 - val_accuracy: 0.0714\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8693 - accuracy: 0.3393 - val_loss: 1.1152 - val_accuracy: 0.0714\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8638 - accuracy: 0.3571 - val_loss: 1.1188 - val_accuracy: 0.0714\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8651 - accuracy: 0.3393 - val_loss: 1.1224 - val_accuracy: 0.0714\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8554 - accuracy: 0.3571 - val_loss: 1.1260 - val_accuracy: 0.0714\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8487 - accuracy: 0.3571 - val_loss: 1.1298 - val_accuracy: 0.0714\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8464 - accuracy: 0.3750 - val_loss: 1.1336 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1336 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=32, batch_size=300, Scores: [1.1335852146148682, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.1335852146148682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9846 - accuracy: 0.0357 - val_loss: 1.0653 - val_accuracy: 0.2143\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9804 - accuracy: 0.2143 - val_loss: 1.0658 - val_accuracy: 0.1429\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9767 - accuracy: 0.0714 - val_loss: 1.0663 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9735 - accuracy: 0.2143 - val_loss: 1.0669 - val_accuracy: 0.1429\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9685 - accuracy: 0.1607 - val_loss: 1.0676 - val_accuracy: 0.1429\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9647 - accuracy: 0.3393 - val_loss: 1.0683 - val_accuracy: 0.1429\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9636 - accuracy: 0.2679 - val_loss: 1.0690 - val_accuracy: 0.1429\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9574 - accuracy: 0.2500 - val_loss: 1.0697 - val_accuracy: 0.1429\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9564 - accuracy: 0.2857 - val_loss: 1.0704 - val_accuracy: 0.1429\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9489 - accuracy: 0.3036 - val_loss: 1.0712 - val_accuracy: 0.1429\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9478 - accuracy: 0.2500 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9441 - accuracy: 0.3571 - val_loss: 1.0729 - val_accuracy: 0.1429\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9387 - accuracy: 0.2500 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9324 - accuracy: 0.3036 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9287 - accuracy: 0.3036 - val_loss: 1.0757 - val_accuracy: 0.1429\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9244 - accuracy: 0.3393 - val_loss: 1.0768 - val_accuracy: 0.1429\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9178 - accuracy: 0.3214 - val_loss: 1.0779 - val_accuracy: 0.1429\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.9145 - accuracy: 0.3393 - val_loss: 1.0791 - val_accuracy: 0.1429\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9101 - accuracy: 0.2500 - val_loss: 1.0804 - val_accuracy: 0.1429\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9055 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.2143\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8996 - accuracy: 0.3036 - val_loss: 1.0834 - val_accuracy: 0.2143\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8960 - accuracy: 0.2857 - val_loss: 1.0853 - val_accuracy: 0.2143\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8886 - accuracy: 0.2857 - val_loss: 1.0873 - val_accuracy: 0.2143\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8851 - accuracy: 0.2857 - val_loss: 1.0895 - val_accuracy: 0.2143\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8817 - accuracy: 0.3036 - val_loss: 1.0919 - val_accuracy: 0.2143\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8789 - accuracy: 0.2500 - val_loss: 1.0944 - val_accuracy: 0.2143\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8683 - accuracy: 0.3571 - val_loss: 1.0972 - val_accuracy: 0.2143\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8632 - accuracy: 0.3214 - val_loss: 1.1001 - val_accuracy: 0.2143\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8628 - accuracy: 0.2857 - val_loss: 1.1031 - val_accuracy: 0.2143\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8516 - accuracy: 0.3214 - val_loss: 1.1064 - val_accuracy: 0.2143\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8449 - accuracy: 0.3393 - val_loss: 1.1098 - val_accuracy: 0.2143\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8471 - accuracy: 0.2857 - val_loss: 1.1134 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1134 - accuracy: 0.2143\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=32, batch_size=400, Scores: [1.113387942314148, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.113387942314148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9861 - accuracy: 0.0893 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 2/32\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9807 - accuracy: 0.1071 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 3/32\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9782 - accuracy: 0.0893 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 4/32\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9730 - accuracy: 0.1964 - val_loss: 1.0747 - val_accuracy: 0.2143\n",
      "Epoch 5/32\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9711 - accuracy: 0.1607 - val_loss: 1.0751 - val_accuracy: 0.2143\n",
      "Epoch 6/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9656 - accuracy: 0.2143 - val_loss: 1.0756 - val_accuracy: 0.2143\n",
      "Epoch 7/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9652 - accuracy: 0.1964 - val_loss: 1.0761 - val_accuracy: 0.2143\n",
      "Epoch 8/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9596 - accuracy: 0.3036 - val_loss: 1.0767 - val_accuracy: 0.2143\n",
      "Epoch 9/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9540 - accuracy: 0.3036 - val_loss: 1.0773 - val_accuracy: 0.2143\n",
      "Epoch 10/32\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9515 - accuracy: 0.2321 - val_loss: 1.0779 - val_accuracy: 0.2143\n",
      "Epoch 11/32\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9474 - accuracy: 0.2143 - val_loss: 1.0786 - val_accuracy: 0.2143\n",
      "Epoch 12/32\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9417 - accuracy: 0.2500 - val_loss: 1.0793 - val_accuracy: 0.2143\n",
      "Epoch 13/32\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9394 - accuracy: 0.2857 - val_loss: 1.0800 - val_accuracy: 0.2143\n",
      "Epoch 14/32\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9352 - accuracy: 0.2679 - val_loss: 1.0809 - val_accuracy: 0.2143\n",
      "Epoch 15/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9333 - accuracy: 0.2857 - val_loss: 1.0817 - val_accuracy: 0.2143\n",
      "Epoch 16/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9289 - accuracy: 0.2679 - val_loss: 1.0827 - val_accuracy: 0.2143\n",
      "Epoch 17/32\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9216 - accuracy: 0.2500 - val_loss: 1.0837 - val_accuracy: 0.2143\n",
      "Epoch 18/32\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9177 - accuracy: 0.2857 - val_loss: 1.0848 - val_accuracy: 0.2143\n",
      "Epoch 19/32\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9105 - accuracy: 0.2500 - val_loss: 1.0860 - val_accuracy: 0.2143\n",
      "Epoch 20/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9081 - accuracy: 0.2679 - val_loss: 1.0874 - val_accuracy: 0.2143\n",
      "Epoch 21/32\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9003 - accuracy: 0.2857 - val_loss: 1.0888 - val_accuracy: 0.2143\n",
      "Epoch 22/32\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8991 - accuracy: 0.2857 - val_loss: 1.0905 - val_accuracy: 0.2143\n",
      "Epoch 23/32\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8926 - accuracy: 0.3036 - val_loss: 1.0923 - val_accuracy: 0.2143\n",
      "Epoch 24/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8866 - accuracy: 0.2679 - val_loss: 1.0943 - val_accuracy: 0.2143\n",
      "Epoch 25/32\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8828 - accuracy: 0.2857 - val_loss: 1.0965 - val_accuracy: 0.2143\n",
      "Epoch 26/32\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8775 - accuracy: 0.2679 - val_loss: 1.0990 - val_accuracy: 0.1429\n",
      "Epoch 27/32\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8707 - accuracy: 0.2679 - val_loss: 1.1018 - val_accuracy: 0.1429\n",
      "Epoch 28/32\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8685 - accuracy: 0.2500 - val_loss: 1.1049 - val_accuracy: 0.1429\n",
      "Epoch 29/32\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8600 - accuracy: 0.2500 - val_loss: 1.1085 - val_accuracy: 0.1429\n",
      "Epoch 30/32\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8545 - accuracy: 0.2679 - val_loss: 1.1124 - val_accuracy: 0.1429\n",
      "Epoch 31/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8495 - accuracy: 0.2857 - val_loss: 1.1167 - val_accuracy: 0.1429\n",
      "Epoch 32/32\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8530 - accuracy: 0.2321 - val_loss: 1.1211 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1211 - accuracy: 0.1429\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=32, batch_size=500, Scores: [1.1211191415786743, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.1211191415786743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9838 - accuracy: 0.1786 - val_loss: 1.0660 - val_accuracy: 0.2143\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9808 - accuracy: 0.1071 - val_loss: 1.0665 - val_accuracy: 0.2143\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9776 - accuracy: 0.2679 - val_loss: 1.0669 - val_accuracy: 0.2143\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9716 - accuracy: 0.3571 - val_loss: 1.0674 - val_accuracy: 0.2143\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9700 - accuracy: 0.3036 - val_loss: 1.0678 - val_accuracy: 0.2143\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9658 - accuracy: 0.3750 - val_loss: 1.0683 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.9637 - accuracy: 0.3571 - val_loss: 1.0688 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9593 - accuracy: 0.3393 - val_loss: 1.0692 - val_accuracy: 0.0714\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.9567 - accuracy: 0.3571 - val_loss: 1.0697 - val_accuracy: 0.0714\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9564 - accuracy: 0.2857 - val_loss: 1.0701 - val_accuracy: 0.0714\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9511 - accuracy: 0.3214 - val_loss: 1.0705 - val_accuracy: 0.0714\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9475 - accuracy: 0.3036 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9431 - accuracy: 0.2679 - val_loss: 1.0713 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9411 - accuracy: 0.3571 - val_loss: 1.0716 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9369 - accuracy: 0.3393 - val_loss: 1.0720 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.9320 - accuracy: 0.3571 - val_loss: 1.0723 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9269 - accuracy: 0.3214 - val_loss: 1.0726 - val_accuracy: 0.1429\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9214 - accuracy: 0.3036 - val_loss: 1.0729 - val_accuracy: 0.1429\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9181 - accuracy: 0.2857 - val_loss: 1.0731 - val_accuracy: 0.1429\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9132 - accuracy: 0.3036 - val_loss: 1.0734 - val_accuracy: 0.1429\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9091 - accuracy: 0.2857 - val_loss: 1.0738 - val_accuracy: 0.1429\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9039 - accuracy: 0.3214 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8961 - accuracy: 0.3214 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8941 - accuracy: 0.3036 - val_loss: 1.0754 - val_accuracy: 0.2143\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8870 - accuracy: 0.2857 - val_loss: 1.0761 - val_accuracy: 0.2143\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8817 - accuracy: 0.3036 - val_loss: 1.0771 - val_accuracy: 0.2143\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8798 - accuracy: 0.3036 - val_loss: 1.0782 - val_accuracy: 0.2143\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8736 - accuracy: 0.3393 - val_loss: 1.0796 - val_accuracy: 0.2143\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8633 - accuracy: 0.3036 - val_loss: 1.0813 - val_accuracy: 0.2143\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8563 - accuracy: 0.3036 - val_loss: 1.0834 - val_accuracy: 0.2143\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8547 - accuracy: 0.3214 - val_loss: 1.0858 - val_accuracy: 0.2143\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8518 - accuracy: 0.2857 - val_loss: 1.0886 - val_accuracy: 0.2143\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8431 - accuracy: 0.2857 - val_loss: 1.0917 - val_accuracy: 0.2143\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8386 - accuracy: 0.2857 - val_loss: 1.0952 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8317 - accuracy: 0.2857 - val_loss: 1.0992 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8239 - accuracy: 0.3214 - val_loss: 1.1037 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8279 - accuracy: 0.3393 - val_loss: 1.1086 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8162 - accuracy: 0.3214 - val_loss: 1.1139 - val_accuracy: 0.1429\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.8101 - accuracy: 0.3393 - val_loss: 1.1197 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8041 - accuracy: 0.3214 - val_loss: 1.1258 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8014 - accuracy: 0.3036 - val_loss: 1.1325 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7919 - accuracy: 0.3571 - val_loss: 1.1398 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7890 - accuracy: 0.2857 - val_loss: 1.1476 - val_accuracy: 0.0714\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7813 - accuracy: 0.2857 - val_loss: 1.1557 - val_accuracy: 0.0714\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.7871 - accuracy: 0.3750 - val_loss: 1.1641 - val_accuracy: 0.0714\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.7770 - accuracy: 0.3571 - val_loss: 1.1727 - val_accuracy: 0.0714\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7747 - accuracy: 0.3393 - val_loss: 1.1814 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7682 - accuracy: 0.3750 - val_loss: 1.1898 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7682 - accuracy: 0.3214 - val_loss: 1.1979 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7647 - accuracy: 0.3393 - val_loss: 1.2058 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7665 - accuracy: 0.3750 - val_loss: 1.2135 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7565 - accuracy: 0.3214 - val_loss: 1.2209 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7511 - accuracy: 0.3750 - val_loss: 1.2273 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.7513 - accuracy: 0.3393 - val_loss: 1.2333 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7489 - accuracy: 0.3393 - val_loss: 1.2389 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7396 - accuracy: 0.3571 - val_loss: 1.2439 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7410 - accuracy: 0.3214 - val_loss: 1.2479 - val_accuracy: 0.0714\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7439 - accuracy: 0.3571 - val_loss: 1.2511 - val_accuracy: 0.0714\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7381 - accuracy: 0.3750 - val_loss: 1.2534 - val_accuracy: 0.0714\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7366 - accuracy: 0.3393 - val_loss: 1.2549 - val_accuracy: 0.0714\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7409 - accuracy: 0.3393 - val_loss: 1.2553 - val_accuracy: 0.0714\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7205 - accuracy: 0.3571 - val_loss: 1.2553 - val_accuracy: 0.0714\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7181 - accuracy: 0.3750 - val_loss: 1.2553 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7218 - accuracy: 0.3571 - val_loss: 1.2549 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2549 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=64, batch_size=100, Scores: [1.2548567056655884, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2548567056655884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9851 - accuracy: 0.0893 - val_loss: 1.0725 - val_accuracy: 0.0714\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.9821 - accuracy: 0.1786 - val_loss: 1.0729 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9777 - accuracy: 0.1786 - val_loss: 1.0734 - val_accuracy: 0.0714\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9731 - accuracy: 0.2143 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9701 - accuracy: 0.3214 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9680 - accuracy: 0.2679 - val_loss: 1.0750 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9630 - accuracy: 0.3036 - val_loss: 1.0756 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9594 - accuracy: 0.3214 - val_loss: 1.0763 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9563 - accuracy: 0.2857 - val_loss: 1.0769 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9521 - accuracy: 0.2321 - val_loss: 1.0776 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9493 - accuracy: 0.2679 - val_loss: 1.0784 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9442 - accuracy: 0.2857 - val_loss: 1.0792 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9420 - accuracy: 0.3393 - val_loss: 1.0800 - val_accuracy: 0.1429\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9359 - accuracy: 0.2679 - val_loss: 1.0809 - val_accuracy: 0.1429\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9287 - accuracy: 0.2679 - val_loss: 1.0818 - val_accuracy: 0.1429\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.9275 - accuracy: 0.2857 - val_loss: 1.0828 - val_accuracy: 0.1429\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9257 - accuracy: 0.3036 - val_loss: 1.0838 - val_accuracy: 0.2143\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9159 - accuracy: 0.2857 - val_loss: 1.0849 - val_accuracy: 0.2143\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.9120 - accuracy: 0.3393 - val_loss: 1.0861 - val_accuracy: 0.2143\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9072 - accuracy: 0.3036 - val_loss: 1.0874 - val_accuracy: 0.2143\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9000 - accuracy: 0.3393 - val_loss: 1.0889 - val_accuracy: 0.2143\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8972 - accuracy: 0.3036 - val_loss: 1.0904 - val_accuracy: 0.2143\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8876 - accuracy: 0.3214 - val_loss: 1.0922 - val_accuracy: 0.2143\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8836 - accuracy: 0.2857 - val_loss: 1.0942 - val_accuracy: 0.2143\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8808 - accuracy: 0.2857 - val_loss: 1.0964 - val_accuracy: 0.2143\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8780 - accuracy: 0.2857 - val_loss: 1.0989 - val_accuracy: 0.2143\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8681 - accuracy: 0.2857 - val_loss: 1.1017 - val_accuracy: 0.2143\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8610 - accuracy: 0.2679 - val_loss: 1.1048 - val_accuracy: 0.2143\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8518 - accuracy: 0.3214 - val_loss: 1.1083 - val_accuracy: 0.2143\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8504 - accuracy: 0.2857 - val_loss: 1.1123 - val_accuracy: 0.2143\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8426 - accuracy: 0.2679 - val_loss: 1.1165 - val_accuracy: 0.2143\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8379 - accuracy: 0.3036 - val_loss: 1.1211 - val_accuracy: 0.2143\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8326 - accuracy: 0.2857 - val_loss: 1.1260 - val_accuracy: 0.2143\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8242 - accuracy: 0.3036 - val_loss: 1.1309 - val_accuracy: 0.2143\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8246 - accuracy: 0.2857 - val_loss: 1.1362 - val_accuracy: 0.2143\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8128 - accuracy: 0.2857 - val_loss: 1.1414 - val_accuracy: 0.2143\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8100 - accuracy: 0.3214 - val_loss: 1.1468 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8069 - accuracy: 0.3036 - val_loss: 1.1524 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8025 - accuracy: 0.2857 - val_loss: 1.1582 - val_accuracy: 0.2143\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.7946 - accuracy: 0.2857 - val_loss: 1.1642 - val_accuracy: 0.2143\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7914 - accuracy: 0.3393 - val_loss: 1.1703 - val_accuracy: 0.2143\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7911 - accuracy: 0.3214 - val_loss: 1.1764 - val_accuracy: 0.2143\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7811 - accuracy: 0.3214 - val_loss: 1.1822 - val_accuracy: 0.2143\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7807 - accuracy: 0.3393 - val_loss: 1.1879 - val_accuracy: 0.2143\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7762 - accuracy: 0.3214 - val_loss: 1.1932 - val_accuracy: 0.2143\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7759 - accuracy: 0.3571 - val_loss: 1.1984 - val_accuracy: 0.2143\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.7810 - accuracy: 0.3214 - val_loss: 1.2031 - val_accuracy: 0.2143\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7664 - accuracy: 0.3750 - val_loss: 1.2072 - val_accuracy: 0.2143\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7647 - accuracy: 0.3393 - val_loss: 1.2110 - val_accuracy: 0.2143\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7577 - accuracy: 0.3214 - val_loss: 1.2144 - val_accuracy: 0.2143\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7538 - accuracy: 0.3750 - val_loss: 1.2176 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7465 - accuracy: 0.3750 - val_loss: 1.2207 - val_accuracy: 0.1429\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7497 - accuracy: 0.3571 - val_loss: 1.2237 - val_accuracy: 0.1429\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7416 - accuracy: 0.3571 - val_loss: 1.2264 - val_accuracy: 0.1429\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7411 - accuracy: 0.3750 - val_loss: 1.2289 - val_accuracy: 0.1429\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7439 - accuracy: 0.3750 - val_loss: 1.2307 - val_accuracy: 0.1429\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7449 - accuracy: 0.3571 - val_loss: 1.2321 - val_accuracy: 0.1429\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.7424 - accuracy: 0.3750 - val_loss: 1.2332 - val_accuracy: 0.1429\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7136 - accuracy: 0.4286 - val_loss: 1.2338 - val_accuracy: 0.1429\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.7238 - accuracy: 0.3929 - val_loss: 1.2332 - val_accuracy: 0.0714\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.7233 - accuracy: 0.3750 - val_loss: 1.2331 - val_accuracy: 0.0714\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7277 - accuracy: 0.3393 - val_loss: 1.2336 - val_accuracy: 0.0714\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7070 - accuracy: 0.3929 - val_loss: 1.2339 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7141 - accuracy: 0.3750 - val_loss: 1.2348 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2348 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=64, batch_size=300, Scores: [1.234848976135254, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.234848976135254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9838 - accuracy: 0.1786 - val_loss: 1.0681 - val_accuracy: 0.1429\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.9839 - accuracy: 0.1071 - val_loss: 1.0686 - val_accuracy: 0.0714\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9777 - accuracy: 0.0714 - val_loss: 1.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9743 - accuracy: 0.1429 - val_loss: 1.0698 - val_accuracy: 0.0714\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.9706 - accuracy: 0.1964 - val_loss: 1.0704 - val_accuracy: 0.0714\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9663 - accuracy: 0.2321 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9629 - accuracy: 0.1786 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9580 - accuracy: 0.2857 - val_loss: 1.0721 - val_accuracy: 0.1429\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9528 - accuracy: 0.3214 - val_loss: 1.0726 - val_accuracy: 0.1429\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9516 - accuracy: 0.3571 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9488 - accuracy: 0.3214 - val_loss: 1.0738 - val_accuracy: 0.1429\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.9421 - accuracy: 0.3393 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9394 - accuracy: 0.3214 - val_loss: 1.0750 - val_accuracy: 0.2143\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9358 - accuracy: 0.3750 - val_loss: 1.0757 - val_accuracy: 0.2143\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9324 - accuracy: 0.3214 - val_loss: 1.0763 - val_accuracy: 0.2143\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9252 - accuracy: 0.3393 - val_loss: 1.0771 - val_accuracy: 0.2143\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.9208 - accuracy: 0.3750 - val_loss: 1.0780 - val_accuracy: 0.2143\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9206 - accuracy: 0.3750 - val_loss: 1.0789 - val_accuracy: 0.2143\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9117 - accuracy: 0.3393 - val_loss: 1.0798 - val_accuracy: 0.2143\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9096 - accuracy: 0.3571 - val_loss: 1.0809 - val_accuracy: 0.2143\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9032 - accuracy: 0.3393 - val_loss: 1.0820 - val_accuracy: 0.2143\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.8972 - accuracy: 0.3036 - val_loss: 1.0834 - val_accuracy: 0.1429\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8921 - accuracy: 0.3393 - val_loss: 1.0850 - val_accuracy: 0.1429\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8892 - accuracy: 0.3571 - val_loss: 1.0867 - val_accuracy: 0.1429\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8865 - accuracy: 0.3393 - val_loss: 1.0887 - val_accuracy: 0.1429\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8746 - accuracy: 0.3571 - val_loss: 1.0909 - val_accuracy: 0.1429\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8721 - accuracy: 0.3214 - val_loss: 1.0932 - val_accuracy: 0.1429\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8711 - accuracy: 0.3393 - val_loss: 1.0957 - val_accuracy: 0.1429\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8647 - accuracy: 0.3393 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8603 - accuracy: 0.3036 - val_loss: 1.1014 - val_accuracy: 0.0714\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8530 - accuracy: 0.3571 - val_loss: 1.1043 - val_accuracy: 0.0714\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8473 - accuracy: 0.3214 - val_loss: 1.1074 - val_accuracy: 0.0714\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8415 - accuracy: 0.3036 - val_loss: 1.1105 - val_accuracy: 0.0714\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8403 - accuracy: 0.3750 - val_loss: 1.1138 - val_accuracy: 0.0714\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8339 - accuracy: 0.3571 - val_loss: 1.1172 - val_accuracy: 0.0714\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.8304 - accuracy: 0.2857 - val_loss: 1.1210 - val_accuracy: 0.0714\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.8250 - accuracy: 0.3571 - val_loss: 1.1253 - val_accuracy: 0.0714\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.8162 - accuracy: 0.3214 - val_loss: 1.1300 - val_accuracy: 0.0714\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8139 - accuracy: 0.3036 - val_loss: 1.1354 - val_accuracy: 0.0714\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8065 - accuracy: 0.3750 - val_loss: 1.1416 - val_accuracy: 0.0714\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8009 - accuracy: 0.3393 - val_loss: 1.1487 - val_accuracy: 0.0714\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7985 - accuracy: 0.3214 - val_loss: 1.1564 - val_accuracy: 0.0714\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7951 - accuracy: 0.3750 - val_loss: 1.1648 - val_accuracy: 0.0714\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7896 - accuracy: 0.3393 - val_loss: 1.1737 - val_accuracy: 0.0714\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7878 - accuracy: 0.3214 - val_loss: 1.1829 - val_accuracy: 0.0714\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.7844 - accuracy: 0.3929 - val_loss: 1.1925 - val_accuracy: 0.0714\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7805 - accuracy: 0.3214 - val_loss: 1.2023 - val_accuracy: 0.0714\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7746 - accuracy: 0.3393 - val_loss: 1.2121 - val_accuracy: 0.0714\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7763 - accuracy: 0.3571 - val_loss: 1.2217 - val_accuracy: 0.0714\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7629 - accuracy: 0.3393 - val_loss: 1.2309 - val_accuracy: 0.0714\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7692 - accuracy: 0.3571 - val_loss: 1.2400 - val_accuracy: 0.0714\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7543 - accuracy: 0.3571 - val_loss: 1.2485 - val_accuracy: 0.0714\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7526 - accuracy: 0.3393 - val_loss: 1.2560 - val_accuracy: 0.0714\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7589 - accuracy: 0.3571 - val_loss: 1.2628 - val_accuracy: 0.0714\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7509 - accuracy: 0.3571 - val_loss: 1.2685 - val_accuracy: 0.0714\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7459 - accuracy: 0.3571 - val_loss: 1.2733 - val_accuracy: 0.0714\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7429 - accuracy: 0.3214 - val_loss: 1.2763 - val_accuracy: 0.0714\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7414 - accuracy: 0.3571 - val_loss: 1.2789 - val_accuracy: 0.0714\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7352 - accuracy: 0.3036 - val_loss: 1.2803 - val_accuracy: 0.0714\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7289 - accuracy: 0.3571 - val_loss: 1.2805 - val_accuracy: 0.0714\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7222 - accuracy: 0.3750 - val_loss: 1.2807 - val_accuracy: 0.0714\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.7195 - accuracy: 0.3214 - val_loss: 1.2810 - val_accuracy: 0.0714\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7186 - accuracy: 0.3393 - val_loss: 1.2820 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7239 - accuracy: 0.3214 - val_loss: 1.2832 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2832 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=64, batch_size=400, Scores: [1.2832021713256836, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2832021713256836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9839 - accuracy: 0.0536 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 2/64\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9798 - accuracy: 0.1250 - val_loss: 1.0699 - val_accuracy: 0.1429\n",
      "Epoch 3/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9749 - accuracy: 0.1607 - val_loss: 1.0703 - val_accuracy: 0.1429\n",
      "Epoch 4/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9716 - accuracy: 0.1786 - val_loss: 1.0709 - val_accuracy: 0.1429\n",
      "Epoch 5/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9691 - accuracy: 0.1964 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 6/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9647 - accuracy: 0.1786 - val_loss: 1.0721 - val_accuracy: 0.1429\n",
      "Epoch 7/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9596 - accuracy: 0.2679 - val_loss: 1.0728 - val_accuracy: 0.1429\n",
      "Epoch 8/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9594 - accuracy: 0.2679 - val_loss: 1.0735 - val_accuracy: 0.2143\n",
      "Epoch 9/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9540 - accuracy: 0.2679 - val_loss: 1.0742 - val_accuracy: 0.2143\n",
      "Epoch 10/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9516 - accuracy: 0.2500 - val_loss: 1.0749 - val_accuracy: 0.2857\n",
      "Epoch 11/64\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9441 - accuracy: 0.2857 - val_loss: 1.0757 - val_accuracy: 0.2857\n",
      "Epoch 12/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9437 - accuracy: 0.2679 - val_loss: 1.0764 - val_accuracy: 0.2857\n",
      "Epoch 13/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9373 - accuracy: 0.2500 - val_loss: 1.0773 - val_accuracy: 0.2857\n",
      "Epoch 14/64\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9326 - accuracy: 0.2679 - val_loss: 1.0781 - val_accuracy: 0.2857\n",
      "Epoch 15/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9286 - accuracy: 0.2321 - val_loss: 1.0791 - val_accuracy: 0.2857\n",
      "Epoch 16/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9241 - accuracy: 0.2679 - val_loss: 1.0801 - val_accuracy: 0.2857\n",
      "Epoch 17/64\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9206 - accuracy: 0.2500 - val_loss: 1.0811 - val_accuracy: 0.2857\n",
      "Epoch 18/64\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9162 - accuracy: 0.2857 - val_loss: 1.0822 - val_accuracy: 0.2857\n",
      "Epoch 19/64\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9087 - accuracy: 0.2321 - val_loss: 1.0834 - val_accuracy: 0.2857\n",
      "Epoch 20/64\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9068 - accuracy: 0.2857 - val_loss: 1.0847 - val_accuracy: 0.2857\n",
      "Epoch 21/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9000 - accuracy: 0.2143 - val_loss: 1.0862 - val_accuracy: 0.2857\n",
      "Epoch 22/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8936 - accuracy: 0.2857 - val_loss: 1.0878 - val_accuracy: 0.2857\n",
      "Epoch 23/64\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8915 - accuracy: 0.2500 - val_loss: 1.0896 - val_accuracy: 0.2857\n",
      "Epoch 24/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.8870 - accuracy: 0.2500 - val_loss: 1.0917 - val_accuracy: 0.2857\n",
      "Epoch 25/64\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8810 - accuracy: 0.2321 - val_loss: 1.0940 - val_accuracy: 0.2857\n",
      "Epoch 26/64\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8723 - accuracy: 0.2679 - val_loss: 1.0966 - val_accuracy: 0.2857\n",
      "Epoch 27/64\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.8686 - accuracy: 0.3214 - val_loss: 1.0994 - val_accuracy: 0.2857\n",
      "Epoch 28/64\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8658 - accuracy: 0.2321 - val_loss: 1.1026 - val_accuracy: 0.2857\n",
      "Epoch 29/64\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.8614 - accuracy: 0.2679 - val_loss: 1.1059 - val_accuracy: 0.2857\n",
      "Epoch 30/64\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8564 - accuracy: 0.1964 - val_loss: 1.1095 - val_accuracy: 0.2857\n",
      "Epoch 31/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8547 - accuracy: 0.2500 - val_loss: 1.1134 - val_accuracy: 0.2857\n",
      "Epoch 32/64\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.8473 - accuracy: 0.2500 - val_loss: 1.1176 - val_accuracy: 0.2857\n",
      "Epoch 33/64\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8404 - accuracy: 0.2500 - val_loss: 1.1220 - val_accuracy: 0.2857\n",
      "Epoch 34/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8381 - accuracy: 0.2321 - val_loss: 1.1267 - val_accuracy: 0.2857\n",
      "Epoch 35/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8322 - accuracy: 0.2857 - val_loss: 1.1318 - val_accuracy: 0.2857\n",
      "Epoch 36/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8288 - accuracy: 0.2500 - val_loss: 1.1368 - val_accuracy: 0.2857\n",
      "Epoch 37/64\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.8256 - accuracy: 0.2857 - val_loss: 1.1419 - val_accuracy: 0.2143\n",
      "Epoch 38/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8231 - accuracy: 0.3036 - val_loss: 1.1471 - val_accuracy: 0.2143\n",
      "Epoch 39/64\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8170 - accuracy: 0.2857 - val_loss: 1.1523 - val_accuracy: 0.1429\n",
      "Epoch 40/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8083 - accuracy: 0.2143 - val_loss: 1.1575 - val_accuracy: 0.1429\n",
      "Epoch 41/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8086 - accuracy: 0.2857 - val_loss: 1.1628 - val_accuracy: 0.1429\n",
      "Epoch 42/64\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8033 - accuracy: 0.3393 - val_loss: 1.1681 - val_accuracy: 0.1429\n",
      "Epoch 43/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7975 - accuracy: 0.2500 - val_loss: 1.1735 - val_accuracy: 0.1429\n",
      "Epoch 44/64\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7878 - accuracy: 0.3214 - val_loss: 1.1792 - val_accuracy: 0.1429\n",
      "Epoch 45/64\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7892 - accuracy: 0.2679 - val_loss: 1.1853 - val_accuracy: 0.1429\n",
      "Epoch 46/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7837 - accuracy: 0.3036 - val_loss: 1.1913 - val_accuracy: 0.1429\n",
      "Epoch 47/64\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7790 - accuracy: 0.3750 - val_loss: 1.1976 - val_accuracy: 0.1429\n",
      "Epoch 48/64\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7743 - accuracy: 0.3214 - val_loss: 1.2038 - val_accuracy: 0.1429\n",
      "Epoch 49/64\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7724 - accuracy: 0.3214 - val_loss: 1.2101 - val_accuracy: 0.1429\n",
      "Epoch 50/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7617 - accuracy: 0.2857 - val_loss: 1.2163 - val_accuracy: 0.1429\n",
      "Epoch 51/64\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7608 - accuracy: 0.3036 - val_loss: 1.2231 - val_accuracy: 0.1429\n",
      "Epoch 52/64\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7573 - accuracy: 0.3214 - val_loss: 1.2295 - val_accuracy: 0.2143\n",
      "Epoch 53/64\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7494 - accuracy: 0.3571 - val_loss: 1.2354 - val_accuracy: 0.2143\n",
      "Epoch 54/64\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7508 - accuracy: 0.3750 - val_loss: 1.2410 - val_accuracy: 0.2143\n",
      "Epoch 55/64\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7468 - accuracy: 0.3393 - val_loss: 1.2460 - val_accuracy: 0.2143\n",
      "Epoch 56/64\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7434 - accuracy: 0.3750 - val_loss: 1.2503 - val_accuracy: 0.2143\n",
      "Epoch 57/64\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.7405 - accuracy: 0.3571 - val_loss: 1.2532 - val_accuracy: 0.2143\n",
      "Epoch 58/64\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7317 - accuracy: 0.3393 - val_loss: 1.2560 - val_accuracy: 0.0714\n",
      "Epoch 59/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7267 - accuracy: 0.3571 - val_loss: 1.2573 - val_accuracy: 0.0714\n",
      "Epoch 60/64\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7262 - accuracy: 0.3393 - val_loss: 1.2581 - val_accuracy: 0.0714\n",
      "Epoch 61/64\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7148 - accuracy: 0.3571 - val_loss: 1.2585 - val_accuracy: 0.0714\n",
      "Epoch 62/64\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7299 - accuracy: 0.3571 - val_loss: 1.2580 - val_accuracy: 0.0714\n",
      "Epoch 63/64\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7250 - accuracy: 0.4107 - val_loss: 1.2575 - val_accuracy: 0.0714\n",
      "Epoch 64/64\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7201 - accuracy: 0.3750 - val_loss: 1.2574 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2574 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=64, batch_size=500, Scores: [1.2573964595794678, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.2573964595794678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9842 - accuracy: 0.0536 - val_loss: 1.0656 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9821 - accuracy: 0.2143 - val_loss: 1.0656 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9760 - accuracy: 0.1964 - val_loss: 1.0657 - val_accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.9725 - accuracy: 0.2143 - val_loss: 1.0659 - val_accuracy: 0.0714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9686 - accuracy: 0.2679 - val_loss: 1.0661 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9654 - accuracy: 0.2143 - val_loss: 1.0663 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9605 - accuracy: 0.2857 - val_loss: 1.0666 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9574 - accuracy: 0.3214 - val_loss: 1.0669 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.9519 - accuracy: 0.3036 - val_loss: 1.0672 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.9481 - accuracy: 0.3036 - val_loss: 1.0675 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9457 - accuracy: 0.3571 - val_loss: 1.0678 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9425 - accuracy: 0.3393 - val_loss: 1.0680 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9335 - accuracy: 0.3214 - val_loss: 1.0683 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9272 - accuracy: 0.3393 - val_loss: 1.0687 - val_accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9236 - accuracy: 0.3929 - val_loss: 1.0690 - val_accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9219 - accuracy: 0.3036 - val_loss: 1.0694 - val_accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9115 - accuracy: 0.3214 - val_loss: 1.0698 - val_accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9109 - accuracy: 0.3214 - val_loss: 1.0703 - val_accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9064 - accuracy: 0.3393 - val_loss: 1.0710 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.8983 - accuracy: 0.3214 - val_loss: 1.0717 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8942 - accuracy: 0.2857 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8866 - accuracy: 0.3214 - val_loss: 1.0740 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.8844 - accuracy: 0.3036 - val_loss: 1.0755 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8768 - accuracy: 0.3214 - val_loss: 1.0773 - val_accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8668 - accuracy: 0.3036 - val_loss: 1.0796 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8656 - accuracy: 0.3036 - val_loss: 1.0823 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.8590 - accuracy: 0.3214 - val_loss: 1.0855 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8563 - accuracy: 0.3571 - val_loss: 1.0892 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8491 - accuracy: 0.3214 - val_loss: 1.0934 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8468 - accuracy: 0.3036 - val_loss: 1.0980 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8417 - accuracy: 0.3036 - val_loss: 1.1032 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8437 - accuracy: 0.3214 - val_loss: 1.1088 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8322 - accuracy: 0.3214 - val_loss: 1.1148 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8316 - accuracy: 0.2679 - val_loss: 1.1213 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8218 - accuracy: 0.3036 - val_loss: 1.1281 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8203 - accuracy: 0.2857 - val_loss: 1.1352 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8159 - accuracy: 0.2857 - val_loss: 1.1426 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8115 - accuracy: 0.3036 - val_loss: 1.1500 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8081 - accuracy: 0.3036 - val_loss: 1.1573 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.8043 - accuracy: 0.3214 - val_loss: 1.1645 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8015 - accuracy: 0.3036 - val_loss: 1.1714 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7966 - accuracy: 0.3393 - val_loss: 1.1783 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7881 - accuracy: 0.3393 - val_loss: 1.1849 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7945 - accuracy: 0.3393 - val_loss: 1.1916 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7938 - accuracy: 0.3393 - val_loss: 1.1978 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7860 - accuracy: 0.3393 - val_loss: 1.2038 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7771 - accuracy: 0.3750 - val_loss: 1.2098 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7755 - accuracy: 0.3393 - val_loss: 1.2155 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.7744 - accuracy: 0.3750 - val_loss: 1.2208 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.7641 - accuracy: 0.4464 - val_loss: 1.2260 - val_accuracy: 0.0714\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7621 - accuracy: 0.3750 - val_loss: 1.2304 - val_accuracy: 0.0714\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7579 - accuracy: 0.3929 - val_loss: 1.2348 - val_accuracy: 0.0714\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7523 - accuracy: 0.3571 - val_loss: 1.2387 - val_accuracy: 0.0714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7530 - accuracy: 0.3929 - val_loss: 1.2420 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7487 - accuracy: 0.3750 - val_loss: 1.2450 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7414 - accuracy: 0.3929 - val_loss: 1.2473 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7453 - accuracy: 0.3571 - val_loss: 1.2498 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7437 - accuracy: 0.4107 - val_loss: 1.2521 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7288 - accuracy: 0.4286 - val_loss: 1.2547 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.7298 - accuracy: 0.3929 - val_loss: 1.2576 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7205 - accuracy: 0.3571 - val_loss: 1.2607 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7229 - accuracy: 0.3393 - val_loss: 1.2636 - val_accuracy: 0.0714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7217 - accuracy: 0.3750 - val_loss: 1.2665 - val_accuracy: 0.0714\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7179 - accuracy: 0.3393 - val_loss: 1.2694 - val_accuracy: 0.0714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7237 - accuracy: 0.3571 - val_loss: 1.2719 - val_accuracy: 0.0714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7027 - accuracy: 0.3214 - val_loss: 1.2741 - val_accuracy: 0.0714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7028 - accuracy: 0.4107 - val_loss: 1.2763 - val_accuracy: 0.0714\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7028 - accuracy: 0.3750 - val_loss: 1.2786 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7013 - accuracy: 0.3750 - val_loss: 1.2809 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6970 - accuracy: 0.3571 - val_loss: 1.2836 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6961 - accuracy: 0.3393 - val_loss: 1.2866 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6831 - accuracy: 0.3750 - val_loss: 1.2896 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6977 - accuracy: 0.3393 - val_loss: 1.2926 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6844 - accuracy: 0.3929 - val_loss: 1.2962 - val_accuracy: 0.0714\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6840 - accuracy: 0.3750 - val_loss: 1.3015 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6809 - accuracy: 0.3750 - val_loss: 1.3072 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6801 - accuracy: 0.3571 - val_loss: 1.3130 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6701 - accuracy: 0.3929 - val_loss: 1.3194 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6753 - accuracy: 0.3750 - val_loss: 1.3250 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6720 - accuracy: 0.3214 - val_loss: 1.3295 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6672 - accuracy: 0.3929 - val_loss: 1.3337 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6530 - accuracy: 0.4107 - val_loss: 1.3385 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.6605 - accuracy: 0.3929 - val_loss: 1.3434 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6434 - accuracy: 0.4464 - val_loss: 1.3474 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6554 - accuracy: 0.4464 - val_loss: 1.3508 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6409 - accuracy: 0.3929 - val_loss: 1.3549 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6416 - accuracy: 0.3929 - val_loss: 1.3602 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6552 - accuracy: 0.3393 - val_loss: 1.3645 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6313 - accuracy: 0.4107 - val_loss: 1.3699 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6342 - accuracy: 0.3929 - val_loss: 1.3756 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6231 - accuracy: 0.3750 - val_loss: 1.3808 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6136 - accuracy: 0.4286 - val_loss: 1.3835 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6278 - accuracy: 0.4286 - val_loss: 1.3858 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6120 - accuracy: 0.3929 - val_loss: 1.3868 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6131 - accuracy: 0.4107 - val_loss: 1.3864 - val_accuracy: 0.0714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6192 - accuracy: 0.3750 - val_loss: 1.3842 - val_accuracy: 0.0714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6088 - accuracy: 0.4107 - val_loss: 1.3820 - val_accuracy: 0.0714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6192 - accuracy: 0.3929 - val_loss: 1.3805 - val_accuracy: 0.0714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5953 - accuracy: 0.3929 - val_loss: 1.3804 - val_accuracy: 0.0714\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6020 - accuracy: 0.3929 - val_loss: 1.3820 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.3820 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=100, batch_size=100, Scores: [1.3819838762283325, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.3819838762283325\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9847 - accuracy: 0.1429 - val_loss: 1.0653 - val_accuracy: 0.2143\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9816 - accuracy: 0.1607 - val_loss: 1.0653 - val_accuracy: 0.2857\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9779 - accuracy: 0.2321 - val_loss: 1.0654 - val_accuracy: 0.2857\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9740 - accuracy: 0.2321 - val_loss: 1.0655 - val_accuracy: 0.2143\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9711 - accuracy: 0.3750 - val_loss: 1.0657 - val_accuracy: 0.2857\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9667 - accuracy: 0.2679 - val_loss: 1.0658 - val_accuracy: 0.2857\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9615 - accuracy: 0.3571 - val_loss: 1.0660 - val_accuracy: 0.2857\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9581 - accuracy: 0.3393 - val_loss: 1.0661 - val_accuracy: 0.2143\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9556 - accuracy: 0.3750 - val_loss: 1.0663 - val_accuracy: 0.2143\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9515 - accuracy: 0.3214 - val_loss: 1.0664 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9494 - accuracy: 0.3036 - val_loss: 1.0666 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9461 - accuracy: 0.3214 - val_loss: 1.0667 - val_accuracy: 0.2143\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9382 - accuracy: 0.3036 - val_loss: 1.0668 - val_accuracy: 0.2143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9360 - accuracy: 0.3393 - val_loss: 1.0669 - val_accuracy: 0.2143\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9323 - accuracy: 0.3036 - val_loss: 1.0670 - val_accuracy: 0.2143\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9260 - accuracy: 0.3036 - val_loss: 1.0671 - val_accuracy: 0.2143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9205 - accuracy: 0.2857 - val_loss: 1.0672 - val_accuracy: 0.2143\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9179 - accuracy: 0.2857 - val_loss: 1.0675 - val_accuracy: 0.2143\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9116 - accuracy: 0.2679 - val_loss: 1.0678 - val_accuracy: 0.2143\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.9073 - accuracy: 0.2679 - val_loss: 1.0682 - val_accuracy: 0.2143\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9023 - accuracy: 0.3036 - val_loss: 1.0688 - val_accuracy: 0.2143\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.8975 - accuracy: 0.3393 - val_loss: 1.0696 - val_accuracy: 0.2143\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.8907 - accuracy: 0.3393 - val_loss: 1.0706 - val_accuracy: 0.2143\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.8865 - accuracy: 0.2857 - val_loss: 1.0719 - val_accuracy: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8837 - accuracy: 0.3214 - val_loss: 1.0735 - val_accuracy: 0.2143\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8717 - accuracy: 0.3036 - val_loss: 1.0754 - val_accuracy: 0.2143\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.8708 - accuracy: 0.2857 - val_loss: 1.0777 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.8612 - accuracy: 0.3036 - val_loss: 1.0803 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.8616 - accuracy: 0.2857 - val_loss: 1.0833 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8590 - accuracy: 0.2857 - val_loss: 1.0865 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8527 - accuracy: 0.3214 - val_loss: 1.0902 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8491 - accuracy: 0.3036 - val_loss: 1.0941 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8397 - accuracy: 0.3214 - val_loss: 1.0982 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8408 - accuracy: 0.3571 - val_loss: 1.1028 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.8377 - accuracy: 0.3393 - val_loss: 1.1075 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8301 - accuracy: 0.3214 - val_loss: 1.1126 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8258 - accuracy: 0.3571 - val_loss: 1.1181 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8179 - accuracy: 0.3214 - val_loss: 1.1239 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8111 - accuracy: 0.4107 - val_loss: 1.1300 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8124 - accuracy: 0.3393 - val_loss: 1.1366 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8145 - accuracy: 0.3393 - val_loss: 1.1432 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7997 - accuracy: 0.3036 - val_loss: 1.1502 - val_accuracy: 0.1429\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7972 - accuracy: 0.3214 - val_loss: 1.1571 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.7849 - accuracy: 0.3571 - val_loss: 1.1640 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.7828 - accuracy: 0.3750 - val_loss: 1.1711 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7769 - accuracy: 0.3571 - val_loss: 1.1783 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7807 - accuracy: 0.3393 - val_loss: 1.1855 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.7720 - accuracy: 0.3929 - val_loss: 1.1924 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7670 - accuracy: 0.3750 - val_loss: 1.1995 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.7707 - accuracy: 0.3571 - val_loss: 1.2061 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7638 - accuracy: 0.3571 - val_loss: 1.2121 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7553 - accuracy: 0.4107 - val_loss: 1.2176 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7574 - accuracy: 0.3393 - val_loss: 1.2221 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7525 - accuracy: 0.3393 - val_loss: 1.2253 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7584 - accuracy: 0.3929 - val_loss: 1.2280 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7464 - accuracy: 0.3393 - val_loss: 1.2305 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7471 - accuracy: 0.3571 - val_loss: 1.2324 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7434 - accuracy: 0.3571 - val_loss: 1.2342 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7304 - accuracy: 0.3214 - val_loss: 1.2356 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7357 - accuracy: 0.3750 - val_loss: 1.2369 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7323 - accuracy: 0.3750 - val_loss: 1.2378 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7307 - accuracy: 0.3214 - val_loss: 1.2394 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7232 - accuracy: 0.3393 - val_loss: 1.2411 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7266 - accuracy: 0.3393 - val_loss: 1.2434 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7136 - accuracy: 0.3571 - val_loss: 1.2456 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7109 - accuracy: 0.3214 - val_loss: 1.2471 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7108 - accuracy: 0.3393 - val_loss: 1.2487 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7168 - accuracy: 0.3214 - val_loss: 1.2498 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7202 - accuracy: 0.3571 - val_loss: 1.2506 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7005 - accuracy: 0.3393 - val_loss: 1.2510 - val_accuracy: 0.2143\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 0.6994 - accuracy: 0.3214 - val_loss: 1.2515 - val_accuracy: 0.2143\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6976 - accuracy: 0.2857 - val_loss: 1.2524 - val_accuracy: 0.2143\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6957 - accuracy: 0.4286 - val_loss: 1.2539 - val_accuracy: 0.2143\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6953 - accuracy: 0.3929 - val_loss: 1.2553 - val_accuracy: 0.2143\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6844 - accuracy: 0.4107 - val_loss: 1.2571 - val_accuracy: 0.2143\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6834 - accuracy: 0.3750 - val_loss: 1.2590 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6804 - accuracy: 0.3571 - val_loss: 1.2615 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6802 - accuracy: 0.3571 - val_loss: 1.2645 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6640 - accuracy: 0.3929 - val_loss: 1.2686 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6610 - accuracy: 0.4286 - val_loss: 1.2715 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6653 - accuracy: 0.3750 - val_loss: 1.2753 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6508 - accuracy: 0.4643 - val_loss: 1.2805 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6611 - accuracy: 0.3929 - val_loss: 1.2854 - val_accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6523 - accuracy: 0.4107 - val_loss: 1.2899 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6510 - accuracy: 0.4107 - val_loss: 1.2943 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6478 - accuracy: 0.4286 - val_loss: 1.3000 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6419 - accuracy: 0.4464 - val_loss: 1.3059 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6408 - accuracy: 0.3750 - val_loss: 1.3115 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6325 - accuracy: 0.3929 - val_loss: 1.3177 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6299 - accuracy: 0.4107 - val_loss: 1.3223 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6204 - accuracy: 0.4821 - val_loss: 1.3267 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6223 - accuracy: 0.4464 - val_loss: 1.3298 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6282 - accuracy: 0.4464 - val_loss: 1.3337 - val_accuracy: 0.1429\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6112 - accuracy: 0.4464 - val_loss: 1.3373 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.6144 - accuracy: 0.4821 - val_loss: 1.3413 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.6252 - accuracy: 0.4464 - val_loss: 1.3441 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6150 - accuracy: 0.4286 - val_loss: 1.3470 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5958 - accuracy: 0.4107 - val_loss: 1.3501 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.5968 - accuracy: 0.5000 - val_loss: 1.3551 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6037 - accuracy: 0.4643 - val_loss: 1.3600 - val_accuracy: 0.1429\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3600 - accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=100, batch_size=300, Scores: [1.3600341081619263, 0.1428571492433548]\n",
      "Accuracy on validation set: 0.1428571492433548\n",
      "Loss on validation set: 1.3600341081619263\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9841 - accuracy: 0.1071 - val_loss: 1.0731 - val_accuracy: 0.2143\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9798 - accuracy: 0.1607 - val_loss: 1.0740 - val_accuracy: 0.2143\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9755 - accuracy: 0.1964 - val_loss: 1.0750 - val_accuracy: 0.2143\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9755 - accuracy: 0.1607 - val_loss: 1.0760 - val_accuracy: 0.2143\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9701 - accuracy: 0.2679 - val_loss: 1.0770 - val_accuracy: 0.2143\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9688 - accuracy: 0.2857 - val_loss: 1.0781 - val_accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9638 - accuracy: 0.3036 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9598 - accuracy: 0.3750 - val_loss: 1.0803 - val_accuracy: 0.0714\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9575 - accuracy: 0.3393 - val_loss: 1.0815 - val_accuracy: 0.0714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.9544 - accuracy: 0.3393 - val_loss: 1.0827 - val_accuracy: 0.0714\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9468 - accuracy: 0.3571 - val_loss: 1.0840 - val_accuracy: 0.0714\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9453 - accuracy: 0.3393 - val_loss: 1.0853 - val_accuracy: 0.0714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9422 - accuracy: 0.3571 - val_loss: 1.0868 - val_accuracy: 0.0714\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9380 - accuracy: 0.3929 - val_loss: 1.0885 - val_accuracy: 0.0714\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9330 - accuracy: 0.3036 - val_loss: 1.0902 - val_accuracy: 0.0714\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9313 - accuracy: 0.3393 - val_loss: 1.0921 - val_accuracy: 0.0714\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9276 - accuracy: 0.3393 - val_loss: 1.0940 - val_accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9245 - accuracy: 0.3393 - val_loss: 1.0962 - val_accuracy: 0.0714\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9156 - accuracy: 0.3750 - val_loss: 1.0984 - val_accuracy: 0.0714\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9135 - accuracy: 0.3571 - val_loss: 1.1008 - val_accuracy: 0.0714\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9048 - accuracy: 0.3393 - val_loss: 1.1034 - val_accuracy: 0.0714\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9054 - accuracy: 0.3929 - val_loss: 1.1061 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.8974 - accuracy: 0.3750 - val_loss: 1.1090 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8884 - accuracy: 0.3929 - val_loss: 1.1121 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8871 - accuracy: 0.3750 - val_loss: 1.1154 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8813 - accuracy: 0.3393 - val_loss: 1.1190 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8747 - accuracy: 0.3393 - val_loss: 1.1229 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8737 - accuracy: 0.3571 - val_loss: 1.1269 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8666 - accuracy: 0.3571 - val_loss: 1.1311 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8571 - accuracy: 0.3571 - val_loss: 1.1353 - val_accuracy: 0.2143\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8475 - accuracy: 0.3393 - val_loss: 1.1394 - val_accuracy: 0.2143\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8462 - accuracy: 0.3571 - val_loss: 1.1433 - val_accuracy: 0.2143\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8407 - accuracy: 0.3750 - val_loss: 1.1471 - val_accuracy: 0.2143\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8391 - accuracy: 0.3214 - val_loss: 1.1506 - val_accuracy: 0.2143\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8322 - accuracy: 0.3214 - val_loss: 1.1538 - val_accuracy: 0.2143\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8275 - accuracy: 0.3750 - val_loss: 1.1567 - val_accuracy: 0.2143\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8203 - accuracy: 0.3571 - val_loss: 1.1592 - val_accuracy: 0.2143\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8107 - accuracy: 0.3214 - val_loss: 1.1619 - val_accuracy: 0.2143\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.8095 - accuracy: 0.3036 - val_loss: 1.1647 - val_accuracy: 0.2143\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8055 - accuracy: 0.3393 - val_loss: 1.1676 - val_accuracy: 0.2143\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8030 - accuracy: 0.3393 - val_loss: 1.1706 - val_accuracy: 0.2143\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7972 - accuracy: 0.3393 - val_loss: 1.1736 - val_accuracy: 0.2143\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.7908 - accuracy: 0.3214 - val_loss: 1.1771 - val_accuracy: 0.2143\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7869 - accuracy: 0.3393 - val_loss: 1.1811 - val_accuracy: 0.2143\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.7853 - accuracy: 0.3393 - val_loss: 1.1858 - val_accuracy: 0.2143\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7727 - accuracy: 0.3750 - val_loss: 1.1910 - val_accuracy: 0.2143\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7780 - accuracy: 0.3214 - val_loss: 1.1961 - val_accuracy: 0.2143\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7704 - accuracy: 0.3750 - val_loss: 1.2013 - val_accuracy: 0.2143\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7651 - accuracy: 0.3571 - val_loss: 1.2058 - val_accuracy: 0.2143\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7563 - accuracy: 0.3571 - val_loss: 1.2101 - val_accuracy: 0.2143\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7572 - accuracy: 0.3750 - val_loss: 1.2137 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7627 - accuracy: 0.3929 - val_loss: 1.2168 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.7498 - accuracy: 0.3929 - val_loss: 1.2199 - val_accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7523 - accuracy: 0.3750 - val_loss: 1.2232 - val_accuracy: 0.1429\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7460 - accuracy: 0.3571 - val_loss: 1.2257 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7490 - accuracy: 0.3750 - val_loss: 1.2286 - val_accuracy: 0.1429\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7436 - accuracy: 0.3214 - val_loss: 1.2303 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7465 - accuracy: 0.3393 - val_loss: 1.2310 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7381 - accuracy: 0.3929 - val_loss: 1.2312 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7322 - accuracy: 0.3571 - val_loss: 1.2310 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7214 - accuracy: 0.3393 - val_loss: 1.2304 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7312 - accuracy: 0.3214 - val_loss: 1.2298 - val_accuracy: 0.0714\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7263 - accuracy: 0.3393 - val_loss: 1.2287 - val_accuracy: 0.0714\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7304 - accuracy: 0.3750 - val_loss: 1.2286 - val_accuracy: 0.0714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7091 - accuracy: 0.3214 - val_loss: 1.2289 - val_accuracy: 0.0714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7103 - accuracy: 0.3929 - val_loss: 1.2298 - val_accuracy: 0.0714\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7075 - accuracy: 0.3571 - val_loss: 1.2313 - val_accuracy: 0.0714\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7066 - accuracy: 0.3571 - val_loss: 1.2335 - val_accuracy: 0.0714\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7031 - accuracy: 0.3393 - val_loss: 1.2365 - val_accuracy: 0.0714\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7040 - accuracy: 0.3393 - val_loss: 1.2395 - val_accuracy: 0.0714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6908 - accuracy: 0.3929 - val_loss: 1.2427 - val_accuracy: 0.0714\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7012 - accuracy: 0.3571 - val_loss: 1.2452 - val_accuracy: 0.0714\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6996 - accuracy: 0.3393 - val_loss: 1.2487 - val_accuracy: 0.0714\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6810 - accuracy: 0.3571 - val_loss: 1.2523 - val_accuracy: 0.0714\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6792 - accuracy: 0.4286 - val_loss: 1.2548 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6760 - accuracy: 0.3750 - val_loss: 1.2574 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6787 - accuracy: 0.3929 - val_loss: 1.2594 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.6790 - accuracy: 0.4107 - val_loss: 1.2622 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6734 - accuracy: 0.3750 - val_loss: 1.2646 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6628 - accuracy: 0.3929 - val_loss: 1.2675 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6704 - accuracy: 0.4286 - val_loss: 1.2715 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6568 - accuracy: 0.3750 - val_loss: 1.2749 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6553 - accuracy: 0.3929 - val_loss: 1.2789 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6589 - accuracy: 0.3929 - val_loss: 1.2835 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6541 - accuracy: 0.4286 - val_loss: 1.2879 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6528 - accuracy: 0.3929 - val_loss: 1.2935 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6475 - accuracy: 0.3929 - val_loss: 1.2983 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6392 - accuracy: 0.4107 - val_loss: 1.3012 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6322 - accuracy: 0.4107 - val_loss: 1.3042 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6298 - accuracy: 0.3929 - val_loss: 1.3085 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6279 - accuracy: 0.4107 - val_loss: 1.3125 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6318 - accuracy: 0.4107 - val_loss: 1.3154 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6276 - accuracy: 0.4107 - val_loss: 1.3178 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6175 - accuracy: 0.3750 - val_loss: 1.3200 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6257 - accuracy: 0.4107 - val_loss: 1.3237 - val_accuracy: 0.0714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5996 - accuracy: 0.3571 - val_loss: 1.3282 - val_accuracy: 0.0714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6071 - accuracy: 0.3750 - val_loss: 1.3339 - val_accuracy: 0.0714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6062 - accuracy: 0.4107 - val_loss: 1.3395 - val_accuracy: 0.0714\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6063 - accuracy: 0.4464 - val_loss: 1.3445 - val_accuracy: 0.0714\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5920 - accuracy: 0.4464 - val_loss: 1.3503 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3503 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=100, batch_size=400, Scores: [1.3503444194793701, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.3503444194793701\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9824 - accuracy: 0.1607 - val_loss: 1.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.9807 - accuracy: 0.1964 - val_loss: 1.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.9761 - accuracy: 0.2321 - val_loss: 1.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9744 - accuracy: 0.1786 - val_loss: 1.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9690 - accuracy: 0.2679 - val_loss: 1.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9654 - accuracy: 0.2679 - val_loss: 1.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9616 - accuracy: 0.2857 - val_loss: 1.0749 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9606 - accuracy: 0.2500 - val_loss: 1.0759 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9568 - accuracy: 0.2679 - val_loss: 1.0768 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9539 - accuracy: 0.2500 - val_loss: 1.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9502 - accuracy: 0.2857 - val_loss: 1.0788 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9462 - accuracy: 0.2500 - val_loss: 1.0799 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9416 - accuracy: 0.3036 - val_loss: 1.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.9370 - accuracy: 0.2857 - val_loss: 1.0822 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9347 - accuracy: 0.2500 - val_loss: 1.0834 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9294 - accuracy: 0.3036 - val_loss: 1.0847 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9265 - accuracy: 0.3393 - val_loss: 1.0860 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9186 - accuracy: 0.2857 - val_loss: 1.0873 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.9161 - accuracy: 0.3571 - val_loss: 1.0887 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9110 - accuracy: 0.3393 - val_loss: 1.0902 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9047 - accuracy: 0.3036 - val_loss: 1.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.9002 - accuracy: 0.3036 - val_loss: 1.0933 - val_accuracy: 0.0714\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9005 - accuracy: 0.3214 - val_loss: 1.0951 - val_accuracy: 0.0714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8910 - accuracy: 0.3036 - val_loss: 1.0970 - val_accuracy: 0.0714\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8869 - accuracy: 0.3393 - val_loss: 1.0990 - val_accuracy: 0.0714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.8774 - accuracy: 0.3571 - val_loss: 1.1012 - val_accuracy: 0.0714\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8739 - accuracy: 0.3036 - val_loss: 1.1037 - val_accuracy: 0.0714\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8703 - accuracy: 0.3214 - val_loss: 1.1065 - val_accuracy: 0.0714\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8616 - accuracy: 0.3393 - val_loss: 1.1096 - val_accuracy: 0.0714\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8558 - accuracy: 0.3571 - val_loss: 1.1129 - val_accuracy: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8501 - accuracy: 0.3393 - val_loss: 1.1166 - val_accuracy: 0.0714\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8431 - accuracy: 0.3571 - val_loss: 1.1205 - val_accuracy: 0.0714\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.8369 - accuracy: 0.3214 - val_loss: 1.1249 - val_accuracy: 0.0714\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8395 - accuracy: 0.3393 - val_loss: 1.1296 - val_accuracy: 0.0714\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8248 - accuracy: 0.3571 - val_loss: 1.1345 - val_accuracy: 0.0714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8212 - accuracy: 0.3750 - val_loss: 1.1399 - val_accuracy: 0.0714\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 0.8117 - accuracy: 0.3393 - val_loss: 1.1456 - val_accuracy: 0.0714\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.8142 - accuracy: 0.3214 - val_loss: 1.1516 - val_accuracy: 0.0714\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.8042 - accuracy: 0.3214 - val_loss: 1.1579 - val_accuracy: 0.0714\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.8049 - accuracy: 0.3214 - val_loss: 1.1643 - val_accuracy: 0.0714\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8017 - accuracy: 0.3214 - val_loss: 1.1709 - val_accuracy: 0.0714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7908 - accuracy: 0.3214 - val_loss: 1.1777 - val_accuracy: 0.0714\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7907 - accuracy: 0.3036 - val_loss: 1.1848 - val_accuracy: 0.0714\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7871 - accuracy: 0.3571 - val_loss: 1.1916 - val_accuracy: 0.0714\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7869 - accuracy: 0.3393 - val_loss: 1.1978 - val_accuracy: 0.0714\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7815 - accuracy: 0.3214 - val_loss: 1.2033 - val_accuracy: 0.0714\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.7789 - accuracy: 0.3214 - val_loss: 1.2083 - val_accuracy: 0.0714\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.7824 - accuracy: 0.3393 - val_loss: 1.2126 - val_accuracy: 0.0714\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7697 - accuracy: 0.3393 - val_loss: 1.2165 - val_accuracy: 0.0714\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7586 - accuracy: 0.3571 - val_loss: 1.2205 - val_accuracy: 0.0714\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7609 - accuracy: 0.3393 - val_loss: 1.2244 - val_accuracy: 0.0714\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7576 - accuracy: 0.3571 - val_loss: 1.2278 - val_accuracy: 0.0714\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7568 - accuracy: 0.3393 - val_loss: 1.2313 - val_accuracy: 0.0714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7494 - accuracy: 0.3750 - val_loss: 1.2344 - val_accuracy: 0.0714\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.7459 - accuracy: 0.3750 - val_loss: 1.2375 - val_accuracy: 0.0714\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7369 - accuracy: 0.3750 - val_loss: 1.2407 - val_accuracy: 0.0714\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.7369 - accuracy: 0.3750 - val_loss: 1.2435 - val_accuracy: 0.0714\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7389 - accuracy: 0.3571 - val_loss: 1.2457 - val_accuracy: 0.0714\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7343 - accuracy: 0.3750 - val_loss: 1.2481 - val_accuracy: 0.0714\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7350 - accuracy: 0.3214 - val_loss: 1.2502 - val_accuracy: 0.0714\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7200 - accuracy: 0.3750 - val_loss: 1.2523 - val_accuracy: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7189 - accuracy: 0.3214 - val_loss: 1.2544 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7151 - accuracy: 0.3214 - val_loss: 1.2568 - val_accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7040 - accuracy: 0.4107 - val_loss: 1.2594 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7180 - accuracy: 0.3571 - val_loss: 1.2626 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7149 - accuracy: 0.3750 - val_loss: 1.2661 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6961 - accuracy: 0.4107 - val_loss: 1.2700 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6981 - accuracy: 0.3750 - val_loss: 1.2737 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6994 - accuracy: 0.3750 - val_loss: 1.2772 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6890 - accuracy: 0.3750 - val_loss: 1.2798 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6842 - accuracy: 0.3214 - val_loss: 1.2827 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6867 - accuracy: 0.3393 - val_loss: 1.2858 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6807 - accuracy: 0.3393 - val_loss: 1.2897 - val_accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6847 - accuracy: 0.3393 - val_loss: 1.2929 - val_accuracy: 0.0714\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6826 - accuracy: 0.3036 - val_loss: 1.2959 - val_accuracy: 0.0714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6703 - accuracy: 0.3036 - val_loss: 1.3004 - val_accuracy: 0.0714\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6811 - accuracy: 0.3214 - val_loss: 1.3043 - val_accuracy: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6597 - accuracy: 0.3393 - val_loss: 1.3087 - val_accuracy: 0.0714\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6520 - accuracy: 0.3214 - val_loss: 1.3143 - val_accuracy: 0.0714\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.6522 - accuracy: 0.3214 - val_loss: 1.3205 - val_accuracy: 0.0714\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6500 - accuracy: 0.3929 - val_loss: 1.3263 - val_accuracy: 0.0714\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6461 - accuracy: 0.3571 - val_loss: 1.3325 - val_accuracy: 0.0714\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6477 - accuracy: 0.3214 - val_loss: 1.3393 - val_accuracy: 0.0714\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6376 - accuracy: 0.3571 - val_loss: 1.3469 - val_accuracy: 0.0714\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6282 - accuracy: 0.3571 - val_loss: 1.3536 - val_accuracy: 0.0714\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6284 - accuracy: 0.3214 - val_loss: 1.3609 - val_accuracy: 0.0714\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6427 - accuracy: 0.3393 - val_loss: 1.3677 - val_accuracy: 0.0714\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6170 - accuracy: 0.3571 - val_loss: 1.3747 - val_accuracy: 0.0714\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6273 - accuracy: 0.3750 - val_loss: 1.3817 - val_accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6133 - accuracy: 0.3929 - val_loss: 1.3873 - val_accuracy: 0.0714\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6185 - accuracy: 0.3571 - val_loss: 1.3920 - val_accuracy: 0.0714\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6078 - accuracy: 0.3393 - val_loss: 1.3977 - val_accuracy: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6073 - accuracy: 0.3750 - val_loss: 1.4030 - val_accuracy: 0.0714\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5998 - accuracy: 0.3750 - val_loss: 1.4100 - val_accuracy: 0.0714\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5959 - accuracy: 0.4107 - val_loss: 1.4161 - val_accuracy: 0.0714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6051 - accuracy: 0.3750 - val_loss: 1.4208 - val_accuracy: 0.0714\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6096 - accuracy: 0.3929 - val_loss: 1.4234 - val_accuracy: 0.0714\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6064 - accuracy: 0.3571 - val_loss: 1.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5794 - accuracy: 0.4286 - val_loss: 1.4291 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5908 - accuracy: 0.3929 - val_loss: 1.4315 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4315 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=100, batch_size=500, Scores: [1.4315402507781982, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.4315402507781982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9833 - accuracy: 0.1786 - val_loss: 1.0706 - val_accuracy: 0.0714\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9838 - accuracy: 0.0714 - val_loss: 1.0711 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.9778 - accuracy: 0.1250 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.9748 - accuracy: 0.1964 - val_loss: 1.0721 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.9701 - accuracy: 0.2857 - val_loss: 1.0726 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9666 - accuracy: 0.2857 - val_loss: 1.0732 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.9643 - accuracy: 0.3214 - val_loss: 1.0737 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.9622 - accuracy: 0.3214 - val_loss: 1.0742 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9566 - accuracy: 0.3036 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.9522 - accuracy: 0.2857 - val_loss: 1.0753 - val_accuracy: 0.1429\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9490 - accuracy: 0.3036 - val_loss: 1.0758 - val_accuracy: 0.1429\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9454 - accuracy: 0.3214 - val_loss: 1.0763 - val_accuracy: 0.1429\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9404 - accuracy: 0.3036 - val_loss: 1.0769 - val_accuracy: 0.1429\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9368 - accuracy: 0.3036 - val_loss: 1.0774 - val_accuracy: 0.1429\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.9329 - accuracy: 0.2857 - val_loss: 1.0781 - val_accuracy: 0.1429\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9300 - accuracy: 0.3214 - val_loss: 1.0789 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9244 - accuracy: 0.3214 - val_loss: 1.0797 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9208 - accuracy: 0.3036 - val_loss: 1.0806 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9172 - accuracy: 0.3750 - val_loss: 1.0816 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9100 - accuracy: 0.2857 - val_loss: 1.0827 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.9067 - accuracy: 0.3393 - val_loss: 1.0839 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.8989 - accuracy: 0.3036 - val_loss: 1.0854 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8956 - accuracy: 0.3036 - val_loss: 1.0870 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.8886 - accuracy: 0.2857 - val_loss: 1.0889 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8813 - accuracy: 0.2857 - val_loss: 1.0911 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8777 - accuracy: 0.3036 - val_loss: 1.0936 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8713 - accuracy: 0.3214 - val_loss: 1.0965 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8655 - accuracy: 0.3036 - val_loss: 1.0997 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8601 - accuracy: 0.3214 - val_loss: 1.1033 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.8562 - accuracy: 0.3036 - val_loss: 1.1074 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8491 - accuracy: 0.2857 - val_loss: 1.1119 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8416 - accuracy: 0.3036 - val_loss: 1.1168 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8393 - accuracy: 0.3393 - val_loss: 1.1220 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.8331 - accuracy: 0.3393 - val_loss: 1.1276 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8343 - accuracy: 0.3214 - val_loss: 1.1334 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8291 - accuracy: 0.2857 - val_loss: 1.1393 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8246 - accuracy: 0.3214 - val_loss: 1.1453 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8160 - accuracy: 0.3214 - val_loss: 1.1514 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8066 - accuracy: 0.3393 - val_loss: 1.1576 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8064 - accuracy: 0.3214 - val_loss: 1.1641 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8047 - accuracy: 0.3750 - val_loss: 1.1709 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7942 - accuracy: 0.2857 - val_loss: 1.1779 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7891 - accuracy: 0.2857 - val_loss: 1.1851 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7902 - accuracy: 0.3036 - val_loss: 1.1922 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7824 - accuracy: 0.3214 - val_loss: 1.1992 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7751 - accuracy: 0.3214 - val_loss: 1.2063 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7741 - accuracy: 0.2679 - val_loss: 1.2132 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7662 - accuracy: 0.3036 - val_loss: 1.2200 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7662 - accuracy: 0.3214 - val_loss: 1.2266 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7619 - accuracy: 0.3214 - val_loss: 1.2327 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7635 - accuracy: 0.3036 - val_loss: 1.2386 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7610 - accuracy: 0.2857 - val_loss: 1.2437 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7557 - accuracy: 0.3214 - val_loss: 1.2482 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7496 - accuracy: 0.3214 - val_loss: 1.2527 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7453 - accuracy: 0.3214 - val_loss: 1.2564 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7416 - accuracy: 0.3214 - val_loss: 1.2598 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7421 - accuracy: 0.3750 - val_loss: 1.2624 - val_accuracy: 0.2143\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7385 - accuracy: 0.3036 - val_loss: 1.2649 - val_accuracy: 0.2143\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.7375 - accuracy: 0.3571 - val_loss: 1.2665 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7292 - accuracy: 0.3214 - val_loss: 1.2676 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7235 - accuracy: 0.3393 - val_loss: 1.2679 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7295 - accuracy: 0.3571 - val_loss: 1.2678 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7234 - accuracy: 0.3929 - val_loss: 1.2681 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7233 - accuracy: 0.3393 - val_loss: 1.2693 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7175 - accuracy: 0.3036 - val_loss: 1.2709 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7241 - accuracy: 0.3393 - val_loss: 1.2726 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7139 - accuracy: 0.3214 - val_loss: 1.2739 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7072 - accuracy: 0.3393 - val_loss: 1.2760 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7015 - accuracy: 0.3214 - val_loss: 1.2785 - val_accuracy: 0.1429\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6932 - accuracy: 0.3750 - val_loss: 1.2809 - val_accuracy: 0.1429\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6953 - accuracy: 0.3036 - val_loss: 1.2822 - val_accuracy: 0.1429\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6974 - accuracy: 0.3750 - val_loss: 1.2835 - val_accuracy: 0.1429\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6865 - accuracy: 0.3750 - val_loss: 1.2846 - val_accuracy: 0.1429\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6848 - accuracy: 0.3750 - val_loss: 1.2860 - val_accuracy: 0.1429\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6895 - accuracy: 0.3750 - val_loss: 1.2873 - val_accuracy: 0.1429\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.6710 - accuracy: 0.4286 - val_loss: 1.2900 - val_accuracy: 0.1429\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6771 - accuracy: 0.3571 - val_loss: 1.2933 - val_accuracy: 0.1429\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6720 - accuracy: 0.4107 - val_loss: 1.2972 - val_accuracy: 0.1429\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6690 - accuracy: 0.4107 - val_loss: 1.3020 - val_accuracy: 0.1429\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6664 - accuracy: 0.3929 - val_loss: 1.3069 - val_accuracy: 0.1429\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6652 - accuracy: 0.4107 - val_loss: 1.3120 - val_accuracy: 0.1429\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6545 - accuracy: 0.3929 - val_loss: 1.3165 - val_accuracy: 0.1429\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6711 - accuracy: 0.3571 - val_loss: 1.3199 - val_accuracy: 0.1429\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6461 - accuracy: 0.4286 - val_loss: 1.3230 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6491 - accuracy: 0.4107 - val_loss: 1.3256 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6464 - accuracy: 0.3750 - val_loss: 1.3287 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6376 - accuracy: 0.4286 - val_loss: 1.3328 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6484 - accuracy: 0.4464 - val_loss: 1.3366 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6282 - accuracy: 0.4107 - val_loss: 1.3401 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6217 - accuracy: 0.4286 - val_loss: 1.3452 - val_accuracy: 0.1429\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6150 - accuracy: 0.4464 - val_loss: 1.3499 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6281 - accuracy: 0.4643 - val_loss: 1.3549 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6011 - accuracy: 0.4464 - val_loss: 1.3614 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6049 - accuracy: 0.4107 - val_loss: 1.3676 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6077 - accuracy: 0.3929 - val_loss: 1.3721 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5955 - accuracy: 0.3929 - val_loss: 1.3775 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6067 - accuracy: 0.4107 - val_loss: 1.3832 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5904 - accuracy: 0.4286 - val_loss: 1.3888 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5875 - accuracy: 0.4286 - val_loss: 1.3960 - val_accuracy: 0.0714\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5897 - accuracy: 0.3750 - val_loss: 1.4028 - val_accuracy: 0.0714\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5878 - accuracy: 0.3571 - val_loss: 1.4093 - val_accuracy: 0.0714\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5827 - accuracy: 0.3929 - val_loss: 1.4154 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5808 - accuracy: 0.4107 - val_loss: 1.4213 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5769 - accuracy: 0.3750 - val_loss: 1.4279 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5682 - accuracy: 0.3929 - val_loss: 1.4334 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5708 - accuracy: 0.3929 - val_loss: 1.4382 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5713 - accuracy: 0.4286 - val_loss: 1.4421 - val_accuracy: 0.1429\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5581 - accuracy: 0.3750 - val_loss: 1.4453 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5648 - accuracy: 0.3750 - val_loss: 1.4488 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5482 - accuracy: 0.4107 - val_loss: 1.4536 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5577 - accuracy: 0.3929 - val_loss: 1.4585 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5381 - accuracy: 0.3750 - val_loss: 1.4632 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5505 - accuracy: 0.3571 - val_loss: 1.4668 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5275 - accuracy: 0.4107 - val_loss: 1.4711 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5312 - accuracy: 0.4107 - val_loss: 1.4752 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5495 - accuracy: 0.3571 - val_loss: 1.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5383 - accuracy: 0.3750 - val_loss: 1.4790 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5193 - accuracy: 0.4107 - val_loss: 1.4813 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5193 - accuracy: 0.4107 - val_loss: 1.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5203 - accuracy: 0.3750 - val_loss: 1.4901 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5114 - accuracy: 0.4107 - val_loss: 1.4933 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4992 - accuracy: 0.3929 - val_loss: 1.4945 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5017 - accuracy: 0.4107 - val_loss: 1.4947 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4948 - accuracy: 0.4286 - val_loss: 1.4969 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4993 - accuracy: 0.4107 - val_loss: 1.5007 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4810 - accuracy: 0.4643 - val_loss: 1.5093 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4783 - accuracy: 0.4286 - val_loss: 1.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4788 - accuracy: 0.4107 - val_loss: 1.5262 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5262 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=128, batch_size=100, Scores: [1.52622389793396, 0.0]\n",
      "Accuracy on validation set: 0.0\n",
      "Loss on validation set: 1.52622389793396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9827 - accuracy: 0.0536 - val_loss: 1.0731 - val_accuracy: 0.1429\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.9808 - accuracy: 0.1071 - val_loss: 1.0739 - val_accuracy: 0.1429\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9762 - accuracy: 0.1786 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9729 - accuracy: 0.1429 - val_loss: 1.0757 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.9700 - accuracy: 0.1964 - val_loss: 1.0767 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.9649 - accuracy: 0.2857 - val_loss: 1.0778 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9616 - accuracy: 0.2321 - val_loss: 1.0789 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9597 - accuracy: 0.2143 - val_loss: 1.0800 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9541 - accuracy: 0.2679 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9526 - accuracy: 0.2857 - val_loss: 1.0823 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9467 - accuracy: 0.2857 - val_loss: 1.0835 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9407 - accuracy: 0.3571 - val_loss: 1.0847 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9425 - accuracy: 0.2679 - val_loss: 1.0859 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9372 - accuracy: 0.3393 - val_loss: 1.0872 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9288 - accuracy: 0.3036 - val_loss: 1.0886 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9271 - accuracy: 0.2500 - val_loss: 1.0900 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.9238 - accuracy: 0.2857 - val_loss: 1.0914 - val_accuracy: 0.1429\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.9202 - accuracy: 0.3214 - val_loss: 1.0930 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9131 - accuracy: 0.2857 - val_loss: 1.0945 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9069 - accuracy: 0.3393 - val_loss: 1.0961 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9005 - accuracy: 0.3393 - val_loss: 1.0978 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8998 - accuracy: 0.3214 - val_loss: 1.0996 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8921 - accuracy: 0.3036 - val_loss: 1.1016 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8843 - accuracy: 0.3214 - val_loss: 1.1037 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8796 - accuracy: 0.3214 - val_loss: 1.1060 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8721 - accuracy: 0.3036 - val_loss: 1.1085 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8679 - accuracy: 0.3036 - val_loss: 1.1112 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.8666 - accuracy: 0.3393 - val_loss: 1.1141 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8589 - accuracy: 0.2321 - val_loss: 1.1173 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8523 - accuracy: 0.3036 - val_loss: 1.1208 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8431 - accuracy: 0.2679 - val_loss: 1.1245 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8398 - accuracy: 0.3214 - val_loss: 1.1284 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8451 - accuracy: 0.3036 - val_loss: 1.1326 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8331 - accuracy: 0.3036 - val_loss: 1.1368 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8286 - accuracy: 0.3214 - val_loss: 1.1409 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8252 - accuracy: 0.3214 - val_loss: 1.1451 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8159 - accuracy: 0.3393 - val_loss: 1.1492 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.8146 - accuracy: 0.3571 - val_loss: 1.1534 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8043 - accuracy: 0.3393 - val_loss: 1.1577 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7982 - accuracy: 0.3393 - val_loss: 1.1620 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.7990 - accuracy: 0.3036 - val_loss: 1.1665 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7881 - accuracy: 0.3929 - val_loss: 1.1711 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7778 - accuracy: 0.3214 - val_loss: 1.1760 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7853 - accuracy: 0.3571 - val_loss: 1.1808 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7812 - accuracy: 0.3036 - val_loss: 1.1855 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7689 - accuracy: 0.3571 - val_loss: 1.1900 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7674 - accuracy: 0.3036 - val_loss: 1.1944 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7645 - accuracy: 0.3571 - val_loss: 1.1988 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7633 - accuracy: 0.3214 - val_loss: 1.2028 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7482 - accuracy: 0.3214 - val_loss: 1.2068 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7482 - accuracy: 0.3750 - val_loss: 1.2104 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7462 - accuracy: 0.3393 - val_loss: 1.2136 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7398 - accuracy: 0.3036 - val_loss: 1.2171 - val_accuracy: 0.1429\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7382 - accuracy: 0.3571 - val_loss: 1.2200 - val_accuracy: 0.1429\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7380 - accuracy: 0.3214 - val_loss: 1.2227 - val_accuracy: 0.1429\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7312 - accuracy: 0.3036 - val_loss: 1.2253 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7284 - accuracy: 0.3571 - val_loss: 1.2272 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7214 - accuracy: 0.3214 - val_loss: 1.2293 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7193 - accuracy: 0.3750 - val_loss: 1.2314 - val_accuracy: 0.0714\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7174 - accuracy: 0.3214 - val_loss: 1.2332 - val_accuracy: 0.0714\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.7060 - accuracy: 0.3393 - val_loss: 1.2355 - val_accuracy: 0.0714\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7187 - accuracy: 0.3750 - val_loss: 1.2380 - val_accuracy: 0.0714\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.7160 - accuracy: 0.3393 - val_loss: 1.2400 - val_accuracy: 0.0714\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.7031 - accuracy: 0.3393 - val_loss: 1.2424 - val_accuracy: 0.0714\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7081 - accuracy: 0.3571 - val_loss: 1.2449 - val_accuracy: 0.0714\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6926 - accuracy: 0.3571 - val_loss: 1.2476 - val_accuracy: 0.0714\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7078 - accuracy: 0.3036 - val_loss: 1.2502 - val_accuracy: 0.0714\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6838 - accuracy: 0.3036 - val_loss: 1.2521 - val_accuracy: 0.0714\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6898 - accuracy: 0.3393 - val_loss: 1.2544 - val_accuracy: 0.0714\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6777 - accuracy: 0.3750 - val_loss: 1.2570 - val_accuracy: 0.0714\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6786 - accuracy: 0.3750 - val_loss: 1.2602 - val_accuracy: 0.0714\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6711 - accuracy: 0.3393 - val_loss: 1.2633 - val_accuracy: 0.0714\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6795 - accuracy: 0.3750 - val_loss: 1.2676 - val_accuracy: 0.0714\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6731 - accuracy: 0.3393 - val_loss: 1.2725 - val_accuracy: 0.0714\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6575 - accuracy: 0.3036 - val_loss: 1.2792 - val_accuracy: 0.0714\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6526 - accuracy: 0.3036 - val_loss: 1.2863 - val_accuracy: 0.0714\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6618 - accuracy: 0.3393 - val_loss: 1.2938 - val_accuracy: 0.0714\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6520 - accuracy: 0.3393 - val_loss: 1.3023 - val_accuracy: 0.0714\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6437 - accuracy: 0.3214 - val_loss: 1.3101 - val_accuracy: 0.0714\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6442 - accuracy: 0.3750 - val_loss: 1.3172 - val_accuracy: 0.0714\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6432 - accuracy: 0.3750 - val_loss: 1.3242 - val_accuracy: 0.0714\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6273 - accuracy: 0.3750 - val_loss: 1.3306 - val_accuracy: 0.0714\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6333 - accuracy: 0.3571 - val_loss: 1.3371 - val_accuracy: 0.0714\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6335 - accuracy: 0.3750 - val_loss: 1.3424 - val_accuracy: 0.0714\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6284 - accuracy: 0.4464 - val_loss: 1.3480 - val_accuracy: 0.0714\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6218 - accuracy: 0.4286 - val_loss: 1.3540 - val_accuracy: 0.0714\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6149 - accuracy: 0.3929 - val_loss: 1.3601 - val_accuracy: 0.0714\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6003 - accuracy: 0.4107 - val_loss: 1.3646 - val_accuracy: 0.0714\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6145 - accuracy: 0.3036 - val_loss: 1.3688 - val_accuracy: 0.0714\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5996 - accuracy: 0.4286 - val_loss: 1.3730 - val_accuracy: 0.0714\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6071 - accuracy: 0.4643 - val_loss: 1.3779 - val_accuracy: 0.1429\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6080 - accuracy: 0.3929 - val_loss: 1.3818 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6000 - accuracy: 0.3929 - val_loss: 1.3860 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6090 - accuracy: 0.4286 - val_loss: 1.3901 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6001 - accuracy: 0.4107 - val_loss: 1.3953 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5777 - accuracy: 0.4286 - val_loss: 1.4001 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5829 - accuracy: 0.4821 - val_loss: 1.4040 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5934 - accuracy: 0.3929 - val_loss: 1.4073 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5745 - accuracy: 0.4107 - val_loss: 1.4089 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5745 - accuracy: 0.4107 - val_loss: 1.4092 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5728 - accuracy: 0.4464 - val_loss: 1.4091 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5605 - accuracy: 0.4821 - val_loss: 1.4097 - val_accuracy: 0.1429\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5666 - accuracy: 0.4107 - val_loss: 1.4091 - val_accuracy: 0.1429\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5591 - accuracy: 0.4107 - val_loss: 1.4109 - val_accuracy: 0.1429\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5601 - accuracy: 0.3750 - val_loss: 1.4136 - val_accuracy: 0.1429\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5487 - accuracy: 0.4107 - val_loss: 1.4197 - val_accuracy: 0.1429\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5584 - accuracy: 0.3929 - val_loss: 1.4275 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5357 - accuracy: 0.3929 - val_loss: 1.4364 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5510 - accuracy: 0.3929 - val_loss: 1.4443 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5545 - accuracy: 0.4286 - val_loss: 1.4521 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5374 - accuracy: 0.4286 - val_loss: 1.4581 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5219 - accuracy: 0.4286 - val_loss: 1.4635 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5501 - accuracy: 0.4464 - val_loss: 1.4667 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5252 - accuracy: 0.4643 - val_loss: 1.4684 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5395 - accuracy: 0.4107 - val_loss: 1.4704 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5321 - accuracy: 0.4286 - val_loss: 1.4721 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5256 - accuracy: 0.4107 - val_loss: 1.4727 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5083 - accuracy: 0.4821 - val_loss: 1.4732 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5181 - accuracy: 0.5000 - val_loss: 1.4723 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5137 - accuracy: 0.4821 - val_loss: 1.4700 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5098 - accuracy: 0.4643 - val_loss: 1.4688 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4983 - accuracy: 0.5179 - val_loss: 1.4704 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4912 - accuracy: 0.4464 - val_loss: 1.4717 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4973 - accuracy: 0.4286 - val_loss: 1.4744 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4952 - accuracy: 0.4464 - val_loss: 1.4763 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4909 - accuracy: 0.4286 - val_loss: 1.4809 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4878 - accuracy: 0.4643 - val_loss: 1.4844 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4841 - accuracy: 0.4643 - val_loss: 1.4870 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4870 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=128, batch_size=300, Scores: [1.487009048461914, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.487009048461914\n",
      "Epoch 1/128\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9823 - accuracy: 0.1429 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9800 - accuracy: 0.1786 - val_loss: 1.0736 - val_accuracy: 0.1429\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9768 - accuracy: 0.2321 - val_loss: 1.0744 - val_accuracy: 0.1429\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.9756 - accuracy: 0.2500 - val_loss: 1.0752 - val_accuracy: 0.1429\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.9695 - accuracy: 0.2857 - val_loss: 1.0762 - val_accuracy: 0.1429\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9653 - accuracy: 0.2143 - val_loss: 1.0772 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9625 - accuracy: 0.2679 - val_loss: 1.0782 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9605 - accuracy: 0.3036 - val_loss: 1.0792 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9548 - accuracy: 0.2857 - val_loss: 1.0803 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.9527 - accuracy: 0.2857 - val_loss: 1.0814 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9472 - accuracy: 0.1964 - val_loss: 1.0825 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.9466 - accuracy: 0.2857 - val_loss: 1.0836 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.9389 - accuracy: 0.3214 - val_loss: 1.0848 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9355 - accuracy: 0.2857 - val_loss: 1.0860 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9348 - accuracy: 0.3036 - val_loss: 1.0873 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9296 - accuracy: 0.3393 - val_loss: 1.0886 - val_accuracy: 0.1429\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.9254 - accuracy: 0.3214 - val_loss: 1.0899 - val_accuracy: 0.2143\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9219 - accuracy: 0.3036 - val_loss: 1.0913 - val_accuracy: 0.1429\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9141 - accuracy: 0.3571 - val_loss: 1.0928 - val_accuracy: 0.1429\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9124 - accuracy: 0.3214 - val_loss: 1.0943 - val_accuracy: 0.1429\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9047 - accuracy: 0.3393 - val_loss: 1.0959 - val_accuracy: 0.1429\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8981 - accuracy: 0.3036 - val_loss: 1.0977 - val_accuracy: 0.1429\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8929 - accuracy: 0.3571 - val_loss: 1.0995 - val_accuracy: 0.1429\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8895 - accuracy: 0.3393 - val_loss: 1.1015 - val_accuracy: 0.1429\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8825 - accuracy: 0.3393 - val_loss: 1.1037 - val_accuracy: 0.1429\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.8792 - accuracy: 0.3393 - val_loss: 1.1062 - val_accuracy: 0.1429\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8742 - accuracy: 0.3393 - val_loss: 1.1089 - val_accuracy: 0.1429\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8662 - accuracy: 0.3393 - val_loss: 1.1119 - val_accuracy: 0.1429\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8598 - accuracy: 0.3571 - val_loss: 1.1150 - val_accuracy: 0.1429\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8560 - accuracy: 0.3393 - val_loss: 1.1184 - val_accuracy: 0.1429\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.8449 - accuracy: 0.3393 - val_loss: 1.1221 - val_accuracy: 0.1429\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8439 - accuracy: 0.3929 - val_loss: 1.1261 - val_accuracy: 0.1429\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8369 - accuracy: 0.3750 - val_loss: 1.1304 - val_accuracy: 0.1429\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8350 - accuracy: 0.3929 - val_loss: 1.1347 - val_accuracy: 0.1429\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8293 - accuracy: 0.3214 - val_loss: 1.1392 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8236 - accuracy: 0.3393 - val_loss: 1.1437 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8185 - accuracy: 0.3571 - val_loss: 1.1482 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.8172 - accuracy: 0.3571 - val_loss: 1.1530 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8113 - accuracy: 0.3571 - val_loss: 1.1579 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8078 - accuracy: 0.3393 - val_loss: 1.1632 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.8047 - accuracy: 0.3393 - val_loss: 1.1687 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8063 - accuracy: 0.3393 - val_loss: 1.1743 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7979 - accuracy: 0.3393 - val_loss: 1.1798 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7938 - accuracy: 0.3393 - val_loss: 1.1854 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7875 - accuracy: 0.3393 - val_loss: 1.1908 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7900 - accuracy: 0.3571 - val_loss: 1.1962 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7833 - accuracy: 0.3393 - val_loss: 1.2015 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7751 - accuracy: 0.3393 - val_loss: 1.2069 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.7668 - accuracy: 0.3750 - val_loss: 1.2126 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.7710 - accuracy: 0.3571 - val_loss: 1.2183 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.7596 - accuracy: 0.3571 - val_loss: 1.2237 - val_accuracy: 0.0714\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7583 - accuracy: 0.3750 - val_loss: 1.2292 - val_accuracy: 0.0714\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7629 - accuracy: 0.3571 - val_loss: 1.2341 - val_accuracy: 0.0714\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7532 - accuracy: 0.3929 - val_loss: 1.2389 - val_accuracy: 0.0714\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7496 - accuracy: 0.4107 - val_loss: 1.2436 - val_accuracy: 0.0714\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7476 - accuracy: 0.3750 - val_loss: 1.2480 - val_accuracy: 0.1429\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7511 - accuracy: 0.3929 - val_loss: 1.2518 - val_accuracy: 0.1429\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7400 - accuracy: 0.4107 - val_loss: 1.2554 - val_accuracy: 0.1429\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7425 - accuracy: 0.4107 - val_loss: 1.2585 - val_accuracy: 0.1429\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7253 - accuracy: 0.3393 - val_loss: 1.2616 - val_accuracy: 0.1429\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.7250 - accuracy: 0.4107 - val_loss: 1.2641 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7193 - accuracy: 0.4107 - val_loss: 1.2666 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7249 - accuracy: 0.3929 - val_loss: 1.2689 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7210 - accuracy: 0.3571 - val_loss: 1.2715 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7084 - accuracy: 0.3929 - val_loss: 1.2748 - val_accuracy: 0.2143\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7059 - accuracy: 0.3929 - val_loss: 1.2784 - val_accuracy: 0.2143\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7144 - accuracy: 0.3750 - val_loss: 1.2821 - val_accuracy: 0.2143\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7005 - accuracy: 0.3393 - val_loss: 1.2861 - val_accuracy: 0.2143\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7001 - accuracy: 0.3750 - val_loss: 1.2901 - val_accuracy: 0.2143\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6951 - accuracy: 0.3929 - val_loss: 1.2936 - val_accuracy: 0.2143\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6896 - accuracy: 0.3750 - val_loss: 1.2971 - val_accuracy: 0.2143\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6912 - accuracy: 0.3571 - val_loss: 1.3009 - val_accuracy: 0.2143\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6857 - accuracy: 0.3750 - val_loss: 1.3041 - val_accuracy: 0.2143\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6747 - accuracy: 0.3571 - val_loss: 1.3078 - val_accuracy: 0.2143\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6841 - accuracy: 0.4107 - val_loss: 1.3113 - val_accuracy: 0.2143\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6679 - accuracy: 0.4107 - val_loss: 1.3151 - val_accuracy: 0.2143\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6669 - accuracy: 0.3393 - val_loss: 1.3192 - val_accuracy: 0.2143\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6722 - accuracy: 0.3929 - val_loss: 1.3227 - val_accuracy: 0.2143\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6562 - accuracy: 0.3571 - val_loss: 1.3267 - val_accuracy: 0.2143\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6486 - accuracy: 0.3929 - val_loss: 1.3312 - val_accuracy: 0.2143\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6549 - accuracy: 0.3571 - val_loss: 1.3367 - val_accuracy: 0.2143\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.6381 - accuracy: 0.4107 - val_loss: 1.3446 - val_accuracy: 0.2143\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6409 - accuracy: 0.4107 - val_loss: 1.3529 - val_accuracy: 0.2143\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6444 - accuracy: 0.3750 - val_loss: 1.3625 - val_accuracy: 0.1429\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6307 - accuracy: 0.4643 - val_loss: 1.3728 - val_accuracy: 0.1429\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6384 - accuracy: 0.3750 - val_loss: 1.3835 - val_accuracy: 0.1429\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6269 - accuracy: 0.3929 - val_loss: 1.3939 - val_accuracy: 0.1429\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6156 - accuracy: 0.4286 - val_loss: 1.4045 - val_accuracy: 0.1429\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6172 - accuracy: 0.4286 - val_loss: 1.4141 - val_accuracy: 0.1429\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.6128 - accuracy: 0.4107 - val_loss: 1.4231 - val_accuracy: 0.2143\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6131 - accuracy: 0.4286 - val_loss: 1.4315 - val_accuracy: 0.2143\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6117 - accuracy: 0.3929 - val_loss: 1.4383 - val_accuracy: 0.2143\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6036 - accuracy: 0.3571 - val_loss: 1.4432 - val_accuracy: 0.2143\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6053 - accuracy: 0.3929 - val_loss: 1.4460 - val_accuracy: 0.2143\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5926 - accuracy: 0.3750 - val_loss: 1.4467 - val_accuracy: 0.2143\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5988 - accuracy: 0.4107 - val_loss: 1.4447 - val_accuracy: 0.2143\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6033 - accuracy: 0.4286 - val_loss: 1.4433 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5974 - accuracy: 0.3929 - val_loss: 1.4442 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5788 - accuracy: 0.3571 - val_loss: 1.4452 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5835 - accuracy: 0.3750 - val_loss: 1.4466 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5739 - accuracy: 0.4286 - val_loss: 1.4474 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5831 - accuracy: 0.3929 - val_loss: 1.4497 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5648 - accuracy: 0.3571 - val_loss: 1.4511 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5558 - accuracy: 0.3750 - val_loss: 1.4543 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5577 - accuracy: 0.4107 - val_loss: 1.4577 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5733 - accuracy: 0.3750 - val_loss: 1.4606 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5639 - accuracy: 0.3750 - val_loss: 1.4631 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5594 - accuracy: 0.4107 - val_loss: 1.4626 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5540 - accuracy: 0.4464 - val_loss: 1.4606 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5623 - accuracy: 0.3929 - val_loss: 1.4583 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5419 - accuracy: 0.3750 - val_loss: 1.4590 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5463 - accuracy: 0.4643 - val_loss: 1.4604 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5309 - accuracy: 0.4107 - val_loss: 1.4643 - val_accuracy: 0.0714\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5487 - accuracy: 0.4286 - val_loss: 1.4663 - val_accuracy: 0.0714\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5242 - accuracy: 0.4464 - val_loss: 1.4655 - val_accuracy: 0.0714\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5366 - accuracy: 0.3571 - val_loss: 1.4637 - val_accuracy: 0.0714\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.5297 - accuracy: 0.4464 - val_loss: 1.4602 - val_accuracy: 0.0714\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5144 - accuracy: 0.3571 - val_loss: 1.4589 - val_accuracy: 0.0714\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5063 - accuracy: 0.3929 - val_loss: 1.4591 - val_accuracy: 0.0714\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5163 - accuracy: 0.4464 - val_loss: 1.4592 - val_accuracy: 0.0714\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5159 - accuracy: 0.4107 - val_loss: 1.4615 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4978 - accuracy: 0.4286 - val_loss: 1.4632 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5216 - accuracy: 0.4821 - val_loss: 1.4660 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4973 - accuracy: 0.4107 - val_loss: 1.4665 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4981 - accuracy: 0.4464 - val_loss: 1.4683 - val_accuracy: 0.0714\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5040 - accuracy: 0.4286 - val_loss: 1.4687 - val_accuracy: 0.0714\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4769 - accuracy: 0.4464 - val_loss: 1.4682 - val_accuracy: 0.0714\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4940 - accuracy: 0.4107 - val_loss: 1.4671 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4671 - accuracy: 0.0714\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=128, batch_size=400, Scores: [1.467079758644104, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.467079758644104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.9845 - accuracy: 0.0714 - val_loss: 1.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/128\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.9793 - accuracy: 0.1607 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 3/128\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9758 - accuracy: 0.2500 - val_loss: 1.0716 - val_accuracy: 0.0714\n",
      "Epoch 4/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9727 - accuracy: 0.2321 - val_loss: 1.0724 - val_accuracy: 0.0714\n",
      "Epoch 5/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9692 - accuracy: 0.3036 - val_loss: 1.0732 - val_accuracy: 0.0714\n",
      "Epoch 6/128\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.9641 - accuracy: 0.2143 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 7/128\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.9607 - accuracy: 0.3571 - val_loss: 1.0750 - val_accuracy: 0.0714\n",
      "Epoch 8/128\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9582 - accuracy: 0.2143 - val_loss: 1.0758 - val_accuracy: 0.0714\n",
      "Epoch 9/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9576 - accuracy: 0.2679 - val_loss: 1.0768 - val_accuracy: 0.0714\n",
      "Epoch 10/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9523 - accuracy: 0.2679 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 11/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9474 - accuracy: 0.2857 - val_loss: 1.0787 - val_accuracy: 0.0714\n",
      "Epoch 12/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9421 - accuracy: 0.3571 - val_loss: 1.0798 - val_accuracy: 0.0714\n",
      "Epoch 13/128\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9393 - accuracy: 0.2857 - val_loss: 1.0808 - val_accuracy: 0.0714\n",
      "Epoch 14/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9381 - accuracy: 0.2679 - val_loss: 1.0819 - val_accuracy: 0.0714\n",
      "Epoch 15/128\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9332 - accuracy: 0.3214 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 16/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9259 - accuracy: 0.3214 - val_loss: 1.0843 - val_accuracy: 0.0714\n",
      "Epoch 17/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9235 - accuracy: 0.3393 - val_loss: 1.0856 - val_accuracy: 0.0714\n",
      "Epoch 18/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9185 - accuracy: 0.3214 - val_loss: 1.0869 - val_accuracy: 0.0714\n",
      "Epoch 19/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9148 - accuracy: 0.3036 - val_loss: 1.0883 - val_accuracy: 0.0714\n",
      "Epoch 20/128\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9115 - accuracy: 0.3214 - val_loss: 1.0897 - val_accuracy: 0.0714\n",
      "Epoch 21/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.9031 - accuracy: 0.3036 - val_loss: 1.0913 - val_accuracy: 0.0714\n",
      "Epoch 22/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.9009 - accuracy: 0.3214 - val_loss: 1.0929 - val_accuracy: 0.0714\n",
      "Epoch 23/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8954 - accuracy: 0.3036 - val_loss: 1.0947 - val_accuracy: 0.0714\n",
      "Epoch 24/128\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.8912 - accuracy: 0.2500 - val_loss: 1.0965 - val_accuracy: 0.0714\n",
      "Epoch 25/128\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.8853 - accuracy: 0.3393 - val_loss: 1.0983 - val_accuracy: 0.0714\n",
      "Epoch 26/128\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.8776 - accuracy: 0.3036 - val_loss: 1.1004 - val_accuracy: 0.0714\n",
      "Epoch 27/128\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8757 - accuracy: 0.3036 - val_loss: 1.1025 - val_accuracy: 0.0714\n",
      "Epoch 28/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8725 - accuracy: 0.2857 - val_loss: 1.1049 - val_accuracy: 0.0714\n",
      "Epoch 29/128\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8660 - accuracy: 0.3214 - val_loss: 1.1074 - val_accuracy: 0.0714\n",
      "Epoch 30/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8581 - accuracy: 0.2679 - val_loss: 1.1103 - val_accuracy: 0.0714\n",
      "Epoch 31/128\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8552 - accuracy: 0.2857 - val_loss: 1.1137 - val_accuracy: 0.0714\n",
      "Epoch 32/128\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.8466 - accuracy: 0.2500 - val_loss: 1.1174 - val_accuracy: 0.0714\n",
      "Epoch 33/128\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.8478 - accuracy: 0.3036 - val_loss: 1.1216 - val_accuracy: 0.0714\n",
      "Epoch 34/128\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.8378 - accuracy: 0.3214 - val_loss: 1.1260 - val_accuracy: 0.0714\n",
      "Epoch 35/128\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8328 - accuracy: 0.2679 - val_loss: 1.1308 - val_accuracy: 0.1429\n",
      "Epoch 36/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8295 - accuracy: 0.2857 - val_loss: 1.1361 - val_accuracy: 0.1429\n",
      "Epoch 37/128\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8268 - accuracy: 0.2679 - val_loss: 1.1418 - val_accuracy: 0.1429\n",
      "Epoch 38/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8157 - accuracy: 0.2857 - val_loss: 1.1478 - val_accuracy: 0.1429\n",
      "Epoch 39/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8118 - accuracy: 0.2679 - val_loss: 1.1543 - val_accuracy: 0.1429\n",
      "Epoch 40/128\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8116 - accuracy: 0.2857 - val_loss: 1.1609 - val_accuracy: 0.1429\n",
      "Epoch 41/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7952 - accuracy: 0.3214 - val_loss: 1.1680 - val_accuracy: 0.1429\n",
      "Epoch 42/128\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8033 - accuracy: 0.2679 - val_loss: 1.1754 - val_accuracy: 0.1429\n",
      "Epoch 43/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7914 - accuracy: 0.2679 - val_loss: 1.1828 - val_accuracy: 0.1429\n",
      "Epoch 44/128\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7860 - accuracy: 0.3036 - val_loss: 1.1904 - val_accuracy: 0.1429\n",
      "Epoch 45/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7874 - accuracy: 0.3036 - val_loss: 1.1977 - val_accuracy: 0.1429\n",
      "Epoch 46/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7829 - accuracy: 0.3036 - val_loss: 1.2045 - val_accuracy: 0.1429\n",
      "Epoch 47/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7700 - accuracy: 0.3036 - val_loss: 1.2109 - val_accuracy: 0.1429\n",
      "Epoch 48/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7792 - accuracy: 0.3571 - val_loss: 1.2165 - val_accuracy: 0.1429\n",
      "Epoch 49/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7651 - accuracy: 0.3571 - val_loss: 1.2219 - val_accuracy: 0.1429\n",
      "Epoch 50/128\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7578 - accuracy: 0.3750 - val_loss: 1.2267 - val_accuracy: 0.1429\n",
      "Epoch 51/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7533 - accuracy: 0.3036 - val_loss: 1.2318 - val_accuracy: 0.1429\n",
      "Epoch 52/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7618 - accuracy: 0.3750 - val_loss: 1.2364 - val_accuracy: 0.1429\n",
      "Epoch 53/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7562 - accuracy: 0.3393 - val_loss: 1.2405 - val_accuracy: 0.2143\n",
      "Epoch 54/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7464 - accuracy: 0.3393 - val_loss: 1.2447 - val_accuracy: 0.2143\n",
      "Epoch 55/128\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7308 - accuracy: 0.3929 - val_loss: 1.2490 - val_accuracy: 0.2143\n",
      "Epoch 56/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7366 - accuracy: 0.3393 - val_loss: 1.2529 - val_accuracy: 0.2143\n",
      "Epoch 57/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7419 - accuracy: 0.3214 - val_loss: 1.2562 - val_accuracy: 0.2143\n",
      "Epoch 58/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7237 - accuracy: 0.3571 - val_loss: 1.2597 - val_accuracy: 0.2143\n",
      "Epoch 59/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7242 - accuracy: 0.3571 - val_loss: 1.2632 - val_accuracy: 0.2143\n",
      "Epoch 60/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7311 - accuracy: 0.3393 - val_loss: 1.2659 - val_accuracy: 0.2143\n",
      "Epoch 61/128\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.7349 - accuracy: 0.3571 - val_loss: 1.2678 - val_accuracy: 0.1429\n",
      "Epoch 62/128\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.7209 - accuracy: 0.3393 - val_loss: 1.2694 - val_accuracy: 0.1429\n",
      "Epoch 63/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7179 - accuracy: 0.3571 - val_loss: 1.2708 - val_accuracy: 0.1429\n",
      "Epoch 64/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7235 - accuracy: 0.3571 - val_loss: 1.2716 - val_accuracy: 0.1429\n",
      "Epoch 65/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7075 - accuracy: 0.3393 - val_loss: 1.2723 - val_accuracy: 0.1429\n",
      "Epoch 66/128\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.7066 - accuracy: 0.3750 - val_loss: 1.2730 - val_accuracy: 0.1429\n",
      "Epoch 67/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7109 - accuracy: 0.3750 - val_loss: 1.2737 - val_accuracy: 0.1429\n",
      "Epoch 68/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6968 - accuracy: 0.3393 - val_loss: 1.2747 - val_accuracy: 0.1429\n",
      "Epoch 69/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6970 - accuracy: 0.3571 - val_loss: 1.2756 - val_accuracy: 0.2143\n",
      "Epoch 70/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6906 - accuracy: 0.4107 - val_loss: 1.2770 - val_accuracy: 0.2143\n",
      "Epoch 71/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6851 - accuracy: 0.3214 - val_loss: 1.2789 - val_accuracy: 0.2143\n",
      "Epoch 72/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6866 - accuracy: 0.3750 - val_loss: 1.2805 - val_accuracy: 0.2143\n",
      "Epoch 73/128\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6852 - accuracy: 0.3393 - val_loss: 1.2820 - val_accuracy: 0.2143\n",
      "Epoch 74/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6806 - accuracy: 0.3929 - val_loss: 1.2833 - val_accuracy: 0.2143\n",
      "Epoch 75/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6777 - accuracy: 0.3750 - val_loss: 1.2848 - val_accuracy: 0.2143\n",
      "Epoch 76/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6663 - accuracy: 0.3929 - val_loss: 1.2865 - val_accuracy: 0.2143\n",
      "Epoch 77/128\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6761 - accuracy: 0.4286 - val_loss: 1.2878 - val_accuracy: 0.2143\n",
      "Epoch 78/128\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6700 - accuracy: 0.4107 - val_loss: 1.2887 - val_accuracy: 0.2143\n",
      "Epoch 79/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6677 - accuracy: 0.3750 - val_loss: 1.2892 - val_accuracy: 0.2143\n",
      "Epoch 80/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6548 - accuracy: 0.3571 - val_loss: 1.2920 - val_accuracy: 0.2143\n",
      "Epoch 81/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6603 - accuracy: 0.3929 - val_loss: 1.2960 - val_accuracy: 0.2143\n",
      "Epoch 82/128\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6572 - accuracy: 0.4286 - val_loss: 1.3005 - val_accuracy: 0.2143\n",
      "Epoch 83/128\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6457 - accuracy: 0.4107 - val_loss: 1.3047 - val_accuracy: 0.2143\n",
      "Epoch 84/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6569 - accuracy: 0.3571 - val_loss: 1.3097 - val_accuracy: 0.2143\n",
      "Epoch 85/128\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6479 - accuracy: 0.4286 - val_loss: 1.3157 - val_accuracy: 0.2143\n",
      "Epoch 86/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6361 - accuracy: 0.3929 - val_loss: 1.3223 - val_accuracy: 0.2143\n",
      "Epoch 87/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6390 - accuracy: 0.4286 - val_loss: 1.3269 - val_accuracy: 0.2143\n",
      "Epoch 88/128\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6346 - accuracy: 0.4107 - val_loss: 1.3297 - val_accuracy: 0.2143\n",
      "Epoch 89/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6210 - accuracy: 0.4464 - val_loss: 1.3318 - val_accuracy: 0.2143\n",
      "Epoch 90/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6185 - accuracy: 0.4286 - val_loss: 1.3334 - val_accuracy: 0.2143\n",
      "Epoch 91/128\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6331 - accuracy: 0.4286 - val_loss: 1.3355 - val_accuracy: 0.2143\n",
      "Epoch 92/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6273 - accuracy: 0.3571 - val_loss: 1.3375 - val_accuracy: 0.1429\n",
      "Epoch 93/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6215 - accuracy: 0.3929 - val_loss: 1.3377 - val_accuracy: 0.1429\n",
      "Epoch 94/128\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6209 - accuracy: 0.4286 - val_loss: 1.3367 - val_accuracy: 0.1429\n",
      "Epoch 95/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6093 - accuracy: 0.3929 - val_loss: 1.3353 - val_accuracy: 0.1429\n",
      "Epoch 96/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6050 - accuracy: 0.3750 - val_loss: 1.3336 - val_accuracy: 0.1429\n",
      "Epoch 97/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6131 - accuracy: 0.4107 - val_loss: 1.3332 - val_accuracy: 0.1429\n",
      "Epoch 98/128\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6062 - accuracy: 0.4286 - val_loss: 1.3357 - val_accuracy: 0.1429\n",
      "Epoch 99/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5877 - accuracy: 0.4107 - val_loss: 1.3399 - val_accuracy: 0.1429\n",
      "Epoch 100/128\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.5847 - accuracy: 0.3929 - val_loss: 1.3460 - val_accuracy: 0.1429\n",
      "Epoch 101/128\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5796 - accuracy: 0.4107 - val_loss: 1.3537 - val_accuracy: 0.1429\n",
      "Epoch 102/128\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.5717 - accuracy: 0.3929 - val_loss: 1.3591 - val_accuracy: 0.0714\n",
      "Epoch 103/128\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5738 - accuracy: 0.4286 - val_loss: 1.3628 - val_accuracy: 0.0714\n",
      "Epoch 104/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5796 - accuracy: 0.3929 - val_loss: 1.3645 - val_accuracy: 0.0714\n",
      "Epoch 105/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5823 - accuracy: 0.4107 - val_loss: 1.3640 - val_accuracy: 0.0714\n",
      "Epoch 106/128\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5634 - accuracy: 0.3929 - val_loss: 1.3627 - val_accuracy: 0.0714\n",
      "Epoch 107/128\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5574 - accuracy: 0.3571 - val_loss: 1.3610 - val_accuracy: 0.0714\n",
      "Epoch 108/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5444 - accuracy: 0.4286 - val_loss: 1.3628 - val_accuracy: 0.0714\n",
      "Epoch 109/128\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5652 - accuracy: 0.3929 - val_loss: 1.3635 - val_accuracy: 0.0714\n",
      "Epoch 110/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5398 - accuracy: 0.4286 - val_loss: 1.3665 - val_accuracy: 0.0714\n",
      "Epoch 111/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5443 - accuracy: 0.4286 - val_loss: 1.3724 - val_accuracy: 0.0714\n",
      "Epoch 112/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5404 - accuracy: 0.3929 - val_loss: 1.3804 - val_accuracy: 0.0714\n",
      "Epoch 113/128\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5433 - accuracy: 0.4107 - val_loss: 1.3880 - val_accuracy: 0.1429\n",
      "Epoch 114/128\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5279 - accuracy: 0.4286 - val_loss: 1.3972 - val_accuracy: 0.1429\n",
      "Epoch 115/128\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5215 - accuracy: 0.4286 - val_loss: 1.4069 - val_accuracy: 0.1429\n",
      "Epoch 116/128\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5137 - accuracy: 0.4286 - val_loss: 1.4142 - val_accuracy: 0.1429\n",
      "Epoch 117/128\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5143 - accuracy: 0.4643 - val_loss: 1.4167 - val_accuracy: 0.1429\n",
      "Epoch 118/128\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5229 - accuracy: 0.4286 - val_loss: 1.4149 - val_accuracy: 0.1429\n",
      "Epoch 119/128\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5138 - accuracy: 0.4464 - val_loss: 1.4152 - val_accuracy: 0.1429\n",
      "Epoch 120/128\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5079 - accuracy: 0.4107 - val_loss: 1.4122 - val_accuracy: 0.1429\n",
      "Epoch 121/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4947 - accuracy: 0.4286 - val_loss: 1.4110 - val_accuracy: 0.0714\n",
      "Epoch 122/128\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4965 - accuracy: 0.4464 - val_loss: 1.4105 - val_accuracy: 0.0714\n",
      "Epoch 123/128\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5016 - accuracy: 0.4107 - val_loss: 1.4121 - val_accuracy: 0.0714\n",
      "Epoch 124/128\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4917 - accuracy: 0.4107 - val_loss: 1.4138 - val_accuracy: 0.0714\n",
      "Epoch 125/128\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4799 - accuracy: 0.4107 - val_loss: 1.4194 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/128\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4905 - accuracy: 0.4107 - val_loss: 1.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/128\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4660 - accuracy: 0.4286 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/128\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4725 - accuracy: 0.4464 - val_loss: 1.4287 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4287 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=128, batch_size=500, Scores: [1.4287492036819458, 0.0]\n",
      "Accuracy on validation set: 0.0\n",
      "Loss on validation set: 1.4287492036819458\n",
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9840 - accuracy: 0.1250 - val_loss: 1.0658 - val_accuracy: 0.1429\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.9802 - accuracy: 0.2679 - val_loss: 1.0664 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9796 - accuracy: 0.2321 - val_loss: 1.0672 - val_accuracy: 0.1429\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.9759 - accuracy: 0.3036 - val_loss: 1.0679 - val_accuracy: 0.2143\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9733 - accuracy: 0.3036 - val_loss: 1.0687 - val_accuracy: 0.2143\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.9689 - accuracy: 0.3214 - val_loss: 1.0696 - val_accuracy: 0.2143\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.9631 - accuracy: 0.3929 - val_loss: 1.0704 - val_accuracy: 0.2857\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9617 - accuracy: 0.3214 - val_loss: 1.0713 - val_accuracy: 0.2857\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9573 - accuracy: 0.2679 - val_loss: 1.0723 - val_accuracy: 0.2857\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9544 - accuracy: 0.3393 - val_loss: 1.0732 - val_accuracy: 0.2857\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9499 - accuracy: 0.2679 - val_loss: 1.0741 - val_accuracy: 0.2857\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9472 - accuracy: 0.3036 - val_loss: 1.0751 - val_accuracy: 0.2857\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9441 - accuracy: 0.3214 - val_loss: 1.0761 - val_accuracy: 0.2857\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.9395 - accuracy: 0.3393 - val_loss: 1.0771 - val_accuracy: 0.2143\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9360 - accuracy: 0.3214 - val_loss: 1.0782 - val_accuracy: 0.2143\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9318 - accuracy: 0.3393 - val_loss: 1.0793 - val_accuracy: 0.2143\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.9272 - accuracy: 0.3393 - val_loss: 1.0805 - val_accuracy: 0.2143\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.9233 - accuracy: 0.3571 - val_loss: 1.0817 - val_accuracy: 0.2143\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9166 - accuracy: 0.2857 - val_loss: 1.0829 - val_accuracy: 0.2143\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9128 - accuracy: 0.3036 - val_loss: 1.0842 - val_accuracy: 0.2143\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9082 - accuracy: 0.3214 - val_loss: 1.0856 - val_accuracy: 0.2143\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9011 - accuracy: 0.3214 - val_loss: 1.0870 - val_accuracy: 0.2143\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8954 - accuracy: 0.3214 - val_loss: 1.0886 - val_accuracy: 0.2143\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8927 - accuracy: 0.3036 - val_loss: 1.0904 - val_accuracy: 0.2143\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8868 - accuracy: 0.3214 - val_loss: 1.0923 - val_accuracy: 0.2143\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8789 - accuracy: 0.3393 - val_loss: 1.0943 - val_accuracy: 0.2143\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8701 - accuracy: 0.3571 - val_loss: 1.0965 - val_accuracy: 0.2143\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.8669 - accuracy: 0.3214 - val_loss: 1.0990 - val_accuracy: 0.2143\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.8637 - accuracy: 0.3036 - val_loss: 1.1017 - val_accuracy: 0.2143\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8552 - accuracy: 0.3036 - val_loss: 1.1047 - val_accuracy: 0.2143\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8536 - accuracy: 0.2679 - val_loss: 1.1080 - val_accuracy: 0.2143\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8464 - accuracy: 0.3036 - val_loss: 1.1115 - val_accuracy: 0.2143\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.8438 - accuracy: 0.2857 - val_loss: 1.1153 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8340 - accuracy: 0.2857 - val_loss: 1.1194 - val_accuracy: 0.2143\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8326 - accuracy: 0.3036 - val_loss: 1.1236 - val_accuracy: 0.2143\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8294 - accuracy: 0.3036 - val_loss: 1.1279 - val_accuracy: 0.2143\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8255 - accuracy: 0.3036 - val_loss: 1.1325 - val_accuracy: 0.2143\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8231 - accuracy: 0.3571 - val_loss: 1.1371 - val_accuracy: 0.2143\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8123 - accuracy: 0.2857 - val_loss: 1.1418 - val_accuracy: 0.2143\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8153 - accuracy: 0.3214 - val_loss: 1.1464 - val_accuracy: 0.2143\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8121 - accuracy: 0.3214 - val_loss: 1.1513 - val_accuracy: 0.2143\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8026 - accuracy: 0.3036 - val_loss: 1.1564 - val_accuracy: 0.2143\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7999 - accuracy: 0.2857 - val_loss: 1.1614 - val_accuracy: 0.2143\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7955 - accuracy: 0.3214 - val_loss: 1.1664 - val_accuracy: 0.2143\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7930 - accuracy: 0.3214 - val_loss: 1.1713 - val_accuracy: 0.2143\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7891 - accuracy: 0.3393 - val_loss: 1.1763 - val_accuracy: 0.2143\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7839 - accuracy: 0.2679 - val_loss: 1.1811 - val_accuracy: 0.2143\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7791 - accuracy: 0.2857 - val_loss: 1.1857 - val_accuracy: 0.2143\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7764 - accuracy: 0.2679 - val_loss: 1.1899 - val_accuracy: 0.2143\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7761 - accuracy: 0.2857 - val_loss: 1.1939 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7625 - accuracy: 0.3036 - val_loss: 1.1981 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7570 - accuracy: 0.3393 - val_loss: 1.2020 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7649 - accuracy: 0.2857 - val_loss: 1.2056 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.7535 - accuracy: 0.3571 - val_loss: 1.2091 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7495 - accuracy: 0.3393 - val_loss: 1.2123 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7451 - accuracy: 0.3036 - val_loss: 1.2150 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7498 - accuracy: 0.3036 - val_loss: 1.2176 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7398 - accuracy: 0.3214 - val_loss: 1.2199 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7272 - accuracy: 0.3214 - val_loss: 1.2224 - val_accuracy: 0.1429\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7353 - accuracy: 0.3393 - val_loss: 1.2241 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7335 - accuracy: 0.3750 - val_loss: 1.2254 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7239 - accuracy: 0.3750 - val_loss: 1.2270 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7167 - accuracy: 0.3929 - val_loss: 1.2289 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7220 - accuracy: 0.3750 - val_loss: 1.2307 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7151 - accuracy: 0.3929 - val_loss: 1.2328 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7122 - accuracy: 0.3571 - val_loss: 1.2353 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7134 - accuracy: 0.3571 - val_loss: 1.2381 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7118 - accuracy: 0.4107 - val_loss: 1.2402 - val_accuracy: 0.0714\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7098 - accuracy: 0.4107 - val_loss: 1.2427 - val_accuracy: 0.0714\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6866 - accuracy: 0.4107 - val_loss: 1.2454 - val_accuracy: 0.0714\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6945 - accuracy: 0.3750 - val_loss: 1.2478 - val_accuracy: 0.0714\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6956 - accuracy: 0.4286 - val_loss: 1.2503 - val_accuracy: 0.0714\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6959 - accuracy: 0.3750 - val_loss: 1.2520 - val_accuracy: 0.0714\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6849 - accuracy: 0.3929 - val_loss: 1.2535 - val_accuracy: 0.0714\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6843 - accuracy: 0.3571 - val_loss: 1.2543 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.6720 - accuracy: 0.4286 - val_loss: 1.2555 - val_accuracy: 0.0714\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6825 - accuracy: 0.4107 - val_loss: 1.2574 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6621 - accuracy: 0.4286 - val_loss: 1.2598 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6687 - accuracy: 0.3929 - val_loss: 1.2618 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6635 - accuracy: 0.3750 - val_loss: 1.2645 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6640 - accuracy: 0.3571 - val_loss: 1.2670 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6555 - accuracy: 0.3571 - val_loss: 1.2705 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6463 - accuracy: 0.4107 - val_loss: 1.2735 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6454 - accuracy: 0.4286 - val_loss: 1.2775 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.6318 - accuracy: 0.3929 - val_loss: 1.2820 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.6517 - accuracy: 0.3571 - val_loss: 1.2864 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6323 - accuracy: 0.3929 - val_loss: 1.2912 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6348 - accuracy: 0.3750 - val_loss: 1.2967 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6227 - accuracy: 0.3750 - val_loss: 1.3020 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6223 - accuracy: 0.4107 - val_loss: 1.3066 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6259 - accuracy: 0.3929 - val_loss: 1.3103 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6135 - accuracy: 0.3750 - val_loss: 1.3134 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6056 - accuracy: 0.4464 - val_loss: 1.3177 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5971 - accuracy: 0.3750 - val_loss: 1.3228 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6110 - accuracy: 0.3929 - val_loss: 1.3285 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6227 - accuracy: 0.3929 - val_loss: 1.3339 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6016 - accuracy: 0.3750 - val_loss: 1.3392 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5960 - accuracy: 0.4464 - val_loss: 1.3443 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5868 - accuracy: 0.3929 - val_loss: 1.3499 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5941 - accuracy: 0.3214 - val_loss: 1.3548 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5831 - accuracy: 0.4286 - val_loss: 1.3585 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5769 - accuracy: 0.3929 - val_loss: 1.3616 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5722 - accuracy: 0.4286 - val_loss: 1.3640 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5782 - accuracy: 0.3929 - val_loss: 1.3659 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5762 - accuracy: 0.4107 - val_loss: 1.3697 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5471 - accuracy: 0.4464 - val_loss: 1.3731 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5522 - accuracy: 0.3750 - val_loss: 1.3762 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5555 - accuracy: 0.4107 - val_loss: 1.3791 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5591 - accuracy: 0.3929 - val_loss: 1.3826 - val_accuracy: 0.2143\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5366 - accuracy: 0.3571 - val_loss: 1.3867 - val_accuracy: 0.2143\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5468 - accuracy: 0.4286 - val_loss: 1.3913 - val_accuracy: 0.2143\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5411 - accuracy: 0.4464 - val_loss: 1.3951 - val_accuracy: 0.2143\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5392 - accuracy: 0.4286 - val_loss: 1.3996 - val_accuracy: 0.2143\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5405 - accuracy: 0.3929 - val_loss: 1.4031 - val_accuracy: 0.2143\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5264 - accuracy: 0.4464 - val_loss: 1.4062 - val_accuracy: 0.2143\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5327 - accuracy: 0.4107 - val_loss: 1.4085 - val_accuracy: 0.2143\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5382 - accuracy: 0.3929 - val_loss: 1.4093 - val_accuracy: 0.2143\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5263 - accuracy: 0.4464 - val_loss: 1.4105 - val_accuracy: 0.2143\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5251 - accuracy: 0.4643 - val_loss: 1.4126 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5173 - accuracy: 0.3929 - val_loss: 1.4170 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5212 - accuracy: 0.4464 - val_loss: 1.4239 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5230 - accuracy: 0.4286 - val_loss: 1.4314 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4972 - accuracy: 0.4643 - val_loss: 1.4368 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5119 - accuracy: 0.4286 - val_loss: 1.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4830 - accuracy: 0.4643 - val_loss: 1.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4960 - accuracy: 0.4821 - val_loss: 1.4322 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4971 - accuracy: 0.4286 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.4808 - accuracy: 0.4286 - val_loss: 1.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4820 - accuracy: 0.4464 - val_loss: 1.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4671 - accuracy: 0.4643 - val_loss: 1.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4707 - accuracy: 0.4821 - val_loss: 1.4378 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4704 - accuracy: 0.4821 - val_loss: 1.4440 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4678 - accuracy: 0.4643 - val_loss: 1.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4563 - accuracy: 0.4464 - val_loss: 1.4614 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4612 - accuracy: 0.4643 - val_loss: 1.4623 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.4547 - accuracy: 0.4107 - val_loss: 1.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4595 - accuracy: 0.4464 - val_loss: 1.4610 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4322 - accuracy: 0.4464 - val_loss: 1.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4404 - accuracy: 0.4286 - val_loss: 1.4542 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4293 - accuracy: 0.4643 - val_loss: 1.4524 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4231 - accuracy: 0.4286 - val_loss: 1.4510 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4340 - accuracy: 0.5000 - val_loss: 1.4510 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4240 - accuracy: 0.5357 - val_loss: 1.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4041 - accuracy: 0.3750 - val_loss: 1.4546 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.4191 - accuracy: 0.4464 - val_loss: 1.4542 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.4043 - accuracy: 0.4464 - val_loss: 1.4559 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4159 - accuracy: 0.4464 - val_loss: 1.4564 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4013 - accuracy: 0.5000 - val_loss: 1.4561 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3877 - accuracy: 0.4464 - val_loss: 1.4566 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3900 - accuracy: 0.6607 - val_loss: 1.4560 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3847 - accuracy: 0.5000 - val_loss: 1.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3726 - accuracy: 0.5179 - val_loss: 1.4664 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3963 - accuracy: 0.4821 - val_loss: 1.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3810 - accuracy: 0.4643 - val_loss: 1.4806 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3771 - accuracy: 0.4821 - val_loss: 1.4844 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3820 - accuracy: 0.5536 - val_loss: 1.4826 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3557 - accuracy: 0.3929 - val_loss: 1.4756 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3563 - accuracy: 0.5000 - val_loss: 1.4663 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3659 - accuracy: 0.4464 - val_loss: 1.4537 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3492 - accuracy: 0.5357 - val_loss: 1.4413 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3618 - accuracy: 0.5714 - val_loss: 1.4360 - val_accuracy: 0.0714\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3629 - accuracy: 0.5179 - val_loss: 1.4341 - val_accuracy: 0.0714\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.3626 - accuracy: 0.4643 - val_loss: 1.4382 - val_accuracy: 0.0714\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3533 - accuracy: 0.4107 - val_loss: 1.4515 - val_accuracy: 0.0714\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3452 - accuracy: 0.5000 - val_loss: 1.4650 - val_accuracy: 0.0714\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3397 - accuracy: 0.5179 - val_loss: 1.4758 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3366 - accuracy: 0.4821 - val_loss: 1.4918 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3457 - accuracy: 0.5179 - val_loss: 1.5047 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3274 - accuracy: 0.5357 - val_loss: 1.5086 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3492 - accuracy: 0.5000 - val_loss: 1.5086 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3253 - accuracy: 0.5536 - val_loss: 1.5029 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3382 - accuracy: 0.5000 - val_loss: 1.4944 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3281 - accuracy: 0.5179 - val_loss: 1.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3393 - accuracy: 0.4821 - val_loss: 1.4958 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3345 - accuracy: 0.5000 - val_loss: 1.5094 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3163 - accuracy: 0.5000 - val_loss: 1.5257 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3133 - accuracy: 0.5536 - val_loss: 1.5448 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3137 - accuracy: 0.5714 - val_loss: 1.5517 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3323 - accuracy: 0.5000 - val_loss: 1.5532 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3014 - accuracy: 0.5357 - val_loss: 1.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3030 - accuracy: 0.5000 - val_loss: 1.5343 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3065 - accuracy: 0.5536 - val_loss: 1.5268 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2882 - accuracy: 0.5179 - val_loss: 1.5188 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2895 - accuracy: 0.5357 - val_loss: 1.5204 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2916 - accuracy: 0.5357 - val_loss: 1.5268 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2865 - accuracy: 0.5357 - val_loss: 1.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2931 - accuracy: 0.5179 - val_loss: 1.5478 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2817 - accuracy: 0.5714 - val_loss: 1.5597 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2974 - accuracy: 0.5714 - val_loss: 1.5628 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2792 - accuracy: 0.5536 - val_loss: 1.5612 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2759 - accuracy: 0.5179 - val_loss: 1.5506 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2813 - accuracy: 0.5179 - val_loss: 1.5391 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2610 - accuracy: 0.5536 - val_loss: 1.5320 - val_accuracy: 0.1429\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2693 - accuracy: 0.4821 - val_loss: 1.5332 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2710 - accuracy: 0.5357 - val_loss: 1.5392 - val_accuracy: 0.0714\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2595 - accuracy: 0.5000 - val_loss: 1.5468 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2633 - accuracy: 0.5893 - val_loss: 1.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2744 - accuracy: 0.5536 - val_loss: 1.5676 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2518 - accuracy: 0.5179 - val_loss: 1.5813 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2538 - accuracy: 0.5357 - val_loss: 1.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2563 - accuracy: 0.5357 - val_loss: 1.6017 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2417 - accuracy: 0.5714 - val_loss: 1.6071 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2598 - accuracy: 0.5714 - val_loss: 1.6079 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2446 - accuracy: 0.5893 - val_loss: 1.6078 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2413 - accuracy: 0.5714 - val_loss: 1.6099 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2349 - accuracy: 0.5714 - val_loss: 1.6141 - val_accuracy: 0.0714\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2331 - accuracy: 0.5179 - val_loss: 1.6209 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2354 - accuracy: 0.5714 - val_loss: 1.6240 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2337 - accuracy: 0.5357 - val_loss: 1.6238 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2363 - accuracy: 0.5357 - val_loss: 1.6238 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2310 - accuracy: 0.4464 - val_loss: 1.6258 - val_accuracy: 0.1429\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2365 - accuracy: 0.6071 - val_loss: 1.6288 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2288 - accuracy: 0.6071 - val_loss: 1.6314 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2046 - accuracy: 0.5000 - val_loss: 1.6293 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2382 - accuracy: 0.6071 - val_loss: 1.6221 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2279 - accuracy: 0.5536 - val_loss: 1.6131 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2361 - accuracy: 0.6071 - val_loss: 1.6110 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.2191 - accuracy: 0.5893 - val_loss: 1.6067 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.2305 - accuracy: 0.6071 - val_loss: 1.6102 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2259 - accuracy: 0.5893 - val_loss: 1.6151 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2172 - accuracy: 0.5179 - val_loss: 1.6214 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2121 - accuracy: 0.6250 - val_loss: 1.6297 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2267 - accuracy: 0.6071 - val_loss: 1.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2098 - accuracy: 0.5536 - val_loss: 1.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2085 - accuracy: 0.6250 - val_loss: 1.6454 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2059 - accuracy: 0.5714 - val_loss: 1.6475 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2260 - accuracy: 0.5714 - val_loss: 1.6448 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1992 - accuracy: 0.5357 - val_loss: 1.6452 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1968 - accuracy: 0.5000 - val_loss: 1.6455 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1948 - accuracy: 0.5536 - val_loss: 1.6380 - val_accuracy: 0.0714\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1950 - accuracy: 0.6250 - val_loss: 1.6371 - val_accuracy: 0.0714\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1996 - accuracy: 0.6250 - val_loss: 1.6371 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1934 - accuracy: 0.5714 - val_loss: 1.6409 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1846 - accuracy: 0.6429 - val_loss: 1.6377 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1867 - accuracy: 0.6964 - val_loss: 1.6320 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1846 - accuracy: 0.6071 - val_loss: 1.6311 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1902 - accuracy: 0.6071 - val_loss: 1.6363 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1782 - accuracy: 0.6250 - val_loss: 1.6471 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1907 - accuracy: 0.5536 - val_loss: 1.6597 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1895 - accuracy: 0.6786 - val_loss: 1.6608 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6608 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=240, batch_size=100, Scores: [1.6608059406280518, 0.0]\n",
      "Accuracy on validation set: 0.0\n",
      "Loss on validation set: 1.6608059406280518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9832 - accuracy: 0.1071 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.9789 - accuracy: 0.1429 - val_loss: 1.0719 - val_accuracy: 0.1429\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.9759 - accuracy: 0.2321 - val_loss: 1.0723 - val_accuracy: 0.1429\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9703 - accuracy: 0.1964 - val_loss: 1.0727 - val_accuracy: 0.1429\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9666 - accuracy: 0.3393 - val_loss: 1.0732 - val_accuracy: 0.1429\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9639 - accuracy: 0.3571 - val_loss: 1.0737 - val_accuracy: 0.1429\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9605 - accuracy: 0.2679 - val_loss: 1.0742 - val_accuracy: 0.1429\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9550 - accuracy: 0.3214 - val_loss: 1.0747 - val_accuracy: 0.1429\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9504 - accuracy: 0.3750 - val_loss: 1.0753 - val_accuracy: 0.1429\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9469 - accuracy: 0.3214 - val_loss: 1.0760 - val_accuracy: 0.1429\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9467 - accuracy: 0.2857 - val_loss: 1.0767 - val_accuracy: 0.1429\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9371 - accuracy: 0.4107 - val_loss: 1.0775 - val_accuracy: 0.1429\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9336 - accuracy: 0.2857 - val_loss: 1.0783 - val_accuracy: 0.1429\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9261 - accuracy: 0.3036 - val_loss: 1.0792 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.9208 - accuracy: 0.3393 - val_loss: 1.0802 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9195 - accuracy: 0.3571 - val_loss: 1.0812 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9117 - accuracy: 0.3214 - val_loss: 1.0823 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.9063 - accuracy: 0.3214 - val_loss: 1.0836 - val_accuracy: 0.2143\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9033 - accuracy: 0.3036 - val_loss: 1.0850 - val_accuracy: 0.2143\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8954 - accuracy: 0.3214 - val_loss: 1.0865 - val_accuracy: 0.2143\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8916 - accuracy: 0.2500 - val_loss: 1.0883 - val_accuracy: 0.2143\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.8844 - accuracy: 0.3036 - val_loss: 1.0903 - val_accuracy: 0.2143\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.8781 - accuracy: 0.3036 - val_loss: 1.0926 - val_accuracy: 0.2143\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.8745 - accuracy: 0.2679 - val_loss: 1.0951 - val_accuracy: 0.2143\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.8669 - accuracy: 0.3036 - val_loss: 1.0978 - val_accuracy: 0.2143\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8584 - accuracy: 0.3214 - val_loss: 1.1008 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.8573 - accuracy: 0.2857 - val_loss: 1.1041 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8490 - accuracy: 0.3571 - val_loss: 1.1076 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.8525 - accuracy: 0.2857 - val_loss: 1.1114 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8402 - accuracy: 0.2679 - val_loss: 1.1152 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8335 - accuracy: 0.3571 - val_loss: 1.1192 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.8341 - accuracy: 0.3214 - val_loss: 1.1232 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.8334 - accuracy: 0.3036 - val_loss: 1.1274 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8261 - accuracy: 0.3750 - val_loss: 1.1319 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.8195 - accuracy: 0.3214 - val_loss: 1.1367 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.8148 - accuracy: 0.2857 - val_loss: 1.1417 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8107 - accuracy: 0.2857 - val_loss: 1.1467 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8026 - accuracy: 0.2857 - val_loss: 1.1518 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8019 - accuracy: 0.3214 - val_loss: 1.1573 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7899 - accuracy: 0.3214 - val_loss: 1.1628 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7943 - accuracy: 0.3214 - val_loss: 1.1686 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7884 - accuracy: 0.3036 - val_loss: 1.1744 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7801 - accuracy: 0.3214 - val_loss: 1.1804 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7771 - accuracy: 0.3393 - val_loss: 1.1864 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7782 - accuracy: 0.3571 - val_loss: 1.1926 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7799 - accuracy: 0.3571 - val_loss: 1.1985 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7733 - accuracy: 0.3750 - val_loss: 1.2040 - val_accuracy: 0.0714\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7668 - accuracy: 0.3571 - val_loss: 1.2090 - val_accuracy: 0.0714\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7632 - accuracy: 0.3036 - val_loss: 1.2139 - val_accuracy: 0.0714\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7624 - accuracy: 0.3571 - val_loss: 1.2180 - val_accuracy: 0.0714\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7591 - accuracy: 0.4107 - val_loss: 1.2212 - val_accuracy: 0.0714\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7488 - accuracy: 0.3393 - val_loss: 1.2240 - val_accuracy: 0.0714\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7492 - accuracy: 0.3571 - val_loss: 1.2258 - val_accuracy: 0.0714\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7510 - accuracy: 0.3393 - val_loss: 1.2273 - val_accuracy: 0.0714\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7499 - accuracy: 0.3393 - val_loss: 1.2284 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7481 - accuracy: 0.3214 - val_loss: 1.2292 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7360 - accuracy: 0.3214 - val_loss: 1.2298 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7412 - accuracy: 0.3036 - val_loss: 1.2304 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7311 - accuracy: 0.3393 - val_loss: 1.2312 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.7371 - accuracy: 0.3393 - val_loss: 1.2320 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7379 - accuracy: 0.3571 - val_loss: 1.2333 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7210 - accuracy: 0.3571 - val_loss: 1.2349 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7142 - accuracy: 0.3214 - val_loss: 1.2367 - val_accuracy: 0.1429\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.7115 - accuracy: 0.3393 - val_loss: 1.2389 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7110 - accuracy: 0.3750 - val_loss: 1.2415 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7140 - accuracy: 0.3214 - val_loss: 1.2439 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7105 - accuracy: 0.3750 - val_loss: 1.2469 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7048 - accuracy: 0.3750 - val_loss: 1.2501 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7062 - accuracy: 0.3214 - val_loss: 1.2535 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6958 - accuracy: 0.3393 - val_loss: 1.2568 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6977 - accuracy: 0.3750 - val_loss: 1.2601 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6935 - accuracy: 0.3214 - val_loss: 1.2631 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.6933 - accuracy: 0.3214 - val_loss: 1.2663 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6788 - accuracy: 0.3750 - val_loss: 1.2697 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6802 - accuracy: 0.3750 - val_loss: 1.2732 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6735 - accuracy: 0.3929 - val_loss: 1.2776 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6809 - accuracy: 0.4107 - val_loss: 1.2828 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6710 - accuracy: 0.4107 - val_loss: 1.2884 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6654 - accuracy: 0.3929 - val_loss: 1.2940 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6682 - accuracy: 0.4464 - val_loss: 1.2987 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6644 - accuracy: 0.3929 - val_loss: 1.3041 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6512 - accuracy: 0.4107 - val_loss: 1.3101 - val_accuracy: 0.1429\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6614 - accuracy: 0.3929 - val_loss: 1.3152 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6470 - accuracy: 0.4464 - val_loss: 1.3197 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6576 - accuracy: 0.4464 - val_loss: 1.3244 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.6467 - accuracy: 0.4107 - val_loss: 1.3280 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6376 - accuracy: 0.3929 - val_loss: 1.3312 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.6430 - accuracy: 0.3750 - val_loss: 1.3324 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.6304 - accuracy: 0.4107 - val_loss: 1.3340 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.6338 - accuracy: 0.3929 - val_loss: 1.3355 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6247 - accuracy: 0.4643 - val_loss: 1.3363 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6226 - accuracy: 0.4286 - val_loss: 1.3379 - val_accuracy: 0.0714\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6170 - accuracy: 0.4286 - val_loss: 1.3400 - val_accuracy: 0.0714\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6225 - accuracy: 0.4107 - val_loss: 1.3427 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6186 - accuracy: 0.4286 - val_loss: 1.3464 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6238 - accuracy: 0.3929 - val_loss: 1.3499 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5881 - accuracy: 0.4643 - val_loss: 1.3535 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5962 - accuracy: 0.4286 - val_loss: 1.3563 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6088 - accuracy: 0.4821 - val_loss: 1.3588 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5982 - accuracy: 0.3929 - val_loss: 1.3629 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6036 - accuracy: 0.4107 - val_loss: 1.3666 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5903 - accuracy: 0.4107 - val_loss: 1.3688 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5773 - accuracy: 0.4107 - val_loss: 1.3711 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5900 - accuracy: 0.3571 - val_loss: 1.3731 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5809 - accuracy: 0.3929 - val_loss: 1.3746 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5754 - accuracy: 0.3929 - val_loss: 1.3768 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5825 - accuracy: 0.3571 - val_loss: 1.3803 - val_accuracy: 0.0714\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5685 - accuracy: 0.4107 - val_loss: 1.3846 - val_accuracy: 0.0714\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5687 - accuracy: 0.3571 - val_loss: 1.3871 - val_accuracy: 0.0714\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5597 - accuracy: 0.3750 - val_loss: 1.3902 - val_accuracy: 0.0714\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5471 - accuracy: 0.3929 - val_loss: 1.3941 - val_accuracy: 0.0714\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5490 - accuracy: 0.4464 - val_loss: 1.3995 - val_accuracy: 0.0714\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5518 - accuracy: 0.4286 - val_loss: 1.4063 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5444 - accuracy: 0.4286 - val_loss: 1.4134 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5302 - accuracy: 0.4286 - val_loss: 1.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5367 - accuracy: 0.3571 - val_loss: 1.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5304 - accuracy: 0.4286 - val_loss: 1.4278 - val_accuracy: 0.0714\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5305 - accuracy: 0.3750 - val_loss: 1.4316 - val_accuracy: 0.0714\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5021 - accuracy: 0.4107 - val_loss: 1.4361 - val_accuracy: 0.0714\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5191 - accuracy: 0.3571 - val_loss: 1.4385 - val_accuracy: 0.0714\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5135 - accuracy: 0.4464 - val_loss: 1.4409 - val_accuracy: 0.0714\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5133 - accuracy: 0.4821 - val_loss: 1.4435 - val_accuracy: 0.0714\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5138 - accuracy: 0.4107 - val_loss: 1.4457 - val_accuracy: 0.0714\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.4920 - accuracy: 0.4107 - val_loss: 1.4487 - val_accuracy: 0.0714\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5099 - accuracy: 0.4107 - val_loss: 1.4510 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4933 - accuracy: 0.4286 - val_loss: 1.4545 - val_accuracy: 0.0714\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4749 - accuracy: 0.4643 - val_loss: 1.4579 - val_accuracy: 0.0714\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4867 - accuracy: 0.4107 - val_loss: 1.4620 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4880 - accuracy: 0.4286 - val_loss: 1.4665 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4644 - accuracy: 0.4107 - val_loss: 1.4703 - val_accuracy: 0.1429\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4743 - accuracy: 0.4286 - val_loss: 1.4737 - val_accuracy: 0.1429\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4693 - accuracy: 0.4286 - val_loss: 1.4760 - val_accuracy: 0.1429\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4556 - accuracy: 0.5179 - val_loss: 1.4758 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4502 - accuracy: 0.4464 - val_loss: 1.4767 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4370 - accuracy: 0.4286 - val_loss: 1.4754 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4474 - accuracy: 0.5179 - val_loss: 1.4748 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4498 - accuracy: 0.4107 - val_loss: 1.4714 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4421 - accuracy: 0.4286 - val_loss: 1.4703 - val_accuracy: 0.1429\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4501 - accuracy: 0.4464 - val_loss: 1.4718 - val_accuracy: 0.1429\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4590 - accuracy: 0.4643 - val_loss: 1.4764 - val_accuracy: 0.1429\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.4161 - accuracy: 0.5536 - val_loss: 1.4806 - val_accuracy: 0.1429\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4209 - accuracy: 0.4286 - val_loss: 1.4837 - val_accuracy: 0.1429\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4510 - accuracy: 0.4286 - val_loss: 1.4897 - val_accuracy: 0.1429\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4228 - accuracy: 0.4286 - val_loss: 1.4950 - val_accuracy: 0.2143\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4217 - accuracy: 0.4643 - val_loss: 1.4976 - val_accuracy: 0.2143\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4081 - accuracy: 0.4643 - val_loss: 1.4982 - val_accuracy: 0.1429\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4008 - accuracy: 0.4643 - val_loss: 1.4992 - val_accuracy: 0.1429\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3869 - accuracy: 0.4821 - val_loss: 1.5059 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3909 - accuracy: 0.5000 - val_loss: 1.5160 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3971 - accuracy: 0.5179 - val_loss: 1.5219 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3748 - accuracy: 0.4643 - val_loss: 1.5252 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3800 - accuracy: 0.5179 - val_loss: 1.5265 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3925 - accuracy: 0.5000 - val_loss: 1.5226 - val_accuracy: 0.2143\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3700 - accuracy: 0.5357 - val_loss: 1.5200 - val_accuracy: 0.2143\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3681 - accuracy: 0.4821 - val_loss: 1.5190 - val_accuracy: 0.2143\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3708 - accuracy: 0.5357 - val_loss: 1.5158 - val_accuracy: 0.2143\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3769 - accuracy: 0.4286 - val_loss: 1.5078 - val_accuracy: 0.2143\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.3532 - accuracy: 0.5000 - val_loss: 1.5021 - val_accuracy: 0.2143\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3670 - accuracy: 0.4286 - val_loss: 1.5009 - val_accuracy: 0.2143\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3439 - accuracy: 0.4821 - val_loss: 1.4990 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3604 - accuracy: 0.5357 - val_loss: 1.4992 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3504 - accuracy: 0.5536 - val_loss: 1.4996 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3528 - accuracy: 0.4643 - val_loss: 1.5065 - val_accuracy: 0.1429\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3589 - accuracy: 0.5179 - val_loss: 1.5119 - val_accuracy: 0.1429\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3398 - accuracy: 0.5000 - val_loss: 1.5114 - val_accuracy: 0.1429\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3427 - accuracy: 0.5000 - val_loss: 1.5082 - val_accuracy: 0.1429\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3351 - accuracy: 0.5000 - val_loss: 1.5060 - val_accuracy: 0.1429\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3320 - accuracy: 0.5179 - val_loss: 1.5050 - val_accuracy: 0.2143\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3182 - accuracy: 0.5000 - val_loss: 1.5127 - val_accuracy: 0.2143\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3231 - accuracy: 0.5536 - val_loss: 1.5262 - val_accuracy: 0.2143\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3096 - accuracy: 0.5357 - val_loss: 1.5386 - val_accuracy: 0.2143\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3167 - accuracy: 0.4643 - val_loss: 1.5431 - val_accuracy: 0.2143\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.3244 - accuracy: 0.5179 - val_loss: 1.5391 - val_accuracy: 0.2143\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3179 - accuracy: 0.5357 - val_loss: 1.5315 - val_accuracy: 0.2143\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3048 - accuracy: 0.4821 - val_loss: 1.5209 - val_accuracy: 0.2143\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3115 - accuracy: 0.5000 - val_loss: 1.5130 - val_accuracy: 0.1429\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2933 - accuracy: 0.5357 - val_loss: 1.5106 - val_accuracy: 0.1429\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3083 - accuracy: 0.5893 - val_loss: 1.5066 - val_accuracy: 0.1429\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3008 - accuracy: 0.5357 - val_loss: 1.5022 - val_accuracy: 0.1429\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3007 - accuracy: 0.5179 - val_loss: 1.5007 - val_accuracy: 0.1429\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3198 - accuracy: 0.4821 - val_loss: 1.4946 - val_accuracy: 0.2143\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2904 - accuracy: 0.6250 - val_loss: 1.4883 - val_accuracy: 0.2143\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2894 - accuracy: 0.5357 - val_loss: 1.4866 - val_accuracy: 0.2143\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2825 - accuracy: 0.5714 - val_loss: 1.4880 - val_accuracy: 0.2143\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2878 - accuracy: 0.5357 - val_loss: 1.4883 - val_accuracy: 0.2143\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2798 - accuracy: 0.5893 - val_loss: 1.4933 - val_accuracy: 0.1429\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2837 - accuracy: 0.5536 - val_loss: 1.4993 - val_accuracy: 0.1429\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3051 - accuracy: 0.5536 - val_loss: 1.5061 - val_accuracy: 0.1429\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2738 - accuracy: 0.5179 - val_loss: 1.5144 - val_accuracy: 0.1429\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2593 - accuracy: 0.5179 - val_loss: 1.5231 - val_accuracy: 0.1429\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2893 - accuracy: 0.6071 - val_loss: 1.5280 - val_accuracy: 0.2143\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2698 - accuracy: 0.5714 - val_loss: 1.5271 - val_accuracy: 0.2143\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2617 - accuracy: 0.5893 - val_loss: 1.5261 - val_accuracy: 0.2143\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2801 - accuracy: 0.6429 - val_loss: 1.5231 - val_accuracy: 0.2143\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2561 - accuracy: 0.5536 - val_loss: 1.5247 - val_accuracy: 0.2143\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2788 - accuracy: 0.6429 - val_loss: 1.5242 - val_accuracy: 0.2143\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2572 - accuracy: 0.5357 - val_loss: 1.5188 - val_accuracy: 0.2143\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2698 - accuracy: 0.6071 - val_loss: 1.5158 - val_accuracy: 0.1429\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2566 - accuracy: 0.5893 - val_loss: 1.5145 - val_accuracy: 0.1429\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2478 - accuracy: 0.6250 - val_loss: 1.5161 - val_accuracy: 0.1429\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2622 - accuracy: 0.5893 - val_loss: 1.5196 - val_accuracy: 0.1429\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2726 - accuracy: 0.5357 - val_loss: 1.5181 - val_accuracy: 0.1429\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2276 - accuracy: 0.6964 - val_loss: 1.5181 - val_accuracy: 0.2143\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2505 - accuracy: 0.6071 - val_loss: 1.5195 - val_accuracy: 0.2143\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2236 - accuracy: 0.5893 - val_loss: 1.5277 - val_accuracy: 0.1429\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2329 - accuracy: 0.6250 - val_loss: 1.5396 - val_accuracy: 0.1429\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2410 - accuracy: 0.5714 - val_loss: 1.5541 - val_accuracy: 0.1429\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2326 - accuracy: 0.5179 - val_loss: 1.5655 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2354 - accuracy: 0.6071 - val_loss: 1.5784 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2288 - accuracy: 0.6786 - val_loss: 1.5865 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2318 - accuracy: 0.5893 - val_loss: 1.5886 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2211 - accuracy: 0.5179 - val_loss: 1.5951 - val_accuracy: 0.1429\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2415 - accuracy: 0.6071 - val_loss: 1.5926 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2231 - accuracy: 0.6964 - val_loss: 1.5823 - val_accuracy: 0.2143\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2120 - accuracy: 0.5893 - val_loss: 1.5690 - val_accuracy: 0.2143\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2282 - accuracy: 0.6250 - val_loss: 1.5515 - val_accuracy: 0.2143\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2257 - accuracy: 0.6071 - val_loss: 1.5352 - val_accuracy: 0.2143\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2111 - accuracy: 0.6786 - val_loss: 1.5263 - val_accuracy: 0.1429\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2343 - accuracy: 0.5536 - val_loss: 1.5230 - val_accuracy: 0.1429\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.2155 - accuracy: 0.6071 - val_loss: 1.5288 - val_accuracy: 0.1429\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2180 - accuracy: 0.6250 - val_loss: 1.5407 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.2135 - accuracy: 0.6071 - val_loss: 1.5502 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2118 - accuracy: 0.5536 - val_loss: 1.5644 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2061 - accuracy: 0.6786 - val_loss: 1.5736 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2098 - accuracy: 0.6071 - val_loss: 1.5786 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2278 - accuracy: 0.5893 - val_loss: 1.5807 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2107 - accuracy: 0.6071 - val_loss: 1.5838 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.1898 - accuracy: 0.6071 - val_loss: 1.5843 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1924 - accuracy: 0.6250 - val_loss: 1.5838 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1997 - accuracy: 0.7143 - val_loss: 1.5822 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1994 - accuracy: 0.6250 - val_loss: 1.5860 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1959 - accuracy: 0.6250 - val_loss: 1.5953 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1915 - accuracy: 0.6429 - val_loss: 1.6089 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1972 - accuracy: 0.7321 - val_loss: 1.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2039 - accuracy: 0.6071 - val_loss: 1.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1961 - accuracy: 0.5893 - val_loss: 1.6345 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1849 - accuracy: 0.6786 - val_loss: 1.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2106 - accuracy: 0.5893 - val_loss: 1.6342 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1809 - accuracy: 0.6429 - val_loss: 1.6314 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1906 - accuracy: 0.6964 - val_loss: 1.6309 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6309 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=240, batch_size=300, Scores: [1.6309477090835571, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.6309477090835571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9837 - accuracy: 0.1429 - val_loss: 1.0705 - val_accuracy: 0.1429\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9790 - accuracy: 0.1964 - val_loss: 1.0715 - val_accuracy: 0.1429\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9772 - accuracy: 0.1607 - val_loss: 1.0726 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9741 - accuracy: 0.1964 - val_loss: 1.0736 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.9678 - accuracy: 0.2679 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9680 - accuracy: 0.2679 - val_loss: 1.0759 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.9641 - accuracy: 0.2143 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.9577 - accuracy: 0.2143 - val_loss: 1.0784 - val_accuracy: 0.0714\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9542 - accuracy: 0.2321 - val_loss: 1.0797 - val_accuracy: 0.0714\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.9519 - accuracy: 0.1964 - val_loss: 1.0811 - val_accuracy: 0.0714\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.9428 - accuracy: 0.3393 - val_loss: 1.0825 - val_accuracy: 0.0714\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9450 - accuracy: 0.2679 - val_loss: 1.0841 - val_accuracy: 0.0714\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.9410 - accuracy: 0.2500 - val_loss: 1.0857 - val_accuracy: 0.0714\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9332 - accuracy: 0.3036 - val_loss: 1.0875 - val_accuracy: 0.1429\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.9305 - accuracy: 0.2679 - val_loss: 1.0894 - val_accuracy: 0.1429\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.9245 - accuracy: 0.2679 - val_loss: 1.0914 - val_accuracy: 0.1429\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9222 - accuracy: 0.2500 - val_loss: 1.0936 - val_accuracy: 0.1429\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9161 - accuracy: 0.3036 - val_loss: 1.0960 - val_accuracy: 0.1429\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9109 - accuracy: 0.2857 - val_loss: 1.0985 - val_accuracy: 0.1429\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.9049 - accuracy: 0.2679 - val_loss: 1.1013 - val_accuracy: 0.1429\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9021 - accuracy: 0.2679 - val_loss: 1.1042 - val_accuracy: 0.1429\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.8977 - accuracy: 0.2679 - val_loss: 1.1072 - val_accuracy: 0.1429\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8875 - accuracy: 0.3571 - val_loss: 1.1105 - val_accuracy: 0.1429\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8831 - accuracy: 0.2679 - val_loss: 1.1137 - val_accuracy: 0.1429\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.8790 - accuracy: 0.2857 - val_loss: 1.1170 - val_accuracy: 0.1429\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.8709 - accuracy: 0.2679 - val_loss: 1.1202 - val_accuracy: 0.1429\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.8694 - accuracy: 0.3036 - val_loss: 1.1234 - val_accuracy: 0.1429\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8639 - accuracy: 0.3036 - val_loss: 1.1260 - val_accuracy: 0.1429\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8604 - accuracy: 0.2857 - val_loss: 1.1283 - val_accuracy: 0.1429\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.8545 - accuracy: 0.2857 - val_loss: 1.1300 - val_accuracy: 0.1429\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8502 - accuracy: 0.3036 - val_loss: 1.1314 - val_accuracy: 0.1429\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8478 - accuracy: 0.3393 - val_loss: 1.1325 - val_accuracy: 0.1429\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.8444 - accuracy: 0.3214 - val_loss: 1.1333 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8388 - accuracy: 0.3393 - val_loss: 1.1343 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8367 - accuracy: 0.3393 - val_loss: 1.1359 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8272 - accuracy: 0.3214 - val_loss: 1.1378 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8200 - accuracy: 0.3393 - val_loss: 1.1402 - val_accuracy: 0.0714\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8195 - accuracy: 0.3214 - val_loss: 1.1434 - val_accuracy: 0.0714\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8116 - accuracy: 0.3393 - val_loss: 1.1476 - val_accuracy: 0.0714\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8036 - accuracy: 0.3214 - val_loss: 1.1525 - val_accuracy: 0.0714\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8009 - accuracy: 0.3214 - val_loss: 1.1581 - val_accuracy: 0.0714\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8053 - accuracy: 0.3929 - val_loss: 1.1644 - val_accuracy: 0.0714\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7907 - accuracy: 0.3750 - val_loss: 1.1709 - val_accuracy: 0.0714\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7941 - accuracy: 0.3750 - val_loss: 1.1775 - val_accuracy: 0.0714\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7793 - accuracy: 0.3750 - val_loss: 1.1845 - val_accuracy: 0.0714\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7813 - accuracy: 0.3750 - val_loss: 1.1912 - val_accuracy: 0.0714\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.7783 - accuracy: 0.3393 - val_loss: 1.1978 - val_accuracy: 0.0714\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7734 - accuracy: 0.3750 - val_loss: 1.2043 - val_accuracy: 0.0714\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7678 - accuracy: 0.3036 - val_loss: 1.2102 - val_accuracy: 0.0714\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7542 - accuracy: 0.3393 - val_loss: 1.2150 - val_accuracy: 0.0714\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.7658 - accuracy: 0.3750 - val_loss: 1.2195 - val_accuracy: 0.0714\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7600 - accuracy: 0.3393 - val_loss: 1.2241 - val_accuracy: 0.0714\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.7611 - accuracy: 0.4107 - val_loss: 1.2275 - val_accuracy: 0.0714\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7556 - accuracy: 0.3393 - val_loss: 1.2310 - val_accuracy: 0.0714\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7547 - accuracy: 0.3571 - val_loss: 1.2336 - val_accuracy: 0.0714\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7376 - accuracy: 0.3214 - val_loss: 1.2364 - val_accuracy: 0.0714\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7454 - accuracy: 0.3036 - val_loss: 1.2389 - val_accuracy: 0.0714\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.7452 - accuracy: 0.3214 - val_loss: 1.2420 - val_accuracy: 0.0714\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7380 - accuracy: 0.3393 - val_loss: 1.2453 - val_accuracy: 0.0714\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7354 - accuracy: 0.3393 - val_loss: 1.2491 - val_accuracy: 0.0714\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7310 - accuracy: 0.3571 - val_loss: 1.2533 - val_accuracy: 0.0714\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.7232 - accuracy: 0.3393 - val_loss: 1.2577 - val_accuracy: 0.0714\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7222 - accuracy: 0.3214 - val_loss: 1.2615 - val_accuracy: 0.0714\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7235 - accuracy: 0.3571 - val_loss: 1.2648 - val_accuracy: 0.0714\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.7064 - accuracy: 0.3750 - val_loss: 1.2678 - val_accuracy: 0.0714\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7165 - accuracy: 0.3929 - val_loss: 1.2704 - val_accuracy: 0.0714\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7012 - accuracy: 0.3750 - val_loss: 1.2734 - val_accuracy: 0.0714\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6949 - accuracy: 0.3393 - val_loss: 1.2760 - val_accuracy: 0.0714\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7140 - accuracy: 0.3571 - val_loss: 1.2798 - val_accuracy: 0.0714\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7055 - accuracy: 0.3571 - val_loss: 1.2843 - val_accuracy: 0.0714\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6888 - accuracy: 0.3750 - val_loss: 1.2887 - val_accuracy: 0.0714\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.6886 - accuracy: 0.3750 - val_loss: 1.2933 - val_accuracy: 0.0714\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6753 - accuracy: 0.4286 - val_loss: 1.2983 - val_accuracy: 0.0714\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6781 - accuracy: 0.3393 - val_loss: 1.3019 - val_accuracy: 0.0714\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6777 - accuracy: 0.3929 - val_loss: 1.3045 - val_accuracy: 0.0714\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6679 - accuracy: 0.4107 - val_loss: 1.3078 - val_accuracy: 0.0714\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6773 - accuracy: 0.3929 - val_loss: 1.3120 - val_accuracy: 0.0714\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6734 - accuracy: 0.3750 - val_loss: 1.3163 - val_accuracy: 0.0714\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6776 - accuracy: 0.3929 - val_loss: 1.3207 - val_accuracy: 0.0714\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6578 - accuracy: 0.3571 - val_loss: 1.3261 - val_accuracy: 0.0714\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.6559 - accuracy: 0.4643 - val_loss: 1.3313 - val_accuracy: 0.0714\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6532 - accuracy: 0.4107 - val_loss: 1.3360 - val_accuracy: 0.0714\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.6600 - accuracy: 0.3929 - val_loss: 1.3392 - val_accuracy: 0.0714\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.6580 - accuracy: 0.3929 - val_loss: 1.3425 - val_accuracy: 0.0714\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6412 - accuracy: 0.4286 - val_loss: 1.3413 - val_accuracy: 0.0714\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6524 - accuracy: 0.4643 - val_loss: 1.3394 - val_accuracy: 0.0714\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6549 - accuracy: 0.3929 - val_loss: 1.3356 - val_accuracy: 0.0714\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6433 - accuracy: 0.4286 - val_loss: 1.3325 - val_accuracy: 0.0714\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6250 - accuracy: 0.4464 - val_loss: 1.3322 - val_accuracy: 0.0714\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6429 - accuracy: 0.3750 - val_loss: 1.3324 - val_accuracy: 0.0714\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6314 - accuracy: 0.4286 - val_loss: 1.3353 - val_accuracy: 0.0714\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.6292 - accuracy: 0.4286 - val_loss: 1.3392 - val_accuracy: 0.0714\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.6236 - accuracy: 0.3571 - val_loss: 1.3421 - val_accuracy: 0.0714\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.6198 - accuracy: 0.3929 - val_loss: 1.3439 - val_accuracy: 0.0714\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6177 - accuracy: 0.3929 - val_loss: 1.3456 - val_accuracy: 0.0714\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6066 - accuracy: 0.4286 - val_loss: 1.3480 - val_accuracy: 0.0714\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6260 - accuracy: 0.4286 - val_loss: 1.3510 - val_accuracy: 0.0714\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.6189 - accuracy: 0.4107 - val_loss: 1.3548 - val_accuracy: 0.0714\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6024 - accuracy: 0.3393 - val_loss: 1.3608 - val_accuracy: 0.0714\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5840 - accuracy: 0.3929 - val_loss: 1.3653 - val_accuracy: 0.0714\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5951 - accuracy: 0.3929 - val_loss: 1.3679 - val_accuracy: 0.0714\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6007 - accuracy: 0.3750 - val_loss: 1.3687 - val_accuracy: 0.0714\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6038 - accuracy: 0.3929 - val_loss: 1.3703 - val_accuracy: 0.0714\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5990 - accuracy: 0.4107 - val_loss: 1.3716 - val_accuracy: 0.0714\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5845 - accuracy: 0.3750 - val_loss: 1.3717 - val_accuracy: 0.0714\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5759 - accuracy: 0.4107 - val_loss: 1.3727 - val_accuracy: 0.0714\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5744 - accuracy: 0.3929 - val_loss: 1.3767 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5746 - accuracy: 0.4107 - val_loss: 1.3825 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5742 - accuracy: 0.3929 - val_loss: 1.3901 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5658 - accuracy: 0.4464 - val_loss: 1.4001 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5551 - accuracy: 0.4107 - val_loss: 1.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5651 - accuracy: 0.4286 - val_loss: 1.4091 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5597 - accuracy: 0.4286 - val_loss: 1.4094 - val_accuracy: 0.0714\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5397 - accuracy: 0.4643 - val_loss: 1.4108 - val_accuracy: 0.0714\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5335 - accuracy: 0.4107 - val_loss: 1.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5518 - accuracy: 0.3571 - val_loss: 1.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5461 - accuracy: 0.3929 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5279 - accuracy: 0.4464 - val_loss: 1.4167 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.5155 - accuracy: 0.4107 - val_loss: 1.4205 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5239 - accuracy: 0.4286 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5132 - accuracy: 0.4286 - val_loss: 1.4349 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.5021 - accuracy: 0.4286 - val_loss: 1.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5132 - accuracy: 0.4286 - val_loss: 1.4462 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5194 - accuracy: 0.3750 - val_loss: 1.4487 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5150 - accuracy: 0.3929 - val_loss: 1.4502 - val_accuracy: 0.0714\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4918 - accuracy: 0.5000 - val_loss: 1.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5009 - accuracy: 0.4107 - val_loss: 1.4561 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5084 - accuracy: 0.3929 - val_loss: 1.4568 - val_accuracy: 0.0714\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4908 - accuracy: 0.4821 - val_loss: 1.4588 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4660 - accuracy: 0.4286 - val_loss: 1.4640 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4931 - accuracy: 0.4286 - val_loss: 1.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5011 - accuracy: 0.4464 - val_loss: 1.4766 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4830 - accuracy: 0.4821 - val_loss: 1.4834 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4769 - accuracy: 0.4286 - val_loss: 1.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4807 - accuracy: 0.5179 - val_loss: 1.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4673 - accuracy: 0.4286 - val_loss: 1.4816 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 0.4727 - accuracy: 0.4286 - val_loss: 1.4727 - val_accuracy: 0.0714\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4555 - accuracy: 0.4464 - val_loss: 1.4660 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4545 - accuracy: 0.3750 - val_loss: 1.4616 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4567 - accuracy: 0.4464 - val_loss: 1.4588 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.4301 - accuracy: 0.3750 - val_loss: 1.4594 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4446 - accuracy: 0.3929 - val_loss: 1.4592 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4519 - accuracy: 0.5000 - val_loss: 1.4666 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4313 - accuracy: 0.4107 - val_loss: 1.4704 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4443 - accuracy: 0.4107 - val_loss: 1.4744 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4491 - accuracy: 0.4286 - val_loss: 1.4682 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.4341 - accuracy: 0.4643 - val_loss: 1.4602 - val_accuracy: 0.0714\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4543 - accuracy: 0.3750 - val_loss: 1.4508 - val_accuracy: 0.0714\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4491 - accuracy: 0.5000 - val_loss: 1.4515 - val_accuracy: 0.0714\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4401 - accuracy: 0.5357 - val_loss: 1.4596 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4322 - accuracy: 0.4643 - val_loss: 1.4678 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4261 - accuracy: 0.4286 - val_loss: 1.4720 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4185 - accuracy: 0.4643 - val_loss: 1.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4011 - accuracy: 0.4643 - val_loss: 1.4640 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3942 - accuracy: 0.5357 - val_loss: 1.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4070 - accuracy: 0.3929 - val_loss: 1.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.4038 - accuracy: 0.4821 - val_loss: 1.4497 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3921 - accuracy: 0.5357 - val_loss: 1.4474 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.3938 - accuracy: 0.5179 - val_loss: 1.4431 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3913 - accuracy: 0.5000 - val_loss: 1.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3680 - accuracy: 0.5357 - val_loss: 1.4474 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3882 - accuracy: 0.5179 - val_loss: 1.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3687 - accuracy: 0.4464 - val_loss: 1.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3648 - accuracy: 0.5536 - val_loss: 1.4442 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3824 - accuracy: 0.5000 - val_loss: 1.4459 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3745 - accuracy: 0.4821 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3566 - accuracy: 0.5893 - val_loss: 1.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3760 - accuracy: 0.5357 - val_loss: 1.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3722 - accuracy: 0.5714 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3596 - accuracy: 0.6250 - val_loss: 1.4318 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.3513 - accuracy: 0.6071 - val_loss: 1.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3379 - accuracy: 0.5536 - val_loss: 1.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3617 - accuracy: 0.5357 - val_loss: 1.4346 - val_accuracy: 0.0714\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3448 - accuracy: 0.5179 - val_loss: 1.4509 - val_accuracy: 0.0714\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3331 - accuracy: 0.6429 - val_loss: 1.4651 - val_accuracy: 0.0714\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3485 - accuracy: 0.6071 - val_loss: 1.4632 - val_accuracy: 0.0714\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3293 - accuracy: 0.5536 - val_loss: 1.4486 - val_accuracy: 0.0714\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3351 - accuracy: 0.5714 - val_loss: 1.4400 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3335 - accuracy: 0.6250 - val_loss: 1.4312 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3401 - accuracy: 0.5714 - val_loss: 1.4297 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3143 - accuracy: 0.5893 - val_loss: 1.4351 - val_accuracy: 0.0714\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3111 - accuracy: 0.6071 - val_loss: 1.4381 - val_accuracy: 0.0714\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3160 - accuracy: 0.6250 - val_loss: 1.4354 - val_accuracy: 0.0714\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3207 - accuracy: 0.6071 - val_loss: 1.4280 - val_accuracy: 0.0714\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3380 - accuracy: 0.4464 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3188 - accuracy: 0.5357 - val_loss: 1.4129 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3012 - accuracy: 0.5893 - val_loss: 1.4077 - val_accuracy: 0.0714\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3230 - accuracy: 0.6071 - val_loss: 1.4061 - val_accuracy: 0.0714\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2970 - accuracy: 0.5714 - val_loss: 1.4120 - val_accuracy: 0.0714\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3080 - accuracy: 0.5714 - val_loss: 1.4209 - val_accuracy: 0.0714\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3029 - accuracy: 0.5179 - val_loss: 1.4312 - val_accuracy: 0.0714\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.3117 - accuracy: 0.5893 - val_loss: 1.4451 - val_accuracy: 0.0714\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2839 - accuracy: 0.5357 - val_loss: 1.4563 - val_accuracy: 0.0714\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2942 - accuracy: 0.6429 - val_loss: 1.4669 - val_accuracy: 0.0714\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2915 - accuracy: 0.5357 - val_loss: 1.4748 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2685 - accuracy: 0.5714 - val_loss: 1.4772 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3072 - accuracy: 0.5357 - val_loss: 1.4695 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2820 - accuracy: 0.6429 - val_loss: 1.4584 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2790 - accuracy: 0.5893 - val_loss: 1.4462 - val_accuracy: 0.0714\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2849 - accuracy: 0.6071 - val_loss: 1.4298 - val_accuracy: 0.0714\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3009 - accuracy: 0.5893 - val_loss: 1.4128 - val_accuracy: 0.0714\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2875 - accuracy: 0.5536 - val_loss: 1.4048 - val_accuracy: 0.0714\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2812 - accuracy: 0.6071 - val_loss: 1.4047 - val_accuracy: 0.0714\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2755 - accuracy: 0.5893 - val_loss: 1.4034 - val_accuracy: 0.0714\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2651 - accuracy: 0.6071 - val_loss: 1.4034 - val_accuracy: 0.0714\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2614 - accuracy: 0.6429 - val_loss: 1.4064 - val_accuracy: 0.0714\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2658 - accuracy: 0.6250 - val_loss: 1.4087 - val_accuracy: 0.0714\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2602 - accuracy: 0.5893 - val_loss: 1.4143 - val_accuracy: 0.0714\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.2555 - accuracy: 0.6071 - val_loss: 1.4182 - val_accuracy: 0.0714\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2668 - accuracy: 0.5893 - val_loss: 1.4229 - val_accuracy: 0.0714\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2507 - accuracy: 0.6250 - val_loss: 1.4284 - val_accuracy: 0.0714\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2481 - accuracy: 0.6429 - val_loss: 1.4310 - val_accuracy: 0.0714\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2451 - accuracy: 0.6071 - val_loss: 1.4357 - val_accuracy: 0.0714\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2412 - accuracy: 0.5536 - val_loss: 1.4378 - val_accuracy: 0.0714\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2417 - accuracy: 0.6429 - val_loss: 1.4411 - val_accuracy: 0.0714\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2622 - accuracy: 0.5893 - val_loss: 1.4457 - val_accuracy: 0.0714\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2406 - accuracy: 0.5536 - val_loss: 1.4511 - val_accuracy: 0.0714\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2454 - accuracy: 0.5893 - val_loss: 1.4570 - val_accuracy: 0.0714\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2451 - accuracy: 0.6071 - val_loss: 1.4617 - val_accuracy: 0.0714\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2410 - accuracy: 0.5179 - val_loss: 1.4663 - val_accuracy: 0.0714\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2345 - accuracy: 0.6250 - val_loss: 1.4660 - val_accuracy: 0.0714\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2255 - accuracy: 0.6071 - val_loss: 1.4640 - val_accuracy: 0.0714\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2443 - accuracy: 0.6250 - val_loss: 1.4595 - val_accuracy: 0.0714\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2449 - accuracy: 0.5714 - val_loss: 1.4542 - val_accuracy: 0.0714\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.2497 - accuracy: 0.5536 - val_loss: 1.4490 - val_accuracy: 0.0714\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.2294 - accuracy: 0.6786 - val_loss: 1.4474 - val_accuracy: 0.0714\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.2342 - accuracy: 0.5714 - val_loss: 1.4483 - val_accuracy: 0.0714\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2277 - accuracy: 0.5893 - val_loss: 1.4553 - val_accuracy: 0.0714\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2213 - accuracy: 0.6786 - val_loss: 1.4662 - val_accuracy: 0.0714\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2201 - accuracy: 0.5179 - val_loss: 1.4770 - val_accuracy: 0.0714\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2308 - accuracy: 0.5893 - val_loss: 1.4824 - val_accuracy: 0.0714\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2146 - accuracy: 0.5714 - val_loss: 1.4840 - val_accuracy: 0.0714\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2168 - accuracy: 0.6786 - val_loss: 1.4827 - val_accuracy: 0.0714\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2107 - accuracy: 0.6250 - val_loss: 1.4758 - val_accuracy: 0.0714\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2179 - accuracy: 0.6429 - val_loss: 1.4689 - val_accuracy: 0.0714\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2159 - accuracy: 0.6429 - val_loss: 1.4625 - val_accuracy: 0.0714\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2093 - accuracy: 0.6071 - val_loss: 1.4563 - val_accuracy: 0.0714\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2084 - accuracy: 0.6607 - val_loss: 1.4509 - val_accuracy: 0.0714\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2171 - accuracy: 0.6071 - val_loss: 1.4523 - val_accuracy: 0.0714\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2116 - accuracy: 0.5893 - val_loss: 1.4606 - val_accuracy: 0.0714\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4606 - accuracy: 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=240, batch_size=400, Scores: [1.4606009721755981, 0.0714285746216774]\n",
      "Accuracy on validation set: 0.0714285746216774\n",
      "Loss on validation set: 1.4606009721755981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9844 - accuracy: 0.1429 - val_loss: 1.0707 - val_accuracy: 0.0714\n",
      "Epoch 2/240\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9814 - accuracy: 0.1786 - val_loss: 1.0708 - val_accuracy: 0.0714\n",
      "Epoch 3/240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.9784 - accuracy: 0.1429 - val_loss: 1.0709 - val_accuracy: 0.0714\n",
      "Epoch 4/240\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.9737 - accuracy: 0.2321 - val_loss: 1.0712 - val_accuracy: 0.0714\n",
      "Epoch 5/240\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.9703 - accuracy: 0.2857 - val_loss: 1.0715 - val_accuracy: 0.0714\n",
      "Epoch 6/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.9674 - accuracy: 0.2500 - val_loss: 1.0718 - val_accuracy: 0.0714\n",
      "Epoch 7/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9642 - accuracy: 0.2857 - val_loss: 1.0721 - val_accuracy: 0.0714\n",
      "Epoch 8/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9588 - accuracy: 0.3214 - val_loss: 1.0724 - val_accuracy: 0.0714\n",
      "Epoch 9/240\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.9569 - accuracy: 0.3036 - val_loss: 1.0727 - val_accuracy: 0.0714\n",
      "Epoch 10/240\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.9492 - accuracy: 0.3036 - val_loss: 1.0729 - val_accuracy: 0.0714\n",
      "Epoch 11/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9493 - accuracy: 0.3393 - val_loss: 1.0732 - val_accuracy: 0.0714\n",
      "Epoch 12/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.9431 - accuracy: 0.3036 - val_loss: 1.0735 - val_accuracy: 0.0714\n",
      "Epoch 13/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.9389 - accuracy: 0.3571 - val_loss: 1.0738 - val_accuracy: 0.0714\n",
      "Epoch 14/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.9336 - accuracy: 0.3929 - val_loss: 1.0741 - val_accuracy: 0.0714\n",
      "Epoch 15/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9322 - accuracy: 0.3214 - val_loss: 1.0744 - val_accuracy: 0.0714\n",
      "Epoch 16/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.9263 - accuracy: 0.3036 - val_loss: 1.0748 - val_accuracy: 0.0714\n",
      "Epoch 17/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9229 - accuracy: 0.3214 - val_loss: 1.0751 - val_accuracy: 0.0714\n",
      "Epoch 18/240\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.9168 - accuracy: 0.3929 - val_loss: 1.0754 - val_accuracy: 0.0714\n",
      "Epoch 19/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9145 - accuracy: 0.2857 - val_loss: 1.0758 - val_accuracy: 0.0714\n",
      "Epoch 20/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9112 - accuracy: 0.3214 - val_loss: 1.0762 - val_accuracy: 0.0714\n",
      "Epoch 21/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.9004 - accuracy: 0.3393 - val_loss: 1.0766 - val_accuracy: 0.0714\n",
      "Epoch 22/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8953 - accuracy: 0.3571 - val_loss: 1.0771 - val_accuracy: 0.0714\n",
      "Epoch 23/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8965 - accuracy: 0.3214 - val_loss: 1.0777 - val_accuracy: 0.0714\n",
      "Epoch 24/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8890 - accuracy: 0.3036 - val_loss: 1.0785 - val_accuracy: 0.0714\n",
      "Epoch 25/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.8810 - accuracy: 0.3393 - val_loss: 1.0794 - val_accuracy: 0.0714\n",
      "Epoch 26/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.8772 - accuracy: 0.3750 - val_loss: 1.0803 - val_accuracy: 0.0714\n",
      "Epoch 27/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.8708 - accuracy: 0.3214 - val_loss: 1.0816 - val_accuracy: 0.0714\n",
      "Epoch 28/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8644 - accuracy: 0.3393 - val_loss: 1.0831 - val_accuracy: 0.0714\n",
      "Epoch 29/240\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.8594 - accuracy: 0.3036 - val_loss: 1.0850 - val_accuracy: 0.0714\n",
      "Epoch 30/240\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.8526 - accuracy: 0.3036 - val_loss: 1.0874 - val_accuracy: 0.0714\n",
      "Epoch 31/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.8514 - accuracy: 0.3214 - val_loss: 1.0899 - val_accuracy: 0.0714\n",
      "Epoch 32/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8416 - accuracy: 0.3036 - val_loss: 1.0928 - val_accuracy: 0.0714\n",
      "Epoch 33/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.8424 - accuracy: 0.3036 - val_loss: 1.0961 - val_accuracy: 0.1429\n",
      "Epoch 34/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8403 - accuracy: 0.2500 - val_loss: 1.0999 - val_accuracy: 0.1429\n",
      "Epoch 35/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.8318 - accuracy: 0.3393 - val_loss: 1.1040 - val_accuracy: 0.1429\n",
      "Epoch 36/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.8188 - accuracy: 0.3036 - val_loss: 1.1086 - val_accuracy: 0.1429\n",
      "Epoch 37/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8203 - accuracy: 0.3036 - val_loss: 1.1136 - val_accuracy: 0.1429\n",
      "Epoch 38/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.8133 - accuracy: 0.3036 - val_loss: 1.1191 - val_accuracy: 0.1429\n",
      "Epoch 39/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.8073 - accuracy: 0.3393 - val_loss: 1.1250 - val_accuracy: 0.1429\n",
      "Epoch 40/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8087 - accuracy: 0.3214 - val_loss: 1.1314 - val_accuracy: 0.1429\n",
      "Epoch 41/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8020 - accuracy: 0.3571 - val_loss: 1.1381 - val_accuracy: 0.1429\n",
      "Epoch 42/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.7915 - accuracy: 0.3393 - val_loss: 1.1452 - val_accuracy: 0.1429\n",
      "Epoch 43/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7871 - accuracy: 0.3393 - val_loss: 1.1524 - val_accuracy: 0.1429\n",
      "Epoch 44/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7855 - accuracy: 0.3571 - val_loss: 1.1599 - val_accuracy: 0.1429\n",
      "Epoch 45/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7836 - accuracy: 0.3393 - val_loss: 1.1674 - val_accuracy: 0.1429\n",
      "Epoch 46/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7870 - accuracy: 0.3571 - val_loss: 1.1746 - val_accuracy: 0.1429\n",
      "Epoch 47/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7705 - accuracy: 0.3571 - val_loss: 1.1818 - val_accuracy: 0.1429\n",
      "Epoch 48/240\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7706 - accuracy: 0.2857 - val_loss: 1.1888 - val_accuracy: 0.1429\n",
      "Epoch 49/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7678 - accuracy: 0.3571 - val_loss: 1.1955 - val_accuracy: 0.1429\n",
      "Epoch 50/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7621 - accuracy: 0.3393 - val_loss: 1.2021 - val_accuracy: 0.1429\n",
      "Epoch 51/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7588 - accuracy: 0.3036 - val_loss: 1.2085 - val_accuracy: 0.1429\n",
      "Epoch 52/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.7551 - accuracy: 0.3393 - val_loss: 1.2144 - val_accuracy: 0.1429\n",
      "Epoch 53/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7534 - accuracy: 0.3036 - val_loss: 1.2201 - val_accuracy: 0.1429\n",
      "Epoch 54/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7430 - accuracy: 0.3393 - val_loss: 1.2254 - val_accuracy: 0.1429\n",
      "Epoch 55/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.7370 - accuracy: 0.3393 - val_loss: 1.2301 - val_accuracy: 0.1429\n",
      "Epoch 56/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7416 - accuracy: 0.3571 - val_loss: 1.2341 - val_accuracy: 0.1429\n",
      "Epoch 57/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.7354 - accuracy: 0.3393 - val_loss: 1.2378 - val_accuracy: 0.1429\n",
      "Epoch 58/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7263 - accuracy: 0.3393 - val_loss: 1.2409 - val_accuracy: 0.1429\n",
      "Epoch 59/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7227 - accuracy: 0.3393 - val_loss: 1.2441 - val_accuracy: 0.2143\n",
      "Epoch 60/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7234 - accuracy: 0.3750 - val_loss: 1.2473 - val_accuracy: 0.1429\n",
      "Epoch 61/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7232 - accuracy: 0.3571 - val_loss: 1.2503 - val_accuracy: 0.1429\n",
      "Epoch 62/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7174 - accuracy: 0.3571 - val_loss: 1.2532 - val_accuracy: 0.1429\n",
      "Epoch 63/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7108 - accuracy: 0.3750 - val_loss: 1.2556 - val_accuracy: 0.1429\n",
      "Epoch 64/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7020 - accuracy: 0.3929 - val_loss: 1.2582 - val_accuracy: 0.1429\n",
      "Epoch 65/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6961 - accuracy: 0.3750 - val_loss: 1.2607 - val_accuracy: 0.1429\n",
      "Epoch 66/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7005 - accuracy: 0.4286 - val_loss: 1.2644 - val_accuracy: 0.1429\n",
      "Epoch 67/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7043 - accuracy: 0.3750 - val_loss: 1.2671 - val_accuracy: 0.1429\n",
      "Epoch 68/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6947 - accuracy: 0.3571 - val_loss: 1.2700 - val_accuracy: 0.1429\n",
      "Epoch 69/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7017 - accuracy: 0.3571 - val_loss: 1.2716 - val_accuracy: 0.1429\n",
      "Epoch 70/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6950 - accuracy: 0.3571 - val_loss: 1.2739 - val_accuracy: 0.1429\n",
      "Epoch 71/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6828 - accuracy: 0.4107 - val_loss: 1.2760 - val_accuracy: 0.1429\n",
      "Epoch 72/240\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6863 - accuracy: 0.3929 - val_loss: 1.2783 - val_accuracy: 0.1429\n",
      "Epoch 73/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6831 - accuracy: 0.3750 - val_loss: 1.2812 - val_accuracy: 0.1429\n",
      "Epoch 74/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6767 - accuracy: 0.4286 - val_loss: 1.2850 - val_accuracy: 0.1429\n",
      "Epoch 75/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6657 - accuracy: 0.4464 - val_loss: 1.2880 - val_accuracy: 0.1429\n",
      "Epoch 76/240\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.6718 - accuracy: 0.4107 - val_loss: 1.2912 - val_accuracy: 0.1429\n",
      "Epoch 77/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.6685 - accuracy: 0.4107 - val_loss: 1.2943 - val_accuracy: 0.1429\n",
      "Epoch 78/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.6581 - accuracy: 0.4286 - val_loss: 1.2992 - val_accuracy: 0.1429\n",
      "Epoch 79/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6503 - accuracy: 0.4286 - val_loss: 1.3053 - val_accuracy: 0.1429\n",
      "Epoch 80/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6601 - accuracy: 0.4286 - val_loss: 1.3110 - val_accuracy: 0.1429\n",
      "Epoch 81/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6585 - accuracy: 0.3571 - val_loss: 1.3169 - val_accuracy: 0.1429\n",
      "Epoch 82/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6534 - accuracy: 0.3929 - val_loss: 1.3235 - val_accuracy: 0.1429\n",
      "Epoch 83/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6381 - accuracy: 0.4643 - val_loss: 1.3291 - val_accuracy: 0.1429\n",
      "Epoch 84/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6400 - accuracy: 0.4286 - val_loss: 1.3331 - val_accuracy: 0.1429\n",
      "Epoch 85/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6492 - accuracy: 0.4107 - val_loss: 1.3365 - val_accuracy: 0.1429\n",
      "Epoch 86/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6381 - accuracy: 0.4107 - val_loss: 1.3388 - val_accuracy: 0.1429\n",
      "Epoch 87/240\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6262 - accuracy: 0.4286 - val_loss: 1.3407 - val_accuracy: 0.1429\n",
      "Epoch 88/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6264 - accuracy: 0.4643 - val_loss: 1.3426 - val_accuracy: 0.1429\n",
      "Epoch 89/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6150 - accuracy: 0.4464 - val_loss: 1.3458 - val_accuracy: 0.1429\n",
      "Epoch 90/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.6124 - accuracy: 0.3750 - val_loss: 1.3507 - val_accuracy: 0.1429\n",
      "Epoch 91/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6088 - accuracy: 0.4107 - val_loss: 1.3549 - val_accuracy: 0.1429\n",
      "Epoch 92/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.6163 - accuracy: 0.4286 - val_loss: 1.3584 - val_accuracy: 0.1429\n",
      "Epoch 93/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6090 - accuracy: 0.4107 - val_loss: 1.3613 - val_accuracy: 0.1429\n",
      "Epoch 94/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6106 - accuracy: 0.4286 - val_loss: 1.3644 - val_accuracy: 0.1429\n",
      "Epoch 95/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5954 - accuracy: 0.4107 - val_loss: 1.3698 - val_accuracy: 0.1429\n",
      "Epoch 96/240\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.6066 - accuracy: 0.3929 - val_loss: 1.3754 - val_accuracy: 0.1429\n",
      "Epoch 97/240\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.5915 - accuracy: 0.4286 - val_loss: 1.3819 - val_accuracy: 0.1429\n",
      "Epoch 98/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5885 - accuracy: 0.4286 - val_loss: 1.3876 - val_accuracy: 0.1429\n",
      "Epoch 99/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6034 - accuracy: 0.4286 - val_loss: 1.3922 - val_accuracy: 0.1429\n",
      "Epoch 100/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5943 - accuracy: 0.4286 - val_loss: 1.3941 - val_accuracy: 0.1429\n",
      "Epoch 101/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5887 - accuracy: 0.4821 - val_loss: 1.3950 - val_accuracy: 0.1429\n",
      "Epoch 102/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5668 - accuracy: 0.3929 - val_loss: 1.3958 - val_accuracy: 0.1429\n",
      "Epoch 103/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5770 - accuracy: 0.4286 - val_loss: 1.3971 - val_accuracy: 0.1429\n",
      "Epoch 104/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5841 - accuracy: 0.4286 - val_loss: 1.4005 - val_accuracy: 0.1429\n",
      "Epoch 105/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5686 - accuracy: 0.4107 - val_loss: 1.4037 - val_accuracy: 0.1429\n",
      "Epoch 106/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5730 - accuracy: 0.4107 - val_loss: 1.4076 - val_accuracy: 0.1429\n",
      "Epoch 107/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5506 - accuracy: 0.4286 - val_loss: 1.4121 - val_accuracy: 0.1429\n",
      "Epoch 108/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5593 - accuracy: 0.4107 - val_loss: 1.4144 - val_accuracy: 0.1429\n",
      "Epoch 109/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5610 - accuracy: 0.3929 - val_loss: 1.4202 - val_accuracy: 0.1429\n",
      "Epoch 110/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5413 - accuracy: 0.4464 - val_loss: 1.4305 - val_accuracy: 0.1429\n",
      "Epoch 111/240\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5577 - accuracy: 0.4286 - val_loss: 1.4398 - val_accuracy: 0.1429\n",
      "Epoch 112/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5452 - accuracy: 0.3750 - val_loss: 1.4444 - val_accuracy: 0.1429\n",
      "Epoch 113/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5484 - accuracy: 0.3929 - val_loss: 1.4463 - val_accuracy: 0.1429\n",
      "Epoch 114/240\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5368 - accuracy: 0.4464 - val_loss: 1.4480 - val_accuracy: 0.1429\n",
      "Epoch 115/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5175 - accuracy: 0.4643 - val_loss: 1.4501 - val_accuracy: 0.1429\n",
      "Epoch 116/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5293 - accuracy: 0.4107 - val_loss: 1.4500 - val_accuracy: 0.1429\n",
      "Epoch 117/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5294 - accuracy: 0.5000 - val_loss: 1.4488 - val_accuracy: 0.1429\n",
      "Epoch 118/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5307 - accuracy: 0.3929 - val_loss: 1.4479 - val_accuracy: 0.1429\n",
      "Epoch 119/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.5296 - accuracy: 0.4821 - val_loss: 1.4462 - val_accuracy: 0.1429\n",
      "Epoch 120/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5255 - accuracy: 0.4286 - val_loss: 1.4441 - val_accuracy: 0.2143\n",
      "Epoch 121/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5125 - accuracy: 0.4107 - val_loss: 1.4423 - val_accuracy: 0.2143\n",
      "Epoch 122/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4912 - accuracy: 0.5000 - val_loss: 1.4431 - val_accuracy: 0.2143\n",
      "Epoch 123/240\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.5142 - accuracy: 0.3929 - val_loss: 1.4439 - val_accuracy: 0.1429\n",
      "Epoch 124/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5057 - accuracy: 0.4464 - val_loss: 1.4461 - val_accuracy: 0.1429\n",
      "Epoch 125/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5051 - accuracy: 0.4821 - val_loss: 1.4504 - val_accuracy: 0.1429\n",
      "Epoch 126/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5092 - accuracy: 0.4821 - val_loss: 1.4556 - val_accuracy: 0.1429\n",
      "Epoch 127/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4859 - accuracy: 0.5000 - val_loss: 1.4604 - val_accuracy: 0.1429\n",
      "Epoch 128/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4890 - accuracy: 0.4286 - val_loss: 1.4670 - val_accuracy: 0.1429\n",
      "Epoch 129/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4807 - accuracy: 0.4821 - val_loss: 1.4713 - val_accuracy: 0.0714\n",
      "Epoch 130/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4978 - accuracy: 0.4286 - val_loss: 1.4761 - val_accuracy: 0.0714\n",
      "Epoch 131/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4779 - accuracy: 0.4821 - val_loss: 1.4811 - val_accuracy: 0.0714\n",
      "Epoch 132/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4842 - accuracy: 0.5000 - val_loss: 1.4843 - val_accuracy: 0.0714\n",
      "Epoch 133/240\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 0.4801 - accuracy: 0.4464 - val_loss: 1.4831 - val_accuracy: 0.1429\n",
      "Epoch 134/240\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4789 - accuracy: 0.4821 - val_loss: 1.4784 - val_accuracy: 0.1429\n",
      "Epoch 135/240\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4769 - accuracy: 0.4821 - val_loss: 1.4707 - val_accuracy: 0.1429\n",
      "Epoch 136/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4607 - accuracy: 0.4464 - val_loss: 1.4654 - val_accuracy: 0.1429\n",
      "Epoch 137/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4488 - accuracy: 0.5000 - val_loss: 1.4617 - val_accuracy: 0.1429\n",
      "Epoch 138/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4559 - accuracy: 0.5357 - val_loss: 1.4632 - val_accuracy: 0.0714\n",
      "Epoch 139/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4474 - accuracy: 0.4464 - val_loss: 1.4682 - val_accuracy: 0.0714\n",
      "Epoch 140/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.4521 - accuracy: 0.5357 - val_loss: 1.4753 - val_accuracy: 0.0714\n",
      "Epoch 141/240\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4430 - accuracy: 0.5000 - val_loss: 1.4822 - val_accuracy: 0.0714\n",
      "Epoch 142/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4554 - accuracy: 0.4643 - val_loss: 1.4848 - val_accuracy: 0.0714\n",
      "Epoch 143/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4181 - accuracy: 0.5000 - val_loss: 1.4848 - val_accuracy: 0.0714\n",
      "Epoch 144/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4340 - accuracy: 0.5179 - val_loss: 1.4853 - val_accuracy: 0.0714\n",
      "Epoch 145/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4350 - accuracy: 0.4643 - val_loss: 1.4839 - val_accuracy: 0.0714\n",
      "Epoch 146/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4234 - accuracy: 0.5000 - val_loss: 1.4839 - val_accuracy: 0.0714\n",
      "Epoch 147/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4319 - accuracy: 0.4464 - val_loss: 1.4839 - val_accuracy: 0.2143\n",
      "Epoch 148/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4186 - accuracy: 0.5000 - val_loss: 1.4874 - val_accuracy: 0.2143\n",
      "Epoch 149/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4049 - accuracy: 0.4464 - val_loss: 1.4927 - val_accuracy: 0.1429\n",
      "Epoch 150/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4128 - accuracy: 0.5000 - val_loss: 1.4947 - val_accuracy: 0.0714\n",
      "Epoch 151/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3981 - accuracy: 0.5000 - val_loss: 1.4997 - val_accuracy: 0.0714\n",
      "Epoch 152/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4025 - accuracy: 0.5000 - val_loss: 1.5032 - val_accuracy: 0.0714\n",
      "Epoch 153/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4208 - accuracy: 0.4464 - val_loss: 1.4990 - val_accuracy: 0.0714\n",
      "Epoch 154/240\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3835 - accuracy: 0.4821 - val_loss: 1.4949 - val_accuracy: 0.0714\n",
      "Epoch 155/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3975 - accuracy: 0.5179 - val_loss: 1.4895 - val_accuracy: 0.0714\n",
      "Epoch 156/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4102 - accuracy: 0.5179 - val_loss: 1.4858 - val_accuracy: 0.0714\n",
      "Epoch 157/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3857 - accuracy: 0.5000 - val_loss: 1.4831 - val_accuracy: 0.0714\n",
      "Epoch 158/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3805 - accuracy: 0.5000 - val_loss: 1.4825 - val_accuracy: 0.0714\n",
      "Epoch 159/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3867 - accuracy: 0.5536 - val_loss: 1.4826 - val_accuracy: 0.0714\n",
      "Epoch 160/240\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3811 - accuracy: 0.5893 - val_loss: 1.4895 - val_accuracy: 0.1429\n",
      "Epoch 161/240\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.3807 - accuracy: 0.5357 - val_loss: 1.4971 - val_accuracy: 0.1429\n",
      "Epoch 162/240\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3613 - accuracy: 0.5357 - val_loss: 1.5013 - val_accuracy: 0.1429\n",
      "Epoch 163/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3529 - accuracy: 0.6071 - val_loss: 1.4970 - val_accuracy: 0.1429\n",
      "Epoch 164/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3650 - accuracy: 0.4821 - val_loss: 1.4873 - val_accuracy: 0.2143\n",
      "Epoch 165/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3721 - accuracy: 0.4107 - val_loss: 1.4709 - val_accuracy: 0.2143\n",
      "Epoch 166/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3493 - accuracy: 0.5000 - val_loss: 1.4613 - val_accuracy: 0.2143\n",
      "Epoch 167/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.3575 - accuracy: 0.5357 - val_loss: 1.4602 - val_accuracy: 0.2143\n",
      "Epoch 168/240\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.3514 - accuracy: 0.5000 - val_loss: 1.4635 - val_accuracy: 0.2143\n",
      "Epoch 169/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3516 - accuracy: 0.5179 - val_loss: 1.4731 - val_accuracy: 0.1429\n",
      "Epoch 170/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3475 - accuracy: 0.5357 - val_loss: 1.4899 - val_accuracy: 0.1429\n",
      "Epoch 171/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3514 - accuracy: 0.5357 - val_loss: 1.5013 - val_accuracy: 0.1429\n",
      "Epoch 172/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3438 - accuracy: 0.5179 - val_loss: 1.5128 - val_accuracy: 0.2143\n",
      "Epoch 173/240\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3218 - accuracy: 0.5000 - val_loss: 1.5242 - val_accuracy: 0.2143\n",
      "Epoch 174/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3307 - accuracy: 0.5714 - val_loss: 1.5269 - val_accuracy: 0.2143\n",
      "Epoch 175/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3404 - accuracy: 0.5000 - val_loss: 1.5203 - val_accuracy: 0.2143\n",
      "Epoch 176/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3340 - accuracy: 0.5357 - val_loss: 1.5099 - val_accuracy: 0.2143\n",
      "Epoch 177/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3278 - accuracy: 0.5893 - val_loss: 1.5054 - val_accuracy: 0.2143\n",
      "Epoch 178/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3407 - accuracy: 0.4643 - val_loss: 1.5010 - val_accuracy: 0.0714\n",
      "Epoch 179/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3170 - accuracy: 0.5536 - val_loss: 1.5021 - val_accuracy: 0.0714\n",
      "Epoch 180/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3225 - accuracy: 0.5536 - val_loss: 1.5090 - val_accuracy: 0.0714\n",
      "Epoch 181/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3153 - accuracy: 0.4821 - val_loss: 1.5175 - val_accuracy: 0.1429\n",
      "Epoch 182/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3117 - accuracy: 0.6071 - val_loss: 1.5269 - val_accuracy: 0.1429\n",
      "Epoch 183/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3112 - accuracy: 0.6429 - val_loss: 1.5357 - val_accuracy: 0.1429\n",
      "Epoch 184/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2836 - accuracy: 0.5357 - val_loss: 1.5420 - val_accuracy: 0.1429\n",
      "Epoch 185/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2949 - accuracy: 0.6071 - val_loss: 1.5478 - val_accuracy: 0.1429\n",
      "Epoch 186/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3037 - accuracy: 0.5714 - val_loss: 1.5435 - val_accuracy: 0.2143\n",
      "Epoch 187/240\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3036 - accuracy: 0.5714 - val_loss: 1.5349 - val_accuracy: 0.2143\n",
      "Epoch 188/240\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2889 - accuracy: 0.5179 - val_loss: 1.5287 - val_accuracy: 0.2143\n",
      "Epoch 189/240\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2849 - accuracy: 0.5714 - val_loss: 1.5278 - val_accuracy: 0.2143\n",
      "Epoch 190/240\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2817 - accuracy: 0.5893 - val_loss: 1.5374 - val_accuracy: 0.2143\n",
      "Epoch 191/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2736 - accuracy: 0.5536 - val_loss: 1.5515 - val_accuracy: 0.2143\n",
      "Epoch 192/240\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2847 - accuracy: 0.5893 - val_loss: 1.5664 - val_accuracy: 0.2143\n",
      "Epoch 193/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2617 - accuracy: 0.6429 - val_loss: 1.5801 - val_accuracy: 0.2143\n",
      "Epoch 194/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2764 - accuracy: 0.5536 - val_loss: 1.5836 - val_accuracy: 0.2143\n",
      "Epoch 195/240\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2824 - accuracy: 0.6071 - val_loss: 1.5840 - val_accuracy: 0.2143\n",
      "Epoch 196/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2896 - accuracy: 0.5893 - val_loss: 1.5753 - val_accuracy: 0.2143\n",
      "Epoch 197/240\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2765 - accuracy: 0.6071 - val_loss: 1.5615 - val_accuracy: 0.2143\n",
      "Epoch 198/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2678 - accuracy: 0.5893 - val_loss: 1.5522 - val_accuracy: 0.2143\n",
      "Epoch 199/240\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2886 - accuracy: 0.6786 - val_loss: 1.5466 - val_accuracy: 0.2143\n",
      "Epoch 200/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2805 - accuracy: 0.5536 - val_loss: 1.5456 - val_accuracy: 0.2143\n",
      "Epoch 201/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2641 - accuracy: 0.5357 - val_loss: 1.5493 - val_accuracy: 0.2143\n",
      "Epoch 202/240\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2676 - accuracy: 0.4821 - val_loss: 1.5603 - val_accuracy: 0.2143\n",
      "Epoch 203/240\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2533 - accuracy: 0.5536 - val_loss: 1.5715 - val_accuracy: 0.2143\n",
      "Epoch 204/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2562 - accuracy: 0.6429 - val_loss: 1.5855 - val_accuracy: 0.2143\n",
      "Epoch 205/240\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2567 - accuracy: 0.6250 - val_loss: 1.5957 - val_accuracy: 0.2143\n",
      "Epoch 206/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2409 - accuracy: 0.5714 - val_loss: 1.6056 - val_accuracy: 0.2143\n",
      "Epoch 207/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2469 - accuracy: 0.6250 - val_loss: 1.6098 - val_accuracy: 0.2143\n",
      "Epoch 208/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2686 - accuracy: 0.6071 - val_loss: 1.6032 - val_accuracy: 0.2143\n",
      "Epoch 209/240\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2388 - accuracy: 0.5536 - val_loss: 1.6024 - val_accuracy: 0.2143\n",
      "Epoch 210/240\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2341 - accuracy: 0.6250 - val_loss: 1.6003 - val_accuracy: 0.2143\n",
      "Epoch 211/240\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2331 - accuracy: 0.5536 - val_loss: 1.5992 - val_accuracy: 0.2143\n",
      "Epoch 212/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2429 - accuracy: 0.5536 - val_loss: 1.5984 - val_accuracy: 0.2143\n",
      "Epoch 213/240\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2249 - accuracy: 0.6071 - val_loss: 1.5947 - val_accuracy: 0.1429\n",
      "Epoch 214/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.2214 - accuracy: 0.5893 - val_loss: 1.5898 - val_accuracy: 0.1429\n",
      "Epoch 215/240\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2425 - accuracy: 0.5536 - val_loss: 1.5886 - val_accuracy: 0.1429\n",
      "Epoch 216/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2266 - accuracy: 0.5357 - val_loss: 1.5865 - val_accuracy: 0.1429\n",
      "Epoch 217/240\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2578 - accuracy: 0.5179 - val_loss: 1.5857 - val_accuracy: 0.2143\n",
      "Epoch 218/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2240 - accuracy: 0.5714 - val_loss: 1.5885 - val_accuracy: 0.2143\n",
      "Epoch 219/240\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2387 - accuracy: 0.6250 - val_loss: 1.5935 - val_accuracy: 0.2143\n",
      "Epoch 220/240\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2365 - accuracy: 0.5179 - val_loss: 1.6065 - val_accuracy: 0.2143\n",
      "Epoch 221/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2308 - accuracy: 0.6786 - val_loss: 1.6197 - val_accuracy: 0.2143\n",
      "Epoch 222/240\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2305 - accuracy: 0.5714 - val_loss: 1.6388 - val_accuracy: 0.2143\n",
      "Epoch 223/240\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2287 - accuracy: 0.5536 - val_loss: 1.6552 - val_accuracy: 0.2143\n",
      "Epoch 224/240\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2100 - accuracy: 0.5536 - val_loss: 1.6610 - val_accuracy: 0.2143\n",
      "Epoch 225/240\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2142 - accuracy: 0.5714 - val_loss: 1.6590 - val_accuracy: 0.2143\n",
      "Epoch 226/240\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.2097 - accuracy: 0.6071 - val_loss: 1.6441 - val_accuracy: 0.2143\n",
      "Epoch 227/240\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.2288 - accuracy: 0.5357 - val_loss: 1.6233 - val_accuracy: 0.2143\n",
      "Epoch 228/240\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.2090 - accuracy: 0.5893 - val_loss: 1.6054 - val_accuracy: 0.2143\n",
      "Epoch 229/240\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2159 - accuracy: 0.6429 - val_loss: 1.5952 - val_accuracy: 0.2143\n",
      "Epoch 230/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2054 - accuracy: 0.5536 - val_loss: 1.5903 - val_accuracy: 0.2143\n",
      "Epoch 231/240\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2118 - accuracy: 0.5714 - val_loss: 1.5909 - val_accuracy: 0.1429\n",
      "Epoch 232/240\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2135 - accuracy: 0.5893 - val_loss: 1.5974 - val_accuracy: 0.1429\n",
      "Epoch 233/240\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2158 - accuracy: 0.5893 - val_loss: 1.6076 - val_accuracy: 0.1429\n",
      "Epoch 234/240\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1952 - accuracy: 0.5714 - val_loss: 1.6230 - val_accuracy: 0.1429\n",
      "Epoch 235/240\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2079 - accuracy: 0.5179 - val_loss: 1.6401 - val_accuracy: 0.2143\n",
      "Epoch 236/240\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2085 - accuracy: 0.6607 - val_loss: 1.6560 - val_accuracy: 0.2143\n",
      "Epoch 237/240\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2085 - accuracy: 0.6071 - val_loss: 1.6641 - val_accuracy: 0.2143\n",
      "Epoch 238/240\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2006 - accuracy: 0.5893 - val_loss: 1.6607 - val_accuracy: 0.2143\n",
      "Epoch 239/240\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1814 - accuracy: 0.6429 - val_loss: 1.6567 - val_accuracy: 0.2143\n",
      "Epoch 240/240\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1950 - accuracy: 0.6786 - val_loss: 1.6543 - val_accuracy: 0.2143\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6543 - accuracy: 0.2143\n",
      "Parameters: lr=0.0001, dropout=0.6, lstm_units=240, wl= 7, epoch=240, batch_size=500, Scores: [1.6542640924453735, 0.2142857164144516]\n",
      "Accuracy on validation set: 0.2142857164144516\n",
      "Loss on validation set: 1.6542640924453735\n",
      "Best Parameters: {'learning_rate': 0.0001, 'dropout_rate': 0.2, 'lstm_unit': 120, 'window_length': 7, 'epoch': 128, 'batch_size': 100}, Best Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter ranges\n",
    "learning_rates = [0.0001]\n",
    "dropout_rates = [0.2, 0.4, 0.6]\n",
    "lstm_units_list = [120, 240]\n",
    "window_lengths = [7]\n",
    "epochs = [32, 64, 100, 128, 240]\n",
    "batch_sizes = [100, 300, 400, 500]\n",
    "\n",
    "# Perform grid search\n",
    "best_score = float('inf')  # Assuming we want to minimize the metric\n",
    "best_params = None\n",
    "\n",
    "for learning_rate, dropout_rate, lstm_unit, window_length, epoch, batch_size in product(learning_rates, dropout_rates, lstm_units_list, window_lengths, epochs, batch_sizes):\n",
    "    scores = build_and_train_model(learning_rate, dropout_rate, lstm_unit, window_length, epoch, batch_size)\n",
    "    print(f'Parameters: lr={learning_rate}, dropout={dropout_rate}, lstm_units={lstm_unit}, wl= {window_length}, epoch={epoch}, batch_size={batch_size}, Scores: {scores}')\n",
    "    accuracy_score = scores[1]\n",
    "    print(f'Accuracy on validation set: {accuracy_score}')\n",
    "    loss_value = scores[0]\n",
    "    print(f'Loss on validation set: {loss_value}')\n",
    "    if accuracy_score < best_score:  # Assuming score[0] is the validation loss\n",
    "        best_score = accuracy_score\n",
    "        best_params = {'learning_rate': learning_rate, 'dropout_rate': dropout_rate, 'lstm_unit': lstm_unit, 'window_length': window_length, 'epoch': epoch, 'batch_size': batch_size}\n",
    "\n",
    "print(f'Best Parameters: {best_params}, Best Score: {best_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e531fc6-13c7-4d3c-88e0-c1b5523af27b",
   "metadata": {},
   "source": [
    "## Train with Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7c8db386-3b12-449a-8e47-d9712478627e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0001,\n",
       " 'dropout_rate': 0.2,\n",
       " 'lstm_unit': 120,\n",
       " 'window_length': 7,\n",
       " 'epoch': 128,\n",
       " 'batch_size': 100}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "73fbb2b9-8738-4acf-8691-bb079e2cfd77",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1/1 - 5s - loss: 1.0008 - accuracy: 0.1429 - 5s/epoch - 5s/step\n",
      "Epoch 2/128\n",
      "1/1 - 0s - loss: 0.9990 - accuracy: 0.1571 - 76ms/epoch - 76ms/step\n",
      "Epoch 3/128\n",
      "1/1 - 0s - loss: 0.9971 - accuracy: 0.2000 - 73ms/epoch - 73ms/step\n",
      "Epoch 4/128\n",
      "1/1 - 0s - loss: 0.9948 - accuracy: 0.2286 - 129ms/epoch - 129ms/step\n",
      "Epoch 5/128\n",
      "1/1 - 0s - loss: 0.9930 - accuracy: 0.2429 - 110ms/epoch - 110ms/step\n",
      "Epoch 6/128\n",
      "1/1 - 0s - loss: 0.9922 - accuracy: 0.2000 - 65ms/epoch - 65ms/step\n",
      "Epoch 7/128\n",
      "1/1 - 0s - loss: 0.9907 - accuracy: 0.2571 - 93ms/epoch - 93ms/step\n",
      "Epoch 8/128\n",
      "1/1 - 0s - loss: 0.9889 - accuracy: 0.2571 - 117ms/epoch - 117ms/step\n",
      "Epoch 9/128\n",
      "1/1 - 0s - loss: 0.9869 - accuracy: 0.2857 - 90ms/epoch - 90ms/step\n",
      "Epoch 10/128\n",
      "1/1 - 0s - loss: 0.9851 - accuracy: 0.3000 - 78ms/epoch - 78ms/step\n",
      "Epoch 11/128\n",
      "1/1 - 0s - loss: 0.9822 - accuracy: 0.3000 - 62ms/epoch - 62ms/step\n",
      "Epoch 12/128\n",
      "1/1 - 0s - loss: 0.9816 - accuracy: 0.2286 - 147ms/epoch - 147ms/step\n",
      "Epoch 13/128\n",
      "1/1 - 0s - loss: 0.9797 - accuracy: 0.2571 - 80ms/epoch - 80ms/step\n",
      "Epoch 14/128\n",
      "1/1 - 0s - loss: 0.9774 - accuracy: 0.2714 - 64ms/epoch - 64ms/step\n",
      "Epoch 15/128\n",
      "1/1 - 0s - loss: 0.9756 - accuracy: 0.2857 - 61ms/epoch - 61ms/step\n",
      "Epoch 16/128\n",
      "1/1 - 0s - loss: 0.9739 - accuracy: 0.2857 - 60ms/epoch - 60ms/step\n",
      "Epoch 17/128\n",
      "1/1 - 0s - loss: 0.9711 - accuracy: 0.2571 - 91ms/epoch - 91ms/step\n",
      "Epoch 18/128\n",
      "1/1 - 0s - loss: 0.9706 - accuracy: 0.2714 - 87ms/epoch - 87ms/step\n",
      "Epoch 19/128\n",
      "1/1 - 0s - loss: 0.9676 - accuracy: 0.2857 - 105ms/epoch - 105ms/step\n",
      "Epoch 20/128\n",
      "1/1 - 0s - loss: 0.9650 - accuracy: 0.2857 - 74ms/epoch - 74ms/step\n",
      "Epoch 21/128\n",
      "1/1 - 0s - loss: 0.9635 - accuracy: 0.2857 - 81ms/epoch - 81ms/step\n",
      "Epoch 22/128\n",
      "1/1 - 0s - loss: 0.9627 - accuracy: 0.3429 - 62ms/epoch - 62ms/step\n",
      "Epoch 23/128\n",
      "1/1 - 0s - loss: 0.9593 - accuracy: 0.3000 - 41ms/epoch - 41ms/step\n",
      "Epoch 24/128\n",
      "1/1 - 0s - loss: 0.9570 - accuracy: 0.2857 - 71ms/epoch - 71ms/step\n",
      "Epoch 25/128\n",
      "1/1 - 0s - loss: 0.9549 - accuracy: 0.3143 - 109ms/epoch - 109ms/step\n",
      "Epoch 26/128\n",
      "1/1 - 0s - loss: 0.9527 - accuracy: 0.3286 - 53ms/epoch - 53ms/step\n",
      "Epoch 27/128\n",
      "1/1 - 0s - loss: 0.9491 - accuracy: 0.3143 - 60ms/epoch - 60ms/step\n",
      "Epoch 28/128\n",
      "1/1 - 0s - loss: 0.9459 - accuracy: 0.3286 - 107ms/epoch - 107ms/step\n",
      "Epoch 29/128\n",
      "1/1 - 0s - loss: 0.9452 - accuracy: 0.3286 - 60ms/epoch - 60ms/step\n",
      "Epoch 30/128\n",
      "1/1 - 0s - loss: 0.9405 - accuracy: 0.2714 - 91ms/epoch - 91ms/step\n",
      "Epoch 31/128\n",
      "1/1 - 0s - loss: 0.9373 - accuracy: 0.3286 - 107ms/epoch - 107ms/step\n",
      "Epoch 32/128\n",
      "1/1 - 0s - loss: 0.9362 - accuracy: 0.2857 - 70ms/epoch - 70ms/step\n",
      "Epoch 33/128\n",
      "1/1 - 0s - loss: 0.9328 - accuracy: 0.3143 - 105ms/epoch - 105ms/step\n",
      "Epoch 34/128\n",
      "1/1 - 0s - loss: 0.9297 - accuracy: 0.2857 - 69ms/epoch - 69ms/step\n",
      "Epoch 35/128\n",
      "1/1 - 0s - loss: 0.9244 - accuracy: 0.3286 - 104ms/epoch - 104ms/step\n",
      "Epoch 36/128\n",
      "1/1 - 0s - loss: 0.9224 - accuracy: 0.3286 - 112ms/epoch - 112ms/step\n",
      "Epoch 37/128\n",
      "1/1 - 0s - loss: 0.9191 - accuracy: 0.3143 - 61ms/epoch - 61ms/step\n",
      "Epoch 38/128\n",
      "1/1 - 0s - loss: 0.9151 - accuracy: 0.3143 - 75ms/epoch - 75ms/step\n",
      "Epoch 39/128\n",
      "1/1 - 0s - loss: 0.9110 - accuracy: 0.2857 - 83ms/epoch - 83ms/step\n",
      "Epoch 40/128\n",
      "1/1 - 0s - loss: 0.9098 - accuracy: 0.3143 - 61ms/epoch - 61ms/step\n",
      "Epoch 41/128\n",
      "1/1 - 0s - loss: 0.9059 - accuracy: 0.3000 - 115ms/epoch - 115ms/step\n",
      "Epoch 42/128\n",
      "1/1 - 0s - loss: 0.9023 - accuracy: 0.3143 - 62ms/epoch - 62ms/step\n",
      "Epoch 43/128\n",
      "1/1 - 0s - loss: 0.8954 - accuracy: 0.2857 - 106ms/epoch - 106ms/step\n",
      "Epoch 44/128\n",
      "1/1 - 0s - loss: 0.8957 - accuracy: 0.2571 - 105ms/epoch - 105ms/step\n",
      "Epoch 45/128\n",
      "1/1 - 0s - loss: 0.8883 - accuracy: 0.2714 - 56ms/epoch - 56ms/step\n",
      "Epoch 46/128\n",
      "1/1 - 0s - loss: 0.8902 - accuracy: 0.2714 - 59ms/epoch - 59ms/step\n",
      "Epoch 47/128\n",
      "1/1 - 0s - loss: 0.8825 - accuracy: 0.2857 - 105ms/epoch - 105ms/step\n",
      "Epoch 48/128\n",
      "1/1 - 0s - loss: 0.8773 - accuracy: 0.2857 - 64ms/epoch - 64ms/step\n",
      "Epoch 49/128\n",
      "1/1 - 0s - loss: 0.8755 - accuracy: 0.2714 - 70ms/epoch - 70ms/step\n",
      "Epoch 50/128\n",
      "1/1 - 0s - loss: 0.8704 - accuracy: 0.3000 - 76ms/epoch - 76ms/step\n",
      "Epoch 51/128\n",
      "1/1 - 0s - loss: 0.8605 - accuracy: 0.3143 - 82ms/epoch - 82ms/step\n",
      "Epoch 52/128\n",
      "1/1 - 0s - loss: 0.8629 - accuracy: 0.3143 - 108ms/epoch - 108ms/step\n",
      "Epoch 53/128\n",
      "1/1 - 0s - loss: 0.8591 - accuracy: 0.2857 - 110ms/epoch - 110ms/step\n",
      "Epoch 54/128\n",
      "1/1 - 0s - loss: 0.8568 - accuracy: 0.3000 - 60ms/epoch - 60ms/step\n",
      "Epoch 55/128\n",
      "1/1 - 0s - loss: 0.8530 - accuracy: 0.3143 - 62ms/epoch - 62ms/step\n",
      "Epoch 56/128\n",
      "1/1 - 0s - loss: 0.8488 - accuracy: 0.3000 - 61ms/epoch - 61ms/step\n",
      "Epoch 57/128\n",
      "1/1 - 0s - loss: 0.8512 - accuracy: 0.3143 - 71ms/epoch - 71ms/step\n",
      "Epoch 58/128\n",
      "1/1 - 0s - loss: 0.8438 - accuracy: 0.2857 - 118ms/epoch - 118ms/step\n",
      "Epoch 59/128\n",
      "1/1 - 0s - loss: 0.8399 - accuracy: 0.3000 - 65ms/epoch - 65ms/step\n",
      "Epoch 60/128\n",
      "1/1 - 0s - loss: 0.8391 - accuracy: 0.3143 - 76ms/epoch - 76ms/step\n",
      "Epoch 61/128\n",
      "1/1 - 0s - loss: 0.8361 - accuracy: 0.3143 - 79ms/epoch - 79ms/step\n",
      "Epoch 62/128\n",
      "1/1 - 0s - loss: 0.8283 - accuracy: 0.3429 - 74ms/epoch - 74ms/step\n",
      "Epoch 63/128\n",
      "1/1 - 0s - loss: 0.8284 - accuracy: 0.3000 - 111ms/epoch - 111ms/step\n",
      "Epoch 64/128\n",
      "1/1 - 0s - loss: 0.8244 - accuracy: 0.3286 - 85ms/epoch - 85ms/step\n",
      "Epoch 65/128\n",
      "1/1 - 0s - loss: 0.8262 - accuracy: 0.3000 - 62ms/epoch - 62ms/step\n",
      "Epoch 66/128\n",
      "1/1 - 0s - loss: 0.8188 - accuracy: 0.3000 - 99ms/epoch - 99ms/step\n",
      "Epoch 67/128\n",
      "1/1 - 0s - loss: 0.8188 - accuracy: 0.3143 - 61ms/epoch - 61ms/step\n",
      "Epoch 68/128\n",
      "1/1 - 0s - loss: 0.8135 - accuracy: 0.3000 - 66ms/epoch - 66ms/step\n",
      "Epoch 69/128\n",
      "1/1 - 0s - loss: 0.8097 - accuracy: 0.2857 - 61ms/epoch - 61ms/step\n",
      "Epoch 70/128\n",
      "1/1 - 0s - loss: 0.8094 - accuracy: 0.3000 - 59ms/epoch - 59ms/step\n",
      "Epoch 71/128\n",
      "1/1 - 0s - loss: 0.8024 - accuracy: 0.3000 - 109ms/epoch - 109ms/step\n",
      "Epoch 72/128\n",
      "1/1 - 0s - loss: 0.8018 - accuracy: 0.3286 - 100ms/epoch - 100ms/step\n",
      "Epoch 73/128\n",
      "1/1 - 0s - loss: 0.7945 - accuracy: 0.3714 - 83ms/epoch - 83ms/step\n",
      "Epoch 74/128\n",
      "1/1 - 0s - loss: 0.7964 - accuracy: 0.3143 - 89ms/epoch - 89ms/step\n",
      "Epoch 75/128\n",
      "1/1 - 0s - loss: 0.7998 - accuracy: 0.3000 - 88ms/epoch - 88ms/step\n",
      "Epoch 76/128\n",
      "1/1 - 0s - loss: 0.7897 - accuracy: 0.3000 - 82ms/epoch - 82ms/step\n",
      "Epoch 77/128\n",
      "1/1 - 0s - loss: 0.7892 - accuracy: 0.3000 - 142ms/epoch - 142ms/step\n",
      "Epoch 78/128\n",
      "1/1 - 0s - loss: 0.7828 - accuracy: 0.3000 - 62ms/epoch - 62ms/step\n",
      "Epoch 79/128\n",
      "1/1 - 0s - loss: 0.7796 - accuracy: 0.3286 - 146ms/epoch - 146ms/step\n",
      "Epoch 80/128\n",
      "1/1 - 0s - loss: 0.7824 - accuracy: 0.3143 - 106ms/epoch - 106ms/step\n",
      "Epoch 81/128\n",
      "1/1 - 0s - loss: 0.7742 - accuracy: 0.3286 - 62ms/epoch - 62ms/step\n",
      "Epoch 82/128\n",
      "1/1 - 0s - loss: 0.7737 - accuracy: 0.3143 - 112ms/epoch - 112ms/step\n",
      "Epoch 83/128\n",
      "1/1 - 0s - loss: 0.7701 - accuracy: 0.3429 - 111ms/epoch - 111ms/step\n",
      "Epoch 84/128\n",
      "1/1 - 0s - loss: 0.7669 - accuracy: 0.3286 - 100ms/epoch - 100ms/step\n",
      "Epoch 85/128\n",
      "1/1 - 0s - loss: 0.7680 - accuracy: 0.3286 - 86ms/epoch - 86ms/step\n",
      "Epoch 86/128\n",
      "1/1 - 0s - loss: 0.7601 - accuracy: 0.3143 - 105ms/epoch - 105ms/step\n",
      "Epoch 87/128\n",
      "1/1 - 0s - loss: 0.7580 - accuracy: 0.3000 - 114ms/epoch - 114ms/step\n",
      "Epoch 88/128\n",
      "1/1 - 0s - loss: 0.7530 - accuracy: 0.3000 - 87ms/epoch - 87ms/step\n",
      "Epoch 89/128\n",
      "1/1 - 0s - loss: 0.7553 - accuracy: 0.3286 - 60ms/epoch - 60ms/step\n",
      "Epoch 90/128\n",
      "1/1 - 0s - loss: 0.7463 - accuracy: 0.3000 - 120ms/epoch - 120ms/step\n",
      "Epoch 91/128\n",
      "1/1 - 0s - loss: 0.7482 - accuracy: 0.3429 - 88ms/epoch - 88ms/step\n",
      "Epoch 92/128\n",
      "1/1 - 0s - loss: 0.7450 - accuracy: 0.3000 - 66ms/epoch - 66ms/step\n",
      "Epoch 93/128\n",
      "1/1 - 0s - loss: 0.7360 - accuracy: 0.3286 - 84ms/epoch - 84ms/step\n",
      "Epoch 94/128\n",
      "1/1 - 0s - loss: 0.7398 - accuracy: 0.3143 - 76ms/epoch - 76ms/step\n",
      "Epoch 95/128\n",
      "1/1 - 0s - loss: 0.7369 - accuracy: 0.3429 - 108ms/epoch - 108ms/step\n",
      "Epoch 96/128\n",
      "1/1 - 0s - loss: 0.7293 - accuracy: 0.3571 - 88ms/epoch - 88ms/step\n",
      "Epoch 97/128\n",
      "1/1 - 0s - loss: 0.7283 - accuracy: 0.3143 - 83ms/epoch - 83ms/step\n",
      "Epoch 98/128\n",
      "1/1 - 0s - loss: 0.7290 - accuracy: 0.3571 - 78ms/epoch - 78ms/step\n",
      "Epoch 99/128\n",
      "1/1 - 0s - loss: 0.7195 - accuracy: 0.3571 - 73ms/epoch - 73ms/step\n",
      "Epoch 100/128\n",
      "1/1 - 0s - loss: 0.7246 - accuracy: 0.2857 - 83ms/epoch - 83ms/step\n",
      "Epoch 101/128\n",
      "1/1 - 0s - loss: 0.7222 - accuracy: 0.3000 - 72ms/epoch - 72ms/step\n",
      "Epoch 102/128\n",
      "1/1 - 0s - loss: 0.7156 - accuracy: 0.3571 - 116ms/epoch - 116ms/step\n",
      "Epoch 103/128\n",
      "1/1 - 0s - loss: 0.7121 - accuracy: 0.3429 - 58ms/epoch - 58ms/step\n",
      "Epoch 104/128\n",
      "1/1 - 0s - loss: 0.7108 - accuracy: 0.3000 - 59ms/epoch - 59ms/step\n",
      "Epoch 105/128\n",
      "1/1 - 0s - loss: 0.7118 - accuracy: 0.3571 - 107ms/epoch - 107ms/step\n",
      "Epoch 106/128\n",
      "1/1 - 0s - loss: 0.7081 - accuracy: 0.3571 - 94ms/epoch - 94ms/step\n",
      "Epoch 107/128\n",
      "1/1 - 0s - loss: 0.6995 - accuracy: 0.3714 - 63ms/epoch - 63ms/step\n",
      "Epoch 108/128\n",
      "1/1 - 0s - loss: 0.7028 - accuracy: 0.3571 - 93ms/epoch - 93ms/step\n",
      "Epoch 109/128\n",
      "1/1 - 0s - loss: 0.6909 - accuracy: 0.3571 - 79ms/epoch - 79ms/step\n",
      "Epoch 110/128\n",
      "1/1 - 0s - loss: 0.6918 - accuracy: 0.3714 - 104ms/epoch - 104ms/step\n",
      "Epoch 111/128\n",
      "1/1 - 0s - loss: 0.6861 - accuracy: 0.3429 - 68ms/epoch - 68ms/step\n",
      "Epoch 112/128\n",
      "1/1 - 0s - loss: 0.6880 - accuracy: 0.3571 - 112ms/epoch - 112ms/step\n",
      "Epoch 113/128\n",
      "1/1 - 0s - loss: 0.6854 - accuracy: 0.3857 - 88ms/epoch - 88ms/step\n",
      "Epoch 114/128\n",
      "1/1 - 0s - loss: 0.6811 - accuracy: 0.3714 - 117ms/epoch - 117ms/step\n",
      "Epoch 115/128\n",
      "1/1 - 0s - loss: 0.6740 - accuracy: 0.4143 - 108ms/epoch - 108ms/step\n",
      "Epoch 116/128\n",
      "1/1 - 0s - loss: 0.6726 - accuracy: 0.3857 - 59ms/epoch - 59ms/step\n",
      "Epoch 117/128\n",
      "1/1 - 0s - loss: 0.6717 - accuracy: 0.3857 - 110ms/epoch - 110ms/step\n",
      "Epoch 118/128\n",
      "1/1 - 0s - loss: 0.6665 - accuracy: 0.3857 - 59ms/epoch - 59ms/step\n",
      "Epoch 119/128\n",
      "1/1 - 0s - loss: 0.6590 - accuracy: 0.3714 - 84ms/epoch - 84ms/step\n",
      "Epoch 120/128\n",
      "1/1 - 0s - loss: 0.6511 - accuracy: 0.4000 - 110ms/epoch - 110ms/step\n",
      "Epoch 121/128\n",
      "1/1 - 0s - loss: 0.6540 - accuracy: 0.4143 - 58ms/epoch - 58ms/step\n",
      "Epoch 122/128\n",
      "1/1 - 0s - loss: 0.6515 - accuracy: 0.4000 - 128ms/epoch - 128ms/step\n",
      "Epoch 123/128\n",
      "1/1 - 0s - loss: 0.6550 - accuracy: 0.4286 - 62ms/epoch - 62ms/step\n",
      "Epoch 124/128\n",
      "1/1 - 0s - loss: 0.6458 - accuracy: 0.3429 - 69ms/epoch - 69ms/step\n",
      "Epoch 125/128\n",
      "1/1 - 0s - loss: 0.6426 - accuracy: 0.3857 - 108ms/epoch - 108ms/step\n",
      "Epoch 126/128\n",
      "1/1 - 0s - loss: 0.6367 - accuracy: 0.3714 - 108ms/epoch - 108ms/step\n",
      "Epoch 127/128\n",
      "1/1 - 0s - loss: 0.6385 - accuracy: 0.4000 - 99ms/epoch - 99ms/step\n",
      "Epoch 128/128\n",
      "1/1 - 0s - loss: 0.6240 - accuracy: 0.4286 - 86ms/epoch - 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2db89ac10>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = Sequential()\n",
    "best_model.add(Bidirectional(LSTM(best_params['lstm_unit'], input_shape=(best_params['window_length'], number_of_features), return_sequences=True)))\n",
    "best_model.add(Dropout(best_params['dropout_rate']))\n",
    "best_model.add(Bidirectional(LSTM(best_params['lstm_unit'], input_shape=(best_params['window_length'], number_of_features), return_sequences=True)))\n",
    "best_model.add(Dropout(best_params['dropout_rate']))\n",
    "best_model.add(Bidirectional(LSTM(best_params['lstm_unit'], input_shape=(best_params['window_length'], number_of_features), return_sequences=True)))\n",
    "best_model.add(Bidirectional(LSTM(best_params['lstm_unit'], input_shape=(best_params['window_length'], number_of_features), return_sequences=False)))\n",
    "best_model.add(Dense(59))\n",
    "best_model.add(Dense(number_of_features))\n",
    "    \n",
    "# Compile the model (replace optimizer and loss with your specific settings)\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss ='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "best_model.fit(x=X, y=y, batch_size=best_params['batch_size'], epochs=best_params['epoch'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ed3cb951-122c-4627-80be-7cff0be551a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A  B  C  D  E  F  A1  A2\n",
       "69  5  0  8  4  3  9   2   9\n",
       "70  0  2  3  3  1  4   2   8\n",
       "71  0  1  8  2  3  5   0   9\n",
       "72  2  9  4  7  8  2   4   7\n",
       "73  3  3  5  3  9  6   2   9\n",
       "74  1  0  4  6  1  6   0   7\n",
       "75  0  6  5  9  0  4   3   7\n",
       "76  3  5  5  0  0  5   2   7"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = data.tail(8)\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1f67405d-7ece-4c29-b746-272cce6d283d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/q9g0yct970jfj27d2wmjx4_80000gn/T/ipykernel_3110/648231250.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  to_predict.drop([to_predict.index[-1]],axis=0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A  B  C  D  E  F  A1  A2\n",
       "69  5  0  8  4  3  9   2   9\n",
       "70  0  2  3  3  1  4   2   8\n",
       "71  0  1  8  2  3  5   0   9\n",
       "72  2  9  4  7  8  2   4   7\n",
       "73  3  3  5  3  9  6   2   9\n",
       "74  1  0  4  6  1  6   0   7\n",
       "75  0  6  5  9  0  4   3   7"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict.drop([to_predict.index[-1]],axis=0, inplace=True)\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e85afe70-e390-4d53-ab19-3221d7b42f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A  B  C  D  E  F  A1  A2\n",
       "76  3  5  5  0  0  5   2   7"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = data.tail(1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9b211a5d-6fd0-49c2-bfeb-f426b9775c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 8, 4, 3, 9, 2, 9],\n",
       "       [0, 2, 3, 3, 1, 4, 2, 8],\n",
       "       [0, 1, 8, 2, 3, 5, 0, 9],\n",
       "       [2, 9, 4, 7, 8, 2, 4, 7],\n",
       "       [3, 3, 5, 3, 9, 6, 2, 9],\n",
       "       [1, 0, 4, 6, 1, 6, 0, 7],\n",
       "       [0, 6, 5, 9, 0, 4, 3, 7]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = np.array(to_predict)\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "702d1983-c980-4319-9adc-897a74815397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87224894, -1.52919193,  1.53137441, -0.15254193, -0.51176822,\n",
       "         1.5127656 ,  0.02695384,  1.78758429],\n",
       "       [-1.05772716, -0.86954051, -0.40803068, -0.54406623, -1.20922226,\n",
       "        -0.34205846,  0.02695384,  0.97312281],\n",
       "       [-1.05772716, -1.19936622,  1.53137441, -0.93559053, -0.51176822,\n",
       "         0.02890635, -1.35667665,  1.78758429],\n",
       "       [-0.28573672,  1.43923946, -0.02014966,  1.02203096,  1.23186688,\n",
       "        -1.08398809,  1.41058433,  0.15866133],\n",
       "       [ 0.1002585 , -0.5397148 ,  0.36773136, -0.54406623,  1.5805939 ,\n",
       "         0.39987116,  0.02695384,  1.78758429],\n",
       "       [-0.67173194, -1.52919193, -0.02014966,  0.63050666, -1.20922226,\n",
       "         0.39987116, -1.35667665,  0.15866133],\n",
       "       [-1.05772716,  0.44976233,  0.36773136,  1.80507956, -1.55794928,\n",
       "        -0.34205846,  0.71876908,  0.15866133]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_to_predict = scaler.transform(to_predict)\n",
    "scaled_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e511f42e-22ec-4599-884f-30686070b128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 977ms/step\n",
      "The predicted numbers in the last lottery game are: [2 5 4 6 7 6 2 7]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(np.array([scaled_to_predict]))\n",
    "abs_y_pred = np.abs(y_pred)\n",
    "print(\"The predicted numbers in the last lottery game are:\", scaler.inverse_transform(abs_y_pred).astype(int)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0881dbb4-8cae-4417-8541-e13f70163145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual numbers in the last lottery game were: [3 5 5 0 0 5 2 7]\n"
     ]
    }
   ],
   "source": [
    "prediction = np.array(prediction)\n",
    "print(\"The actual numbers in the last lottery game were:\", prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de132b-4a64-4f07-bada-e319e8ffa755",
   "metadata": {},
   "source": [
    "2 number sout of 7 numbers, not bad at all! Especially considering the fact that there was not supposed to be a model within the data, that is, the numbers had to be 100% random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c24049d9-f05b-462e-9129-ee610b973a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d3113270-2552-4e2c-8b7b-6c00047d8a80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A  B  C  D  E  F  A1  A2\n",
       "70  0  2  3  3  1  4   2   8\n",
       "71  0  1  8  2  3  5   0   9\n",
       "72  2  9  4  7  8  2   4   7\n",
       "73  3  3  5  3  9  6   2   9\n",
       "74  1  0  4  6  1  6   0   7\n",
       "75  0  6  5  9  0  4   3   7\n",
       "76  3  5  5  0  0  5   2   7"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = data.tail(7)\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3963f525-0130-4f1c-b3e2-bddc6b2a9495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 3, 1, 4, 2, 8],\n",
       "       [0, 1, 8, 2, 3, 5, 0, 9],\n",
       "       [2, 9, 4, 7, 8, 2, 4, 7],\n",
       "       [3, 3, 5, 3, 9, 6, 2, 9],\n",
       "       [1, 0, 4, 6, 1, 6, 0, 7],\n",
       "       [0, 6, 5, 9, 0, 4, 3, 7],\n",
       "       [3, 5, 5, 0, 0, 5, 2, 7]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = np.array(to_predict)\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6bd3f037-218c-4489-943f-60ede27b77c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05772716, -0.86954051, -0.40803068, -0.54406623, -1.20922226,\n",
       "        -0.34205846,  0.02695384,  0.97312281],\n",
       "       [-1.05772716, -1.19936622,  1.53137441, -0.93559053, -0.51176822,\n",
       "         0.02890635, -1.35667665,  1.78758429],\n",
       "       [-0.28573672,  1.43923946, -0.02014966,  1.02203096,  1.23186688,\n",
       "        -1.08398809,  1.41058433,  0.15866133],\n",
       "       [ 0.1002585 , -0.5397148 ,  0.36773136, -0.54406623,  1.5805939 ,\n",
       "         0.39987116,  0.02695384,  1.78758429],\n",
       "       [-0.67173194, -1.52919193, -0.02014966,  0.63050666, -1.20922226,\n",
       "         0.39987116, -1.35667665,  0.15866133],\n",
       "       [-1.05772716,  0.44976233,  0.36773136,  1.80507956, -1.55794928,\n",
       "        -0.34205846,  0.71876908,  0.15866133],\n",
       "       [ 0.1002585 ,  0.11993662,  0.36773136, -1.71863913, -1.55794928,\n",
       "         0.02890635,  0.02695384,  0.15866133]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_to_predict = scaler.transform(to_predict)\n",
    "scaled_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ce066c33-bf18-45ff-8a72-a16272adc51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "The predicted numbers in the last lottery game are: [4 4 4 2 3 6 2 7]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(np.array([scaled_to_predict]))\n",
    "#abs_y_pred = np.abs(y_pred)\n",
    "print(\"The predicted numbers in the last lottery game are:\", scaler.inverse_transform(y_pred).astype(int)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
